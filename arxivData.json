[
    {
        "title": "Synthesizing Deep Neural Network Architectures using Biological Synaptic\n  Strength Distributions",
        "authors": [
            "A. H. Karimi",
            "M. J. Shafiee",
            "A. Ghodsi",
            "A. Wong"
        ],
        "summary": "In this work, we perform an exploratory study on synthesizing deep neural\nnetworks using biological synaptic strength distributions, and the potential\ninfluence of different distributions on modelling performance particularly for\nthe scenario associated with small data sets. Surprisingly, a CNN with\nconvolutional layer synaptic strengths drawn from biologically-inspired\ndistributions such as log-normal or correlated center-surround distributions\nperformed relatively well suggesting a possibility for designing deep neural\nnetwork architectures that do not require many data samples to learn, and can\nsidestep current training procedures while maintaining or boosting modelling\nperformance.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "What Happened to My Dog in That Network: Unraveling Top-down Generators\n  in Convolutional Neural Networks",
        "authors": [
            "Patrick W. Gallagher",
            "Shuai Tang",
            "Zhuowen Tu"
        ],
        "summary": "Top-down information plays a central role in human perception, but plays\nrelatively little role in many current state-of-the-art deep networks, such as\nConvolutional Neural Networks (CNNs). This work seeks to explore a path by\nwhich top-down information can have a direct impact within current deep\nnetworks. We explore this path by learning and using \"generators\" corresponding\nto the network internal effects of three types of transformation (each a\nrestriction of a general affine transformation): rotation, scaling, and\ntranslation. We demonstrate how these learned generators can be used to\ntransfer top-down information to novel settings, as mediated by the \"feature\nflows\" that the transformations (and the associated generators) correspond to\ninside the network. Specifically, we explore three aspects: 1) using generators\nas part of a method for synthesizing transformed images --- given a previously\nunseen image, produce versions of that image corresponding to one or more\nspecified transformations, 2) \"zero-shot learning\" --- when provided with a\nfeature flow corresponding to the effect of a transformation of unknown amount,\nleverage learned generators as part of a method by which to perform an accurate\ncategorization of the amount of transformation, even for amounts never observed\nduring training, and 3) (inside-CNN) \"data augmentation\" --- improve the\nclassification performance of an existing network by using the learned\ngenerators to directly provide additional training \"inside the CNN\".",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "A Multi-World Approach to Question Answering about Real-World Scenes\n  based on Uncertain Input",
        "authors": [
            "Mateusz Malinowski",
            "Mario Fritz"
        ],
        "summary": "We propose a method for automatically answering questions about images by\nbringing together recent advances from natural language processing and computer\nvision. We combine discrete reasoning with uncertain predictions by a\nmulti-world approach that represents uncertainty about the perceived world in a\nbayesian framework. Our approach can handle human questions of high complexity\nabout realistic scenes and replies with range of answer like counts, object\nclasses, instances and lists of them. The system is directly trained from\nquestion-answer pairs. We establish a first benchmark for this task that can be\nseen as a modern attempt at a visual turing test.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Hard to Cheat: A Turing Test based on Answering Questions about Images",
        "authors": [
            "Mateusz Malinowski",
            "Mario Fritz"
        ],
        "summary": "Progress in language and image understanding by machines has sparkled the\ninterest of the research community in more open-ended, holistic tasks, and\nrefueled an old AI dream of building intelligent machines. We discuss a few\nprominent challenges that characterize such holistic tasks and argue for\n\"question answering about images\" as a particular appealing instance of such a\nholistic task. In particular, we point out that it is a version of a Turing\nTest that is likely to be more robust to over-interpretations and contrast it\nwith tasks like grounding and generation of descriptions. Finally, we discuss\ntools to measure progress in this field.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "An agent-driven semantical identifier using radial basis neural networks\n  and reinforcement learning",
        "authors": [
            "Christian Napoli",
            "Giuseppe Pappalardo",
            "Emiliano Tramontana"
        ],
        "summary": "Due to the huge availability of documents in digital form, and the deception\npossibility raise bound to the essence of digital documents and the way they\nare spread, the authorship attribution problem has constantly increased its\nrelevance. Nowadays, authorship attribution,for both information retrieval and\nanalysis, has gained great importance in the context of security, trust and\ncopyright preservation. This work proposes an innovative multi-agent driven\nmachine learning technique that has been developed for authorship attribution.\nBy means of a preprocessing for word-grouping and time-period related analysis\nof the common lexicon, we determine a bias reference level for the recurrence\nfrequency of the words within analysed texts, and then train a Radial Basis\nNeural Networks (RBPNN)-based classifier to identify the correct author. The\nmain advantage of the proposed approach lies in the generality of the semantic\nanalysis, which can be applied to different contexts and lexical domains,\nwithout requiring any modification. Moreover, the proposed system is able to\nincorporate an external input, meant to tune the classifier, and then\nself-adjust by means of continuous learning reinforcement.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "Towards a Visual Turing Challenge",
        "authors": [
            "Mateusz Malinowski",
            "Mario Fritz"
        ],
        "summary": "As language and visual understanding by machines progresses rapidly, we are\nobserving an increasing interest in holistic architectures that tightly\ninterlink both modalities in a joint learning and inference process. This trend\nhas allowed the community to progress towards more challenging and open tasks\nand refueled the hope at achieving the old AI dream of building machines that\ncould pass a turing test in open domains. In order to steadily make progress\ntowards this goal, we realize that quantifying performance becomes increasingly\ndifficult. Therefore we ask how we can precisely define such challenges and how\nwe can evaluate different algorithms on this open tasks? In this paper, we\nsummarize and discuss such challenges as well as try to give answers where\nappropriate options are available in the literature. We exemplify some of the\nsolutions on a recently presented dataset of question-answering task based on\nreal-world indoor images that establishes a visual turing challenge. Finally,\nwe argue despite the success of unique ground-truth annotation, we likely have\nto step away from carefully curated dataset and rather rely on 'social\nconsensus' as the main driving force to create suitable benchmarks. Providing\ncoverage in this inherently ambiguous output space is an emerging challenge\nthat we face in order to make quantifiable progress in this area.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Learning to Transduce with Unbounded Memory",
        "authors": [
            "Edward Grefenstette",
            "Karl Moritz Hermann",
            "Mustafa Suleyman",
            "Phil Blunsom"
        ],
        "summary": "Recently, strong results have been demonstrated by Deep Recurrent Neural\nNetworks on natural language transduction problems. In this paper we explore\nthe representational power of these models using synthetic grammars designed to\nexhibit phenomena similar to those found in real transduction problems such as\nmachine translation. These experiments lead us to propose new memory-based\nrecurrent networks that implement continuously differentiable analogues of\ntraditional data structures such as Stacks, Queues, and DeQues. We show that\nthese architectures exhibit superior generalisation performance to Deep RNNs\nand are often able to learn the underlying generating algorithms in our\ntransduction experiments.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "Combining Representation Learning with Logic for Language Processing",
        "authors": [
            "Tim Rockt\u00e4schel"
        ],
        "summary": "The current state-of-the-art in many natural language processing and\nautomated knowledge base completion tasks is held by representation learning\nmethods which learn distributed vector representations of symbols via\ngradient-based optimization. They require little or no hand-crafted features,\nthus avoiding the need for most preprocessing steps and task-specific\nassumptions. However, in many cases representation learning requires a large\namount of annotated training data to generalize well to unseen data. Such\nlabeled training data is provided by human annotators who often use formal\nlogic as the language for specifying annotations. This thesis investigates\ndifferent combinations of representation learning methods with logic for\nreducing the need for annotated training data, and for improving\ngeneralization.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "Homogeneous Spiking Neuromorphic System for Real-World Pattern\n  Recognition",
        "authors": [
            "Xinyu Wu",
            "Vishal Saxena",
            "Kehan Zhu"
        ],
        "summary": "A neuromorphic chip that combines CMOS analog spiking neurons and memristive\nsynapses offers a promising solution to brain-inspired computing, as it can\nprovide massive neural network parallelism and density. Previous hybrid analog\nCMOS-memristor approaches required extensive CMOS circuitry for training, and\nthus eliminated most of the density advantages gained by the adoption of\nmemristor synapses. Further, they used different waveforms for pre and\npost-synaptic spikes that added undesirable circuit overhead. Here we describe\na hardware architecture that can feature a large number of memristor synapses\nto learn real-world patterns. We present a versatile CMOS neuron that combines\nintegrate-and-fire behavior, drives passive memristors and implements\ncompetitive learning in a compact circuit module, and enables in-situ\nplasticity in the memristor synapses. We demonstrate handwritten-digits\nrecognition using the proposed architecture using transistor-level circuit\nsimulations. As the described neuromorphic architecture is homogeneous, it\nrealizes a fundamental building block for large-scale energy-efficient\nbrain-inspired silicon chips that could lead to next-generation cognitive\ncomputing.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "Learning to Execute",
        "authors": [
            "Wojciech Zaremba",
            "Ilya Sutskever"
        ],
        "summary": "Recurrent Neural Networks (RNNs) with Long Short-Term Memory units (LSTM) are\nwidely used because they are expressive and are easy to train. Our interest\nlies in empirically evaluating the expressiveness and the learnability of LSTMs\nin the sequence-to-sequence regime by training them to evaluate short computer\nprograms, a domain that has traditionally been seen as too complex for neural\nnetworks. We consider a simple class of programs that can be evaluated with a\nsingle left-to-right pass using constant memory. Our main result is that LSTMs\ncan learn to map the character-level representations of such programs to their\ncorrect outputs. Notably, it was necessary to use curriculum learning, and\nwhile conventional curriculum learning proved ineffective, we developed a new\nvariant of curriculum learning that improved our networks' performance in all\nexperimental conditions. The improved curriculum had a dramatic impact on an\naddition problem, making it possible to train an LSTM to add two 9-digit\nnumbers with 99% accuracy.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "Autonomous development and learning in artificial intelligence and\n  robotics: Scaling up deep learning to human--like learning",
        "authors": [
            "Pierre-Yves Oudeyer"
        ],
        "summary": "Autonomous lifelong development and learning is a fundamental capability of\nhumans, differentiating them from current deep learning systems. However, other\nbranches of artificial intelligence have designed crucial ingredients towards\nautonomous learning: curiosity and intrinsic motivation, social learning and\nnatural interaction with peers, and embodiment. These mechanisms guide\nexploration and autonomous choice of goals, and integrating them with deep\nlearning opens stimulating perspectives. Deep learning (DL) approaches made\ngreat advances in artificial intelligence, but are still far away from human\nlearning. As argued convincingly by Lake et al., differences include human\ncapabilities to learn causal models of the world from very little data,\nleveraging compositional representations and priors like intuitive physics and\npsychology. However, there are other fundamental differences between current DL\nsystems and human learning, as well as technical ingredients to fill this gap,\nthat are either superficially, or not adequately, discussed by Lake et al.\nThese fundamental mechanisms relate to autonomous development and learning.\nThey are bound to play a central role in artificial intelligence in the future.\nCurrent DL systems require engineers to manually specify a task-specific\nobjective function for every new task, and learn through off-line processing of\nlarge training databases. On the contrary, humans learn autonomously open-ended\nrepertoires of skills, deciding for themselves which goals to pursue or value,\nand which skills to explore, driven by intrinsic motivation/curiosity and\nsocial learning through natural interaction with peers. Such learning processes\nare incremental, online, and progressive. Human child development involves a\nprogressive increase of complexity in a curriculum of learning where skills are\nexplored, acquired, and built on each other, through particular ordering and\ntiming. Finally, human learning happens in the physical world, and through\nbodily and physical experimentation, under severe constraints on energy, time,\nand computational resources. In the two last decades, the field of\nDevelopmental and Cognitive Robotics (Cangelosi and Schlesinger, 2015, Asada et\nal., 2009), in strong interaction with developmental psychology and\nneuroscience, has achieved significant advances in computational",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Fitness inheritance in the Bayesian optimization algorithm",
        "authors": [
            "Martin Pelikan",
            "Kumara Sastry"
        ],
        "summary": "This paper describes how fitness inheritance can be used to estimate fitness\nfor a proportion of newly sampled candidate solutions in the Bayesian\noptimization algorithm (BOA). The goal of estimating fitness for some candidate\nsolutions is to reduce the number of fitness evaluations for problems where\nfitness evaluation is expensive. Bayesian networks used in BOA to model\npromising solutions and generate the new ones are extended to allow not only\nfor modeling and sampling candidate solutions, but also for estimating their\nfitness. The results indicate that fitness inheritance is a promising concept\nin BOA, because population-sizing requirements for building appropriate models\nof promising solutions lead to good fitness estimates even if only a small\nproportion of candidate solutions is evaluated using the actual fitness\nfunction. This can lead to a reduction of the number of actual fitness\nevaluations by a factor of 30 or more.",
        "year": 2004,
        "label": "cs.NE"
    },
    {
        "title": "Transfer Learning, Soft Distance-Based Bias, and the Hierarchical BOA",
        "authors": [
            "Martin Pelikan",
            "Mark W. Hauschild",
            "Pier Luca Lanzi"
        ],
        "summary": "An automated technique has recently been proposed to transfer learning in the\nhierarchical Bayesian optimization algorithm (hBOA) based on distance-based\nstatistics. The technique enables practitioners to improve hBOA efficiency by\ncollecting statistics from probabilistic models obtained in previous hBOA runs\nand using the obtained statistics to bias future hBOA runs on similar problems.\nThe purpose of this paper is threefold: (1) test the technique on several\nclasses of NP-complete problems, including MAXSAT, spin glasses and minimum\nvertex cover; (2) demonstrate that the technique is effective even when\nprevious runs were done on problems of different size; (3) provide empirical\nevidence that combining transfer learning with other efficiency enhancement\ntechniques can often yield nearly multiplicative speedups.",
        "year": 2012,
        "label": "cs.NE"
    },
    {
        "title": "Programming with a Differentiable Forth Interpreter",
        "authors": [
            "Matko Bo\u0161njak",
            "Tim Rockt\u00e4schel",
            "Jason Naradowsky",
            "Sebastian Riedel"
        ],
        "summary": "Given that in practice training data is scarce for all but a small set of\nproblems, a core question is how to incorporate prior knowledge into a model.\nIn this paper, we consider the case of prior procedural knowledge for neural\nnetworks, such as knowing how a program should traverse a sequence, but not\nwhat local actions should be performed at each step. To this end, we present an\nend-to-end differentiable interpreter for the programming language Forth which\nenables programmers to write program sketches with slots that can be filled\nwith behaviour trained from program input-output data. We can optimise this\nbehaviour directly through gradient descent techniques on user-specified\nobjectives, and also integrate the program into any larger neural computation\ngraph. We show empirically that our interpreter is able to effectively leverage\ndifferent levels of prior program structure and learn complex behaviours such\nas sequence sorting and addition. When connected to outputs of an LSTM and\ntrained jointly, our interpreter achieves state-of-the-art accuracy for\nend-to-end reasoning about quantities expressed in natural language stories.",
        "year": 2016,
        "label": "cs.NE"
    },
    {
        "title": "Learning to learn with backpropagation of Hebbian plasticity",
        "authors": [
            "Thomas Miconi"
        ],
        "summary": "Hebbian plasticity is a powerful principle that allows biological brains to\nlearn from their lifetime experience. By contrast, artificial neural networks\ntrained with backpropagation generally have fixed connection weights that do\nnot change once training is complete. While recent methods can endow neural\nnetworks with long-term memories, Hebbian plasticity is currently not amenable\nto gradient descent. Here we derive analytical expressions for activity\ngradients in neural networks with Hebbian plastic connections. Using these\nexpressions, we can use backpropagation to train not just the baseline weights\nof the connections, but also their plasticity. As a result, the networks \"learn\nhow to learn\" in order to solve the problem at hand: the trained networks\nautomatically perform fast learning of unpredictable environmental features\nduring their lifetime, expanding the range of solvable problems. We test the\nalgorithm on various on-line learning tasks, including pattern completion,\none-shot learning, and reversal learning. The algorithm successfully learns how\nto learn the relevant associations from one-shot instruction, and fine-tunes\nthe temporal dynamics of plasticity to allow for continual learning in response\nto changing environmental parameters. We conclude that backpropagation of\nHebbian plasticity offers a powerful model for lifelong learning.",
        "year": 2016,
        "label": "cs.NE"
    },
    {
        "title": "End-to-End Differentiable Proving",
        "authors": [
            "Tim Rockt\u00e4schel",
            "Sebastian Riedel"
        ],
        "summary": "We introduce neural networks for end-to-end differentiable proving of queries\nto knowledge bases by operating on dense vector representations of symbols.\nThese neural networks are constructed recursively by taking inspiration from\nthe backward chaining algorithm as used in Prolog. Specifically, we replace\nsymbolic unification with a differentiable computation on vector\nrepresentations of symbols using a radial basis function kernel, thereby\ncombining symbolic reasoning with learning subsymbolic vector representations.\nBy using gradient descent, the resulting neural network can be trained to infer\nfacts from a given incomplete knowledge base. It learns to (i) place\nrepresentations of similar symbols in close proximity in a vector space, (ii)\nmake use of such similarities to prove queries, (iii) induce logical rules, and\n(iv) use provided and induced logical rules for multi-hop reasoning. We\ndemonstrate that this architecture outperforms ComplEx, a state-of-the-art\nneural link prediction model, on three out of four benchmark knowledge bases\nwhile at the same time inducing interpretable function-free first-order logic\nrules.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "Multimodal Content Analysis for Effective Advertisements on YouTube",
        "authors": [
            "Nikhita Vedula",
            "Wei Sun",
            "Hyunhwan Lee",
            "Harsh Gupta",
            "Mitsunori Ogihara",
            "Joseph Johnson",
            "Gang Ren",
            "Srinivasan Parthasarathy"
        ],
        "summary": "The rapid advances in e-commerce and Web 2.0 technologies have greatly\nincreased the impact of commercial advertisements on the general public. As a\nkey enabling technology, a multitude of recommender systems exists which\nanalyzes user features and browsing patterns to recommend appealing\nadvertisements to users. In this work, we seek to study the characteristics or\nattributes that characterize an effective advertisement and recommend a useful\nset of features to aid the designing and production processes of commercial\nadvertisements. We analyze the temporal patterns from multimedia content of\nadvertisement videos including auditory, visual and textual components, and\nstudy their individual roles and synergies in the success of an advertisement.\nThe objective of this work is then to measure the effectiveness of an\nadvertisement, and to recommend a useful set of features to advertisement\ndesigners to make it more successful and approachable to users. Our proposed\nframework employs the signal processing technique of cross modality feature\nlearning where data streams from different components are employed to train\nseparate neural network models and are then fused together to learn a shared\nrepresentation. Subsequently, a neural network model trained on this joint\nfeature embedding representation is utilized as a classifier to predict\nadvertisement effectiveness. We validate our approach using subjective ratings\nfrom a dedicated user study, the sentiment strength of online viewer comments,\nand a viewer opinion metric of the ratio of the Likes and Views received by\neach advertisement from an online platform.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Sparse Penalty in Deep Belief Networks: Using the Mixed Norm Constraint",
        "authors": [
            "Xanadu Halkias",
            "Sebastien Paris",
            "Herve Glotin"
        ],
        "summary": "Deep Belief Networks (DBN) have been successfully applied on popular machine\nlearning tasks. Specifically, when applied on hand-written digit recognition,\nDBNs have achieved approximate accuracy rates of 98.8%. In an effort to\noptimize the data representation achieved by the DBN and maximize their\ndescriptive power, recent advances have focused on inducing sparse constraints\nat each layer of the DBN. In this paper we present a theoretical approach for\nsparse constraints in the DBN using the mixed norm for both non-overlapping and\noverlapping groups. We explore how these constraints affect the classification\naccuracy for digit recognition in three different datasets (MNIST, USPS, RIMES)\nand provide initial estimations of their usefulness by altering different\nparameters such as the group size and overlap percentage.",
        "year": 2013,
        "label": "cs.NE"
    },
    {
        "title": "Online Deep Learning: Growing RBM on the fly",
        "authors": [
            "Savitha Ramasamy",
            "Kanagasabai Rajaraman",
            "Pavitra Krishnaswamy",
            "Vijay Chandrasekhar"
        ],
        "summary": "We propose a novel online learning algorithm for Restricted Boltzmann\nMachines (RBM), namely, the Online Generative Discriminative Restricted\nBoltzmann Machine (OGD-RBM), that provides the ability to build and adapt the\nnetwork architecture of RBM according to the statistics of streaming data. The\nOGD-RBM is trained in two phases: (1) an online generative phase for\nunsupervised feature representation at the hidden layer and (2) a\ndiscriminative phase for classification. The online generative training begins\nwith zero neurons in the hidden layer, adds and updates the neurons to adapt to\nstatistics of streaming data in a single pass unsupervised manner, resulting in\na feature representation best suited to the data. The discriminative phase is\nbased on stochastic gradient descent and associates the represented features to\nthe class labels. We demonstrate the OGD-RBM on a set of multi-category and\nbinary classification problems for data sets having varying degrees of\nclass-imbalance. We first apply the OGD-RBM algorithm on the multi-class MNIST\ndataset to characterize the network evolution. We demonstrate that the online\ngenerative phase converges to a stable, concise network architecture, wherein\nindividual neurons are inherently discriminative to the class labels despite\nunsupervised training. We then benchmark OGD-RBM performance to other machine\nlearning, neural network and ClassRBM techniques for credit scoring\napplications using 3 public non-stationary two-class credit datasets with\nvarying degrees of class-imbalance. We report that OGD-RBM improves accuracy by\n2.5-3% over batch learning techniques while requiring at least 24%-70% fewer\nneurons and fewer training samples. This online generative training approach\ncan be extended greedily to multiple layers for training Deep Belief Networks\nin non-stationary data mining applications without the need for a priori fixed\narchitectures.",
        "year": 2018,
        "label": "cs.NE"
    },
    {
        "title": "BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks",
        "authors": [
            "Surat Teerapittayanon",
            "Bradley McDanel",
            "H. T. Kung"
        ],
        "summary": "Deep neural networks are state of the art methods for many learning tasks due\nto their ability to extract increasingly better features at each network layer.\nHowever, the improved performance of additional layers in a deep network comes\nat the cost of added latency and energy usage in feedforward inference. As\nnetworks continue to get deeper and larger, these costs become more prohibitive\nfor real-time and energy-sensitive applications. To address this issue, we\npresent BranchyNet, a novel deep network architecture that is augmented with\nadditional side branch classifiers. The architecture allows prediction results\nfor a large portion of test samples to exit the network early via these\nbranches when samples can already be inferred with high confidence. BranchyNet\nexploits the observation that features learned at an early layer of a network\nmay often be sufficient for the classification of many data points. For more\ndifficult samples, which are expected less frequently, BranchyNet will use\nfurther or all network layers to provide the best likelihood of correct\nprediction. We study the BranchyNet architecture using several well-known\nnetworks (LeNet, AlexNet, ResNet) and datasets (MNIST, CIFAR10) and show that\nit can both improve accuracy and significantly reduce the inference time of the\nnetwork.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "Inferring Robot Task Plans from Human Team Meetings: A Generative\n  Modeling Approach with Logic-Based Prior",
        "authors": [
            "Been Kim",
            "Caleb M. Chacha",
            "Julie Shah"
        ],
        "summary": "We aim to reduce the burden of programming and deploying autonomous systems\nto work in concert with people in time-critical domains, such as military field\noperations and disaster response. Deployment plans for these operations are\nfrequently negotiated on-the-fly by teams of human planners. A human operator\nthen translates the agreed upon plan into machine instructions for the robots.\nWe present an algorithm that reduces this translation burden by inferring the\nfinal plan from a processed form of the human team's planning conversation. Our\napproach combines probabilistic generative modeling with logical plan\nvalidation used to compute a highly structured prior over possible plans. This\nhybrid approach enables us to overcome the challenge of performing inference\nover the large solution space with only a small amount of noisy data from the\nteam planning session. We validate the algorithm through human subject\nexperimentation and show we are able to infer a human team's final plan with\n83% accuracy on average. We also describe a robot demonstration in which two\npeople plan and execute a first-response collaborative task with a PR2 robot.\nTo the best of our knowledge, this is the first work that integrates a logical\nplanning technique within a generative model to perform plan inference.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Evaluation Evaluation a Monte Carlo study",
        "authors": [
            "David M. W. Powers"
        ],
        "summary": "Over the last decade there has been increasing concern about the biases\nembodied in traditional evaluation methods for Natural Language\nProcessing/Learning, particularly methods borrowed from Information Retrieval.\nWithout knowledge of the Bias and Prevalence of the contingency being tested,\nor equivalently the expectation due to chance, the simple conditional\nprobabilities Recall, Precision and Accuracy are not meaningful as evaluation\nmeasures, either individually or in combinations such as F-factor. The\nexistence of bias in NLP measures leads to the 'improvement' of systems by\nincreasing their bias, such as the practice of improving tagging and parsing\nscores by using most common value (e.g. water is always a Noun) rather than the\nattempting to discover the correct one. The measures Cohen Kappa and Powers\nInformedness are discussed as unbiased alternative to Recall and related to the\npsychologically significant measure DeltaP. In this paper we will analyze both\nbiased and unbiased measures theoretically, characterizing the precise\nrelationship between all these measures as well as evaluating the evaluation\nmeasures themselves empirically using a Monte Carlo simulation.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Open challenges in understanding development and evolution of speech\n  forms: The roles of embodied self-organization, motivation and active\n  exploration",
        "authors": [
            "Pierre-Yves Oudeyer"
        ],
        "summary": "This article discusses open scientific challenges for understanding\ndevelopment and evolution of speech forms, as a commentary to Moulin-Frier et\nal. (Moulin-Frier et al., 2015). Based on the analysis of mathematical models\nof the origins of speech forms, with a focus on their assumptions , we study\nthe fundamental question of how speech can be formed out of non--speech, at\nboth developmental and evolutionary scales. In particular, we emphasize the\nimportance of embodied self-organization , as well as the role of mechanisms of\nmotivation and active curiosity-driven exploration in speech formation. Finally\n, we discuss an evolutionary-developmental perspective of the origins of\nspeech.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Distance-based Confidence Score for Neural Network Classifiers",
        "authors": [
            "Amit Mandelbaum",
            "Daphna Weinshall"
        ],
        "summary": "The reliable measurement of confidence in classifiers' predictions is very\nimportant for many applications and is, therefore, an important part of\nclassifier design. Yet, although deep learning has received tremendous\nattention in recent years, not much progress has been made in quantifying the\nprediction confidence of neural network classifiers. Bayesian models offer a\nmathematically grounded framework to reason about model uncertainty, but\nusually come with prohibitive computational costs. In this paper we propose a\nsimple, scalable method to achieve a reliable confidence score, based on the\ndata embedding derived from the penultimate layer of the network. We\ninvestigate two ways to achieve desirable embeddings, by using either a\ndistance-based loss or Adversarial Training. We then test the benefits of our\nmethod when used for classification error prediction, weighting an ensemble of\nclassifiers, and novelty detection. In all tasks we show significant\nimprovement over traditional, commonly used confidence scores.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Balanced Excitation and Inhibition are Required for High-Capacity,\n  Noise-Robust Neuronal Selectivity",
        "authors": [
            "Ran Rubin",
            "L. F. Abbott",
            "Haim Sompolinsky"
        ],
        "summary": "Neurons and networks in the cerebral cortex must operate reliably despite\nmultiple sources of noise. To evaluate the impact of both input and output\nnoise, we determine the robustness of single-neuron stimulus selective\nresponses, as well as the robustness of attractor states of networks of neurons\nperforming memory tasks. We find that robustness to output noise requires\nsynaptic connections to be in a balanced regime in which excitation and\ninhibition are strong and largely cancel each other. We evaluate the conditions\nrequired for this regime to exist and determine the properties of networks\noperating within it. A plausible synaptic plasticity rule for learning that\nbalances weight configurations is presented. Our theory predicts an optimal\nratio of the number of excitatory and inhibitory synapses for maximizing the\nencoding capacity of balanced networks for a given statistics of afferent\nactivations. Previous work has shown that balanced networks amplify\nspatio-temporal variability and account for observed asynchronous irregular\nstates. Here we present a novel type of balanced network that amplifies small\nchanges in the impinging signals, and emerges automatically from learning to\nperform neuronal and network functions robustly.",
        "year": 2017,
        "label": "q-bio.NC"
    },
    {
        "title": "A Variational Approximation for Bayesian Networks with Discrete and\n  Continuous Latent Variables",
        "authors": [
            "Kevin Murphy"
        ],
        "summary": "We show how to use a variational approximation to the logistic function to\nperform approximate inference in Bayesian networks containing discrete nodes\nwith continuous parents. Essentially, we convert the logistic function to a\nGaussian, which facilitates exact inference, and then iteratively adjust the\nvariational parameters to improve the quality of the approximation. We\ndemonstrate experimentally that this approximation is faster and potentially\nmore accurate than sampling. We also introduce a simple new technique for\nhandling evidence, which allows us to handle arbitrary distributions on\nobserved nodes, as well as achieving a significant speedup in networks with\ndiscrete variables of large cardinality.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Reinforcement Learning in Rich-Observation MDPs using Spectral Methods",
        "authors": [
            "Kamyar Azizzadenesheli",
            "Alessandro Lazaric",
            "Animashree Anandkumar"
        ],
        "summary": "Designing effective exploration-exploitation algorithms in Markov decision\nprocesses (MDPs) with large state-action spaces is the main challenge in\nreinforcement learning (RL). In fact, the learning performance degrades with\nthe number of states and actions in the MDP. However, MDPs often exhibit a\nlow-dimensional latent structure in practice, where a small hidden state is\nobservable through a possibly large number of observations. In this paper, we\nstudy the setting of rich-observation Markov decision processes (\\richmdp),\nwhere hidden states are mapped to observations through an injective mapping, so\nthat an observation can be generated by only one hidden state. While this\nmapping is unknown a priori, we introduce a spectral decomposition method that\nconsistently estimates how observations are clustered in the hidden states. The\nestimated clustering is then integrated into an optimistic algorithm for RL\n(UCRL), which operates on the smaller clustered space. The resulting algorithm\nproceeds through phases and we show that its per-step regret (i.e., the\ndifference in cumulative reward between the algorithm and the optimal policy)\ndecreases as more observations are clustered together and finally, matches the\n(ideal) performance of an RL algorithm running directly on the hidden MDP.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Human-Level Intelligence or Animal-Like Abilities?",
        "authors": [
            "Adnan Darwiche"
        ],
        "summary": "The vision systems of the eagle and the snake outperform everything that we\ncan make in the laboratory, but snakes and eagles cannot build an eyeglass or a\ntelescope or a microscope. (Judea Pearl)",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "The threshold EM algorithm for parameter learning in bayesian network\n  with incomplete data",
        "authors": [
            "Fradj Ben Lamine",
            "Karim Kalti",
            "Mohamed Ali Mahjoub"
        ],
        "summary": "Bayesian networks (BN) are used in a big range of applications but they have\none issue concerning parameter learning. In real application, training data are\nalways incomplete or some nodes are hidden. To deal with this problem many\nlearning parameter algorithms are suggested foreground EM, Gibbs sampling and\nRBE algorithms. In order to limit the search space and escape from local maxima\nproduced by executing EM algorithm, this paper presents a learning parameter\nalgorithm that is a fusion of EM and RBE algorithms. This algorithm\nincorporates the range of a parameter into the EM algorithm. This range is\ncalculated by the first step of RBE algorithm allowing a regularization of each\nparameter in bayesian network after the maximization step of the EM algorithm.\nThe threshold EM algorithm is applied in brain tumor diagnosis and show some\nadvantages and disadvantages over the EM algorithm.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "A Branch-and-Bound Algorithm for MDL Learning Bayesian Networks",
        "authors": [
            "Jin Tian"
        ],
        "summary": "This paper extends the work in [Suzuki, 1996] and presents an efficient\ndepth-first branch-and-bound algorithm for learning Bayesian network\nstructures, based on the minimum description length (MDL) principle, for a\ngiven (consistent) variable ordering. The algorithm exhaustively searches\nthrough all network structures and guarantees to find the network with the best\nMDL score. Preliminary experiments show that the algorithm is efficient, and\nthat the time complexity grows slowly with the sample size. The algorithm is\nuseful for empirically studying both the performance of suboptimal heuristic\nsearch algorithms and the adequacy of the MDL principle in learning Bayesian\nnetworks.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Learning Bayesian Network Parameters with Prior Knowledge about\n  Context-Specific Qualitative Influences",
        "authors": [
            "Ad Feelders",
            "Linda C. van der Gaag"
        ],
        "summary": "We present a method for learning the parameters of a Bayesian network with\nprior knowledge about the signs of influences between variables. Our method\naccommodates not just the standard signs, but provides for context-specific\nsigns as well. We show how the various signs translate into order constraints\non the network parameters and how isotonic regression can be used to compute\norder-constrained estimates from the available data. Our experimental results\nshow that taking prior knowledge about the signs of influences into account\nleads to an improved fit of the true distribution, especially when only a small\nsample of data is available. Moreover, the computed estimates are guaranteed to\nbe consistent with the specified signs, thereby resulting in a network that is\nmore likely to be accepted by experts in its domain of application.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Meta-Learning of Exploration/Exploitation Strategies: The Multi-Armed\n  Bandit Case",
        "authors": [
            "Francis Maes",
            "Damien Ernst",
            "Louis Wehenkel"
        ],
        "summary": "The exploration/exploitation (E/E) dilemma arises naturally in many subfields\nof Science. Multi-armed bandit problems formalize this dilemma in its canonical\nform. Most current research in this field focuses on generic solutions that can\nbe applied to a wide range of problems. However, in practice, it is often the\ncase that a form of prior information is available about the specific class of\ntarget problems. Prior knowledge is rarely used in current solutions due to the\nlack of a systematic approach to incorporate it into the E/E strategy.\n  To address a specific class of E/E problems, we propose to proceed in three\nsteps: (i) model prior knowledge in the form of a probability distribution over\nthe target class of E/E problems; (ii) choose a large hypothesis space of\ncandidate E/E strategies; and (iii), solve an optimization problem to find a\ncandidate E/E strategy of maximal average performance over a sample of problems\ndrawn from the prior distribution.\n  We illustrate this meta-learning approach with two different hypothesis\nspaces: one where E/E strategies are numerically parameterized and another\nwhere E/E strategies are represented as small symbolic formulas. We propose\nappropriate optimization algorithms for both cases. Our experiments, with\ntwo-armed Bernoulli bandit problems and various playing budgets, show that the\nmeta-learnt E/E strategies outperform generic strategies of the literature\n(UCB1, UCB1-Tuned, UCB-v, KL-UCB and epsilon greedy); they also evaluate the\nrobustness of the learnt E/E strategies, by tests carried out on arms whose\nrewards follow a truncated Gaussian distribution.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Accuracy Bounds for Belief Propagation",
        "authors": [
            "Alexander T. Ihler"
        ],
        "summary": "The belief propagation (BP) algorithm is widely applied to perform\napproximate inference on arbitrary graphical models, in part due to its\nexcellent empirical properties and performance. However, little is known\ntheoretically about when this algorithm will perform well. Using recent\nanalysis of convergence and stability properties in BP and new results on\napproximations in binary systems, we derive a bound on the error in BP's\nestimates for pairwise Markov random fields over discrete valued random\nvariables. Our bound is relatively simple to compute, and compares favorably\nwith a previous method of bounding the accuracy of BP.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Learning Bayesian Networks with Local Structure",
        "authors": [
            "Nir Friedman",
            "Moises Goldszmidt"
        ],
        "summary": "In this paper we examine a novel addition to the known methods for learning\nBayesian networks from data that improves the quality of the learned networks.\nOur approach explicitly represents and learns the local structure in the\nconditional probability tables (CPTs), that quantify these networks. This\nincreases the space of possible models, enabling the representation of CPTs\nwith a variable number of parameters that depends on the learned local\nstructures. The resulting learning procedure is capable of inducing models that\nbetter emulate the real complexity of the interactions present in the data. We\ndescribe the theoretical foundations and practical aspects of learning local\nstructures, as well as an empirical evaluation of the proposed method. This\nevaluation indicates that learning curves characterizing the procedure that\nexploits the local structure converge faster than these of the standard\nprocedure. Our results also show that networks learned with local structure\ntend to be more complex (in terms of arcs), yet require less parameters.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Learning Markov networks with context-specific independences",
        "authors": [
            "Alejandro Edera",
            "Federico Schl\u00fcter",
            "Facundo Bromberg"
        ],
        "summary": "Learning the Markov network structure from data is a problem that has\nreceived considerable attention in machine learning, and in many other\napplication fields. This work focuses on a particular approach for this purpose\ncalled independence-based learning. Such approach guarantees the learning of\nthe correct structure efficiently, whenever data is sufficient for representing\nthe underlying distribution. However, an important issue of such approach is\nthat the learned structures are encoded in an undirected graph. The problem\nwith graphs is that they cannot encode some types of independence relations,\nsuch as the context-specific independences. They are a particular case of\nconditional independences that is true only for a certain assignment of its\nconditioning set, in contrast to conditional independences that must hold for\nall its assignments. In this work we present CSPC, an independence-based\nalgorithm for learning structures that encode context-specific independences,\nand encoding them in a log-linear model, instead of a graph. The central idea\nof CSPC is combining the theoretical guarantees provided by the\nindependence-based approach with the benefits of representing complex\nstructures by using features in a log-linear model. We present experiments in a\nsynthetic case, showing that CSPC is more accurate than the state-of-the-art IB\nalgorithms when the underlying distribution contains CSIs.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Value Iteration with Options and State Aggregation",
        "authors": [
            "Kamil Ciosek",
            "David Silver"
        ],
        "summary": "This paper presents a way of solving Markov Decision Processes that combines\nstate abstraction and temporal abstraction. Specifically, we combine state\naggregation with the options framework and demonstrate that they work well\ntogether and indeed it is only after one combines the two that the full benefit\nof each is realized. We introduce a hierarchical value iteration algorithm\nwhere we first coarsely solve subgoals and then use these approximate solutions\nto exactly solve the MDP. This algorithm solved several problems faster than\nvanilla value iteration.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Holographic Embeddings of Knowledge Graphs",
        "authors": [
            "Maximilian Nickel",
            "Lorenzo Rosasco",
            "Tomaso Poggio"
        ],
        "summary": "Learning embeddings of entities and relations is an efficient and versatile\nmethod to perform machine learning on relational data such as knowledge graphs.\nIn this work, we propose holographic embeddings (HolE) to learn compositional\nvector space representations of entire knowledge graphs. The proposed method is\nrelated to holographic models of associative memory in that it employs circular\ncorrelation to create compositional representations. By using correlation as\nthe compositional operator HolE can capture rich interactions but\nsimultaneously remains efficient to compute, easy to train, and scalable to\nvery large datasets. In extensive experiments we show that holographic\nembeddings are able to outperform state-of-the-art methods for link prediction\nin knowledge graphs and relational learning benchmark datasets.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Safe, Multi-Agent, Reinforcement Learning for Autonomous Driving",
        "authors": [
            "Shai Shalev-Shwartz",
            "Shaked Shammah",
            "Amnon Shashua"
        ],
        "summary": "Autonomous driving is a multi-agent setting where the host vehicle must apply\nsophisticated negotiation skills with other road users when overtaking, giving\nway, merging, taking left and right turns and while pushing ahead in\nunstructured urban roadways. Since there are many possible scenarios, manually\ntackling all possible cases will likely yield a too simplistic policy.\nMoreover, one must balance between unexpected behavior of other\ndrivers/pedestrians and at the same time not to be too defensive so that normal\ntraffic flow is maintained.\n  In this paper we apply deep reinforcement learning to the problem of forming\nlong term driving strategies. We note that there are two major challenges that\nmake autonomous driving different from other robotic tasks. First, is the\nnecessity for ensuring functional safety - something that machine learning has\ndifficulty with given that performance is optimized at the level of an\nexpectation over many instances. Second, the Markov Decision Process model\noften used in robotics is problematic in our case because of unpredictable\nbehavior of other agents in this multi-agent scenario. We make three\ncontributions in our work. First, we show how policy gradient iterations can be\nused without Markovian assumptions. Second, we decompose the problem into a\ncomposition of a Policy for Desires (which is to be learned) and trajectory\nplanning with hard constraints (which is not learned). The goal of Desires is\nto enable comfort of driving, while hard constraints guarantees the safety of\ndriving. Third, we introduce a hierarchical temporal abstraction we call an\n\"Option Graph\" with a gating mechanism that significantly reduces the effective\nhorizon and thereby reducing the variance of the gradient estimation even\nfurther.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Inference Compilation and Universal Probabilistic Programming",
        "authors": [
            "Tuan Anh Le",
            "Atilim Gunes Baydin",
            "Frank Wood"
        ],
        "summary": "We introduce a method for using deep neural networks to amortize the cost of\ninference in models from the family induced by universal probabilistic\nprogramming languages, establishing a framework that combines the strengths of\nprobabilistic programming and deep learning methods. We call what we do\n\"compilation of inference\" because our method transforms a denotational\nspecification of an inference problem in the form of a probabilistic program\nwritten in a universal programming language into a trained neural network\ndenoted in a neural network specification language. When at test time this\nneural network is fed observational data and executed, it performs approximate\ninference in the original model specified by the probabilistic program. Our\ntraining objective and learning procedure are designed to allow the trained\nneural network to be used as a proposal distribution in a sequential importance\nsampling inference engine. We illustrate our method on mixture models and\nCaptcha solving and show significant speedups in the efficiency of inference.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Experimental results : Reinforcement Learning of POMDPs using Spectral\n  Methods",
        "authors": [
            "Kamyar Azizzadenesheli",
            "Alessandro Lazaric",
            "Animashree Anandkumar"
        ],
        "summary": "We propose a new reinforcement learning algorithm for partially observable\nMarkov decision processes (POMDP) based on spectral decomposition methods.\nWhile spectral methods have been previously employed for consistent learning of\n(passive) latent variable models such as hidden Markov models, POMDPs are more\nchallenging since the learner interacts with the environment and possibly\nchanges the future observations in the process. We devise a learning algorithm\nrunning through epochs, in each epoch we employ spectral techniques to learn\nthe POMDP parameters from a trajectory generated by a fixed policy. At the end\nof the epoch, an optimization oracle returns the optimal memoryless planning\npolicy which maximizes the expected reward based on the estimated POMDP model.\nWe prove an order-optimal regret bound with respect to the optimal memoryless\npolicy and efficient scaling with respect to the dimensionality of observation\nand action spaces.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Shallow Updates for Deep Reinforcement Learning",
        "authors": [
            "Nir Levine",
            "Tom Zahavy",
            "Daniel J. Mankowitz",
            "Aviv Tamar",
            "Shie Mannor"
        ],
        "summary": "Deep reinforcement learning (DRL) methods such as the Deep Q-Network (DQN)\nhave achieved state-of-the-art results in a variety of challenging,\nhigh-dimensional domains. This success is mainly attributed to the power of\ndeep neural networks to learn rich domain representations for approximating the\nvalue function or policy. Batch reinforcement learning methods with linear\nrepresentations, on the other hand, are more stable and require less hyper\nparameter tuning. Yet, substantial feature engineering is necessary to achieve\ngood results. In this work we propose a hybrid approach -- the Least Squares\nDeep Q-Network (LS-DQN), which combines rich feature representations learned by\na DRL algorithm with the stability of a linear least squares method. We do this\nby periodically re-training the last hidden layer of a DRL network with a batch\nleast squares update. Key to our approach is a Bayesian regularization term for\nthe least squares update, which prevents over-fitting to the more recent data.\nWe tested LS-DQN on five Atari games and demonstrate significant improvement\nover vanilla DQN and Double-DQN. We also investigated the reasons for the\nsuperior performance of our method. Interestingly, we found that the\nperformance improvement can be attributed to the large batch size used by the\nLS method when optimizing the last layer.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Fairness-aware machine learning: a perspective",
        "authors": [
            "Indre Zliobaite"
        ],
        "summary": "Algorithms learned from data are increasingly used for deciding many aspects\nin our life: from movies we see, to prices we pay, or medicine we get. Yet\nthere is growing evidence that decision making by inappropriately trained\nalgorithms may unintentionally discriminate people. For example, in automated\nmatching of candidate CVs with job descriptions, algorithms may capture and\npropagate ethnicity related biases. Several repairs for selected algorithms\nhave already been proposed, but the underlying mechanisms how such\ndiscrimination happens from the computational perspective are not yet\nscientifically understood. We need to develop theoretical understanding how\nalgorithms may become discriminatory, and establish fundamental machine\nlearning principles for prevention. We need to analyze machine learning process\nas a whole to systematically explain the roots of discrimination occurrence,\nwhich will allow to devise global machine learning optimization criteria for\nguaranteed prevention, as opposed to pushing empirical constraints into\nexisting algorithms case-by-case. As a result, the state-of-the-art will\nadvance from heuristic repairing, to proactive and theoretically supported\nprevention. This is needed not only because law requires to protect vulnerable\npeople. Penetration of big data initiatives will only increase, and computer\nscience needs to provide solid explanations and accountability to the public,\nbefore public concerns lead to unnecessarily restrictive regulations against\nmachine learning.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Learning to Search with MCTSnets",
        "authors": [
            "Arthur Guez",
            "Th\u00e9ophane Weber",
            "Ioannis Antonoglou",
            "Karen Simonyan",
            "Oriol Vinyals",
            "Daan Wierstra",
            "R\u00e9mi Munos",
            "David Silver"
        ],
        "summary": "Planning problems are among the most important and well-studied problems in\nartificial intelligence. They are most typically solved by tree search\nalgorithms that simulate ahead into the future, evaluate future states, and\nback-up those evaluations to the root of a search tree. Among these algorithms,\nMonte-Carlo tree search (MCTS) is one of the most general, powerful and widely\nused. A typical implementation of MCTS uses cleverly designed rules, optimized\nto the particular characteristics of the domain. These rules control where the\nsimulation traverses, what to evaluate in the states that are reached, and how\nto back-up those evaluations. In this paper we instead learn where, what and\nhow to search. Our architecture, which we call an MCTSnet, incorporates\nsimulation-based search inside a neural network, by expanding, evaluating and\nbacking-up a vector embedding. The parameters of the network are trained\nend-to-end using gradient-based optimisation. When applied to small searches in\nthe well known planning problem Sokoban, the learned search algorithm\nsignificantly outperformed MCTS baselines.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "Deeply Semantic Inductive Spatio-Temporal Learning",
        "authors": [
            "Jakob Suchan",
            "Mehul Bhatt",
            "Carl Schultz"
        ],
        "summary": "We present an inductive spatio-temporal learning framework rooted in\ninductive logic programming. With an emphasis on visuo-spatial language, logic,\nand cognition, the framework supports learning with relational spatio-temporal\nfeatures identifiable in a range of domains involving the processing and\ninterpretation of dynamic visuo-spatial imagery. We present a prototypical\nsystem, and an example application in the domain of computing for visual arts\nand computational cognitive science.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Between Sense and Sensibility: Declarative narrativisation of mental\n  models as a basis and benchmark for visuo-spatial cognition and computation\n  focussed collaborative cognitive systems",
        "authors": [
            "Mehul Bhatt"
        ],
        "summary": "What lies between `\\emph{sensing}' and `\\emph{sensibility}'? In other words,\nwhat kind of cognitive processes mediate sensing capability, and the formation\nof sensible impressions ---e.g., abstractions, analogies, hypotheses and theory\nformation, beliefs and their revision, argument formation--- in domain-specific\nproblem solving, or in regular activities of everyday living, working and\nsimply going around in the environment? How can knowledge and reasoning about\nsuch capabilities, as exhibited by humans in particular problem contexts, be\nused as a model and benchmark for the development of collaborative cognitive\n(interaction) systems concerned with human assistance, assurance, and\nempowerment?\n  We pose these questions in the context of a range of assistive technologies\nconcerned with \\emph{visuo-spatial perception and cognition} tasks encompassing\naspects such as commonsense, creativity, and the application of specialist\ndomain knowledge and problem-solving thought processes. Assistive technologies\nbeing considered include: (a) human activity interpretation; (b) high-level\ncognitive rovotics; (c) people-centred creative design in domains such as\narchitecture & digital media creation, and (d) qualitative analyses geographic\ninformation systems. Computational narratives not only provide a rich cognitive\nbasis, but they also serve as a benchmark of functional performance in our\ndevelopment of computational cognitive assistance systems. We posit that\ncomputational narrativisation pertaining to space, actions, and change provides\na useful model of \\emph{visual} and \\emph{spatio-temporal thinking} within a\nwide-range of problem-solving tasks and application areas where collaborative\ncognitive systems could serve an assistive and empowering function.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Reinforcement Learning of POMDPs using Spectral Methods",
        "authors": [
            "Kamyar Azizzadenesheli",
            "Alessandro Lazaric",
            "Animashree Anandkumar"
        ],
        "summary": "We propose a new reinforcement learning algorithm for partially observable\nMarkov decision processes (POMDP) based on spectral decomposition methods.\nWhile spectral methods have been previously employed for consistent learning of\n(passive) latent variable models such as hidden Markov models, POMDPs are more\nchallenging since the learner interacts with the environment and possibly\nchanges the future observations in the process. We devise a learning algorithm\nrunning through episodes, in each episode we employ spectral techniques to\nlearn the POMDP parameters from a trajectory generated by a fixed policy. At\nthe end of the episode, an optimization oracle returns the optimal memoryless\nplanning policy which maximizes the expected reward based on the estimated\nPOMDP model. We prove an order-optimal regret bound with respect to the optimal\nmemoryless policy and efficient scaling with respect to the dimensionality of\nobservation and action spaces.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Guided Deep Reinforcement Learning for Swarm Systems",
        "authors": [
            "Maximilian H\u00fcttenrauch",
            "Adrian \u0160o\u0161i\u0107",
            "Gerhard Neumann"
        ],
        "summary": "In this paper, we investigate how to learn to control a group of cooperative\nagents with limited sensing capabilities such as robot swarms. The agents have\nonly very basic sensor capabilities, yet in a group they can accomplish\nsophisticated tasks, such as distributed assembly or search and rescue tasks.\nLearning a policy for a group of agents is difficult due to distributed partial\nobservability of the state. Here, we follow a guided approach where a critic\nhas central access to the global state during learning, which simplifies the\npolicy evaluation problem from a reinforcement learning point of view. For\nexample, we can get the positions of all robots of the swarm using a camera\nimage of a scene. This camera image is only available to the critic and not to\nthe control policies of the robots. We follow an actor-critic approach, where\nthe actors base their decisions only on locally sensed information. In\ncontrast, the critic is learned based on the true global state. Our algorithm\nuses deep reinforcement learning to approximate both the Q-function and the\npolicy. The performance of the algorithm is evaluated on two tasks with simple\nsimulated 2D agents: 1) finding and maintaining a certain distance to each\nothers and 2) locating a target.",
        "year": 2017,
        "label": "cs.MA"
    },
    {
        "title": "Learning Complex Swarm Behaviors by Exploiting Local Communication\n  Protocols with Deep Reinforcement Learning",
        "authors": [
            "Maximilian H\u00fcttenrauch",
            "Adrian \u0160o\u0161i\u0107",
            "Gerhard Neumann"
        ],
        "summary": "Swarm systems constitute a challenging problem for reinforcement learning\n(RL) as the algorithm needs to learn decentralized control policies that can\ncope with limited local sensing and communication abilities of the agents.\nAlthough there have been recent advances of deep RL algorithms applied to\nmulti-agent systems, learning communication protocols while simultaneously\nlearning the behavior of the agents is still beyond the reach of deep RL\nalgorithms. However, while it is often difficult to directly define the\nbehavior of the agents, simple communication protocols can be defined more\neasily using prior knowledge about the given task. In this paper, we propose a\nnumber of simple communication protocols that can be exploited by deep\nreinforcement learning to find decentralized control policies in a multi-robot\nswarm environment. The protocols are based on histograms that encode the local\nneighborhood relations of the agents and can also transmit task-specific\ninformation, such as the shortest distance and direction to a desired target.\nIn our framework, we use an adaptation of Trust Region Policy Optimization to\nlearn complex collaborative tasks, such as formation building, building a\ncommunication link, and pushing an intruder. We evaluate our findings in a\nsimulated 2D-physics environment, and compare the implications of different\ncommunication protocols.",
        "year": 2017,
        "label": "cs.MA"
    },
    {
        "title": "Evolution of a Subsumption Architecture Neurocontroller",
        "authors": [
            "Julian Togelius"
        ],
        "summary": "An approach to robotics called layered evolution and merging features from\nthe subsumption architecture into evolutionary robotics is presented, and its\nadvantages are discussed. This approach is used to construct a layered\ncontroller for a simulated robot that learns which light source to approach in\nan environment with obstacles. The evolvability and performance of layered\nevolution on this task is compared to (standard) monolithic evolution,\nincremental and modularised evolution. To corroborate the hypothesis that a\nlayered controller performs at least as well as an integrated one, the evolved\nlayers are merged back into a single network. On the grounds of the test\nresults, it is argued that layered evolution provides a superior approach for\nmany tasks, and it is suggested that this approach may be the key to scaling up\nevolutionary robotics.",
        "year": 2004,
        "label": "cs.AI"
    },
    {
        "title": "Multiobjective hBOA, Clustering, and Scalability",
        "authors": [
            "Martin Pelikan",
            "Kumara Sastry",
            "David E. Goldberg"
        ],
        "summary": "This paper describes a scalable algorithm for solving multiobjective\ndecomposable problems by combining the hierarchical Bayesian optimization\nalgorithm (hBOA) with the nondominated sorting genetic algorithm (NSGA-II) and\nclustering in the objective space. It is first argued that for good\nscalability, clustering or some other form of niching in the objective space is\nnecessary and the size of each niche should be approximately equal.\nMultiobjective hBOA (mohBOA) is then described that combines hBOA, NSGA-II and\nclustering in the objective space. The algorithm mohBOA differs from the\nmultiobjective variants of BOA and hBOA proposed in the past by including\nclustering in the objective space and allocating an approximately equally sized\nportion of the population to each cluster. The algorithm mohBOA is shown to\nscale up well on a number of problems on which standard multiobjective\nevolutionary algorithms perform poorly.",
        "year": 2005,
        "label": "cs.NE"
    },
    {
        "title": "Decomposable Problems, Niching, and Scalability of Multiobjective\n  Estimation of Distribution Algorithms",
        "authors": [
            "Kumara Sastry",
            "Martin Pelikan",
            "David E. Goldberg"
        ],
        "summary": "The paper analyzes the scalability of multiobjective estimation of\ndistribution algorithms (MOEDAs) on a class of boundedly-difficult\nadditively-separable multiobjective optimization problems. The paper\nillustrates that even if the linkage is correctly identified, massive\nmultimodality of the search problems can easily overwhelm the nicher and lead\nto exponential scale-up. Facetwise models are subsequently used to propose a\ngrowth rate of the number of differing substructures between the two objectives\nto avoid the niching method from being overwhelmed and lead to polynomial\nscalability of MOEDAs.",
        "year": 2005,
        "label": "cs.NE"
    },
    {
        "title": "An associative memory for the on-line recognition and prediction of\n  temporal sequences",
        "authors": [
            "J. Bose",
            "S. B. Furber",
            "J. L. Shapiro"
        ],
        "summary": "This paper presents the design of an associative memory with feedback that is\ncapable of on-line temporal sequence learning. A framework for on-line sequence\nlearning has been proposed, and different sequence learning models have been\nanalysed according to this framework. The network model is an associative\nmemory with a separate store for the sequence context of a symbol. A sparse\ndistributed memory is used to gain scalability. The context store combines the\nfunctionality of a neural layer with a shift register. The sensitivity of the\nmachine to the sequence context is controllable, resulting in different\ncharacteristic behaviours. The model can store and predict on-line sequences of\nvarious types and length. Numerical simulations on the model have been carried\nout to determine its properties.",
        "year": 2006,
        "label": "cs.NE"
    },
    {
        "title": "Analysis of Estimation of Distribution Algorithms and Genetic Algorithms\n  on NK Landscapes",
        "authors": [
            "Martin Pelikan"
        ],
        "summary": "This study analyzes performance of several genetic and evolutionary\nalgorithms on randomly generated NK fitness landscapes with various values of n\nand k. A large number of NK problem instances are first generated for each n\nand k, and the global optimum of each instance is obtained using the\nbranch-and-bound algorithm. Next, the hierarchical Bayesian optimization\nalgorithm (hBOA), the univariate marginal distribution algorithm (UMDA), and\nthe simple genetic algorithm (GA) with uniform and two-point crossover\noperators are applied to all generated instances. Performance of all algorithms\nis then analyzed and compared, and the results are discussed.",
        "year": 2008,
        "label": "cs.NE"
    },
    {
        "title": "iBOA: The Incremental Bayesian Optimization Algorithm",
        "authors": [
            "Martin Pelikan",
            "Kumara Sastry",
            "David E. Goldberg"
        ],
        "summary": "This paper proposes the incremental Bayesian optimization algorithm (iBOA),\nwhich modifies standard BOA by removing the population of solutions and using\nincremental updates of the Bayesian network. iBOA is shown to be able to learn\nand exploit unrestricted Bayesian networks using incremental techniques for\nupdating both the structure as well as the parameters of the probabilistic\nmodel. This represents an important step toward the design of competent\nincremental estimation of distribution algorithms that can solve difficult\nnearly decomposable problems scalably and reliably.",
        "year": 2008,
        "label": "cs.NE"
    },
    {
        "title": "On the Effects of Idiotypic Interactions for Recommendation Communities\n  in Artificial Immune Systems",
        "authors": [
            "Steve Cayzer",
            "Uwe Aickelin"
        ],
        "summary": "It has previously been shown that a recommender based on immune system\nidiotypic principles can out perform one based on correlation alone. This paper\nreports the results of work in progress, where we undertake some investigations\ninto the nature of this beneficial effect. The initial findings are that the\nimmune system recommender tends to produce different neighbourhoods, and that\nthe superior performance of this recommender is due partly to the different\nneighbourhoods, and partly to the way that the idiotypic effect is used to\nweight each neighbours recommendations.",
        "year": 2008,
        "label": "cs.NE"
    },
    {
        "title": "Partnering Strategies for Fitness Evaluation in a Pyramidal Evolutionary\n  Algorithm",
        "authors": [
            "Uwe Aickelin",
            "Larry Bull"
        ],
        "summary": "This paper combines the idea of a hierarchical distributed genetic algorithm\nwith different inter-agent partnering strategies. Cascading clusters of\nsub-populations are built from bottom up, with higher-level sub-populations\noptimising larger parts of the problem. Hence higher-level sub-populations\nsearch a larger search space with a lower resolution whilst lower-level\nsub-populations search a smaller search space with a higher resolution. The\neffects of different partner selection schemes for (sub-)fitness evaluation\npurposes are examined for two multiple-choice optimisation problems. It is\nshown that random partnering strategies perform best by providing better\nsampling and more diversity.",
        "year": 2008,
        "label": "cs.NE"
    },
    {
        "title": "Artificial Immune Systems (AIS) - A New Paradigm for Heuristic Decision\n  Making",
        "authors": [
            "Uwe Aickelin"
        ],
        "summary": "Over the last few years, more and more heuristic decision making techniques\nhave been inspired by nature, e.g. evolutionary algorithms, ant colony\noptimisation and simulated annealing. More recently, a novel computational\nintelligence technique inspired by immunology has emerged, called Artificial\nImmune Systems (AIS). This immune system inspired technique has already been\nuseful in solving some computational problems. In this keynote, we will very\nbriefly describe the immune system metaphors that are relevant to AIS. We will\nthen give some illustrative real-world problems suitable for AIS use and show a\nstep-by-step algorithm walkthrough. A comparison of AIS to other well-known\nalgorithms and areas for future work will round this keynote off. It should be\nnoted that as AIS is still a young and evolving field, there is not yet a fixed\nalgorithm template and hence actual implementations might differ somewhat from\nthe examples given here.",
        "year": 2008,
        "label": "cs.NE"
    },
    {
        "title": "Weak Evolvability Equals Strong Evolvability",
        "authors": [
            "Yang Yu",
            "Zhi-Hua Zhou"
        ],
        "summary": "An updated version will be uploaded later.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Nurse Rostering with Genetic Algorithms",
        "authors": [
            "Uwe Aickelin"
        ],
        "summary": "In recent years genetic algorithms have emerged as a useful tool for the\nheuristic solution of complex discrete optimisation problems. In particular\nthere has been considerable interest in their use in tackling problems arising\nin the areas of scheduling and timetabling. However, the classical genetic\nalgorithm paradigm is not well equipped to handle constraints and successful\nimplementations usually require some sort of modification to enable the search\nto exploit problem specific knowledge in order to overcome this shortcoming.\nThis paper is concerned with the development of a family of genetic algorithms\nfor the solution of a nurse rostering problem at a major UK hospital. The\nhospital is made up of wards of up to 30 nurses. Each ward has its own group of\nnurses whose shifts have to be scheduled on a weekly basis. In addition to\nfulfilling the minimum demand for staff over three daily shifts, nurses' wishes\nand qualifications have to be taken into account. The schedules must also be\nseen to be fair, in that unpopular shifts have to be spread evenly amongst all\nnurses, and other restrictions, such as team nursing and special conditions for\nsenior staff, have to be satisfied. The basis of the family of genetic\nalgorithms is a classical genetic algorithm consisting of n-point crossover,\nsingle-bit mutation and a rank-based selection. The solution space consists of\nall schedules in which each nurse works the required number of shifts, but the\nremaining constraints, both hard and soft, are relaxed and penalised in the\nfitness function. The talk will start with a detailed description of the\nproblem and the initial implementation and will go on to highlight the\nshortcomings of such an approach, in terms of the key element of balancing\nfeasibility, i.e. covering the demand and work regulations, and quality, as\nmeasured by the nurses' preferences. A series of experiments involving\nparameter adaptation, niching, intelligent weights, delta coding, local hill\nclimbing, migration and special selection rules will then be outlined and it\nwill be shown how a series of these enhancements were able to eradicate these\ndifficulties. Results based on several months' real data will be used to\nmeasure the impact of each modification, and to show that the final algorithm\nis able to compete with a tabu search approach currently employed at the\nhospital. The talk will conclude with some observations as to the overall\nquality of this approach to this and similar problems.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "Introducing Dendritic Cells as a Novel Immune-Inspired Algorithm for\n  Anomoly Detection",
        "authors": [
            "Julie Greensmith",
            "Uwe Aickelin",
            "Steve Cayzer"
        ],
        "summary": "Dendritic cells are antigen presenting cells that provide a vital link\nbetween the innate and adaptive immune system. Research into this family of\ncells has revealed that they perform the role of coordinating T-cell based\nimmune responses, both reactive and for generating tolerance. We have derived\nan algorithm based on the functionality of these cells, and have used the\nsignals and differentiation pathways to build a control mechanism for an\nartificial immune system. We present our algorithmic details in addition to\nsome preliminary results, where the algorithm was applied for the purpose of\nanomaly detection. We hope that this algorithm will eventually become the key\ncomponent within a large, distributed immune system, based on sound\nimmunological concepts.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "Efficient Independence-Based MAP Approach for Robust Markov Networks\n  Structure Discovery",
        "authors": [
            "Facundo Bromberg",
            "Federico Schl\u00fcter"
        ],
        "summary": "This work introduces the IB-score, a family of independence-based score\nfunctions for robust learning of Markov networks independence structures.\nMarkov networks are a widely used graphical representation of probability\ndistributions, with many applications in several fields of science. The main\nadvantage of the IB-score is the possibility of computing it without the need\nof estimation of the numerical parameters, an NP-hard problem, usually solved\nthrough an approximate, data-intensive, iterative optimization. We derive a\nformal expression for the IB-score from first principles, mainly maximum a\nposteriori and conditional independence properties, and exemplify several\ninstantiations of it, resulting in two novel algorithms for structure learning:\nIBMAP-HC and IBMAP-TS. Experimental results over both artificial and real world\ndata show these algorithms achieve important error reductions in the learnt\nstructures when compared with the state-of-the-art independence-based structure\nlearning algorithm GSMN, achieving increments of more than 50% in the amount of\nindependencies they encode correctly, and in some cases, learning correctly\nover 90% of the edges that GSMN learnt incorrectly. Theoretical analysis shows\nIBMAP-HC proceeds efficiently, achieving these improvements in a time\npolynomial to the number of random variables in the domain.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Neural Networks for Handwritten English Alphabet Recognition",
        "authors": [
            "Yusuf Perwej",
            "Ashish Chaturvedi"
        ],
        "summary": "This paper demonstrates the use of neural networks for developing a system\nthat can recognize hand-written English alphabets. In this system, each English\nalphabet is represented by binary values that are used as input to a simple\nfeature extraction system, whose output is fed to our neural network system.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks",
        "authors": [
            "Victor Campos",
            "Brendan Jou",
            "Xavier Giro-i-Nieto",
            "Jordi Torres",
            "Shih-Fu Chang"
        ],
        "summary": "Recurrent Neural Networks (RNNs) continue to show outstanding performance in\nsequence modeling tasks. However, training RNNs on long sequences often face\nchallenges like slow inference, vanishing gradients and difficulty in capturing\nlong term dependencies. In backpropagation through time settings, these issues\nare tightly coupled with the large, sequential computational graph resulting\nfrom unfolding the RNN in time. We introduce the Skip RNN model which extends\nexisting RNN models by learning to skip state updates and shortens the\neffective size of the computational graph. This model can also be encouraged to\nperform fewer state updates through a budget constraint. We evaluate the\nproposed model on various tasks and show how it can reduce the number of\nrequired RNN updates while preserving, and sometimes even improving, the\nperformance of the baseline RNN models. Source code is publicly available at\nhttps://imatge-upc.github.io/skiprnn-2017-telecombcn/ .",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "FixaTons: A collection of Human Fixations Datasets and Metrics for\n  Scanpath Similarity",
        "authors": [
            "Dario Zanca",
            "Valeria Serchi",
            "Pietro Piu",
            "Francesca Rosini",
            "Alessandra Rufa"
        ],
        "summary": "In the last three decades, human visual attention has been a topic of great\ninterest in various disciplines. In computer vision, many models have been\nproposed to predict the distribution of human fixations on a visual input.\nRecently, thanks to the creation of large collections of data, machine learning\nalgorithms have obtained state-of-the-art performance on the task of saliency\nmap estimation. On the other hand, computational models of scanpath are much\nless studied. Works are often only descriptive or task specific. Computational\nmodels of scanpath with general purpose are present in the literature, but are\nthen evaluated in tasks of saliency prediction, losing therefore information\nabout the dynamics and the behaviour. This is due to the fact that the scanpath\nis harder to model because it must include the description of a dynamic. In\naddition to the difficulty of the problem itself, two technical reasons have\nlimited the research. The first reason is the lack of robust and uniformly used\nset of metrics to compare the similarity between scanpath. The second reason is\nthe lack of sufficiently large and varied scanpath datasets. In this report we\nwant to help in both directions. We present FixaTons, a large collection of\nhuman scanpaths (and saliency maps). It comes along with a software library for\neasy data usage, statistics calculation and measures for scanpaths (and\nsaliency maps) similarity.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "Unsupervised Learning through Prediction in a Model of Cortex",
        "authors": [
            "Christos H. Papadimitriou",
            "Santosh S. Vempala"
        ],
        "summary": "We propose a primitive called PJOIN, for \"predictive join,\" which combines\nand extends the operations JOIN and LINK, which Valiant proposed as the basis\nof a computational theory of cortex. We show that PJOIN can be implemented in\nValiant's model. We also show that, using PJOIN, certain reasonably complex\nlearning and pattern matching tasks can be performed, in a way that involves\nphenomena which have been observed in cognition and the brain, namely\nmemory-based prediction and downward traffic in the cortical hierarchy.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "New Error Bounds for Solomonoff Prediction",
        "authors": [
            "Marcus Hutter"
        ],
        "summary": "Solomonoff sequence prediction is a scheme to predict digits of binary\nstrings without knowing the underlying probability distribution. We call a\nprediction scheme informed when it knows the true probability distribution of\nthe sequence. Several new relations between universal Solomonoff sequence\nprediction and informed prediction and general probabilistic prediction schemes\nwill be proved. Among others, they show that the number of errors in Solomonoff\nprediction is finite for computable distributions, if finite in the informed\ncase. Deterministic variants will also be studied. The most interesting result\nis that the deterministic variant of Solomonoff prediction is optimal compared\nto any other probabilistic or deterministic prediction scheme apart from\nadditive square root corrections only. This makes it well suited even for\ndifficult prediction problems, where it does not suffice when the number of\nerrors is minimal to within some factor greater than one. Solomonoff's original\nbound and the ones presented here complement each other in a useful way.",
        "year": 1999,
        "label": "cs.AI"
    },
    {
        "title": "Robust Feature Selection by Mutual Information Distributions",
        "authors": [
            "Marco Zaffalon",
            "Marcus Hutter"
        ],
        "summary": "Mutual information is widely used in artificial intelligence, in a\ndescriptive way, to measure the stochastic dependence of discrete random\nvariables. In order to address questions such as the reliability of the\nempirical value, one must consider sample-to-population inferential approaches.\nThis paper deals with the distribution of mutual information, as obtained in a\nBayesian framework by a second-order Dirichlet prior distribution. The exact\nanalytical expression for the mean and an analytical approximation of the\nvariance are reported. Asymptotic approximations of the distribution are\nproposed. The results are applied to the problem of selecting features for\nincremental learning and classification of the naive Bayes classifier. A fast,\nnewly defined method is shown to outperform the traditional approach based on\nempirical mutual information on a number of real data sets. Finally, a\ntheoretical development is reported that allows one to efficiently extend the\nabove methods to incomplete samples in an easy and effective way.",
        "year": 2002,
        "label": "cs.AI"
    },
    {
        "title": "Universal Algorithmic Intelligence: A mathematical top->down approach",
        "authors": [
            "Marcus Hutter"
        ],
        "summary": "Sequential decision theory formally solves the problem of rational agents in\nuncertain worlds if the true environmental prior probability distribution is\nknown. Solomonoff's theory of universal induction formally solves the problem\nof sequence prediction for unknown prior distribution. We combine both ideas\nand get a parameter-free theory of universal Artificial Intelligence. We give\nstrong arguments that the resulting AIXI model is the most intelligent unbiased\nagent possible. We outline how the AIXI model can formally solve a number of\nproblem classes, including sequence prediction, strategic games, function\nminimization, reinforcement and supervised learning. The major drawback of the\nAIXI model is that it is uncomputable. To overcome this problem, we construct a\nmodified algorithm AIXItl that is still effectively more intelligent than any\nother time t and length l bounded agent. The computation time of AIXItl is of\nthe order t x 2^l. The discussion includes formal definitions of intelligence\norder relations, the horizon problem and relations of the AIXI theory to other\nAI approaches.",
        "year": 2007,
        "label": "cs.AI"
    },
    {
        "title": "A survey on independence-based Markov networks learning",
        "authors": [
            "Federico Schl\u00fcter"
        ],
        "summary": "This work reports the most relevant technical aspects in the problem of\nlearning the \\emph{Markov network structure} from data. Such problem has become\nincreasingly important in machine learning, and many other application fields\nof machine learning. Markov networks, together with Bayesian networks, are\nprobabilistic graphical models, a widely used formalism for handling\nprobability distributions in intelligent systems. Learning graphical models\nfrom data have been extensively applied for the case of Bayesian networks, but\nfor Markov networks learning it is not tractable in practice. However, this\nsituation is changing with time, given the exponential growth of computers\ncapacity, the plethora of available digital data, and the researching on new\nlearning technologies. This work stresses on a technology called\nindependence-based learning, which allows the learning of the independence\nstructure of those networks from data in an efficient and sound manner,\nwhenever the dataset is sufficiently large, and data is a representative\nsampling of the target distribution. In the analysis of such technology, this\nwork surveys the current state-of-the-art algorithms for learning Markov\nnetworks structure, discussing its current limitations, and proposing a series\nof open problems where future works may produce some advances in the area in\nterms of quality and efficiency. The paper concludes by opening a discussion\nabout how to develop a general formalism for improving the quality of the\nstructures learned, when data is scarce.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "A probabilistic methodology for multilabel classification",
        "authors": [
            "Alfonso E. Romero",
            "Luis M. de Campos"
        ],
        "summary": "Multilabel classification is a relatively recent subfield of machine\nlearning. Unlike to the classical approach, where instances are labeled with\nonly one category, in multilabel classification, an arbitrary number of\ncategories is chosen to label an instance. Due to the problem complexity (the\nsolution is one among an exponential number of alternatives), a very common\nsolution (the binary method) is frequently used, learning a binary classifier\nfor every category, and combining them all afterwards. The assumption taken in\nthis solution is not realistic, and in this work we give examples where the\ndecisions for all the labels are not taken independently, and thus, a\nsupervised approach should learn those existing relationships among categories\nto make a better classification. Therefore, we show here a generic methodology\nthat can improve the results obtained by a set of independent probabilistic\nbinary classifiers, by using a combination procedure with a classifier trained\non the co-occurrences of the labels. We show an exhaustive experimentation in\nthree different standard corpora of labeled documents (Reuters-21578,\nOhsumed-23 and RCV1), which present noticeable improvements in all of them,\nwhen using our methodology, in three probabilistic base classifiers.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "The IBMAP approach for Markov networks structure learning",
        "authors": [
            "Federico Schl\u00fcter",
            "Facundo Bromberg",
            "Alejandro Edera"
        ],
        "summary": "In this work we consider the problem of learning the structure of Markov\nnetworks from data. We present an approach for tackling this problem called\nIBMAP, together with an efficient instantiation of the approach: the IBMAP-HC\nalgorithm, designed for avoiding important limitations of existing\nindependence-based algorithms. These algorithms proceed by performing\nstatistical independence tests on data, trusting completely the outcome of each\ntest. In practice tests may be incorrect, resulting in potential cascading\nerrors and the consequent reduction in the quality of the structures learned.\nIBMAP contemplates this uncertainty in the outcome of the tests through a\nprobabilistic maximum-a-posteriori approach. The approach is instantiated in\nthe IBMAP-HC algorithm, a structure selection strategy that performs a\npolynomial heuristic local search in the space of possible structures. We\npresent an extensive empirical evaluation on synthetic and real data, showing\nthat our algorithm outperforms significantly the current independence-based\nalgorithms, in terms of data efficiency and quality of learned structures, with\nequivalent computational complexities. We also show the performance of IBMAP-HC\nin a real-world application of knowledge discovery: EDAs, which are\nevolutionary algorithms that use structure learning on each generation for\nmodeling the distribution of populations. The experiments show that when\nIBMAP-HC is used to learn the structure, EDAs improve the convergence to the\noptimum.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Learning the Structure of Dynamic Probabilistic Networks",
        "authors": [
            "Nir Friedman",
            "Kevin Murphy",
            "Stuart Russell"
        ],
        "summary": "Dynamic probabilistic networks are a compact representation of complex\nstochastic processes. In this paper we examine how to learn the structure of a\nDPN from data. We extend structure scoring rules for standard probabilistic\nnetworks to the dynamic case, and show how to search for structure when some of\nthe variables are hidden. Finally, we examine two applications where such a\ntechnology might be useful: predicting and classifying dynamic behaviors, and\nlearning causal orderings in biological processes. We provide empirical results\nthat demonstrate the applicability of our methods in both domains.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Markov random fields factorization with context-specific independences",
        "authors": [
            "Alejandro Edera",
            "Facundo Bromberg",
            "Federico Schl\u00fcter"
        ],
        "summary": "Markov random fields provide a compact representation of joint probability\ndistributions by representing its independence properties in an undirected\ngraph. The well-known Hammersley-Clifford theorem uses these conditional\nindependences to factorize a Gibbs distribution into a set of factors. However,\nan important issue of using a graph to represent independences is that it\ncannot encode some types of independence relations, such as the\ncontext-specific independences (CSIs). They are a particular case of\nconditional independences that is true only for a certain assignment of its\nconditioning set; in contrast to conditional independences that must hold for\nall its assignments. This work presents a method for factorizing a Markov\nrandom field according to CSIs present in a distribution, and formally\nguarantees that this factorization is correct. This is presented in our main\ncontribution, the context-specific Hammersley-Clifford theorem, a\ngeneralization to CSIs of the Hammersley-Clifford theorem that applies for\nconditional independences.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Optimistic Agents are Asymptotically Optimal",
        "authors": [
            "Peter Sunehag",
            "Marcus Hutter"
        ],
        "summary": "We use optimism to introduce generic asymptotically optimal reinforcement\nlearning agents. They achieve, with an arbitrary finite or compact class of\nenvironments, asymptotically optimal behavior. Furthermore, in the finite\ndeterministic case we provide finite error bounds.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "On the Choice of Regions for Generalized Belief Propagation",
        "authors": [
            "Max Welling"
        ],
        "summary": "Generalized belief propagation (GBP) has proven to be a promising technique\nfor approximate inference tasks in AI and machine learning. However, the choice\nof a good set of clusters to be used in GBP has remained more of an art then a\nscience until this day. This paper proposes a sequential approach to adding new\nclusters of nodes and their interactions (i.e. \"regions\") to the approximation.\nWe first review and analyze the recently introduced region graphs and find that\nthree kinds of operations (\"split\", \"merge\" and \"death\") leave the free energy\nand (under some conditions) the fixed points of GBP invariant. This leads to\nthe notion of \"weakly irreducible\" regions as the natural candidates to be\nadded to the approximation. Computational complexity of the GBP algorithm is\ncontrolled by restricting attention to regions with small \"region-width\".\nCombining the above with an efficient (i.e. local in the graph) measure to\npredict the improved accuracy of GBP leads to the sequential \"region pursuit\"\nalgorithm for adding new regions bottom-up to the region graph. Experiments\nshow that this algorithm can indeed perform close to optimally.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "MCTS Based on Simple Regret",
        "authors": [
            "David Tolpin",
            "Solomon Eyal Shimony"
        ],
        "summary": "UCT, a state-of-the art algorithm for Monte Carlo tree search (MCTS) in games\nand Markov decision processes, is based on UCB, a sampling policy for the\nMulti-armed Bandit problem (MAB) that minimizes the cumulative regret. However,\nsearch differs from MAB in that in MCTS it is usually only the final \"arm pull\"\n(the actual move selection) that collects a reward, rather than all \"arm\npulls\". Therefore, it makes more sense to minimize the simple regret, as\nopposed to the cumulative regret. We begin by introducing policies for\nmulti-armed bandits with lower finite-time and asymptotic simple regret than\nUCB, using it to develop a two-stage scheme (SR+CR) for MCTS which outperforms\nUCT empirically.\n  Optimizing the sampling process is itself a metareasoning problem, a solution\nof which can use value of information (VOI) techniques. Although the theory of\nVOI for search exists, applying it to MCTS is non-trivial, as typical myopic\nassumptions fail. Lacking a complete working VOI theory for MCTS, we\nnevertheless propose a sampling scheme that is \"aware\" of VOI, achieving an\nalgorithm that in empirical evaluation outperforms both UCT and the other\nproposed algorithms.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "VOI-aware MCTS",
        "authors": [
            "David Tolpin",
            "Solomon Eyal Shimony"
        ],
        "summary": "UCT, a state-of-the art algorithm for Monte Carlo tree search (MCTS) in games\nand Markov decision processes, is based on UCB1, a sampling policy for the\nMulti-armed Bandit problem (MAB) that minimizes the cumulative regret. However,\nsearch differs from MAB in that in MCTS it is usually only the final \"arm pull\"\n(the actual move selection) that collects a reward, rather than all \"arm\npulls\". In this paper, an MCTS sampling policy based on Value of Information\n(VOI) estimates of rollouts is suggested. Empirical evaluation of the policy\nand comparison to UCB1 and UCT is performed on random MAB instances as well as\non Computer Go.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Back to the Basics: Bayesian extensions of IRT outperform neural\n  networks for proficiency estimation",
        "authors": [
            "Kevin H. Wilson",
            "Yan Karklin",
            "Bojian Han",
            "Chaitanya Ekanadham"
        ],
        "summary": "Estimating student proficiency is an important task for computer based\nlearning systems. We compare a family of IRT-based proficiency estimation\nmethods to Deep Knowledge Tracing (DKT), a recently proposed recurrent neural\nnetwork model with promising initial results. We evaluate how well each model\npredicts a student's future response given previous responses using two\npublicly available and one proprietary data set. We find that IRT-based methods\nconsistently matched or outperformed DKT across all data sets at the finest\nlevel of content granularity that was tractable for them to be trained on. A\nhierarchical extension of IRT that captured item grouping structure performed\nbest overall. When data sets included non-trivial autocorrelations in student\nresponse patterns, a temporal extension of IRT improved performance over\nstandard IRT while the RNN-based method did not. We conclude that IRT-based\nmodels provide a simpler, better-performing alternative to existing RNN-based\nmodels of student interaction data while also affording more interpretability\nand guarantees due to their formulation as Bayesian probabilistic models.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Efficient Classification of Multi-Labelled Text Streams by Clashing",
        "authors": [
            "Ricardo \u00d1anculef",
            "Ilias Flaounas",
            "Nello Cristianini"
        ],
        "summary": "We present a method for the classification of multi-labelled text documents\nexplicitly designed for data stream applications that require to process a\nvirtually infinite sequence of data using constant memory and constant\nprocessing time. Our method is composed of an online procedure used to\nefficiently map text into a low-dimensional feature space and a partition of\nthis space into a set of regions for which the system extracts and keeps\nstatistics used to predict multi-label text annotations. Documents are fed into\nthe system as a sequence of words, mapped to a region of the partition, and\nannotated using the statistics computed from the labelled instances colliding\nin the same region. This approach is referred to as clashing. We illustrate the\nmethod in real-world text data, comparing the results with those obtained using\nother text classifiers. In addition, we provide an analysis about the effect of\nthe representation space dimensionality on the predictive performance of the\nsystem. Our results show that the online embedding indeed approximates the\ngeometry of the full corpus-wise TF and TF-IDF space. The model obtains\ncompetitive F measures with respect to the most accurate methods, using\nsignificantly fewer computational resources. In addition, the method achieves a\nhigher macro-averaged F measure than methods with similar running time.\nFurthermore, the system is able to learn faster than the other methods from\npartially labelled streams.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Compositional Planning Using Optimal Option Models",
        "authors": [
            "David Silver",
            "Kamil Ciosek"
        ],
        "summary": "In this paper we introduce a framework for option model composition. Option\nmodels are temporal abstractions that, like macro-operators in classical\nplanning, jump directly from a start state to an end state. Prior work has\nfocused on constructing option models from primitive actions, by intra-option\nmodel learning; or on using option models to construct a value function, by\ninter-option planning. We present a unified view of intra- and inter-option\nmodel learning, based on a major generalisation of the Bellman equation. Our\nfundamental operation is the recursive composition of option models into other\noption models. This key idea enables compositional planning over many levels of\nabstraction. We illustrate our framework using a dynamic programming algorithm\nthat simultaneously constructs optimal option models for multiple subgoals, and\nalso searches over those option models to provide rapid progress towards other\nsubgoals.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Sequential Update of Bayesian Network Structure",
        "authors": [
            "Nir Friedman",
            "Moises Goldszmidt"
        ],
        "summary": "There is an obvious need for improving the performance and accuracy of a\nBayesian network as new data is observed. Because of errors in model\nconstruction and changes in the dynamics of the domains, we cannot afford to\nignore the information in new data. While sequential update of parameters for a\nfixed structure can be accomplished using standard techniques, sequential\nupdate of network structure is still an open problem. In this paper, we\ninvestigate sequential update of Bayesian networks were both parameters and\nstructure are expected to change. We introduce a new approach that allows for\nthe flexible manipulation of the tradeoff between the quality of the learned\nnetworks and the amount of information that is maintained about past\nobservations. We formally describe our approach including the necessary\nmodifications to the scoring functions for learning Bayesian networks, evaluate\nits effectiveness through an empirical study, and extend it to the case of\nmissing data.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "POWERPLAY: Training an Increasingly General Problem Solver by\n  Continually Searching for the Simplest Still Unsolvable Problem",
        "authors": [
            "J\u00fcrgen Schmidhuber"
        ],
        "summary": "Most of computer science focuses on automatically solving given computational\nproblems. I focus on automatically inventing or discovering problems in a way\ninspired by the playful behavior of animals and humans, to train a more and\nmore general problem solver from scratch in an unsupervised fashion. Consider\nthe infinite set of all computable descriptions of tasks with possibly\ncomputable solutions. The novel algorithmic framework POWERPLAY (2011)\ncontinually searches the space of possible pairs of new tasks and modifications\nof the current problem solver, until it finds a more powerful problem solver\nthat provably solves all previously learned tasks plus the new one, while the\nunmodified predecessor does not. Wow-effects are achieved by continually making\npreviously learned skills more efficient such that they require less time and\nspace. New skills may (partially) re-use previously learned skills. POWERPLAY's\nsearch orders candidate pairs of tasks and solver modifications by their\nconditional computational (time & space) complexity, given the stored\nexperience so far. The new task and its corresponding task-solving skill are\nthose first found and validated. The computational costs of validating new\ntasks need not grow with task repertoire size. POWERPLAY's ongoing search for\nnovelty keeps breaking the generalization abilities of its present solver. This\nis related to Goedel's sequence of increasingly powerful formal theories based\non adding formerly unprovable statements to the axioms without affecting\npreviously provable theorems. The continually increasing repertoire of problem\nsolving procedures can be exploited by a parallel search for solutions to\nadditional externally posed tasks. POWERPLAY may be viewed as a greedy but\npractical implementation of basic principles of creativity. A first\nexperimental analysis can be found in separate papers [53,54].",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Ranking Algorithms by Performance",
        "authors": [
            "Lars Kotthoff"
        ],
        "summary": "A common way of doing algorithm selection is to train a machine learning\nmodel and predict the best algorithm from a portfolio to solve a particular\nproblem. While this method has been highly successful, choosing only a single\nalgorithm has inherent limitations -- if the choice was bad, no remedial action\ncan be taken and parallelism cannot be exploited, to name but a few problems.\nIn this paper, we investigate how to predict the ranking of the portfolio\nalgorithms on a particular problem. This information can be used to choose the\nsingle best algorithm, but also to allocate resources to the algorithms\naccording to their rank. We evaluate a range of approaches to predict the\nranking of a set of algorithms on a problem. We furthermore introduce a\nframework for categorizing ranking predictions that allows to judge the\nexpressiveness of the predictive output. Our experimental evaluation\ndemonstrates on a range of data sets from the literature that it is beneficial\nto consider the relationship between algorithms when predicting rankings. We\nfurthermore show that relatively naive approaches deliver rankings of good\nquality already.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Extreme State Aggregation Beyond MDPs",
        "authors": [
            "Marcus Hutter"
        ],
        "summary": "We consider a Reinforcement Learning setup where an agent interacts with an\nenvironment in observation-reward-action cycles without any (esp.\\ MDP)\nassumptions on the environment. State aggregation and more generally feature\nreinforcement learning is concerned with mapping histories/raw-states to\nreduced/aggregated states. The idea behind both is that the resulting reduced\nprocess (approximately) forms a small stationary finite-state MDP, which can\nthen be efficiently solved or learnt. We considerably generalize existing\naggregation results by showing that even if the reduced process is not an MDP,\nthe (q-)value functions and (optimal) policies of an associated MDP with same\nstate-space size solve the original problem, as long as the solution can\napproximately be represented as a function of the reduced states. This implies\nan upper bound on the required state space size that holds uniformly for all RL\nproblems. It may also explain why RL algorithms designed for MDPs sometimes\nperform well beyond MDPs.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Falling Rule Lists",
        "authors": [
            "Fulton Wang",
            "Cynthia Rudin"
        ],
        "summary": "Falling rule lists are classification models consisting of an ordered list of\nif-then rules, where (i) the order of rules determines which example should be\nclassified by each rule, and (ii) the estimated probability of success\ndecreases monotonically down the list. These kinds of rule lists are inspired\nby healthcare applications where patients would be stratified into risk sets\nand the highest at-risk patients should be considered first. We provide a\nBayesian framework for learning falling rule lists that does not rely on\ntraditional greedy decision tree learning methods.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "On the Computability of Solomonoff Induction and Knowledge-Seeking",
        "authors": [
            "Jan Leike",
            "Marcus Hutter"
        ],
        "summary": "Solomonoff induction is held as a gold standard for learning, but it is known\nto be incomputable. We quantify its incomputability by placing various flavors\nof Solomonoff's prior M in the arithmetical hierarchy. We also derive\ncomputability bounds for knowledge-seeking agents, and give a limit-computable\nweakly asymptotically optimal reinforcement learning agent.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Bad Universal Priors and Notions of Optimality",
        "authors": [
            "Jan Leike",
            "Marcus Hutter"
        ],
        "summary": "A big open question of algorithmic information theory is the choice of the\nuniversal Turing machine (UTM). For Kolmogorov complexity and Solomonoff\ninduction we have invariance theorems: the choice of the UTM changes bounds\nonly by a constant. For the universally intelligent agent AIXI (Hutter, 2005)\nno invariance theorem is known. Our results are entirely negative: we discuss\ncases in which unlucky or adversarial choices of the UTM cause AIXI to\nmisbehave drastically. We show that Legg-Hutter intelligence and thus balanced\nPareto optimality is entirely subjective, and that every policy is Pareto\noptimal in the class of all computable environments. This undermines all\nexisting optimality properties for AIXI. While it may still serve as a gold\nstandard for AI, our results imply that AIXI is a relative theory, dependent on\nthe choice of the UTM.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Learning Shared Representations in Multi-task Reinforcement Learning",
        "authors": [
            "Diana Borsa",
            "Thore Graepel",
            "John Shawe-Taylor"
        ],
        "summary": "We investigate a paradigm in multi-task reinforcement learning (MT-RL) in\nwhich an agent is placed in an environment and needs to learn to perform a\nseries of tasks, within this space. Since the environment does not change,\nthere is potentially a lot of common ground amongst tasks and learning to solve\nthem individually seems extremely wasteful. In this paper, we explicitly model\nand learn this shared structure as it arises in the state-action value space.\nWe will show how one can jointly learn optimal value-functions by modifying the\npopular Value-Iteration and Policy-Iteration procedures to accommodate this\nshared representation assumption and leverage the power of multi-task\nsupervised learning. Finally, we demonstrate that the proposed model and\ntraining procedures, are able to infer good value functions, even under low\nsamples regimes. In addition to data efficiency, we will show in our analysis,\nthat learning abstractions of the state space jointly across tasks leads to\nmore robust, transferable representations with the potential for better\ngeneralization. this shared representation assumption and leverage the power of\nmulti-task supervised learning. Finally, we demonstrate that the proposed model\nand training procedures, are able to infer good value functions, even under low\nsamples regimes. In addition to data efficiency, we will show in our analysis,\nthat learning abstractions of the state space jointly across tasks leads to\nmore robust, transferable representations with the potential for better\ngeneralization.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Possibilistic Networks: Parameters Learning from Imprecise Data and\n  Evaluation strategy",
        "authors": [
            "Maroua Haddad",
            "Philippe Leray",
            "Nahla Ben Amor"
        ],
        "summary": "There has been an ever-increasing interest in multidisciplinary research on\nrepresenting and reasoning with imperfect data. Possibilistic networks present\none of the powerful frameworks of interest for representing uncertain and\nimprecise information. This paper covers the problem of their parameters\nlearning from imprecise datasets, i.e., containing multi-valued data. We\npropose in the rst part of this paper a possibilistic networks sampling\nprocess. In the second part, we propose a likelihood function which explores\nthe link between random sets theory and possibility theory. This function is\nthen deployed to parametrize possibilistic networks.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Dynamic Key-Value Memory Networks for Knowledge Tracing",
        "authors": [
            "Jiani Zhang",
            "Xingjian Shi",
            "Irwin King",
            "Dit-Yan Yeung"
        ],
        "summary": "Knowledge Tracing (KT) is a task of tracing evolving knowledge state of\nstudents with respect to one or more concepts as they engage in a sequence of\nlearning activities. One important purpose of KT is to personalize the practice\nsequence to help students learn knowledge concepts efficiently. However,\nexisting methods such as Bayesian Knowledge Tracing and Deep Knowledge Tracing\neither model knowledge state for each predefined concept separately or fail to\npinpoint exactly which concepts a student is good at or unfamiliar with. To\nsolve these problems, this work introduces a new model called Dynamic Key-Value\nMemory Networks (DKVMN) that can exploit the relationships between underlying\nconcepts and directly output a student's mastery level of each concept. Unlike\nstandard memory-augmented neural networks that facilitate a single memory\nmatrix or two static memory matrices, our model has one static matrix called\nkey, which stores the knowledge concepts and the other dynamic matrix called\nvalue, which stores and updates the mastery levels of corresponding concepts.\nExperiments show that our model consistently outperforms the state-of-the-art\nmodel in a range of KT datasets. Moreover, the DKVMN model can automatically\ndiscover underlying concepts of exercises typically performed by human\nannotations and depict the changing knowledge state of a student.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Bayesian Unification of Gradient and Bandit-based Learning for\n  Accelerated Global Optimisation",
        "authors": [
            "Ole-Christoffer Granmo"
        ],
        "summary": "Bandit based optimisation has a remarkable advantage over gradient based\napproaches due to their global perspective, which eliminates the danger of\ngetting stuck at local optima. However, for continuous optimisation problems or\nproblems with a large number of actions, bandit based approaches can be\nhindered by slow learning. Gradient based approaches, on the other hand,\nnavigate quickly in high-dimensional continuous spaces through local\noptimisation, following the gradient in fine grained steps. Yet, apart from\nbeing susceptible to local optima, these schemes are less suited for online\nlearning due to their reliance on extensive trial-and-error before the optimum\ncan be identified. In this paper, we propose a Bayesian approach that unifies\nthe above two paradigms in one single framework, with the aim of combining\ntheir advantages. At the heart of our approach we find a stochastic linear\napproximation of the function to be optimised, where both the gradient and\nvalues of the function are explicitly captured. This allows us to learn from\nboth noisy function and gradient observations, and predict these properties\nacross the action space to support optimisation. We further propose an\naccompanying bandit driven exploration scheme that uses Bayesian credible\nbounds to trade off exploration against exploitation. Our empirical results\ndemonstrate that by unifying bandit and gradient based learning, one obtains\nconsistently improved performance across a wide spectrum of problem\nenvironments. Furthermore, even when gradient feedback is unavailable, the\nflexibility of our model, including gradient prediction, still allows us\noutperform competing approaches, although with a smaller margin. Due to the\npervasiveness of bandit based optimisation, our scheme opens up for improved\nperformance both in meta-optimisation and in applications where gradient\nrelated information is readily available.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Bridging the Gap between Probabilistic and Deterministic Models: A\n  Simulation Study on a Variational Bayes Predictive Coding Recurrent Neural\n  Network Model",
        "authors": [
            "Ahmadreza Ahmadi",
            "Jun Tani"
        ],
        "summary": "The current paper proposes a novel variational Bayes predictive coding RNN\nmodel, which can learn to generate fluctuated temporal patterns from exemplars.\nThe model learns to maximize the lower bound of the weighted sum of the\nregularization and reconstruction error terms. We examined how this weighting\ncan affect development of different types of information processing while\nlearning fluctuated temporal patterns. Simulation results show that strong\nweighting of the reconstruction term causes the development of deterministic\nchaos for imitating the randomness observed in target sequences, while strong\nweighting of the regularization term causes the development of stochastic\ndynamics imitating probabilistic processes observed in targets. Moreover,\nresults indicate that the most generalized learning emerges between these two\nextremes. The paper concludes with implications in terms of the underlying\nneuronal mechanisms for autism spectrum disorder and for free action.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Elements of Effective Deep Reinforcement Learning towards Tactical\n  Driving Decision Making",
        "authors": [
            "Jingchu Liu",
            "Pengfei Hou",
            "Lisen Mu",
            "Yinan Yu",
            "Chang Huang"
        ],
        "summary": "Tactical driving decision making is crucial for autonomous driving systems\nand has attracted considerable interest in recent years. In this paper, we\npropose several practical components that can speed up deep reinforcement\nlearning algorithms towards tactical decision making tasks: 1) non-uniform\naction skipping as a more stable alternative to action-repetition frame\nskipping, 2) a counter-based penalty for lanes on which ego vehicle has less\nright-of-road, and 3) heuristic inference-time action masking for apparently\nundesirable actions. We evaluate the proposed components in a realistic driving\nsimulator and compare them with several baselines. Results show that the\nproposed scheme provides superior performance in terms of safety, efficiency,\nand comfort.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "L2-Nonexpansive Neural Networks",
        "authors": [
            "Haifeng Qian",
            "Mark N. Wegman"
        ],
        "summary": "This paper proposes a class of well-conditioned neural networks in which a\nunit amount of change in the inputs causes at most a unit amount of change in\nthe outputs or any of the internal layers. We develop the known methodology of\ncontrolling Lipschitz constants to realize its full potential in maximizing\nrobustness: our linear and convolution layers subsume those in the previous\nParseval networks as a special case and allow greater degrees of freedom;\naggregation, pooling, splitting and other operators are adapted in new ways,\nand a new loss function is proposed, all for the purpose of improving\nrobustness. With MNIST and CIFAR-10 classifiers, we demonstrate a number of\nadvantages. Without needing any adversarial training, the proposed classifiers\nexceed the state of the art in robustness against white-box L2-bounded\nadversarial attacks. Their outputs are quantitatively more meaningful than\nordinary networks and indicate levels of confidence. They are also free of\nexploding gradients, among other desirable properties.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "Computational Theories of Curiosity-Driven Learning",
        "authors": [
            "Pierre-Yves Oudeyer"
        ],
        "summary": "What are the functions of curiosity? What are the mechanisms of\ncuriosity-driven learning? We approach these questions using concepts and tools\nfrom machine learning and developmental robotics. We argue that\ncuriosity-driven learning enables organisms to make discoveries to solve\ncomplex problems with rare or deceptive rewards. By fostering exploration and\ndiscovery of a diversity of behavioural skills, and ignoring these rewards,\ncuriosity can be efficient to bootstrap learning when there is no information,\nor deceptive information, about local improvement towards these problems. We\nreview both normative and heuristic computational frameworks used to understand\nthe mechanisms of curiosity in humans, conceptualizing the child as a\nsense-making organism. These frameworks enable us to discuss the bi-directional\ncausal links between curiosity and learning, and to provide new hypotheses\nabout the fundamental role of curiosity in self-organizing developmental\nstructures through curriculum learning. We present various developmental\nrobotics experiments that study these mechanisms in action, both supporting\nthese hypotheses and opening new research avenues in machine learning and\nartificial intelligence. Finally, we discuss challenges for the design of\nexperimental paradigms for studying curiosity in psychology and cognitive\nneuroscience. Keywords: Curiosity, intrinsic motivation, lifelong learning,\npredictions, world model, rewards, free-energy principle, learning progress,\nmachine learning, AI, developmental robotics, development, curriculum learning,\nself-organization.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "Evolving controllers for simulated car racing",
        "authors": [
            "Julian Togelius",
            "Simon M. Lucas"
        ],
        "summary": "This paper describes the evolution of controllers for racing a simulated\nradio-controlled car around a track, modelled on a real physical track. Five\ndifferent controller architectures were compared, based on neural networks,\nforce fields and action sequences. The controllers use either egocentric (first\nperson), Newtonian (third person) or no information about the state of the car\n(open-loop controller). The only controller that was able to evolve good racing\nbehaviour was based on a neural network acting on egocentric inputs.",
        "year": 2006,
        "label": "cs.NE"
    },
    {
        "title": "An Elementary Analysis of the Probability That a Binomial Random\n  Variable Exceeds Its Expectation",
        "authors": [
            "Benjamin Doerr"
        ],
        "summary": "We give an elementary proof of the fact that a binomial random variable $X$\nwith parameters $n$ and $0.29/n \\le p < 1$ with probability at least $1/4$\nstrictly exceeds its expectation. We also show that for $1/n \\le p < 1 - 1/n$,\n$X$ exceeds its expectation by more than one with probability at least\n$0.0370$. Both probabilities approach $1/2$ when $np$ and $n(1-p)$ tend to\ninfinity.",
        "year": 2017,
        "label": "math.PR"
    },
    {
        "title": "Quantum Interference in Cognition: Structural Aspects of the Brain",
        "authors": [
            "Diederik Aerts",
            "Sandro Sozzo"
        ],
        "summary": "We identify the presence of typically quantum effects, namely 'superposition'\nand 'interference', in what happens when human concepts are combined, and\nprovide a quantum model in complex Hilbert space that represents faithfully\nexperimental data measuring the situation of combining concepts. Our model\nshows how 'interference of concepts' explains the effects of underextension and\noverextension when two concepts combine to the disjunction of these two\nconcepts. This result supports our earlier hypothesis that human thought has a\nsuperposed two-layered structure, one layer consisting of 'classical logical\nthought' and a superposed layer consisting of 'quantum conceptual thought'.\nPossible connections with recent findings of a 'grid-structure' for the brain\nare analyzed, and influences on the mind/brain relation, and consequences on\napplied disciplines, such as artificial intelligence and quantum computation,\nare considered.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Quantum and Concept Combination, Entangled Measurements and Prototype\n  Theory",
        "authors": [
            "Diederik Aerts"
        ],
        "summary": "We analyze the meaning of the violation of the marginal probability law for\nsituations of correlation measurements where entanglement is identified. We\nshow that for quantum theory applied to the cognitive realm such a violation\ndoes not lead to the type of problems commonly believed to occur in situations\nof quantum theory applied to the physical realm. We briefly situate our quantum\napproach for modeling concepts and their combinations with respect to the\nnotions of 'extension' and 'intension' in theories of meaning, and in existing\nconcept theories.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Quantum Entanglement in Concept Combinations",
        "authors": [
            "Diederik Aerts",
            "Sandro Sozzo"
        ],
        "summary": "Research in the application of quantum structures to cognitive science\nconfirms that these structures quite systematically appear in the dynamics of\nconcepts and their combinations and quantum-based models faithfully represent\nexperimental data of situations where classical approaches are problematical.\nIn this paper, we analyze the data we collected in an experiment on a specific\nconceptual combination, showing that Bell's inequalities are violated in the\nexperiment. We present a new refined entanglement scheme to model these data\nwithin standard quantum theory rules, where 'entangled measurements and\nentangled evolutions' occur, in addition to the expected 'entangled states',\nand present a full quantum representation in complex Hilbert space of the data.\nThis stronger form of entanglement in measurements and evolutions might have\nrelevant applications in the foundations of quantum theory, as well as in the\ninterpretation of nonlocality tests. It could indeed explain some\nnon-negligible 'anomalies' identified in EPR-Bell experiments.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Automatic Extraction of Causal Relations from Natural Language Texts: A\n  Comprehensive Survey",
        "authors": [
            "Nabiha Asghar"
        ],
        "summary": "Automatic extraction of cause-effect relationships from natural language\ntexts is a challenging open problem in Artificial Intelligence. Most of the\nearly attempts at its solution used manually constructed linguistic and\nsyntactic rules on small and domain-specific data sets. However, with the\nadvent of big data, the availability of affordable computing power and the\nrecent popularization of machine learning, the paradigm to tackle this problem\nhas slowly shifted. Machines are now expected to learn generic causal\nextraction rules from labelled data with minimal supervision, in a domain\nindependent-manner. In this paper, we provide a comprehensive survey of causal\nrelation extraction techniques from both paradigms, and analyse their relative\nstrengths and weaknesses, with recommendations for future work.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Efficient Online Inference for Infinite Evolutionary Cluster models with\n  Applications to Latent Social Event Discovery",
        "authors": [
            "Wei Wei",
            "Kennth Joseph",
            "Kathleen Carley"
        ],
        "summary": "The Recurrent Chinese Restaurant Process (RCRP) is a powerful statistical\nmethod for modeling evolving clusters in large scale social media data. With\nthe RCRP, one can allow both the number of clusters and the cluster parameters\nin a model to change over time. However, application of the RCRP has largely\nbeen limited due to the non-conjugacy between the cluster evolutionary priors\nand the Multinomial likelihood. This non-conjugacy makes inference di cult and\nrestricts the scalability of models which use the RCRP, leading to the RCRP\nbeing applied only in simple problems, such as those that can be approximated\nby a single Gaussian emission. In this paper, we provide a novel solution for\nthe non-conjugacy issues for the RCRP and an example of how to leverage our\nsolution for one speci c problem - the social event discovery problem. By\nutilizing Sequential Monte Carlo methods in inference, our approach can be\nmassively paralleled and is highly scalable, to the extent it can work on tens\nof millions of documents. We are able to generate high quality topical and\nlocation distributions of the clusters that can be directly interpreted as real\nsocial events, and our experimental results suggest that the approaches\nproposed achieve much better predictive performance than techniques reported in\nprior work. We also demonstrate how the techniques we develop can be used in a\nmuch more general ways toward similar problems.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "TIP: Typifying the Interpretability of Procedures",
        "authors": [
            "Amit Dhurandhar",
            "Vijay Iyengar",
            "Ronny Luss",
            "Karthikeyan Shanmugam"
        ],
        "summary": "We provide a novel notion of what it means to be interpretable, looking past\nthe usual association with human understanding. Our key insight is that\ninterpretability is not an absolute concept and so we define it relative to a\ntarget model, which may or may not be a human. We define a framework that\nallows for comparing interpretable procedures by linking it to important\npractical aspects such as accuracy and robustness. We characterize many of the\ncurrent state-of-the-art interpretable methods in our framework portraying its\ngeneral applicability. Finally, principled interpretable strategies are\nproposed and empirically evaluated on synthetic data, as well as on the largest\npublic olfaction dataset that was made recently available \\cite{olfs}. We also\nexperiment on MNIST with a simple target model and different oracle models of\nvarying complexity. This leads to the insight that the improvement in the\ntarget model is not only a function of the oracle models performance, but also\nits relative complexity with respect to the target model.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Beyond the technical challenges for deploying Machine Learning solutions\n  in a software company",
        "authors": [
            "Ilias Flaounas"
        ],
        "summary": "Recently software development companies started to embrace Machine Learning\n(ML) techniques for introducing a series of advanced functionality in their\nproducts such as personalisation of the user experience, improved search,\ncontent recommendation and automation. The technical challenges for tackling\nthese problems are heavily researched in literature. A less studied area is a\npragmatic approach to the role of humans in a complex modern industrial\nenvironment where ML based systems are developed. Key stakeholders affect the\nsystem from inception and up to operation and maintenance. Product managers\nwant to embed \"smart\" experiences for their users and drive the decisions on\nwhat should be built next; software engineers are challenged to build or\nutilise ML software tools that require skills that are well outside of their\ncomfort zone; legal and risk departments may influence design choices and data\naccess; operations teams are requested to maintain ML systems which are\nnon-stationary in their nature and change behaviour over time; and finally ML\npractitioners should communicate with all these stakeholders to successfully\nbuild a reliable system. This paper discusses some of the challenges we faced\nin Atlassian as we started investing more in the ML space.",
        "year": 2017,
        "label": "cs.HC"
    },
    {
        "title": "A Categorical Approach for Recognizing Emotional Effects of Music",
        "authors": [
            "Mohsen Sahraei Ardakani",
            "Ehsan Arbabi"
        ],
        "summary": "Recently, digital music libraries have been developed and can be plainly\naccessed. Latest research showed that current organization and retrieval of\nmusic tracks based on album information are inefficient. Moreover, they\ndemonstrated that people use emotion tags for music tracks in order to search\nand retrieve them. In this paper, we discuss separability of a set of emotional\nlabels, proposed in the categorical emotion expression, using Fisher's\nseparation theorem. We determine a set of adjectives to tag music parts: happy,\nsad, relaxing, exciting, epic and thriller. Temporal, frequency and energy\nfeatures have been extracted from the music parts. It could be seen that the\nmaximum separability within the extracted features occurs between relaxing and\nepic music parts. Finally, we have trained a classifier using Support Vector\nMachines to automatically recognize and generate emotional labels for a music\npart. Accuracy for recognizing each label has been calculated; where the\nresults show that epic music can be recognized more accurately (77.4%),\ncomparing to the other types of music.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "ROTUNDE - A Smart Meeting Cinematography Initiative: Tools, Datasets,\n  and Benchmarks for Cognitive Interpretation and Control",
        "authors": [
            "Mehul Bhatt",
            "Jakob Suchan",
            "Christian Freksa"
        ],
        "summary": "We construe smart meeting cinematography with a focus on professional\nsituations such as meetings and seminars, possibly conducted in a distributed\nmanner across socio-spatially separated groups. The basic objective in smart\nmeeting cinematography is to interpret professional interactions involving\npeople, and automatically produce dynamic recordings of discussions, debates,\npresentations etc in the presence of multiple communication modalities. Typical\nmodalities include gestures (e.g., raising one's hand for a question,\napplause), voice and interruption, electronic apparatus (e.g., pressing a\nbutton), movement (e.g., standing-up, moving around) etc. ROTUNDE, an instance\nof smart meeting cinematography concept, aims to: (a) develop\nfunctionality-driven benchmarks with respect to the interpretation and control\ncapabilities of human-cinematographers, real-time video editors, surveillance\npersonnel, and typical human performance in everyday situations; (b) Develop\ngeneral tools for the commonsense cognitive interpretation of dynamic scenes\nfrom the viewpoint of visuo-spatial cognition centred perceptual\nnarrativisation. Particular emphasis is placed on declarative representations\nand interfacing mechanisms that seamlessly integrate within large-scale\ncognitive (interaction) systems and companion technologies consisting of\ndiverse AI sub-components. For instance, the envisaged tools would provide\ngeneral capabilities for high-level commonsense reasoning about space, events,\nactions, change, and interaction.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Cognitive Interpretation of Everyday Activities: Toward Perceptual\n  Narrative Based Visuo-Spatial Scene Interpretation",
        "authors": [
            "Mehul Bhatt",
            "Jakob Suchan",
            "Carl Schultz"
        ],
        "summary": "We position a narrative-centred computational model for high-level knowledge\nrepresentation and reasoning in the context of a range of assistive\ntechnologies concerned with \"visuo-spatial perception and cognition\" tasks. Our\nproposed narrative model encompasses aspects such as \\emph{space, events,\nactions, change, and interaction} from the viewpoint of commonsense reasoning\nand learning in large-scale cognitive systems. The broad focus of this paper is\non the domain of \"human-activity interpretation\" in smart environments, ambient\nintelligence etc. In the backdrop of a \"smart meeting cinematography\" domain,\nwe position the proposed narrative model, preliminary work on perceptual\nnarrativisation, and the immediate outlook on constructing general-purpose\nopen-source tools for perceptual narrativisation.\n  ACM Classification: I.2 Artificial Intelligence: I.2.0 General -- Cognitive\nSimulation, I.2.4 Knowledge Representation Formalisms and Methods, I.2.10\nVision and Scene Understanding: Architecture and control structures, Motion,\nPerceptual reasoning, Shape, Video analysis\n  General keywords: cognitive systems; human-computer interaction; spatial\ncognition and computation; commonsense reasoning; spatial and temporal\nreasoning; assistive technologies",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Yum-me: A Personalized Nutrient-based Meal Recommender System",
        "authors": [
            "Longqi Yang",
            "Cheng-Kang Hsieh",
            "Hongjian Yang",
            "Nicola Dell",
            "Serge Belongie",
            "Curtis Cole",
            "Deborah Estrin"
        ],
        "summary": "Nutrient-based meal recommendations have the potential to help individuals\nprevent or manage conditions such as diabetes and obesity. However, learning\npeople's food preferences and making recommendations that simultaneously appeal\nto their palate and satisfy nutritional expectations are challenging. Existing\napproaches either only learn high-level preferences or require a prolonged\nlearning period. We propose Yum-me, a personalized nutrient-based meal\nrecommender system designed to meet individuals' nutritional expectations,\ndietary restrictions, and fine-grained food preferences. Yum-me enables a\nsimple and accurate food preference profiling procedure via a visual quiz-based\nuser interface, and projects the learned profile into the domain of\nnutritionally appropriate food options to find ones that will appeal to the\nuser. We present the design and implementation of Yum-me, and further describe\nand evaluate two innovative contributions. The first contriution is an open\nsource state-of-the-art food image analysis model, named FoodDist. We\ndemonstrate FoodDist's superior performance through careful benchmarking and\ndiscuss its applicability across a wide array of dietary applications. The\nsecond contribution is a novel online learning framework that learns food\npreference from item-wise and pairwise image comparisons. We evaluate the\nframework in a field study of 227 anonymous users and demonstrate that it\noutperforms other baselines by a significant margin. We further conducted an\nend-to-end validation of the feasibility and effectiveness of Yum-me through a\n60-person user study, in which Yum-me improves the recommendation acceptance\nrate by 42.63%.",
        "year": 2016,
        "label": "cs.HC"
    },
    {
        "title": "Sharing deep generative representation for perceived image\n  reconstruction from human brain activity",
        "authors": [
            "Changde Du",
            "Changying Du",
            "Huiguang He"
        ],
        "summary": "Decoding human brain activities via functional magnetic resonance imaging\n(fMRI) has gained increasing attention in recent years. While encouraging\nresults have been reported in brain states classification tasks, reconstructing\nthe details of human visual experience still remains difficult. Two main\nchallenges that hinder the development of effective models are the perplexing\nfMRI measurement noise and the high dimensionality of limited data instances.\nExisting methods generally suffer from one or both of these issues and yield\ndissatisfactory results. In this paper, we tackle this problem by casting the\nreconstruction of visual stimulus as the Bayesian inference of missing view in\na multiview latent variable model. Sharing a common latent representation, our\njoint generative model of external stimulus and brain response is not only\n\"deep\" in extracting nonlinear features from visual images, but also powerful\nin capturing correlations among voxel activities of fMRI recordings. The\nnonlinearity and deep structure endow our model with strong representation\nability, while the correlations of voxel activities are critical for\nsuppressing noise and improving prediction. We devise an efficient variational\nBayesian method to infer the latent variables and the model parameters. To\nfurther improve the reconstruction accuracy, the latent representations of\ntesting instances are enforced to be close to that of their neighbours from the\ntraining set via posterior regularization. Experiments on three fMRI recording\ndatasets demonstrate that our approach can more accurately reconstruct visual\nstimuli.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Visual Explanation by High-Level Abduction: On Answer-Set Programming\n  Driven Reasoning about Moving Objects",
        "authors": [
            "Jakob Suchan",
            "Mehul Bhatt",
            "Przemys\u0142aw Wa\u0142\u0119ga",
            "Carl Schultz"
        ],
        "summary": "We propose a hybrid architecture for systematically computing robust visual\nexplanation(s) encompassing hypothesis formation, belief revision, and default\nreasoning with video data. The architecture consists of two tightly integrated\nsynergistic components: (1) (functional) answer set programming based abductive\nreasoning with space-time tracklets as native entities; and (2) a visual\nprocessing pipeline for detection based object tracking and motion analysis.\n  We present the formal framework, its general implementation as a\n(declarative) method in answer set programming, and an example application and\nevaluation based on two diverse video datasets: the MOTChallenge benchmark\ndeveloped by the vision community, and a recently developed Movie Dataset.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Mismatch in the Classification of Linear Subspaces: Sufficient\n  Conditions for Reliable Classification",
        "authors": [
            "Jure Sokolic",
            "Francesco Renna",
            "Robert Calderbank",
            "Miguel R. D. Rodrigues"
        ],
        "summary": "This paper considers the classification of linear subspaces with mismatched\nclassifiers. In particular, we assume a model where one observes signals in the\npresence of isotropic Gaussian noise and the distribution of the signals\nconditioned on a given class is Gaussian with a zero mean and a low-rank\ncovariance matrix. We also assume that the classifier knows only a mismatched\nversion of the parameters of input distribution in lieu of the true parameters.\nBy constructing an asymptotic low-noise expansion of an upper bound to the\nerror probability of such a mismatched classifier, we provide sufficient\nconditions for reliable classification in the low-noise regime that are able to\nsharply predict the absence of a classification error floor. Such conditions\nare a function of the geometry of the true signal distribution, the geometry of\nthe mismatched signal distributions as well as the interplay between such\ngeometries, namely, the principal angles and the overlap between the true and\nthe mismatched signal subspaces. Numerical results demonstrate that our\nconditions for reliable classification can sharply predict the behavior of a\nmismatched classifier both with synthetic data and in a motion segmentation and\na hand-written digit classification applications.",
        "year": 2015,
        "label": "cs.IT"
    },
    {
        "title": "A Theory of Universal Artificial Intelligence based on Algorithmic\n  Complexity",
        "authors": [
            "Marcus Hutter"
        ],
        "summary": "Decision theory formally solves the problem of rational agents in uncertain\nworlds if the true environmental prior probability distribution is known.\nSolomonoff's theory of universal induction formally solves the problem of\nsequence prediction for unknown prior distribution. We combine both ideas and\nget a parameterless theory of universal Artificial Intelligence. We give strong\narguments that the resulting AIXI model is the most intelligent unbiased agent\npossible. We outline for a number of problem classes, including sequence\nprediction, strategic games, function minimization, reinforcement and\nsupervised learning, how the AIXI model can formally solve them. The major\ndrawback of the AIXI model is that it is uncomputable. To overcome this\nproblem, we construct a modified algorithm AIXI-tl, which is still effectively\nmore intelligent than any other time t and space l bounded agent. The\ncomputation time of AIXI-tl is of the order tx2^l. Other discussed topics are\nformal definitions of intelligence order relations, the horizon problem and\nrelations of the AIXI theory to other AI approaches.",
        "year": 2000,
        "label": "cs.AI"
    },
    {
        "title": "General Loss Bounds for Universal Sequence Prediction",
        "authors": [
            "Marcus Hutter"
        ],
        "summary": "The Bayesian framework is ideally suited for induction problems. The\nprobability of observing $x_t$ at time $t$, given past observations\n$x_1...x_{t-1}$ can be computed with Bayes' rule if the true distribution $\\mu$\nof the sequences $x_1x_2x_3...$ is known. The problem, however, is that in many\ncases one does not even have a reasonable estimate of the true distribution. In\norder to overcome this problem a universal distribution $\\xi$ is defined as a\nweighted sum of distributions $\\mu_i\\inM$, where $M$ is any countable set of\ndistributions including $\\mu$. This is a generalization of Solomonoff\ninduction, in which $M$ is the set of all enumerable semi-measures. Systems\nwhich predict $y_t$, given $x_1...x_{t-1}$ and which receive loss $l_{x_t y_t}$\nif $x_t$ is the true next symbol of the sequence are considered. It is proven\nthat using the universal $\\xi$ as a prior is nearly as good as using the\nunknown true distribution $\\mu$. Furthermore, games of chance, defined as a\nsequence of bets, observations, and rewards are studied. The time needed to\nreach the winning zone is bounded in terms of the relative entropy of $\\mu$ and\n$\\xi$. Extensions to arbitrary alphabets, partial and delayed prediction, and\nmore active systems are discussed.",
        "year": 2001,
        "label": "cs.AI"
    },
    {
        "title": "Fitness Uniform Selection to Preserve Genetic Diversity",
        "authors": [
            "Marcus Hutter"
        ],
        "summary": "In evolutionary algorithms, the fitness of a population increases with time\nby mutating and recombining individuals and by a biased selection of more fit\nindividuals. The right selection pressure is critical in ensuring sufficient\noptimization progress on the one hand and in preserving genetic diversity to be\nable to escape from local optima on the other. We propose a new selection\nscheme, which is uniform in the fitness values. It generates selection pressure\ntowards sparsely populated fitness regions, not necessarily towards higher\nfitness, as is the case for all other selection schemes. We show that the new\nselection scheme can be much more effective than standard selection schemes.",
        "year": 2001,
        "label": "cs.AI"
    },
    {
        "title": "Self-Optimizing and Pareto-Optimal Policies in General Environments\n  based on Bayes-Mixtures",
        "authors": [
            "Marcus Hutter"
        ],
        "summary": "The problem of making sequential decisions in unknown probabilistic\nenvironments is studied. In cycle $t$ action $y_t$ results in perception $x_t$\nand reward $r_t$, where all quantities in general may depend on the complete\nhistory. The perception $x_t$ and reward $r_t$ are sampled from the (reactive)\nenvironmental probability distribution $\\mu$. This very general setting\nincludes, but is not limited to, (partial observable, k-th order) Markov\ndecision processes. Sequential decision theory tells us how to act in order to\nmaximize the total expected reward, called value, if $\\mu$ is known.\nReinforcement learning is usually used if $\\mu$ is unknown. In the Bayesian\napproach one defines a mixture distribution $\\xi$ as a weighted sum of\ndistributions $\\nu\\in\\M$, where $\\M$ is any class of distributions including\nthe true environment $\\mu$. We show that the Bayes-optimal policy $p^\\xi$ based\non the mixture $\\xi$ is self-optimizing in the sense that the average value\nconverges asymptotically for all $\\mu\\in\\M$ to the optimal value achieved by\nthe (infeasible) Bayes-optimal policy $p^\\mu$ which knows $\\mu$ in advance. We\nshow that the necessary condition that $\\M$ admits self-optimizing policies at\nall, is also sufficient. No other structural assumptions are made on $\\M$. As\nan example application, we discuss ergodic Markov decision processes, which\nallow for self-optimizing policies. Furthermore, we show that $p^\\xi$ is\nPareto-optimal in the sense that there is no other policy yielding higher or\nequal value in {\\em all} environments $\\nu\\in\\M$ and a strictly higher value in\nat least one.",
        "year": 2002,
        "label": "cs.AI"
    },
    {
        "title": "Universal Sequential Decisions in Unknown Environments",
        "authors": [
            "Marcus Hutter"
        ],
        "summary": "We give a brief introduction to the AIXI model, which unifies and overcomes\nthe limitations of sequential decision theory and universal Solomonoff\ninduction. While the former theory is suited for active agents in known\nenvironments, the latter is suited for passive prediction of unknown\nenvironments.",
        "year": 2003,
        "label": "cs.AI"
    },
    {
        "title": "Bridging the Gap between Reinforcement Learning and Knowledge\n  Representation: A Logical Off- and On-Policy Framework",
        "authors": [
            "Emad Saad"
        ],
        "summary": "Knowledge Representation is important issue in reinforcement learning. In\nthis paper, we bridge the gap between reinforcement learning and knowledge\nrepresentation, by providing a rich knowledge representation framework, based\non normal logic programs with answer set semantics, that is capable of solving\nmodel-free reinforcement learning problems for more complex do-mains and\nexploits the domain-specific knowledge. We prove the correctness of our\napproach. We show that the complexity of finding an offline and online policy\nfor a model-free reinforcement learning problem in our approach is NP-complete.\nMoreover, we show that any model-free reinforcement learning problem in MDP\nenvironment can be encoded as a SAT problem. The importance of that is\nmodel-free reinforcement",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "Decayed MCMC Filtering",
        "authors": [
            "Bhaskara Marthi",
            "Hanna Pasula",
            "Stuart Russell",
            "Yuval Peres"
        ],
        "summary": "Filtering---estimating the state of a partially observable Markov process\nfrom a sequence of observations---is one of the most widely studied problems in\ncontrol theory, AI, and computational statistics. Exact computation of the\nposterior distribution is generally intractable for large discrete systems and\nfor nonlinear continuous systems, so a good deal of effort has gone into\ndeveloping robust approximation algorithms. This paper describes a simple\nstochastic approximation algorithm for filtering called {em decayed MCMC}. The\nalgorithm applies Markov chain Monte Carlo sampling to the space of state\ntrajectories using a proposal distribution that favours flips of more recent\nstate variables. The formal analysis of the algorithm involves a generalization\nof standard coupling arguments for MCMC convergence. We prove that for any\nergodic underlying Markov process, the convergence time of decayed MCMC with\ninverse-polynomial decay remains bounded as the length of the observation\nsequence grows. We show experimentally that decayed MCMC is at least\ncompetitive with other approximation algorithms such as particle filtering.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Inference and learning in probabilistic logic programs using weighted\n  Boolean formulas",
        "authors": [
            "Daan Fierens",
            "Guy Van den Broeck",
            "Joris Renkens",
            "Dimitar Shterionov",
            "Bernd Gutmann",
            "Ingo Thon",
            "Gerda Janssens",
            "Luc De Raedt"
        ],
        "summary": "Probabilistic logic programs are logic programs in which some of the facts\nare annotated with probabilities. This paper investigates how classical\ninference and learning tasks known from the graphical model community can be\ntackled for probabilistic logic programs. Several such tasks such as computing\nthe marginals given evidence and learning from (partial) interpretations have\nnot really been addressed for probabilistic logic programs before.\n  The first contribution of this paper is a suite of efficient algorithms for\nvarious inference tasks. It is based on a conversion of the program and the\nqueries and evidence to a weighted Boolean formula. This allows us to reduce\nthe inference tasks to well-studied tasks such as weighted model counting,\nwhich can be solved using state-of-the-art methods known from the graphical\nmodel and knowledge compilation literature. The second contribution is an\nalgorithm for parameter estimation in the learning from interpretations\nsetting. The algorithm employs Expectation Maximization, and is built on top of\nthe developed inference algorithms.\n  The proposed approach is experimentally evaluated. The results show that the\ninference algorithms improve upon the state-of-the-art in probabilistic logic\nprogramming and that it is indeed possible to learn the parameters of a\nprobabilistic logic program from interpretations.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Feature Markov Decision Processes",
        "authors": [
            "Marcus Hutter"
        ],
        "summary": "General purpose intelligent learning agents cycle through (complex,non-MDP)\nsequences of observations, actions, and rewards. On the other hand,\nreinforcement learning is well-developed for small finite state Markov Decision\nProcesses (MDPs). So far it is an art performed by human designers to extract\nthe right state representation out of the bare observations, i.e. to reduce the\nagent setup to the MDP framework. Before we can think of mechanizing this\nsearch for suitable MDPs, we need a formal objective criterion. The main\ncontribution of this article is to develop such a criterion. I also integrate\nthe various parts into one learning algorithm. Extensions to more realistic\ndynamic Bayesian networks are developed in a companion article.",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "Feature Dynamic Bayesian Networks",
        "authors": [
            "Marcus Hutter"
        ],
        "summary": "Feature Markov Decision Processes (PhiMDPs) are well-suited for learning\nagents in general environments. Nevertheless, unstructured (Phi)MDPs are\nlimited to relatively simple environments. Structured MDPs like Dynamic\nBayesian Networks (DBNs) are used for large-scale real-world problems. In this\narticle I extend PhiMDP to PhiDBN. The primary contribution is to derive a cost\ncriterion that allows to automatically extract the most relevant features from\nthe environment, leading to the \"best\" DBN representation. I discuss all\nbuilding blocks required for a complete general learning algorithm.",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "Open Problems in Universal Induction & Intelligence",
        "authors": [
            "Marcus Hutter"
        ],
        "summary": "Specialized intelligent systems can be found everywhere: finger print,\nhandwriting, speech, and face recognition, spam filtering, chess and other game\nprograms, robots, et al. This decade the first presumably complete mathematical\ntheory of artificial intelligence based on universal\ninduction-prediction-decision-action has been proposed. This\ninformation-theoretic approach solidifies the foundations of inductive\ninference and artificial intelligence. Getting the foundations right usually\nmarks a significant progress and maturing of a field. The theory provides a\ngold standard and guidance for researchers working on intelligent algorithms.\nThe roots of universal induction have been laid exactly half-a-century ago and\nthe roots of universal intelligence exactly one decade ago. So it is timely to\ntake stock of what has been achieved and what remains to be done. Since there\nare already good recent surveys, I describe the state-of-the-art only in\npassing and refer the reader to the literature. This article concentrates on\nthe open problems in universal induction and its extension to universal\nintelligence.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Analysing the behaviour of robot teams through relational sequential\n  pattern mining",
        "authors": [
            "Grazia Bombini",
            "Raquel Ros",
            "Stefano Ferilli",
            "Ramon Lopez de Mantaras"
        ],
        "summary": "This report outlines the use of a relational representation in a Multi-Agent\ndomain to model the behaviour of the whole system. A desired property in this\nsystems is the ability of the team members to work together to achieve a common\ngoal in a cooperative manner. The aim is to define a systematic method to\nverify the effective collaboration among the members of a team and comparing\nthe different multi-agent behaviours. Using external observations of a\nMulti-Agent System to analyse, model, recognize agent behaviour could be very\nuseful to direct team actions. In particular, this report focuses on the\nchallenge of autonomous unsupervised sequential learning of the team's\nbehaviour from observations. Our approach allows to learn a symbolic sequence\n(a relational representation) to translate raw multi-agent, multi-variate\nobservations of a dynamic, complex environment, into a set of sequential\nbehaviours that are characteristic of the team in question, represented by a\nset of sequences expressed in first-order logic atoms. We propose to use a\nrelational learning algorithm to mine meaningful frequent patterns among the\nrelational sequences to characterise team behaviours. We compared the\nperformance of two teams in the RoboCup four-legged league environment, that\nhave a very different approach to the game. One uses a Case Based Reasoning\napproach, the other uses a pure reactive behaviour.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "A new parameter Learning Method for Bayesian Networks with Qualitative\n  Influences",
        "authors": [
            "Ad Feelders"
        ],
        "summary": "We propose a new method for parameter learning in Bayesian networks with\nqualitative influences. This method extends our previous work from networks of\nbinary variables to networks of discrete variables with ordered values. The\nspecified qualitative influences correspond to certain order restrictions on\nthe parameters in the network. These parameters may therefore be estimated\nusing constrained maximum likelihood estimation. We propose an alternative\nmethod, based on the isotonic regression. The constrained maximum likelihood\nestimates are fairly complicated to compute, whereas computation of the\nisotonic regression estimates only requires the repeated application of the\nPool Adjacent Violators algorithm for linear orders. Therefore, the isotonic\nregression estimator is to be preferred from the viewpoint of computational\ncomplexity. Through experiments on simulated and real data, we show that the\nnew learning method is competitive in performance to the constrained maximum\nlikelihood estimator, and that both estimators improve on the standard\nestimator.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Network of Bandits insure Privacy of end-users",
        "authors": [
            "Rapha\u00ebl F\u00e9raud"
        ],
        "summary": "In order to distribute the best arm identification task as close as possible\nto the user's devices, on the edge of the Radio Access Network, we propose a\nnew problem setting, where distributed players collaborate to find the best\narm. This architecture guarantees privacy to end-users since no events are\nstored. The only thing that can be observed by an adversary through the core\nnetwork is aggregated information across users. We provide a first algorithm,\nDistributed Median Elimination, which is optimal in term of number of\ntransmitted bits and near optimal in term of speed-up factor with respect to an\noptimal algorithm run independently on each player. In practice, this first\nalgorithm cannot handle the trade-off between the communication cost and the\nspeed-up factor, and requires some knowledge about the distribution of players.\nExtended Distributed Median Elimination overcomes these limitations, by playing\nin parallel different instances of Distributed Median Elimination and selecting\nthe best one. Experiments illustrate and complete the analysis. According to\nthe analysis, in comparison to Median Elimination performed on each player, the\nproposed algorithm shows significant practical improvements.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Hierarchical Decision Making In Electricity Grid Management",
        "authors": [
            "Gal Dalal",
            "Elad Gilboa",
            "Shie Mannor"
        ],
        "summary": "The power grid is a complex and vital system that necessitates careful\nreliability management. Managing the grid is a difficult problem with multiple\ntime scales of decision making and stochastic behavior due to renewable energy\ngenerations, variable demand and unplanned outages. Solving this problem in the\nface of uncertainty requires a new methodology with tractable algorithms. In\nthis work, we introduce a new model for hierarchical decision making in complex\nsystems. We apply reinforcement learning (RL) methods to learn a proxy, i.e., a\nlevel of abstraction, for real-time power grid reliability. We devise an\nalgorithm that alternates between slow time-scale policy improvement, and fast\ntime-scale value function approximation. We compare our results to prevailing\nheuristics, and show the strength of our method.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "A Formal Solution to the Grain of Truth Problem",
        "authors": [
            "Jan Leike",
            "Jessica Taylor",
            "Benya Fallenstein"
        ],
        "summary": "A Bayesian agent acting in a multi-agent environment learns to predict the\nother agents' policies if its prior assigns positive probability to them (in\nother words, its prior contains a \\emph{grain of truth}). Finding a reasonably\nlarge class of policies that contains the Bayes-optimal policies with respect\nto this class is known as the \\emph{grain of truth problem}. Only small classes\nare known to have a grain of truth and the literature contains several related\nimpossibility results. In this paper we present a formal and general solution\nto the full grain of truth problem: we construct a class of policies that\ncontains all computable policies as well as Bayes-optimal policies for every\nlower semicomputable prior over the class. When the environment is unknown,\nBayes-optimal agents may fail to act optimally even asymptotically. However,\nagents based on Thompson sampling converge to play {\\epsilon}-Nash equilibria\nin arbitrary unknown computable multi-agent environments. While these results\nare purely theoretical, we show that they can be computationally approximated\narbitrarily closely.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Toward negotiable reinforcement learning: shifting priorities in Pareto\n  optimal sequential decision-making",
        "authors": [
            "Andrew Critch"
        ],
        "summary": "Existing multi-objective reinforcement learning (MORL) algorithms do not\naccount for objectives that arise from players with differing beliefs.\nConcretely, consider two players with different beliefs and utility functions\nwho may cooperate to build a machine that takes actions on their behalf. A\nrepresentation is needed for how much the machine's policy will prioritize each\nplayer's interests over time. Assuming the players have reached common\nknowledge of their situation, this paper derives a recursion that any Pareto\noptimal policy must satisfy. Two qualitative observations can be made from the\nrecursion: the machine must (1) use each player's own beliefs in evaluating how\nwell an action will serve that player's utility function, and (2) shift the\nrelative priority it assigns to each player's expected utilities over time, by\na factor proportional to how well that player's beliefs predict the machine's\ninputs. Observation (2) represents a substantial divergence from na\\\"{i}ve\nlinear utility aggregation (as in Harsanyi's utilitarian theorem, and existing\nMORL algorithms), which is shown here to be inadequate for Pareto optimal\nsequential decision-making on behalf of players with different beliefs.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Towards a Common Implementation of Reinforcement Learning for Multiple\n  Robotic Tasks",
        "authors": [
            "Angel Mart\u00ednez-Tenor",
            "Juan Antonio Fern\u00e1ndez-Madrigal",
            "Ana Cruz-Mart\u00edn",
            "Javier Gonz\u00e1lez-Jim\u00e9nez"
        ],
        "summary": "Mobile robots are increasingly being employed for performing complex tasks in\ndynamic environments. Reinforcement learning (RL) methods are recognized to be\npromising for specifying such tasks in a relatively simple manner. However, the\nstrong dependency between the learning method and the task to learn is a\nwell-known problem that restricts practical implementations of RL in robotics,\noften requiring major modifications of parameters and adding other techniques\nfor each particular task. In this paper we present a practical core\nimplementation of RL which enables the learning process for multiple robotic\ntasks with minimal per-task tuning or none. Based on value iteration methods,\nthis implementation includes a novel approach for action selection, called\nQ-biased softmax regression (QBIASSR), which avoids poor performance of the\nlearning process when the robot reaches new unexplored states. Our approach\ntakes advantage of the structure of the state space by attending the physical\nvariables involved (e.g., distances to obstacles, X,Y,{\\theta} pose, etc.),\nthus experienced sets of states may favor the decision-making process of\nunexplored or rarely-explored states. This improvement has a relevant role in\nreducing the tuning of the algorithm for particular tasks. Experiments with\nreal and simulated robots, performed with the software framework also\nintroduced here, show that our implementation is effectively able to learn\ndifferent robotic tasks without tuning the learning method. Results also\nsuggest that the combination of true online SARSA({\\lambda}) with QBIASSR can\noutperform the existing RL core algorithms in low-dimensional robotic tasks.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Improving Latent User Models in Online Social Media",
        "authors": [
            "Adit Krishnan",
            "Ashish Sharma",
            "Hari Sundaram"
        ],
        "summary": "Modern social platforms are characterized by the presence of rich\nuser-behavior data associated with the publication, sharing and consumption of\ntextual content. Users interact with content and with each other in a complex\nand dynamic social environment while simultaneously evolving over time. In\norder to effectively characterize users and predict their future behavior in\nsuch a setting, it is necessary to overcome several challenges. Content\nheterogeneity and temporal inconsistency of behavior data result in severe\nsparsity at the user level. In this paper, we propose a novel\nmutual-enhancement framework to simultaneously partition and learn latent\nactivity profiles of users. We propose a flexible user partitioning approach to\neffectively discover rare behaviors and tackle user-level sparsity. We\nextensively evaluate the proposed framework on massive datasets from real-world\nplatforms including Q&A networks and interactive online courses (MOOCs). Our\nresults indicate significant gains over state-of-the-art behavior models ( 15%\navg ) in a varied range of tasks and our gains are further magnified for users\nwith limited interaction data. The proposed algorithms are amenable to\nparallelization, scale linearly in the size of datasets, and provide\nflexibility to model diverse facets of user behavior.",
        "year": 2017,
        "label": "cs.SI"
    },
    {
        "title": "Active Clustering: Robust and Efficient Hierarchical Clustering using\n  Adaptively Selected Similarities",
        "authors": [
            "Brian Eriksson",
            "Gautam Dasarathy",
            "Aarti Singh",
            "Robert Nowak"
        ],
        "summary": "Hierarchical clustering based on pairwise similarities is a common tool used\nin a broad range of scientific applications. However, in many problems it may\nbe expensive to obtain or compute similarities between the items to be\nclustered. This paper investigates the hierarchical clustering of N items based\non a small subset of pairwise similarities, significantly less than the\ncomplete set of N(N-1)/2 similarities. First, we show that if the intracluster\nsimilarities exceed intercluster similarities, then it is possible to correctly\ndetermine the hierarchical clustering from as few as 3N log N similarities. We\ndemonstrate this order of magnitude savings in the number of pairwise\nsimilarities necessitates sequentially selecting which similarities to obtain\nin an adaptive fashion, rather than picking them at random. We then propose an\nactive clustering method that is robust to a limited fraction of anomalous\nsimilarities, and show how even in the presence of these noisy similarity\nvalues we can resolve the hierarchical clustering using only O(N log^2 N)\npairwise similarities.",
        "year": 2011,
        "label": "cs.IT"
    },
    {
        "title": "Information, learning and falsification",
        "authors": [
            "David Balduzzi"
        ],
        "summary": "There are (at least) three approaches to quantifying information. The first,\nalgorithmic information or Kolmogorov complexity, takes events as strings and,\ngiven a universal Turing machine, quantifies the information content of a\nstring as the length of the shortest program producing it. The second, Shannon\ninformation, takes events as belonging to ensembles and quantifies the\ninformation resulting from observing the given event in terms of the number of\nalternate events that have been ruled out. The third, statistical learning\ntheory, has introduced measures of capacity that control (in part) the expected\nrisk of classifiers. These capacities quantify the expectations regarding\nfuture data that learning algorithms embed into classifiers.\n  This note describes a new method of quantifying information, effective\ninformation, that links algorithmic information to Shannon information, and\nalso links both to capacities arising in statistical learning theory. After\nintroducing the measure, we show that it provides a non-universal analog of\nKolmogorov complexity. We then apply it to derive basic capacities in\nstatistical learning theory: empirical VC-entropy and empirical Rademacher\ncomplexity. A nice byproduct of our approach is an interpretation of the\nexplanatory power of a learning algorithm in terms of the number of hypotheses\nit falsifies, counted in two different ways for the two capacities. We also\ndiscuss how effective information relates to information gain, Shannon and\nmutual information.",
        "year": 2011,
        "label": "cs.IT"
    },
    {
        "title": "Towards a learning-theoretic analysis of spike-timing dependent\n  plasticity",
        "authors": [
            "David Balduzzi",
            "Michel Besserve"
        ],
        "summary": "This paper suggests a learning-theoretic perspective on how synaptic\nplasticity benefits global brain functioning. We introduce a model, the\nselectron, that (i) arises as the fast time constant limit of leaky\nintegrate-and-fire neurons equipped with spiking timing dependent plasticity\n(STDP) and (ii) is amenable to theoretical analysis. We show that the selectron\nencodes reward estimates into spikes and that an error bound on spikes is\ncontrolled by a spiking margin and the sum of synaptic weights. Moreover, the\nefficacy of spikes (their usefulness to other reward maximizing selectrons)\nalso depends on total synaptic strength. Finally, based on our analysis, we\npropose a regularized version of STDP, and show the regularization improves the\nrobustness of neuronal learning when faced with multiple stimuli.",
        "year": 2012,
        "label": "q-bio.NC"
    },
    {
        "title": "Belief Propagation for Continuous State Spaces: Stochastic\n  Message-Passing with Quantitative Guarantees",
        "authors": [
            "Nima Noorshams",
            "Martin J. Wainwright"
        ],
        "summary": "The sum-product or belief propagation (BP) algorithm is a widely used\nmessage-passing technique for computing approximate marginals in graphical\nmodels. We introduce a new technique, called stochastic orthogonal series\nmessage-passing (SOSMP), for computing the BP fixed point in models with\ncontinuous random variables. It is based on a deterministic approximation of\nthe messages via orthogonal series expansion, and a stochastic approximation\nvia Monte Carlo estimates of the integral updates of the basis coefficients. We\nprove that the SOSMP iterates converge to a \\delta-neighborhood of the unique\nBP fixed point for any tree-structured graph, and for any graphs with cycles in\nwhich the BP updates satisfy a contractivity condition. In addition, we\ndemonstrate how to choose the number of basis coefficients as a function of the\ndesired approximation accuracy \\delta and smoothness of the compatibility\nfunctions. We illustrate our theory with both simulated examples and in\napplication to optical flow estimation.",
        "year": 2012,
        "label": "cs.IT"
    },
    {
        "title": "Fast Marginalized Block Sparse Bayesian Learning Algorithm",
        "authors": [
            "Benyuan Liu",
            "Zhilin Zhang",
            "Hongqi Fan",
            "Qiang Fu"
        ],
        "summary": "The performance of sparse signal recovery from noise corrupted,\nunderdetermined measurements can be improved if both sparsity and correlation\nstructure of signals are exploited. One typical correlation structure is the\nintra-block correlation in block sparse signals. To exploit this structure, a\nframework, called block sparse Bayesian learning (BSBL), has been proposed\nrecently. Algorithms derived from this framework showed superior performance\nbut they are not very fast, which limits their applications. This work derives\nan efficient algorithm from this framework, using a marginalized likelihood\nmaximization method. Compared to existing BSBL algorithms, it has close\nrecovery performance but is much faster. Therefore, it is more suitable for\nlarge scale datasets and applications requiring real-time implementation.",
        "year": 2012,
        "label": "cs.IT"
    },
    {
        "title": "A spectral method for community detection in moderately-sparse\n  degree-corrected stochastic block models",
        "authors": [
            "Lennart Gulikers",
            "Marc Lelarge",
            "Laurent Massouli\u00e9"
        ],
        "summary": "We consider community detection in Degree-Corrected Stochastic Block Models\n(DC-SBM). We propose a spectral clustering algorithm based on a suitably\nnormalized adjacency matrix. We show that this algorithm consistently recovers\nthe block-membership of all but a vanishing fraction of nodes, in the regime\nwhere the lowest degree is of order log$(n)$ or higher. Recovery succeeds even\nfor very heterogeneous degree-distributions. The used algorithm does not rely\non parameters as input. In particular, it does not need to know the number of\ncommunities.",
        "year": 2015,
        "label": "math.PR"
    },
    {
        "title": "An Impossibility Result for Reconstruction in a Degree-Corrected\n  Planted-Partition Model",
        "authors": [
            "Lennart Gulikers",
            "Marc Lelarge",
            "Laurent Massouli\u00e9"
        ],
        "summary": "We consider a Degree-Corrected Planted-Partition model: a random graph on $n$\nnodes with two asymptotically equal-sized clusters. The model parameters are\ntwo constants $a,b > 0$ and an i.i.d. sequence of weights $(\\phi_u)_{u=1}^n$,\nwith finite second moment $\\Phi^{(2)}$. Vertices $u$ and $v$ are joined by an\nedge with probability $\\frac{\\phi_u \\phi_v}{n}a$ when they are in the same\nclass and with probability $\\frac{\\phi_u \\phi_v}{n}b$ otherwise.\n  We prove that it is information-theoretically impossible to estimate the\nspins in a way positively correlated with the true community structure when\n$(a-b)^2 \\Phi^{(2)} \\leq 2(a+b)$.\n  A by-product of our proof is a precise coupling-result for\nlocal-neighbourhoods in Degree-Corrected Planted-Partition models, which could\nbe of independent interest.",
        "year": 2015,
        "label": "math.PR"
    },
    {
        "title": "Non-Backtracking Spectrum of Degree-Corrected Stochastic Block Models",
        "authors": [
            "Lennart Gulikers",
            "Marc Lelarge",
            "Laurent Massouli\u00e9"
        ],
        "summary": "Motivated by community detection, we characterise the spectrum of the\nnon-backtracking matrix $B$ in the Degree-Corrected Stochastic Block Model.\n  Specifically, we consider a random graph on $n$ vertices partitioned into two\nequal-sized clusters. The vertices have i.i.d. weights $\\{ \\phi_u \\}_{u=1}^n$\nwith second moment $\\Phi^{(2)}$. The intra-cluster connection probability for\nvertices $u$ and $v$ is $\\frac{\\phi_u \\phi_v}{n}a$ and the inter-cluster\nconnection probability is $\\frac{\\phi_u \\phi_v}{n}b$.\n  We show that with high probability, the following holds: The leading\neigenvalue of the non-backtracking matrix $B$ is asymptotic to $\\rho =\n\\frac{a+b}{2} \\Phi^{(2)}$. The second eigenvalue is asymptotic to $\\mu_2 =\n\\frac{a-b}{2} \\Phi^{(2)}$ when $\\mu_2^2 > \\rho$, but asymptotically bounded by\n$\\sqrt{\\rho}$ when $\\mu_2^2 \\leq \\rho$. All the remaining eigenvalues are\nasymptotically bounded by $\\sqrt{\\rho}$. As a result, a clustering\npositively-correlated with the true communities can be obtained based on the\nsecond eigenvector of $B$ in the regime where $\\mu_2^2 > \\rho.$\n  In a previous work we obtained that detection is impossible when $\\mu_2^2 <\n\\rho,$ meaning that there occurs a phase-transition in the sparse regime of the\nDegree-Corrected Stochastic Block Model.\n  As a corollary, we obtain that Degree-Corrected Erd\\H{o}s-R\\'enyi graphs\nasymptotically satisfy the graph Riemann hypothesis, a quasi-Ramanujan\nproperty.\n  A by-product of our proof is a weak law of large numbers for\nlocal-functionals on Degree-Corrected Stochastic Block Models, which could be\nof independent interest.",
        "year": 2016,
        "label": "math.PR"
    },
    {
        "title": "An Introduction to MM Algorithms for Machine Learning and Statistical",
        "authors": [
            "Hien D. Nguyen"
        ],
        "summary": "MM (majorization--minimization) algorithms are an increasingly popular tool\nfor solving optimization problems in machine learning and statistical\nestimation. This article introduces the MM algorithm framework in general and\nvia three popular example applications: Gaussian mixture regressions,\nmultinomial logistic regressions, and support vector machines. Specific\nalgorithms for the three examples are derived and numerical demonstrations are\npresented. Theoretical and practical aspects of MM algorithm design are\ndiscussed.",
        "year": 2016,
        "label": "stat.CO"
    },
    {
        "title": "struc2vec: Learning Node Representations from Structural Identity",
        "authors": [
            "Leonardo F. R. Ribeiro",
            "Pedro H. P. Saverese",
            "Daniel R. Figueiredo"
        ],
        "summary": "Structural identity is a concept of symmetry in which network nodes are\nidentified according to the network structure and their relationship to other\nnodes. Structural identity has been studied in theory and practice over the\npast decades, but only recently has it been addressed with representational\nlearning techniques. This work presents struc2vec, a novel and flexible\nframework for learning latent representations for the structural identity of\nnodes. struc2vec uses a hierarchy to measure node similarity at different\nscales, and constructs a multilayer graph to encode structural similarities and\ngenerate structural context for nodes. Numerical experiments indicate that\nstate-of-the-art techniques for learning node representations fail in capturing\nstronger notions of structural identity, while struc2vec exhibits much superior\nperformance in this task, as it overcomes limitations of prior approaches. As a\nconsequence, numerical experiments indicate that struc2vec improves performance\non classification tasks that depend more on structural identity.",
        "year": 2017,
        "label": "cs.SI"
    },
    {
        "title": "Attributed Network Embedding for Learning in a Dynamic Environment",
        "authors": [
            "Jundong Li",
            "Harsh Dani",
            "Xia Hu",
            "Jiliang Tang",
            "Yi Chang",
            "Huan Liu"
        ],
        "summary": "Network embedding leverages the node proximity manifested to learn a\nlow-dimensional node vector representation. The learned embeddings could\nadvance various learning tasks such as node classification, network clustering,\nand link prediction. Most, if not all, of the existing work, is overwhelmingly\nperformed in the context of plain and static networks. Nonetheless, in reality,\nnetwork structure often evolves over time with addition/deletion of links and\nnodes. Also, a vast majority of real-world networks are associated with a rich\nset of node attributes, and their attribute values are also naturally changing,\nwith the emerging of new content and the fading of old content. These changing\ncharacteristics motivate us to seek an effective embedding representation to\ncapture network and attribute evolving patterns, which is of fundamental\nimportance for learning in a dynamic environment. To our best knowledge, we are\nthe first to tackle this problem with the following two challenges: (1) the\ninherently correlated network and node attributes could be noisy and\nincomplete, it necessitates a robust consensus representation to capture their\nindividual properties and correlations; (2) the embedding learning needs to be\nperformed in an online fashion to adapt to the changes accordingly. In this\npaper, we tackle this problem by proposing a novel dynamic attributed network\nembedding framework - DANE. In particular, DANE provides an offline method for\na consensus embedding first and then leverages matrix perturbation theory to\nmaintain the freshness of the end embedding results in an online manner. We\nperform extensive experiments on both synthetic and real attributed networks to\ncorroborate the effectiveness and efficiency of the proposed framework.",
        "year": 2017,
        "label": "cs.SI"
    },
    {
        "title": "Inductive Representation Learning on Large Graphs",
        "authors": [
            "William L. Hamilton",
            "Rex Ying",
            "Jure Leskovec"
        ],
        "summary": "Low-dimensional embeddings of nodes in large graphs have proved extremely\nuseful in a variety of prediction tasks, from content recommendation to\nidentifying protein functions. However, most existing approaches require that\nall nodes in the graph are present during training of the embeddings; these\nprevious approaches are inherently transductive and do not naturally generalize\nto unseen nodes. Here we present GraphSAGE, a general, inductive framework that\nleverages node feature information (e.g., text attributes) to efficiently\ngenerate node embeddings for previously unseen data. Instead of training\nindividual embeddings for each node, we learn a function that generates\nembeddings by sampling and aggregating features from a node's local\nneighborhood. Our algorithm outperforms strong baselines on three inductive\nnode-classification benchmarks: we classify the category of unseen nodes in\nevolving information graphs based on citation and Reddit post data, and we show\nthat our algorithm generalizes to completely unseen graphs using a multi-graph\ndataset of protein-protein interactions.",
        "year": 2017,
        "label": "cs.SI"
    },
    {
        "title": "Towards a Universal Theory of Artificial Intelligence based on\n  Algorithmic Probability and Sequential Decision Theory",
        "authors": [
            "Marcus Hutter"
        ],
        "summary": "Decision theory formally solves the problem of rational agents in uncertain\nworlds if the true environmental probability distribution is known.\nSolomonoff's theory of universal induction formally solves the problem of\nsequence prediction for unknown distribution. We unify both theories and give\nstrong arguments that the resulting universal AIXI model behaves optimal in any\ncomputable environment. The major drawback of the AIXI model is that it is\nuncomputable. To overcome this problem, we construct a modified algorithm\nAIXI^tl, which is still superior to any other time t and space l bounded agent.\nThe computation time of AIXI^tl is of the order t x 2^l.",
        "year": 2000,
        "label": "cs.AI"
    },
    {
        "title": "Cortical prediction markets",
        "authors": [
            "David Balduzzi"
        ],
        "summary": "We investigate cortical learning from the perspective of mechanism design.\nFirst, we show that discretizing standard models of neurons and synaptic\nplasticity leads to rational agents maximizing simple scoring rules. Second,\nour main result is that the scoring rules are proper, implying that neurons\nfaithfully encode expected utilities in their synaptic weights and encode\nhigh-scoring outcomes in their spikes. Third, with this foundation in hand, we\npropose a biologically plausible mechanism whereby neurons backpropagate\nincentives which allows them to optimize their usefulness to the rest of\ncortex. Finally, experiments show that networks that backpropagate incentives\ncan learn simple tasks.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Optimization by a quantum reinforcement algorithm",
        "authors": [
            "A. Ramezanpour"
        ],
        "summary": "A reinforcement algorithm solves a classical optimization problem by\nintroducing a feedback to the system which slowly changes the energy landscape\nand converges the algorithm to an optimal solution in the configuration space.\nHere, we use this strategy to concentrate (localize) preferentially the wave\nfunction of a quantum particle, which explores the configuration space of the\nproblem, on an optimal configuration. We examine the method by solving\nnumerically the equations governing the evolution of the system, which are\nsimilar to the nonlinear Schr\\\"odinger equations, for small problem sizes. In\nparticular, we observe that reinforcement increases the minimal energy gap of\nthe system in a quantum annealing algorithm. Our numerical simulations and the\nlatter observation show that such kind of quantum feedbacks might be helpful in\nsolving a computationally hard optimization problem by a quantum reinforcement\nalgorithm.",
        "year": 2017,
        "label": "cond-mat.dis-nn"
    },
    {
        "title": "Anomaly Detection in Clutter using Spectrally Enhanced Ladar",
        "authors": [
            "Puneet S Chhabra",
            "Andrew M Wallace",
            "James R Hopgood"
        ],
        "summary": "Discrete return (DR) Laser Detection and Ranging (Ladar) systems provide a\nseries of echoes that reflect from objects in a scene. These can be first, last\nor multi-echo returns. In contrast, Full-Waveform (FW)-Ladar systems measure\nthe intensity of light reflected from objects continuously over a period of\ntime. In a camouflaged scenario, e.g., objects hidden behind dense foliage, a\nFW-Ladar penetrates such foliage and returns a sequence of echoes including\nburied faint echoes. The aim of this paper is to learn local-patterns of\nco-occurring echoes characterised by their measured spectra. A deviation from\nsuch patterns defines an abnormal event in a forest/tree depth profile. As far\nas the authors know, neither DR or FW-Ladar, along with several spectral\nmeasurements, has not been applied to anomaly detection. This work presents an\nalgorithm that allows detection of spectral and temporal anomalies in FW-Multi\nSpectral Ladar (FW-MSL) data samples. An anomaly is defined as a full waveform\ntemporal and spectral signature that does not conform to a prior expectation,\nrepresented using a learnt subspace (dictionary) and set of coefficients that\ncapture co-occurring local-patterns using an overlapping temporal window. A\nmodified optimization scheme is proposed for subspace learning based on\nstochastic approximations. The objective function is augmented with a\ndiscriminative term that represents the subspace's separability properties and\nsupports anomaly characterisation. The algorithm detects several man-made\nobjects and anomalous spectra hidden in a dense clutter of vegetation and also\nallows tree species classification.",
        "year": 2016,
        "label": "physics.optics"
    },
    {
        "title": "Sequence Prediction based on Monotone Complexity",
        "authors": [
            "Marcus Hutter"
        ],
        "summary": "This paper studies sequence prediction based on the monotone Kolmogorov\ncomplexity Km=-log m, i.e. based on universal deterministic/one-part MDL. m is\nextremely close to Solomonoff's prior M, the latter being an excellent\npredictor in deterministic as well as probabilistic environments, where\nperformance is measured in terms of convergence of posteriors or losses.\nDespite this closeness to M, it is difficult to assess the prediction quality\nof m, since little is known about the closeness of their posteriors, which are\nthe important quantities for prediction. We show that for deterministic\ncomputable environments, the \"posterior\" and losses of m converge, but rapid\nconvergence could only be shown on-sequence; the off-sequence behavior is\nunclear. In probabilistic environments, neither the posterior nor the losses\nconverge, in general.",
        "year": 2003,
        "label": "cs.AI"
    },
    {
        "title": "Parameter-less Optimization with the Extended Compact Genetic Algorithm\n  and Iterated Local Search",
        "authors": [
            "Claudio F. Lima",
            "Fernando G. Lobo"
        ],
        "summary": "This paper presents a parameter-less optimization framework that uses the\nextended compact genetic algorithm (ECGA) and iterated local search (ILS), but\nis not restricted to these algorithms. The presented optimization algorithm\n(ILS+ECGA) comes as an extension of the parameter-less genetic algorithm (GA),\nwhere the parameters of a selecto-recombinative GA are eliminated. The approach\nthat we propose is tested on several well known problems. In the absence of\ndomain knowledge, it is shown that ILS+ECGA is a robust and easy-to-use\noptimization method.",
        "year": 2004,
        "label": "cs.NE"
    },
    {
        "title": "A philosophical essay on life and its connections with genetic\n  algorithms",
        "authors": [
            "Fernando G. Lobo"
        ],
        "summary": "This paper makes a number of connections between life and various facets of\ngenetic and evolutionary algorithms research. Specifically, it addresses the\ntopics of adaptation, multiobjective optimization, decision making, deception,\nand search operators, among others. It argues that human life, from birth to\ndeath, is an adaptive or dynamic optimization problem where people are\ncontinuously searching for happiness. More important, the paper speculates that\ngenetic algorithms can be used as a source of inspiration for helping people\nmake decisions in their everyday life.",
        "year": 2004,
        "label": "cs.NE"
    },
    {
        "title": "Efficiency Enhancement of Probabilistic Model Building Genetic\n  Algorithms",
        "authors": [
            "Kumara Sastry",
            "David E. Goldberg",
            "Martin Pelikan"
        ],
        "summary": "This paper presents two different efficiency-enhancement techniques for\nprobabilistic model building genetic algorithms. The first technique proposes\nthe use of a mutation operator which performs local search in the sub-solution\nneighborhood identified through the probabilistic model. The second technique\nproposes building and using an internal probabilistic model of the fitness\nalong with the probabilistic model of variable interactions. The fitness values\nof some offspring are estimated using the probabilistic model, thereby avoiding\ncomputationally expensive function evaluations. The scalability of the\naforementioned techniques are analyzed using facetwise models for convergence\ntime and population sizing. The speed-up obtained by each of the methods is\npredicted and verified with empirical results. The results show that for\nadditively separable problems the competent mutation operator requires O(k 0.5\nlogm)--where k is the building-block size, and m is the number of building\nblocks--less function evaluations than its selectorecombinative counterpart.\nThe results also show that the use of an internal probabilistic fitness model\nreduces the required number of function evaluations to as low as 1-10% and\nyields a speed-up of 2--50.",
        "year": 2004,
        "label": "cs.NE"
    },
    {
        "title": "Let's Get Ready to Rumble: Crossover Versus Mutation Head to Head",
        "authors": [
            "Kumara Sastry",
            "David E. Goldberg"
        ],
        "summary": "This paper analyzes the relative advantages between crossover and mutation on\na class of deterministic and stochastic additively separable problems. This\nstudy assumes that the recombination and mutation operators have the knowledge\nof the building blocks (BBs) and effectively exchange or search among competing\nBBs. Facetwise models of convergence time and population sizing have been used\nto determine the scalability of each algorithm. The analysis shows that for\nadditively separable deterministic problems, the BB-wise mutation is more\nefficient than crossover, while the crossover outperforms the mutation on\nadditively separable problems perturbed with additive Gaussian noise. The\nresults show that the speed-up of using BB-wise mutation on deterministic\nproblems is O(k^{0.5}logm), where k is the BB size, and m is the number of BBs.\nLikewise, the speed-up of using crossover on stochastic problems with fixed\nnoise variance is O(mk^{0.5}log m).",
        "year": 2004,
        "label": "cs.NE"
    },
    {
        "title": "Designing Competent Mutation Operators via Probabilistic Model Building\n  of Neighborhoods",
        "authors": [
            "Kumara Sastry",
            "David E. Goldberg"
        ],
        "summary": "This paper presents a competent selectomutative genetic algorithm (GA), that\nadapts linkage and solves hard problems quickly, reliably, and accurately. A\nprobabilistic model building process is used to automatically identify key\nbuilding blocks (BBs) of the search problem. The mutation operator uses the\nprobabilistic model of linkage groups to find the best among competing building\nblocks. The competent selectomutative GA successfully solves additively\nseparable problems of bounded difficulty, requiring only subquadratic number of\nfunction evaluations. The results show that for additively separable problems\nthe probabilistic model building BB-wise mutation scales as O(2^km^{1.5}), and\nrequires O(k^{0.5}logm) less function evaluations than its selectorecombinative\ncounterpart, confirming theoretical results reported elsewhere (Sastry &\nGoldberg, 2004).",
        "year": 2004,
        "label": "cs.NE"
    },
    {
        "title": "Efficiency Enhancement of Genetic Algorithms via Building-Block-Wise\n  Fitness Estimation",
        "authors": [
            "Kumara Sastry",
            "Martin Pelikan",
            "David E. Goldberg"
        ],
        "summary": "This paper studies fitness inheritance as an efficiency enhancement technique\nfor a class of competent genetic algorithms called estimation distribution\nalgorithms. Probabilistic models of important sub-solutions are developed to\nestimate the fitness of a proportion of individuals in the population, thereby\navoiding computationally expensive function evaluations. The effect of fitness\ninheritance on the convergence time and population sizing are modeled and the\nspeed-up obtained through inheritance is predicted. The results show that a\nfitness-inheritance mechanism which utilizes information on building-block\nfitnesses provides significant efficiency enhancement. For additively separable\nproblems, fitness inheritance reduces the number of function evaluations to\nabout half and yields a speed-up of about 1.75--2.25.",
        "year": 2004,
        "label": "cs.NE"
    },
    {
        "title": "Artificial Neural Networks and their Applications",
        "authors": [
            "Nitin Malik"
        ],
        "summary": "The Artificial Neural network is a functional imitation of simplified model\nof the biological neurons and their goal is to construct useful computers for\nreal world problems. The ANN applications have increased dramatically in the\nlast few years fired by both theoretical and practical applications in a wide\nvariety of applications. A brief theory of ANN is presented and potential areas\nare identified and future trends are discussed.",
        "year": 2005,
        "label": "cs.NE"
    },
    {
        "title": "On the utility of the multimodal problem generator for assessing the\n  performance of Evolutionary Algorithms",
        "authors": [
            "Fernando G. Lobo",
            "Claudio F. Lima"
        ],
        "summary": "This paper looks in detail at how an evolutionary algorithm attempts to solve\ninstances from the multimodal problem generator. The paper shows that in order\nto consistently reach the global optimum, an evolutionary algorithm requires a\npopulation size that should grow at least linearly with the number of peaks. It\nis also shown a close relationship between the supply and decision making\nissues that have been identified previously in the context of population sizing\nmodels for additively decomposable problems.\n  The most important result of the paper, however, is that solving an instance\nof the multimodal problem generator is like solving a peak-in-a-haystack, and\nit is argued that evolutionary algorithms are not the best algorithms for such\na task. Finally, and as opposed to what several researchers have been doing, it\nis our strong belief that the multimodal problem generator is not adequate for\nassessing the performance of evolutionary algorithms.",
        "year": 2006,
        "label": "cs.NE"
    },
    {
        "title": "Revisiting Evolutionary Algorithms with On-the-Fly Population Size\n  Adjustment",
        "authors": [
            "Fernando G. Lobo",
            "Claudio F. Lima"
        ],
        "summary": "In an evolutionary algorithm, the population has a very important role as its\nsize has direct implications regarding solution quality, speed, and\nreliability. Theoretical studies have been done in the past to investigate the\nrole of population sizing in evolutionary algorithms. In addition to those\nstudies, several self-adjusting population sizing mechanisms have been proposed\nin the literature. This paper revisits the latter topic and pays special\nattention to the genetic algorithm with adaptive population size (APGA), for\nwhich several researchers have claimed to be very effective at autonomously\n(re)sizing the population.\n  As opposed to those previous claims, this paper suggests a complete opposite\nview. Specifically, it shows that APGA is not capable of adapting the\npopulation size at all. This claim is supported on theoretical grounds and\nconfirmed by computer simulations.",
        "year": 2006,
        "label": "cs.NE"
    },
    {
        "title": "Towards Analyzing Crossover Operators in Evolutionary Search via General\n  Markov Chain Switching Theorem",
        "authors": [
            "Yang Yu",
            "Chao Qian",
            "Zhi-Hua Zhou"
        ],
        "summary": "Evolutionary algorithms (EAs), simulating the evolution process of natural\nspecies, are used to solve optimization problems. Crossover (also called\nrecombination), originated from simulating the chromosome exchange phenomena in\nzoogamy reproduction, is widely employed in EAs to generate offspring\nsolutions, of which the effectiveness has been examined empirically in\napplications. However, due to the irregularity of crossover operators and the\ncomplicated interactions to mutation, crossover operators are hard to analyze\nand thus have few theoretical results. Therefore, analyzing crossover not only\nhelps in understanding EAs, but also helps in developing novel techniques for\nanalyzing sophisticated metaheuristic algorithms.\n  In this paper, we derive the General Markov Chain Switching Theorem (GMCST)\nto facilitate theoretical studies of crossover-enabled EAs. The theorem allows\nus to analyze the running time of a sophisticated EA from an easy-to-analyze\nEA. Using this tool, we analyze EAs with several crossover operators on the\nLeadingOnes and OneMax problems, which are noticeably two well studied problems\nfor mutation-only EAs but with few results for crossover-enabled EAs. We first\nderive the bounds of running time of the (2+2)-EA with crossover operators;\nthen we study the running time gap between the mutation-only (2:2)-EA and the\n(2:2)-EA with crossover operators; finally, we develop strategies that apply\ncrossover operators only when necessary, which improve from the mutation-only\nas well as the crossover-all-the-time (2:2)-EA. The theoretical results are\nverified by experiments.",
        "year": 2011,
        "label": "cs.NE"
    },
    {
        "title": "Production System Rules as Protein Complexes from Genetic Regulatory\n  Networks",
        "authors": [
            "Larry Bull"
        ],
        "summary": "This short paper introduces a new way by which to design production system\nrules. An indirect encoding scheme is presented which views such rules as\nprotein complexes produced by the temporal behaviour of an artificial genetic\nregulatory network. This initial study begins by using a simple Boolean\nregulatory network to produce traditional ternary-encoded rules before moving\nto a fuzzy variant to produce real-valued rules. Competitive performance is\nshown with related genetic regulatory networks and rule-based systems on\nbenchmark problems.",
        "year": 2012,
        "label": "cs.NE"
    },
    {
        "title": "Computational Complexity Analysis of Multi-Objective Genetic Programming",
        "authors": [
            "Frank Neumann"
        ],
        "summary": "The computational complexity analysis of genetic programming (GP) has been\nstarted recently by analyzing simple (1+1) GP algorithms for the problems ORDER\nand MAJORITY. In this paper, we study how taking the complexity as an\nadditional criteria influences the runtime behavior. We consider\ngeneralizations of ORDER and MAJORITY and present a computational complexity\nanalysis of (1+1) GP using multi-criteria fitness functions that take into\naccount the original objective and the complexity of a syntax tree as a\nsecondary measure. Furthermore, we study the expected time until\npopulation-based multi-objective genetic programming algorithms have computed\nthe Pareto front when taking the complexity of a syntax tree as an equally\nimportant objective.",
        "year": 2012,
        "label": "cs.NE"
    },
    {
        "title": "Self-Adaptive Surrogate-Assisted Covariance Matrix Adaptation Evolution\n  Strategy",
        "authors": [
            "Ilya Loshchilov",
            "Marc Schoenauer",
            "Mich\u00e8le Sebag"
        ],
        "summary": "This paper presents a novel mechanism to adapt surrogate-assisted\npopulation-based algorithms. This mechanism is applied to ACM-ES, a recently\nproposed surrogate-assisted variant of CMA-ES. The resulting algorithm,\nsaACM-ES, adjusts online the lifelength of the current surrogate model (the\nnumber of CMA-ES generations before learning a new surrogate) and the surrogate\nhyper-parameters. Both heuristics significantly improve the quality of the\nsurrogate model, yielding a significant speed-up of saACM-ES compared to the\nACM-ES and CMA-ES baselines. The empirical validation of saACM-ES on the\nBBOB-2012 noiseless testbed demonstrates the efficiency and the scalability\nw.r.t the problem dimension and the population size of the proposed approach,\nthat reaches new best results on some of the benchmark problems.",
        "year": 2012,
        "label": "cs.NE"
    },
    {
        "title": "Hybridization of Evolutionary Algorithms",
        "authors": [
            "Iztok Fister",
            "Marjan Mernik",
            "Janez Brest"
        ],
        "summary": "Evolutionary algorithms are good general problem solver but suffer from a\nlack of domain specific knowledge. However, the problem specific knowledge can\nbe added to evolutionary algorithms by hybridizing. Interestingly, all the\nelements of the evolutionary algorithms can be hybridized. In this chapter, the\nhybridization of the three elements of the evolutionary algorithms is\ndiscussed: the objective function, the survivor selection operator and the\nparameter settings. As an objective function, the existing heuristic function\nthat construct the solution of the problem in traditional way is used. However,\nthis function is embedded into the evolutionary algorithm that serves as a\ngenerator of new solutions. In addition, the objective function is improved by\nlocal search heuristics. The new neutral selection operator has been developed\nthat is capable to deal with neutral solutions, i.e. solutions that have the\ndifferent representation but expose the equal values of objective function. The\naim of this operator is to directs the evolutionary search into a new\nundiscovered regions of the search space. To avoid of wrong setting of\nparameters that control the behavior of the evolutionary algorithm, the\nself-adaptation is used. Finally, such hybrid self-adaptive evolutionary\nalgorithm is applied to the two real-world NP-hard problems: the graph\n3-coloring and the optimization of markers in the clothing industry. Extensive\nexperiments shown that these hybridization improves the results of the\nevolutionary algorithms a lot. Furthermore, the impact of the particular\nhybridizations is analyzed in details as well.",
        "year": 2013,
        "label": "cs.NE"
    },
    {
        "title": "Recurrent Neural Network Method in Arabic Words Recognition System",
        "authors": [
            "Yusuf Perwej"
        ],
        "summary": "The recognition of unconstrained handwriting continues to be a difficult task\nfor computers despite active research for several decades. This is because\nhandwritten text offers great challenges such as character and word\nsegmentation, character recognition, variation between handwriting styles,\ndifferent character size and no font constraints as well as the background\nclarity. In this paper primarily discussed Online Handwriting Recognition\nmethods for Arabic words which being often used among then across the Middle\nEast and North Africa people. Because of the characteristic of the whole body\nof the Arabic words, namely connectivity between the characters, thereby the\nsegmentation of An Arabic word is very difficult. We introduced a recurrent\nneural network to online handwriting Arabic word recognition. The key\ninnovation is a recently produce recurrent neural networks objective function\nknown as connectionist temporal classification. The system consists of an\nadvanced recurrent neural network with an output layer designed for sequence\nlabeling, partially combined with a probabilistic language model. Experimental\nresults show that unconstrained Arabic words achieve recognition rates about\n79%, which is significantly higher than the about 70% using a previously\ndeveloped hidden markov model based recognition system.",
        "year": 2013,
        "label": "cs.NE"
    },
    {
        "title": "Optimization of supply diversity for the self-assembly of simple objects\n  in two and three dimensions",
        "authors": [
            "Fabio R. J. Vieira",
            "Valmir C. Barbosa"
        ],
        "summary": "The field of algorithmic self-assembly is concerned with the design and\nanalysis of self-assembly systems from a computational perspective, that is,\nfrom the perspective of mathematical problems whose study may give insight into\nthe natural processes through which elementary objects self-assemble into more\ncomplex ones. One of the main problems of algorithmic self-assembly is the\nminimum tile set problem (MTSP), which asks for a collection of types of\nelementary objects (called tiles) to be found for the self-assembly of an\nobject having a pre-established shape. Such a collection is to be as concise as\npossible, thus minimizing supply diversity, while satisfying a set of stringent\nconstraints having to do with the termination and other properties of the\nself-assembly process from its tile types. We present a study of what we think\nis the first practical approach to MTSP. Our study starts with the introduction\nof an evolutionary heuristic to tackle MTSP and includes results from extensive\nexperimentation with the heuristic on the self-assembly of simple objects in\ntwo and three dimensions. The heuristic we introduce combines classic elements\nfrom the field of evolutionary computation with a problem-specific variant of\nPareto dominance into a multi-objective approach to MTSP.",
        "year": 2007,
        "label": "cs.NE"
    },
    {
        "title": "Neutral Fitness Landscape in the Cellular Automata Majority Problem",
        "authors": [
            "S\u00e9bastien Verel",
            "Philippe Collard",
            "Marco Tomassini",
            "Leonardo Vanneschi"
        ],
        "summary": "We study in detail the fitness landscape of a difficult cellular automata\ncomputational task: the majority problem. Our results show why this problem\nlandscape is so hard to search, and we quantify the large degree of neutrality\nfound in various ways. We show that a particular subspace of the solution\nspace, called the \"Olympus\", is where good solutions concentrate, and give\nmeasures to quantitatively characterize this subspace.",
        "year": 2008,
        "label": "cs.NE"
    },
    {
        "title": "Effect of Degree Distribution on Evolutionary Search",
        "authors": [
            "Susan Khor"
        ],
        "summary": "This paper introduces a method to generate hierarchically modular networks\nwith prescribed node degree list and proposes a metric to measure network\nmodularity based on the notion of edge distance. The generated networks are\nused as test problems to explore the effect of modularity and degree\ndistribution on evolutionary algorithm performance. Results from the\nexperiments (i) confirm a previous finding that modularity increases the\nperformance advantage of genetic algorithms over hill climbers, and (ii)\nsupport a new conjecture that test problems with modularized constraint\nnetworks having heavy-tailed right-skewed degree distributions are more easily\nsolved than test problems with modularized constraint networks having\nbell-shaped normal degree distributions.",
        "year": 2009,
        "label": "cs.NE"
    },
    {
        "title": "Idealized Dynamic Population Sizing for Uniformly Scaled Problems",
        "authors": [
            "Fernando G. Lobo"
        ],
        "summary": "This paper explores an idealized dynamic population sizing strategy for\nsolving additive decomposable problems of uniform scale. The method is designed\non top of the foundations of existing population sizing theory for this class\nof problems, and is carefully compared with an optimal fixed population sized\ngenetic algorithm. The resulting strategy should be close to a lower bound in\nterms of what can be achieved, performance-wise, by self-adjusting population\nsizing algorithms for this class of problems.",
        "year": 2011,
        "label": "cs.NE"
    },
    {
        "title": "A swarm optimization algorithm inspired in the behavior of the\n  social-spider",
        "authors": [
            "Erik Cuevas",
            "Miguel Cienfuegos",
            "Daniel Zaldivar",
            "Marco Perez"
        ],
        "summary": "Swarm intelligence is a research field that models the collective behavior in\nswarms of insects or animals. Several algorithms arising from such models have\nbeen proposed to solve a wide range of complex optimization problems. In this\npaper, a novel swarm algorithm called the Social Spider Optimization (SSO) is\nproposed for solving optimization tasks. The SSO algorithm is based on the\nsimulation of cooperative behavior of social-spiders. In the proposed\nalgorithm, individuals emulate a group of spiders which interact to each other\nbased on the biological laws of the cooperative colony. The algorithm considers\ntwo different search agents (spiders): males and females. Depending on gender,\neach individual is conducted by a set of different evolutionary operators which\nmimic different cooperative behaviors that are typically found in the colony.\nIn order to illustrate the proficiency and robustness of the proposed approach,\nit is compared to other well-known evolutionary methods. The comparison\nexamines several standard benchmark functions that are commonly considered\nwithin the literature of evolutionary algorithms. The outcome shows a high\nperformance of the proposed method for searching a global optimum with several\nbenchmark functions.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "General Riemannian SOM",
        "authors": [
            "Jascha A. Schewtschenko"
        ],
        "summary": "Kohonen's Self-Organizing Maps (SOMs) have proven to be a successful\ndata-reduction method to identify the intrinsic lower-dimensional sub-manifold\nof a data set that is scattered in the higher-dimensional feature space.\nMotivated by the possibly non-Euclidian nature of the feature space and of the\nintrinsic geometry of the data set, we extend the definition of classic SOMs to\nobtain the General Riemannian SOM (GRiSOM). We additionally provide an\nimplementation as a proof-of-concept for geometries with constant curvature. We\nfurthermore perform the analytic and numerical analysis of the stability limits\nof certain (GRi)SOM configurations covering the different possible regular\ntessellation of the map space in each geometry. A deviation between the\nnumerical and analytic stability limit has been observed for the square and\nhexagonal Euclidean maps for very small neighbourhoods in the map space as well\nas agreement in case of longer-ranged relations between the map nodes.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "Information Utilization Ratio in Heuristic Optimization Algorithms",
        "authors": [
            "Junzhi Li",
            "Ying Tan"
        ],
        "summary": "Heuristic algorithms are able to optimize objective functions efficiently\nbecause they use intelligently the information about the objective functions.\nThus, information utilization is critical to the performance of heuristics.\nHowever, the concept of information utilization has remained vague and abstract\nbecause there is no reliable metric to reflect the extent to which the\ninformation about the objective function is utilized by heuristic algorithms.\nIn this paper, the metric of information utilization ratio (IUR) is defined,\nwhich is the ratio of the utilized information quantity over the acquired\ninformation quantity in the search process. The IUR proves to be well-defined.\nSeveral examples of typical heuristic algorithms are given to demonstrate the\nprocedure of calculating the IUR. Empirical evidences on the correlation\nbetween the IUR and the performance of a heuristic are also provided. The IUR\ncan be an index of how finely an algorithm is designed and guide the invention\nof new heuristics and the improvement of existing ones.",
        "year": 2016,
        "label": "cs.NE"
    },
    {
        "title": "Black-box optimization benchmarking of IPOP-saACM-ES on the BBOB-2012\n  noisy testbed",
        "authors": [
            "Ilya Loshchilov",
            "Marc Schoenauer",
            "Mich\u00e8le Sebag"
        ],
        "summary": "In this paper, we study the performance of IPOP-saACM-ES, recently proposed\nself-adaptive surrogate-assisted Covariance Matrix Adaptation Evolution\nStrategy. The algorithm was tested using restarts till a total number of\nfunction evaluations of $10^6D$ was reached, where $D$ is the dimension of the\nfunction search space. The experiments show that the surrogate model control\nallows IPOP-saACM-ES to be as robust as the original IPOP-aCMA-ES and\noutperforms the latter by a factor from 2 to 3 on 6 benchmark problems with\nmoderate noise. On 15 out of 30 benchmark problems in dimension 20,\nIPOP-saACM-ES exceeds the records observed during BBOB-2009 and BBOB-2010.",
        "year": 2012,
        "label": "cs.NE"
    },
    {
        "title": "Speeding up the construction of slow adaptive walks",
        "authors": [
            "Susan Khor"
        ],
        "summary": "An algorithm (bliss) is proposed to speed up the construction of slow\nadaptive walks. Slow adaptive walks are adaptive walks biased towards closer\npoints or smaller move steps. They were previously introduced to explore a\nsearch space, e.g. to detect potential local optima or to assess the ruggedness\nof a fitness landscape. To avoid the quadratic cost of computing Hamming\ndistance (HD) for all-pairs of strings in a set in order to find the set of\nclosest strings for each string, strings are sorted and clustered by bliss such\nthat similar strings are more likely to get paired off for HD computation. To\nefficiently arrange the strings by similarity, bliss employs the idea of shared\nnon-overlapping position specific subsequences between strings which is\ninspired by an alignment-free protein sequence comparison algorithm. Tests are\nperformed to evaluate the quality of b-walks, i.e. slow adaptive walks\nconstructed from the output of bliss, on enumerated search spaces. Finally,\nb-walks are applied to explore larger search spaces with the help of\nWang-Landau sampling.",
        "year": 2012,
        "label": "cs.NE"
    },
    {
        "title": "Black-box optimization benchmarking of IPOP-saACM-ES and BIPOP-saACM-ES\n  on the BBOB-2012 noiseless testbed",
        "authors": [
            "Ilya Loshchilov",
            "Marc Schoenauer",
            "Mich\u00e8le Sebag"
        ],
        "summary": "In this paper, we study the performance of IPOP-saACM-ES and BIPOP-saACM-ES,\nrecently proposed self-adaptive surrogate-assisted Covariance Matrix Adaptation\nEvolution Strategies. Both algorithms were tested using restarts till a total\nnumber of function evaluations of $10^6D$ was reached, where $D$ is the\ndimension of the function search space. We compared surrogate-assisted\nalgorithms with their surrogate-less versions IPOP-saACM-ES and BIPOP-saACM-ES,\ntwo algorithms with one of the best overall performance observed during the\nBBOB-2009 and BBOB-2010. The comparison shows that the surrogate-assisted\nversions outperform the original CMA-ES algorithms by a factor from 2 to 4 on 8\nout of 24 noiseless benchmark problems, showing the best results among all\nalgorithms of the BBOB-2009 and BBOB-2010 on Ellipsoid, Discus, Bent Cigar,\nSharp Ridge and Sum of different powers functions.",
        "year": 2012,
        "label": "cs.NE"
    },
    {
        "title": "Dienstplanerstellung in Krankenhaeusern mittels genetischer Algorithmen",
        "authors": [
            "Uwe Aickelin"
        ],
        "summary": "This thesis investigates the use of problem-specific knowledge to enhance a\ngenetic algorithm approach to multiple-choice optimisation problems. It shows\nthat such information can significantly enhance performance, but that the\nchoice of information and the way it is included are important factors for\nsuccess.",
        "year": 2013,
        "label": "cs.NE"
    },
    {
        "title": "Multimodal Optimization by Sparkling Squid Populations",
        "authors": [
            "Videh Seksaria"
        ],
        "summary": "The swarm intelligence of animals is a natural paradigm to apply to\noptimization problems. Ant colony, bee colony, firefly and bat algorithms are\namongst those that have been demonstrated to efficiently to optimize complex\nconstraints. This paper proposes the new Sparkling Squid Algorithm (SSA) for\nmultimodal optimization, inspired by the intelligent swarm behavior of its\nnamesake. After an introduction, formulation and discussion of its\nimplementation, it will be compared to other popular metaheuristics. Finally,\napplications to well - known problems such as image registration and the\ntraveling salesperson problem will be discussed.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "Evolutionary Optimization for Decision Making under Uncertainty",
        "authors": [
            "Ronald Hochreiter"
        ],
        "summary": "Optimizing decision problems under uncertainty can be done using a variety of\nsolution methods. Soft computing and heuristic approaches tend to be powerful\nfor solving such problems. In this overview article, we survey Evolutionary\nOptimization techniques to solve Stochastic Programming problems - both for the\nsingle-stage and multi-stage case.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "Unbiased Black-Box Complexities of Jump Functions",
        "authors": [
            "Benjamin Doerr",
            "Carola Doerr",
            "Timo K\u00f6tzing"
        ],
        "summary": "We analyze the unbiased black-box complexity of jump functions with small,\nmedium, and large sizes of the fitness plateau surrounding the optimal\nsolution.\n  Among other results, we show that when the jump size is $(1/2 -\n\\varepsilon)n$, that is, only a small constant fraction of the fitness values\nis visible, then the unbiased black-box complexities for arities $3$ and higher\nare of the same order as those for the simple \\textsc{OneMax} function. Even\nfor the extreme jump function, in which all but the two fitness values $n/2$\nand $n$ are blanked out, polynomial-time mutation-based (i.e., unary unbiased)\nblack-box optimization algorithms exist. This is quite surprising given that\nfor the extreme jump function almost the whole search space (all but a\n$\\Theta(n^{-1/2})$ fraction) is a plateau of constant fitness.\n  To prove these results, we introduce new tools for the analysis of unbiased\nblack-box complexities, for example, selecting the new parent individual not by\ncomparing the fitnesses of the competing search points, but also by taking into\naccount the (empirical) expected fitnesses of their offspring.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "Radial basis function process neural network training based on\n  generalized frechet distance and GA-SA hybrid strategy",
        "authors": [
            "Bing Wang",
            "Yao-hua Meng",
            "Xiao-hong Yu"
        ],
        "summary": "For learning problem of Radial Basis Function Process Neural Network\n(RBF-PNN), an optimization training method based on GA combined with SA is\nproposed in this paper. Through building generalized Fr\\'echet distance to\nmeasure similarity between time-varying function samples, the learning problem\nof radial basis centre functions and connection weights is converted into the\ntraining on corresponding discrete sequence coefficients. Network training\nobjective function is constructed according to the least square error\ncriterion, and global optimization solving of network parameters is implemented\nin feasible solution space by use of global optimization feature of GA and\nprobabilistic jumping property of SA . The experiment results illustrate that\nthe training algorithm improves the network training efficiency and stability.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "Memetic Search in Differential Evolution Algorithm",
        "authors": [
            "Sandeep Kumar",
            "Vivek Kumar Sharma",
            "Rajani Kumari"
        ],
        "summary": "Differential Evolution (DE) is a renowned optimization stratagem that can\neasily solve nonlinear and comprehensive problems. DE is a well known and\nuncomplicated population based probabilistic approach for comprehensive\noptimization. It has apparently outperformed a number of Evolutionary\nAlgorithms and further search heuristics in the vein of Particle Swarm\nOptimization at what time of testing over both yardstick and actual world\nproblems. Nevertheless, DE, like other probabilistic optimization algorithms,\nfrom time to time exhibits precipitate convergence and stagnates at suboptimal\nposition. In order to stay away from stagnation behavior while maintaining an\nexcellent convergence speed, an innovative search strategy is introduced, named\nmemetic search in DE. In the planned strategy, positions update equation\ncustomized as per a memetic search stratagem. In this strategy a better\nsolution participates more times in the position modernize procedure. The\nposition update equation is inspired from the memetic search in artificial bee\ncolony algorithm. The proposed strategy is named as Memetic Search in\nDifferential Evolution (MSDE). To prove efficiency and efficacy of MSDE, it is\ntested over 8 benchmark optimization problems and three real world optimization\nproblems. A comparative analysis has also been carried out among proposed MSDE\nand original DE. Results show that the anticipated algorithm go one better than\nthe basic DE and its recent deviations in a good number of the experiments.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "Randomized Memetic Artificial Bee Colony Algorithm",
        "authors": [
            "Sandeep Kumar",
            "Vivek Kumar Sharma",
            "Rajani Kumari"
        ],
        "summary": "Artificial Bee Colony (ABC) optimization algorithm is one of the recent\npopulation based probabilistic approach developed for global optimization. ABC\nis simple and has been showed significant improvement over other Nature\nInspired Algorithms (NIAs) when tested over some standard benchmark functions\nand for some complex real world optimization problems. Memetic Algorithms also\nbecome one of the key methodologies to solve the very large and complex\nreal-world optimization problems. The solution search equation of Memetic ABC\nis based on Golden Section Search and an arbitrary value which tries to balance\nexploration and exploitation of search space. But still there are some chances\nto skip the exact solution due to its step size. In order to balance between\ndiversification and intensification capability of the Memetic ABC, it is\nrandomized the step size in Memetic ABC. The proposed algorithm is named as\nRandomized Memetic ABC (RMABC). In RMABC, new solutions are generated nearby\nthe best so far solution and it helps to increase the exploitation capability\nof Memetic ABC. The experiments on some test problems of different complexities\nand one well known engineering optimization application show that the proposed\nalgorithm outperforms over Memetic ABC (MeABC) and some other variant of ABC\nalgorithm(like Gbest guided ABC (GABC),Hooke Jeeves ABC (HJABC), Best-So-Far\nABC (BSFABC) and Modified ABC (MABC) in case of almost all the problems.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "Positive Neural Networks in Discrete Time Implement Monotone-Regular\n  Behaviors",
        "authors": [
            "Tom J. Ameloot",
            "Jan Van den Bussche"
        ],
        "summary": "We study the expressive power of positive neural networks. The model uses\npositive connection weights and multiple input neurons. Different behaviors can\nbe expressed by varying the connection weights. We show that in discrete time,\nand in absence of noise, the class of positive neural networks captures the\nso-called monotone-regular behaviors, that are based on regular languages. A\nfiner picture emerges if one takes into account the delay by which a\nmonotone-regular behavior is implemented. Each monotone-regular behavior can be\nimplemented by a positive neural network with a delay of one time unit. Some\nmonotone-regular behaviors can be implemented with zero delay. And,\ninterestingly, some simple monotone-regular behaviors can not be implemented\nwith zero delay.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "Technical Analysis on Financial Forecasting",
        "authors": [
            "S. Gopal Krishna Patro",
            "Pragyan Parimita Sahoo",
            "Ipsita Panda",
            "Kishore Kumar Sahu"
        ],
        "summary": "Financial forecasting is an estimation of future financial outcomes for a\ncompany, industry, country using historical internal accounting and sales data.\nWe may predict the future outcome of BSE_SENSEX practically by some soft\ncomputing techniques and can also optimized using PSO (Particle Swarm\nOptimization), EA (Evolutionary Algorithm) or DEA (Differential Evolutionary\nAlgorithm) etc. PSO is a biologically inspired computational search &\noptimization method developed in 1995 by Dr. Eberhart and Dr. Kennedy based on\nthe social behaviors of fish schooling or birds flocking. PSO is a promising\nmethod to train Artificial Neural Network (ANN). It is easy to implement then\nGenetic Algorithm except few parameters are adjusted. PSO is a random & pattern\nsearch technique based on populating of particle. In PSO, the particles are\nhaving some position and velocity in the search space. Two terms are used in\nPSO one is Local Best and another one is Global Best. To optimize problems that\nare like Irregular, Noisy, Change over time, Static etc. PSO uses a classic\noptimization method such as Gradient Decent & Quasi-Newton Methods. The\nobservation and review of few related studies in the last few years, focusing\non function of PSO, modification of PSO and operation that have implemented\nusing PSO like function optimization, ANN Training & Fuzzy Control etc.\nDifferential Evolution is an efficient EA technique for optimization of\nnumerical problems, financial problems etc. PSO technique is introduced due to\nthe swarming behavior of animals which is the collective behavior of similar\nsize that aggregates together.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "Neural Turing Machines: Convergence of Copy Tasks",
        "authors": [
            "Janez Ale\u0161"
        ],
        "summary": "The architecture of neural Turing machines is differentiable end to end and\nis trainable with gradient descent methods. Due to their large unfolded depth\nNeural Turing Machines are hard to train and because of their linear access of\ncomplete memory they do not scale. Other architectures have been studied to\novercome these difficulties. In this report we focus on improving the quality\nof prediction of the original linear memory architecture on copy and repeat\ncopy tasks. Copy task predictions on sequences of length six times larger than\nthose the neural Turing machine was trained on prove to be highly accurate and\nso do predictions of repeat copy tasks for sequences with twice the repetition\nnumber and twice the sequence length neural Turing machine was trained on.",
        "year": 2016,
        "label": "cs.NE"
    },
    {
        "title": "Search space analysis with Wang-Landau sampling and slow adaptive walks",
        "authors": [
            "Susan Khor"
        ],
        "summary": "Two complementary techniques for analyzing search spaces are proposed: (i) an\nalgorithm to detect search points with potential to be local optima; and (ii) a\nslightly adjusted Wang-Landau sampling algorithm to explore larger search\nspaces. The detection algorithm assumes that local optima are points which are\neasier to reach and harder to leave by a slow adaptive walker. A slow adaptive\nwalker moves to a nearest fitter point. Thus, points with larger outgoing step\nsizes relative to incoming step sizes are marked using the local optima score\nformulae as potential local optima points (PLOPs). Defining local optima in\nthese more general terms allows their detection within the closure of a subset\nof a search space, and the sampling of a search space unshackled by a\nparticular move set. Tests are done with NK and HIFF problems to confirm that\nPLOPs detected in the manner proposed retain characteristics of local optima,\nand that the adjusted Wang-Landau samples are more representative of the search\nspace than samples produced by choosing points uniformly at random. While our\napproach shows promise, more needs to be done to reduce its computation cost\nthat it may pave a way toward analyzing larger search spaces of practical\nmeaning.",
        "year": 2011,
        "label": "cs.NE"
    },
    {
        "title": "A Bayesian Interpretation of the Particle Swarm Optimization and Its\n  Kernel Extension",
        "authors": [
            "Peter Andras"
        ],
        "summary": "Particle swarm optimization is a popular method for solving difficult\noptimization problems. There have been attempts to formulate the method in\nformal probabilistic or stochastic terms (e.g. bare bones particle swarm) with\nthe aim to achieve more generality and explain the practical behavior of the\nmethod. Here we present a Bayesian interpretation of the particle swarm\noptimization. This interpretation provides a formal framework for incorporation\nof prior knowledge about the problem that is being solved. Furthermore, it also\nallows to extend the particle optimization method through the use of kernel\nfunctions that represent the intermediary transformation of the data into a\ndifferent space where the optimization problem is expected to be easier to be\nresolved, such transformation can be seen as a form of prior knowledge about\nthe nature of the optimization problem. We derive from the general Bayesian\nformulation the commonly used particle swarm methods as particular cases.",
        "year": 2012,
        "label": "cs.NE"
    },
    {
        "title": "My First Deep Learning System of 1991 + Deep Learning Timeline 1962-2013",
        "authors": [
            "J\u00fcrgen Schmidhuber"
        ],
        "summary": "Deep Learning has attracted significant attention in recent years. Here I\npresent a brief overview of my first Deep Learner of 1991, and its historic\ncontext, with a timeline of Deep Learning highlights.",
        "year": 2013,
        "label": "cs.NE"
    },
    {
        "title": "A Computationally Efficient Limited Memory CMA-ES for Large Scale\n  Optimization",
        "authors": [
            "Ilya Loshchilov"
        ],
        "summary": "We propose a computationally efficient limited memory Covariance Matrix\nAdaptation Evolution Strategy for large scale optimization, which we call the\nLM-CMA-ES. The LM-CMA-ES is a stochastic, derivative-free algorithm for\nnumerical optimization of non-linear, non-convex optimization problems in\ncontinuous domain. Inspired by the limited memory BFGS method of Liu and\nNocedal (1989), the LM-CMA-ES samples candidate solutions according to a\ncovariance matrix reproduced from $m$ direction vectors selected during the\noptimization process. The decomposition of the covariance matrix into Cholesky\nfactors allows to reduce the time and memory complexity of the sampling to\n$O(mn)$, where $n$ is the number of decision variables. When $n$ is large\n(e.g., $n$ > 1000), even relatively small values of $m$ (e.g., $m=20,30$) are\nsufficient to efficiently solve fully non-separable problems and to reduce the\noverall run-time.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "Improved Onlooker Bee Phase in Artificial Bee Colony Algorithm",
        "authors": [
            "Sandeep Kumar",
            "Vivek Kumar Sharma",
            "Rajani Kumari"
        ],
        "summary": "Artificial Bee Colony (ABC) is a distinguished optimization strategy that can\nresolve nonlinear and multifaceted problems. It is comparatively a\nstraightforward and modern population based probabilistic approach for\ncomprehensive optimization. In the vein of the other population based\nalgorithms, ABC is moreover computationally classy due to its slow nature of\nsearch procedure. The solution exploration equation of ABC is extensively\ninfluenced by a arbitrary quantity which helps in exploration at the cost of\nexploitation of the better search space. In the solution exploration equation\nof ABC due to the outsized step size the chance of skipping the factual\nsolution is high. Therefore, here this paper improve onlooker bee phase with\nhelp of a local search strategy inspired by memetic algorithm to balance the\ndiversity and convergence capability of the ABC. The proposed algorithm is\nnamed as Improved Onlooker Bee Phase in ABC (IoABC). It is tested over 12 well\nknown un-biased test problems of diverse complexities and two engineering\noptimization problems; results show that the anticipated algorithm go one\nbetter than the basic ABC and its recent deviations in a good number of the\nexperiments.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "Towards a Calculus of Echo State Networks",
        "authors": [
            "Alireza Goudarzi",
            "Darko Stefanovic"
        ],
        "summary": "Reservoir computing is a recent trend in neural networks which uses the\ndynamical perturbations on the phase space of a system to compute a desired\ntarget function. We present how one can formulate an expectation of system\nperformance in a simple class of reservoir computing called echo state\nnetworks. In contrast with previous theoretical frameworks, which only reveal\nan upper bound on the total memory in the system, we analytically calculate the\nentire memory curve as a function of the structure of the system and the\nproperties of the input and the target function. We demonstrate the precision\nof our framework by validating its result for a wide range of system sizes and\nspectral radii. Our analytical calculation agrees with numerical simulations.\nTo the best of our knowledge this work presents the first exact analytical\ncharacterization of the memory curve in echo state networks.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "Recurrent Neural Network Regularization",
        "authors": [
            "Wojciech Zaremba",
            "Ilya Sutskever",
            "Oriol Vinyals"
        ],
        "summary": "We present a simple regularization technique for Recurrent Neural Networks\n(RNNs) with Long Short-Term Memory (LSTM) units. Dropout, the most successful\ntechnique for regularizing neural networks, does not work well with RNNs and\nLSTMs. In this paper, we show how to correctly apply dropout to LSTMs, and show\nthat it substantially reduces overfitting on a variety of tasks. These tasks\ninclude language modeling, speech recognition, image caption generation, and\nmachine translation.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "An OvS-MultiObjective Algorithm Approach for Lane Reversal Problem",
        "authors": [
            "Enrique Gabriel Baquela",
            "Ana Carolina Olivera"
        ],
        "summary": "The lane reversal has proven to be a useful method to mitigate traffic\ncongestion during rush hour or in case of specific events that affect high\ntraffic volumes. In this work we propose a methodology that is placed within\noptimization via Simulation, by means of which a multi-objective genetic\nalgorithm and simulations of traffic are used to determine the configuration of\nideal lane reversal.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "Introduction and Ranking Results of the ICSI 2014 Competition on Single\n  Objective Optimization",
        "authors": [
            "Ying Tan",
            "Junzhi Li",
            "Zhongyang Zheng"
        ],
        "summary": "This technical report includes the introduction and ranking results of the\nICSI 2014 Competition on Single Objective Optimization.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "A New Repair Operator for Multi-objective Evolutionary Algorithm in\n  Constrained Optimization Problems",
        "authors": [
            "Zhun Fan",
            "Wenji Li",
            "Xinye Cai",
            "Huibiao Lin",
            "Shuxiang Xie",
            "Erik Goodman"
        ],
        "summary": "In this paper, we design a set of multi-objective constrained optimization\nproblems (MCOPs) and propose a new repair operator to address them. The\nproposed repair operator is used to fix the solutions that violate the box\nconstraints. More specifically, it employs a reversed correction strategy that\ncan effectively avoid the population falling into local optimum. In addition,\nwe integrate the proposed repair operator into two classical multi-objective\nevolutionary algorithms MOEA/D and NSGA-II. The proposed repair operator is\ncompared with other two kinds of commonly used repair operators on benchmark\nproblems CTPs and MCOPs. The experiment results demonstrate that our proposed\napproach is very effective in terms of convergence and diversity.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "Optimal Parameter Choices Through Self-Adjustment: Applying the 1/5-th\n  Rule in Discrete Settings",
        "authors": [
            "Benjamin Doerr",
            "Carola Doerr"
        ],
        "summary": "While evolutionary algorithms are known to be very successful for a broad\nrange of applications, the algorithm designer is often left with many\nalgorithmic choices, for example, the size of the population, the mutation\nrates, and the crossover rates of the algorithm. These parameters are known to\nhave a crucial influence on the optimization time, and thus need to be chosen\ncarefully, a task that often requires substantial efforts. Moreover, the\noptimal parameters can change during the optimization process. It is therefore\nof great interest to design mechanisms that dynamically choose best-possible\nparameters. An example for such an update mechanism is the one-fifth success\nrule for step-size adaption in evolutionary strategies. While in continuous\ndomains this principle is well understood also from a mathematical point of\nview, no comparable theory is available for problems in discrete domains.\n  In this work we show that the one-fifth success rule can be effective also in\ndiscrete settings. We regard the $(1+(\\lambda,\\lambda))$~GA proposed in\n[Doerr/Doerr/Ebel: From black-box complexity to designing new genetic\nalgorithms, TCS 2015]. We prove that if its population size is chosen according\nto the one-fifth success rule then the expected optimization time on\n\\textsc{OneMax} is linear. This is better than what \\emph{any} static\npopulation size $\\lambda$ can achieve and is asymptotically optimal also among\nall adaptive parameter choices.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "Combined A*-Ants Algorithm: A New Multi-Parameter Vehicle Navigation\n  Scheme",
        "authors": [
            "Hojjat Salehinejad",
            "Hossein Nezamabadi-pour",
            "Saeid Saryazdi",
            "Fereydoun Farrahi-Moghaddam"
        ],
        "summary": "In this paper a multi-parameter A*(A- star)-ants based algorithm is proposed\nin order to find the best optimized multi-parameter path between two desired\npoints in regions. This algorithm recognizes paths, according to user desired\nparameters using electronic maps. The proposed algorithm is a combination of A*\nand ants algorithm in which the proposed A* algorithm is the prologue to the\nsuggested ant based algorithm .In fact, this A* algorithm invigorates some\npaths pheromones in ants algorithm. As one of implementations of this method,\nthis algorithm was applied on a part of Kerman city, Iran as a multi-parameter\nvehicle navigator. It finds the best optimized multi-parameter direction\nbetween two desired junctions based on city traveler parameters. Comparison\nresults between the proposed method and ants algorithm demonstrates efficiency\nand lower cost function results of the proposed method versus ants algorithm.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "Memory and information processing in neuromorphic systems",
        "authors": [
            "Giacomo Indiveri",
            "Shih-Chii Liu"
        ],
        "summary": "A striking difference between brain-inspired neuromorphic processors and\ncurrent von Neumann processors architectures is the way in which memory and\nprocessing is organized. As Information and Communication Technologies continue\nto address the need for increased computational power through the increase of\ncores within a digital processor, neuromorphic engineers and scientists can\ncomplement this need by building processor architectures where memory is\ndistributed with the processing. In this paper we present a survey of\nbrain-inspired processor architectures that support models of cortical networks\nand deep neural networks. These architectures range from serial clocked\nimplementations of multi-neuron systems to massively parallel asynchronous ones\nand from purely digital systems to mixed analog/digital systems which implement\nmore biological-like models of neurons and synapses together with a suite of\nadaptation and learning mechanisms analogous to the ones found in biological\nnervous systems. We describe the advantages of the different approaches being\npursued and present the challenges that need to be addressed for building\nartificial neural processing systems that can display the richness of behaviors\nseen in biological systems.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "Solving Problems with Unknown Solution Length at (Almost) No Extra Cost",
        "authors": [
            "Benjamin Doerr",
            "Carola Doerr",
            "Timo K\u00f6tzing"
        ],
        "summary": "Most research in the theory of evolutionary computation assumes that the\nproblem at hand has a fixed problem size. This assumption does not always apply\nto real-world optimization challenges, where the length of an optimal solution\nmay be unknown a priori.\n  Following up on previous work of Cathabard, Lehre, and Yao [FOGA 2011] we\nanalyze variants of the (1+1) evolutionary algorithm for problems with unknown\nsolution length. For their setting, in which the solution length is sampled\nfrom a geometric distribution, we provide mutation rates that yield an expected\noptimization time that is of the same order as that of the (1+1) EA knowing the\nsolution length.\n  We then show that almost the same run times can be achieved even if \\emph{no}\na priori information on the solution length is available.\n  Finally, we provide mutation rates suitable for settings in which neither the\nsolution length nor the positions of the relevant bits are known. Again we\nobtain almost optimal run times for the \\textsc{OneMax} and\n\\textsc{LeadingOnes} test functions, thus solving an open problem from\nCathabard et al.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "A Tight Runtime Analysis of the $(1+(\u03bb, \u03bb))$ Genetic\n  Algorithm on OneMax",
        "authors": [
            "Benjamin Doerr",
            "Carola Doerr"
        ],
        "summary": "Understanding how crossover works is still one of the big challenges in\nevolutionary computation research, and making our understanding precise and\nproven by mathematical means might be an even bigger one. As one of few\nexamples where crossover provably is useful, the $(1+(\\lambda, \\lambda))$\nGenetic Algorithm (GA) was proposed recently in [Doerr, Doerr, Ebel: TCS 2015].\nUsing the fitness level method, the expected optimization time on general\nOneMax functions was analyzed and a $O(\\max\\{n\\log(n)/\\lambda, \\lambda n\\})$\nbound was proven for any offspring population size $\\lambda \\in [1..n]$.\n  We improve this work in several ways, leading to sharper bounds and a better\nunderstanding of how the use of crossover speeds up the runtime in this\nalgorithm. We first improve the upper bound on the runtime to\n$O(\\max\\{n\\log(n)/\\lambda, n\\lambda \\log\\log(\\lambda)/\\log(\\lambda)\\})$. This\nimprovement is made possible from observing that in the parallel generation of\n$\\lambda$ offspring via crossover (but not mutation), the best of these often\nis better than the expected value, and hence several fitness levels can be\ngained in one iteration.\n  We then present the first lower bound for this problem. It matches our upper\nbound for all values of $\\lambda$. This allows to determine the asymptotically\noptimal value for the population size. It is $\\lambda =\n\\Theta(\\sqrt{\\log(n)\\log\\log(n)/\\log\\log\\log(n)})$, which gives an optimization\ntime of $\\Theta(n \\sqrt{\\log(n)\\log\\log\\log(n)/\\log\\log(n)})$. Hence the\nimproved runtime analysis gives a better runtime guarantee along with a better\nsuggestion for the parameter $\\lambda$.\n  We finally give a tail bound for the upper tail of the runtime distribution,\nwhich shows that the actual runtime exceeds our runtime guarantee by a factor\nof $(1+\\delta)$ with probability $O((n/\\lambda^2)^{-\\delta})$ only.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "A hybrid COA$\u03b5$-constraint method for solving multi-objective\n  problems",
        "authors": [
            "Mahdi parvizi",
            "Elham Shadkam",
            "Niloofar Jahani"
        ],
        "summary": "In this paper, a hybrid method for solving multi-objective problem has been\nprovided. The proposed method is combining the {\\epsilon}-Constraint and the\nCuckoo algorithm. First the multi objective problem transfers into a\nsingle-objective problem using $\\epsilon$-Constraint, then the Cuckoo\noptimization algorithm will optimize the problem in each task. At last the\noptimized Pareto frontier will be drawn. The advantage of this method is the\nhigh accuracy and the dispersion of its Pareto frontier. In order to testing\nthe efficiency of the suggested method, a lot of test problems have been solved\nusing this method. Comparing the results of this method with the results of\nother similar methods shows that the Cuckoo algorithm is more suitable for\nsolving the multi-objective problems.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "Conversion of Artificial Recurrent Neural Networks to Spiking Neural\n  Networks for Low-power Neuromorphic Hardware",
        "authors": [
            "Peter U. Diehl",
            "Guido Zarrella",
            "Andrew Cassidy",
            "Bruno U. Pedroni",
            "Emre Neftci"
        ],
        "summary": "In recent years the field of neuromorphic low-power systems that consume\norders of magnitude less power gained significant momentum. However, their\nwider use is still hindered by the lack of algorithms that can harness the\nstrengths of such architectures. While neuromorphic adaptations of\nrepresentation learning algorithms are now emerging, efficient processing of\ntemporal sequences or variable length-inputs remain difficult. Recurrent neural\nnetworks (RNN) are widely used in machine learning to solve a variety of\nsequence learning tasks. In this work we present a train-and-constrain\nmethodology that enables the mapping of machine learned (Elman) RNNs on a\nsubstrate of spiking neurons, while being compatible with the capabilities of\ncurrent and near-future neuromorphic systems. This \"train-and-constrain\" method\nconsists of first training RNNs using backpropagation through time, then\ndiscretizing the weights and finally converting them to spiking RNNs by\nmatching the responses of artificial neurons with those of the spiking neurons.\nWe demonstrate our approach by mapping a natural language processing task\n(question classification), where we demonstrate the entire mapping process of\nthe recurrent layer of the network on IBM's Neurosynaptic System \"TrueNorth\", a\nspike-based digital neuromorphic hardware architecture. TrueNorth imposes\nspecific constraints on connectivity, neural and synaptic parameters. To\nsatisfy these constraints, it was necessary to discretize the synaptic weights\nand neural activities to 16 levels, and to limit fan-in to 64 inputs. We find\nthat short synaptic delays are sufficient to implement the dynamical (temporal)\naspect of the RNN in the question classification task. The hardware-constrained\nmodel achieved 74% accuracy in question classification while using less than\n0.025% of the cores on one TrueNorth chip, resulting in an estimated power\nconsumption of ~17 uW.",
        "year": 2016,
        "label": "cs.NE"
    },
    {
        "title": "Learning Over Long Time Lags",
        "authors": [
            "Hojjat Salehinejad"
        ],
        "summary": "The advantage of recurrent neural networks (RNNs) in learning dependencies\nbetween time-series data has distinguished RNNs from other deep learning\nmodels. Recently, many advances are proposed in this emerging field. However,\nthere is a lack of comprehensive review on memory models in RNNs in the\nliterature. This paper provides a fundamental review on RNNs and long short\nterm memory (LSTM) model. Then, provides a surveys of recent advances in\ndifferent memory enhancements and learning techniques for capturing long term\ndependencies in RNNs.",
        "year": 2016,
        "label": "cs.NE"
    },
    {
        "title": "Multiplier-less Artificial Neurons Exploiting Error Resiliency for\n  Energy-Efficient Neural Computing",
        "authors": [
            "Syed Shakib Sarwar",
            "Swagath Venkataramani",
            "Anand Raghunathan",
            "Kaushik Roy"
        ],
        "summary": "Large-scale artificial neural networks have shown significant promise in\naddressing a wide range of classification and recognition applications.\nHowever, their large computational requirements stretch the capabilities of\ncomputing platforms. The fundamental components of these neural networks are\nthe neurons and its synapses. The core of a digital hardware neuron consists of\nmultiplier, accumulator and activation function. Multipliers consume most of\nthe processing energy in the digital neurons, and thereby in the hardware\nimplementations of artificial neural networks. We propose an approximate\nmultiplier that utilizes the notion of computation sharing and exploits error\nresilience of neural network applications to achieve improved energy\nconsumption. We also propose Multiplier-less Artificial Neuron (MAN) for even\nlarger improvement in energy consumption and adapt the training process to\nensure minimal degradation in accuracy. We evaluated the proposed design on 5\nrecognition applications. The results show, 35% and 60% reduction in energy\nconsumption, for neuron sizes of 8 bits and 12 bits, respectively, with a\nmaximum of ~2.83% loss in network accuracy, compared to a conventional neuron\nimplementation. We also achieve 37% and 62% reduction in area for a neuron size\nof 8 bits and 12 bits, respectively, under iso-speed conditions.",
        "year": 2016,
        "label": "cs.NE"
    },
    {
        "title": "Neural networks with differentiable structure",
        "authors": [
            "Thomas Miconi"
        ],
        "summary": "While gradient descent has proven highly successful in learning connection\nweights for neural networks, the actual structure of these networks is usually\ndetermined by hand, or by other optimization algorithms. Here we describe a\nsimple method to make network structure differentiable, and therefore\naccessible to gradient descent. We test this method on recurrent neural\nnetworks applied to simple sequence prediction problems. Starting with initial\nnetworks containing only one node, the method automatically builds networks\nthat successfully solve the tasks. The number of nodes in the final network\ncorrelates with task difficulty. The method can dynamically increase network\nsize in response to an abrupt complexification in the task; however, reduction\nin network size in response to task simplification is not evident for\nreasonable meta-parameters. The method does not penalize network performance\nfor these test tasks: variable-size networks actually reach better performance\nthan fixed-size networks of higher, lower or identical size. We conclude by\ndiscussing how this method could be applied to more complex networks, such as\nfeedforward layered networks, or multiple-area networks of arbitrary shape.",
        "year": 2016,
        "label": "cs.NE"
    },
    {
        "title": "Robust Particle Swarm Optimizer based on Chemomimicry",
        "authors": [
            "Casey Kneale",
            "Karl S. Booksh"
        ],
        "summary": "A particle swarm optimizer (PSO) loosely based on the phenomena of\ncrystallization and a chaos factor which follows the complimentary error\nfunction is described. The method features three phases: diffusion, directed\nmotion, and nucleation. During the diffusion phase random walk is the only\ncontributor to particle motion. As the algorithm progresses the contribution\nfrom chaos decreases and movement toward global best locations is pursued until\nconvergence has occurred. The algorithm was found to be more robust to local\nminima in multimodal test functions than a standard PSO algorithm and is\ndesigned for problems which feature experimental precision.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "Fast Genetic Algorithms",
        "authors": [
            "Benjamin Doerr",
            "Huu Phuoc Le",
            "R\u00e9gis Makhmara",
            "Ta Duy Nguyen"
        ],
        "summary": "For genetic algorithms using a bit-string representation of length~$n$, the\ngeneral recommendation is to take $1/n$ as mutation rate. In this work, we\ndiscuss whether this is really justified for multimodal functions. Taking jump\nfunctions and the $(1+1)$ evolutionary algorithm as the simplest example, we\nobserve that larger mutation rates give significantly better runtimes. For the\n$\\jump_{m,n}$ function, any mutation rate between $2/n$ and $m/n$ leads to a\nspeed-up at least exponential in $m$ compared to the standard choice.\n  The asymptotically best runtime, obtained from using the mutation rate $m/n$\nand leading to a speed-up super-exponential in $m$, is very sensitive to small\nchanges of the mutation rate. Any deviation by a small $(1 \\pm \\eps)$ factor\nleads to a slow-down exponential in $m$. Consequently, any fixed mutation rate\ngives strongly sub-optimal results for most jump functions.\n  Building on this observation, we propose to use a random mutation rate\n$\\alpha/n$, where $\\alpha$ is chosen from a power-law distribution. We prove\nthat the $(1+1)$ EA with this heavy-tailed mutation rate optimizes any\n$\\jump_{m,n}$ function in a time that is only a small polynomial (in~$m$)\nfactor above the one stemming from the optimal rate for this $m$.\n  Our heavy-tailed mutation operator yields similar speed-ups (over the best\nknown performance guarantees) for the vertex cover problem in bipartite graphs\nand the matching problem in general graphs.\n  Following the example of fast simulated annealing, fast evolution strategies,\nand fast evolutionary programming, we propose to call genetic algorithms using\na heavy-tailed mutation operator \\emph{fast genetic algorithms}.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "The Emergence of Canalization and Evolvability in an Open-Ended,\n  Interactive Evolutionary System",
        "authors": [
            "Joost Huizinga",
            "Kenneth O. Stanley",
            "Jeff Clune"
        ],
        "summary": "Natural evolution has produced a tremendous diversity of functional\norganisms. Many believe an essential component of this process was the\nevolution of evolvability, whereby evolution speeds up its ability to innovate\nby generating a more adaptive pool of offspring. One hypothesized mechanism for\nevolvability is developmental canalization, wherein certain dimensions of\nvariation become more likely to be traversed and others are prevented from\nbeing explored (e.g. offspring tend to have similarly sized legs, and mutations\naffect the length of both legs, not each leg individually). While ubiquitous in\nnature, canalization almost never evolves in computational simulations of\nevolution. Not only does that deprive us of in silico models in which to study\nthe evolution of evolvability, but it also raises the question of which\nconditions give rise to this form of evolvability. Answering this question\nwould shed light on why such evolvability emerged naturally and could\naccelerate engineering efforts to harness evolution to solve important\nengineering challenges. In this paper we reveal a unique system in which\ncanalization did emerge in computational evolution. We document that genomes\nentrench certain dimensions of variation that were frequently explored during\ntheir evolutionary history. The genetic representation of these organisms also\nevolved to be highly modular and hierarchical, and we show that these\norganizational properties correlate with increased fitness. Interestingly, the\ntype of computational evolutionary experiment that produced this evolvability\nwas very different from traditional digital evolution in that there was no\nobjective, suggesting that open-ended, divergent evolutionary processes may be\nnecessary for the evolution of evolvability.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "How Noisy Data Affects Geometric Semantic Genetic Programming",
        "authors": [
            "Luis F. Miranda",
            "Luiz Otavio V. B. Oliveira",
            "Joao Francisco B. S. Martins",
            "Gisele L. Pappa"
        ],
        "summary": "Noise is a consequence of acquiring and pre-processing data from the\nenvironment, and shows fluctuations from different sources---e.g., from\nsensors, signal processing technology or even human error. As a machine\nlearning technique, Genetic Programming (GP) is not immune to this problem,\nwhich the field has frequently addressed. Recently, Geometric Semantic Genetic\nProgramming (GSGP), a semantic-aware branch of GP, has shown robustness and\nhigh generalization capability. Researchers believe these characteristics may\nbe associated with a lower sensibility to noisy data. However, there is no\nsystematic study on this matter. This paper performs a deep analysis of the\nGSGP performance over the presence of noise. Using 15 synthetic datasets where\nnoise can be controlled, we added different ratios of noise to the data and\ncompared the results obtained with those of a canonical GP. The results show\nthat, as we increase the percentage of noisy instances, the generalization\nperformance degradation is more pronounced in GSGP than GP. However, in\ngeneral, GSGP is more robust to noise than GP in the presence of up to 10% of\nnoise, and presents no statistical difference for values higher than that in\nthe test bed.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "Preselection via Classification: A Case Study on Evolutionary\n  Multiobjective Optimization",
        "authors": [
            "Jinyuan Zhang",
            "Aimin Zhou",
            "Ke Tang",
            "Guixu Zhang"
        ],
        "summary": "In evolutionary algorithms, a preselection operator aims to select the\npromising offspring solutions from a candidate offspring set. It is usually\nbased on the estimated or real objective values of the candidate offspring\nsolutions. In a sense, the preselection can be treated as a classification\nprocedure, which classifies the candidate offspring solutions into promising\nones and unpromising ones. Following this idea, we propose a classification\nbased preselection (CPS) strategy for evolutionary multiobjective optimization.\nWhen applying classification based preselection, an evolutionary algorithm\nmaintains two external populations (training data set) that consist of some\nselected good and bad solutions found so far; then it trains a classifier based\non the training data set in each generation. Finally it uses the classifier to\nfilter the unpromising candidate offspring solutions and choose a promising one\nfrom the generated candidate offspring set for each parent solution. In such\ncases, it is not necessary to estimate or evaluate the objective values of the\ncandidate offspring solutions. The classification based preselection is applied\nto three state-of-the-art multiobjective evolutionary algorithms (MOEAs) and is\nempirically studied on two sets of test instances. The experimental results\nsuggest that classification based preselection can successfully improve the\nperformance of these MOEAs.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "Evolution in Virtual Worlds",
        "authors": [
            "Tim Taylor"
        ],
        "summary": "This chapter discusses the possibility of instilling a virtual world with\nmechanisms for evolution and natural selection in order to generate rich\necosystems of complex organisms in a process akin to biological evolution. Some\nprevious work in the area is described, and successes and failures are\ndiscussed. The components of a more comprehensive framework for designing such\nworlds are mapped out, including the design of the individual organisms, the\nproperties and dynamics of the environmental medium in which they are evolving,\nand the representational relationship between organism and environment. Some of\nthe key issues discussed include how to allow organisms to evolve new\nstructures and functions with few restrictions, and how to create an\ninterconnectedness between organisms in order to generate drives for continuing\nevolutionary activity.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "Community detection with spiking neural networks for neuromorphic\n  hardware",
        "authors": [
            "Kathleen E. Hamilton",
            "Neena Imam",
            "Travis S. Humble"
        ],
        "summary": "We present results related to the performance of an algorithm for community\ndetection which incorporates event-driven computation. We define a mapping\nwhich takes a graph G to a system of spiking neurons. Using a fully connected\nspiking neuron system, with both inhibitory and excitatory synaptic\nconnections, the firing patterns of neurons within the same community can be\ndistinguished from firing patterns of neurons in different communities. On a\nrandom graph with 128 vertices and known community structure we show that by\nusing binary decoding and a Hamming-distance based metric, individual\ncommunities can be identified from spike train similarities. Using bipolar\ndecoding and finite rate thresholding, we verify that inhibitory connections\nprevent the spread of spiking patterns.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "Backpropagation generalized for output derivatives",
        "authors": [
            "V. I. Avrutskiy"
        ],
        "summary": "Backpropagation algorithm is the cornerstone for neural network analysis.\nPaper extends it for training any derivatives of neural network's output with\nrespect to its input. By the dint of it feedforward networks can be used to\nsolve or verify solutions of partial or simple, linear or nonlinear\ndifferential equations. This method vastly differs from traditional ones like\nfinite differences on a mesh. It contains no approximations, but rather an\nexact form of differential operators. Algorithm is built to train a feed\nforward network with any number of hidden layers and any kind of sufficiently\nsmooth activation functions. It's presented in a form of matrix-vector products\nso highly parallel implementation is readily possible. First part derives the\nmethod for 2D case with first and second order derivatives, second part extends\nit to N-dimensional case with any derivatives. All necessary expressions for\nusing this method to solve most applied PDE can be found in Appendix D.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "Enhancing approximation abilities of neural networks by training\n  derivatives",
        "authors": [
            "V. I. Avrutskiy"
        ],
        "summary": "Method for increasing precision of feedforward networks is presented. With\nthe aid of it they can serve as a better tool for describing smooth functions.\nNamely, it is shown that when training uses derivatives of target function up\nto the fourth order, approximation can be nearly machine precise. It is\ndemonstrated in a number of cases: 2D function approximation, training\nautoencoder to compress 3D spiral into 1D, and solving 2D boundary value\nproblem for Poisson equation with nonlinear source. In the first case cost\nfunction in addition to squared difference between output and target contains\nsquared differences between their derivatives with respect to input variables.\nTraining autoencoder is similar, but differentiation is done with respect to\nparameter that generates the spiral. Supplied with derivatives up to the fourth\nthe method is found to be 30-200 times more accurate than regular training\nprovided networks are of sufficient size and depth. Solving PDE is more\npractical since higher derivatives are not calculated beforehand, but\ninformation about them is extracted from the equation itself. Classical\napproach is to put perceptron in place of unknown function, choose the cost as\nsquared residual and to minimize it with respect to weights. This would ensure\nthat equation holds within some margin of error. Additional terms used in cost\nfunction are squared derivatives of the residual with respect to independent\nvariables. Supplied with terms up to the second order the method is found to be\n5 times more accurate. Efficient GPU version of algorithm is proposed.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "Neural networks catching up with finite differences in solving partial\n  differential equations in higher dimensions",
        "authors": [
            "V. I. Avrutskiy"
        ],
        "summary": "Fully connected multilayer perceptrons are used for obtaining numerical\nsolutions of partial differential equations in various dimensions. Independent\nvariables are fed into the input layer, and the output is considered as\nsolution's value. To train such a network one can use square of equation's\nresidual as a cost function and minimize it with respect to weights by gradient\ndescent. Following previously developed method, derivatives of the equation's\nresidual along random directions in space of independent variables are also\nadded to cost function. Similar procedure is known to produce nearly machine\nprecision results using less than 8 grid points per dimension for 2D case. The\nsame effect is observed here for higher dimensions: solutions are obtained on\nlow density grids, but maintain their precision in the entire region. Boundary\nvalue problems for linear and nonlinear Poisson equations are solved inside 2,\n3, 4, and 5 dimensional balls. Grids for linear cases have 40, 159, 512 and\n1536 points and for nonlinear 64, 350, 1536 and 6528 points respectively. In\nall cases maximum error is less than $8.8\\cdot10^{-6}$, and median error is\nless than $2.4\\cdot10^{-6}$. Very weak grid requirements enable neural networks\nto obtain solution of 5D linear problem within 22 minutes, whereas projected\nsolving time for finite differences on the same hardware is 50 minutes. Method\nis applied to second order equation, but requires little to none modifications\nto solve systems or higher order PDEs.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "Complexity Theory for Discrete Black-Box Optimization Heuristics",
        "authors": [
            "Carola Doerr"
        ],
        "summary": "A predominant topic in the theory of evolutionary algorithms and, more\ngenerally, theory of randomized black-box optimization techniques is running\ntime analysis. Running time analysis aims at understanding the performance of a\ngiven heuristic on a given problem by bounding the number of function\nevaluations that are needed by the heuristic to identify a solution of a\ndesired quality. As in general algorithms theory, this running time perspective\nis most useful when it is complemented by a meaningful complexity theory that\nstudies the limits of algorithmic solutions.\n  In the context of discrete black-box optimization, several black-box\ncomplexity models have been developed to analyze the best possible performance\nthat a black-box optimization algorithm can achieve on a given problem. The\nmodels differ in the classes of algorithms to which these lower bounds apply.\nThis way, black-box complexity contributes to a better understanding of how\ncertain algorithmic choices (such as the amount of memory used by a heuristic,\nits selective pressure, or properties of the strategies that it uses to create\nnew solution candidates) influences performance.\n  In this chapter we review the different black-box complexity models that have\nbeen proposed in the literature, survey the bounds that have been obtained for\nthese models, and discuss how the interplay of running time analysis and\nblack-box complexity can inspire new algorithmic solutions to well-researched\nproblems in evolutionary computation. We also discuss in this chapter several\ninteresting open questions for future work.",
        "year": 2018,
        "label": "cs.NE"
    },
    {
        "title": "Brain-inspired photonic signal processor for periodic pattern generation\n  and chaotic system emulation",
        "authors": [
            "Piotr Antonik",
            "Marc Haelterman",
            "Serge Massar"
        ],
        "summary": "Reservoir computing is a bio-inspired computing paradigm for processing\ntime-dependent signals. Its hardware implementations have received much\nattention because of their simplicity and remarkable performance on a series of\nbenchmark tasks. In previous experiments the output was uncoupled from the\nsystem and in most cases simply computed offline on a post-processing computer.\nHowever, numerical investigations have shown that feeding the output back into\nthe reservoir would open the possibility of long-horizon time series\nforecasting. Here we present a photonic reservoir computer with output\nfeedback, and demonstrate its capacity to generate periodic time series and to\nemulate chaotic systems. We study in detail the effect of experimental noise on\nsystem performance. In the case of chaotic systems, this leads us to introduce\nseveral metrics, based on standard signal processing techniques, to evaluate\nthe quality of the emulation. Our work significantly enlarges the range of\ntasks that can be solved by hardware reservoir computers, and therefore the\nrange of applications they could potentially tackle. It also raises novel\nquestions in nonlinear dynamics and chaos theory.",
        "year": 2018,
        "label": "cs.NE"
    },
    {
        "title": "Energy-Efficient CMOS Memristive Synapses for Mixed-Signal Neuromorphic\n  System-on-a-Chip",
        "authors": [
            "Vishal Saxena",
            "Xinyu Wu",
            "Kehan Zhu"
        ],
        "summary": "Emerging non-volatile memory (NVM), or memristive, devices promise\nenergy-efficient realization of deep learning, when efficiently integrated with\nmixed-signal integrated circuits on a CMOS substrate. Even though several\nalgorithmic challenges need to be addressed to turn the vision of memristive\nNeuromorphic Systems-on-a-Chip (NeuSoCs) into reality, issues at the device and\ncircuit interface need immediate attention from the community. In this work, we\nperform energy-estimation of a NeuSoC system and predict the desirable circuit\nand device parameters for energy-efficiency optimization. Also, CMOS synapse\ncircuits based on the concept of CMOS memristor emulator are presented as a\nsystem prototyping methodology, while practical memristor devices are being\ndeveloped and integrated with general-purpose CMOS. The proposed mixed-signal\nmemristive synapse can be designed and fabricated using standard CMOS\ntechnologies and open doors to interesting applications in cognitive computing\ncircuits.",
        "year": 2018,
        "label": "cs.NE"
    },
    {
        "title": "Avoiding overfitting of multilayer perceptrons by training derivatives",
        "authors": [
            "V. I. Avrutskiy"
        ],
        "summary": "Resistance to overfitting is observed for neural networks trained with\nextended backpropagation algorithm. In addition to target values, its cost\nfunction uses derivatives of those up to the $4^{\\mathrm{th}}$ order. For\ncommon applications of neural networks, high order derivatives are not readily\navailable, so simpler cases are considered: training network to approximate\nanalytical function inside 2D and 5D domains and solving Poisson equation\ninside a 2D circle. For function approximation, the cost is a sum of squared\ndifferences between output and target as well as their derivatives with respect\nto the input. Differential equations are usually solved by putting a multilayer\nperceptron in place of unknown function and training its weights, so that\nequation holds within some margin of error. Commonly used cost is the\nequation's residual squared. Added terms are squared derivatives of said\nresidual with respect to the independent variables. To investigate overfitting,\nthe cost is minimized for points of regular grids with various spacing, and its\nroot mean is compared with its value on much denser test set. Fully connected\nperceptrons with six hidden layers and $2\\cdot10^{4}$, $1\\cdot10^{6}$ and\n$5\\cdot10^{6}$ weights in total are trained with Rprop until cost changes by\nless than 10% for last 1000 epochs, or when the $10000^{\\mathrm{th}}$ epoch is\nreached. Training the network with $5\\cdot10^{6}$ weights to represent simple\n2D function using 10 points with 8 extra derivatives in each produces cost test\nto train ratio of $1.5$, whereas for classical backpropagation in comparable\nconditions this ratio is $2\\cdot10^{4}$.",
        "year": 2018,
        "label": "cs.NE"
    },
    {
        "title": "Precisely Verifying the Null Space Conditions in Compressed Sensing: A\n  Sandwiching Algorithm",
        "authors": [
            "Myung Cho",
            "Weiyu Xu"
        ],
        "summary": "In this paper, we propose new efficient algorithms to verify the null space\ncondition in compressed sensing (CS). Given an $(n-m) \\times n$ ($m>0$) CS\nmatrix $A$ and a positive $k$, we are interested in computing $\\displaystyle\n\\alpha_k = \\max_{\\{z: Az=0,z\\neq 0\\}}\\max_{\\{K: |K|\\leq k\\}}$ ${\\|z_K\n\\|_{1}}{\\|z\\|_{1}}$, where $K$ represents subsets of $\\{1,2,...,n\\}$, and $|K|$\nis the cardinality of $K$. In particular, we are interested in finding the\nmaximum $k$ such that $\\alpha_k < {1}{2}$. However, computing $\\alpha_k$ is\nknown to be extremely challenging. In this paper, we first propose a series of\nnew polynomial-time algorithms to compute upper bounds on $\\alpha_k$. Based on\nthese new polynomial-time algorithms, we further design a new sandwiching\nalgorithm, to compute the \\emph{exact} $\\alpha_k$ with greatly reduced\ncomplexity. When needed, this new sandwiching algorithm also achieves a smooth\ntradeoff between computational complexity and result accuracy. Empirical\nresults show the performance improvements of our algorithm over existing known\nmethods; and our algorithm outputs precise values of $\\alpha_k$, with much\nlower complexity than exhaustive search.",
        "year": 2013,
        "label": "cs.IT"
    },
    {
        "title": "Discrete MDL Predicts in Total Variation",
        "authors": [
            "Marcus Hutter"
        ],
        "summary": "The Minimum Description Length (MDL) principle selects the model that has the\nshortest code for data plus model. We show that for a countable class of\nmodels, MDL predictions are close to the true distribution in a strong sense.\nThe result is completely general. No independence, ergodicity, stationarity,\nidentifiability, or other assumption on the model class need to be made. More\nformally, we show that for any countable class of models, the distributions\nselected by MDL (or MAP) asymptotically predict (merge with) the true measure\nin the class in total variation distance. Implications for non-i.i.d. domains\nlike time-series forecasting, discriminative learning, and reinforcement\nlearning are discussed.",
        "year": 2009,
        "label": "math.PR"
    },
    {
        "title": "Network Detection Theory and Performance",
        "authors": [
            "Steven T. Smith",
            "Kenneth D. Senne",
            "Scott Philips",
            "Edward K. Kao",
            "Garrett Bernstein"
        ],
        "summary": "Network detection is an important capability in many areas of applied\nresearch in which data can be represented as a graph of entities and\nrelationships. Oftentimes the object of interest is a relatively small subgraph\nin an enormous, potentially uninteresting background. This aspect characterizes\nnetwork detection as a \"big data\" problem. Graph partitioning and network\ndiscovery have been major research areas over the last ten years, driven by\ninterest in internet search, cyber security, social networks, and criminal or\nterrorist activities. The specific problem of network discovery is addressed as\na special case of graph partitioning in which membership in a small subgraph of\ninterest must be determined. Algebraic graph theory is used as the basis to\nanalyze and compare different network detection methods. A new Bayesian network\ndetection framework is introduced that partitions the graph based on prior\ninformation and direct observations. The new approach, called space-time threat\npropagation, is proved to maximize the probability of detection and is\ntherefore optimum in the Neyman-Pearson sense. This optimality criterion is\ncompared to spectral community detection approaches which divide the global\ngraph into subsets or communities with optimal connectivity properties. We also\nexplore a new generative stochastic model for covert networks and analyze using\nreceiver operating characteristics the detection performance of both classes of\noptimal detection techniques.",
        "year": 2013,
        "label": "cs.SI"
    },
    {
        "title": "Bayesian Discovery of Threat Networks",
        "authors": [
            "Steven T. Smith",
            "Edward K. Kao",
            "Kenneth D. Senne",
            "Garrett Bernstein",
            "Scott Philips"
        ],
        "summary": "A novel unified Bayesian framework for network detection is developed, under\nwhich a detection algorithm is derived based on random walks on graphs. The\nalgorithm detects threat networks using partial observations of their activity,\nand is proved to be optimum in the Neyman-Pearson sense. The algorithm is\ndefined by a graph, at least one observation, and a diffusion model for threat.\nA link to well-known spectral detection methods is provided, and the\nequivalence of the random walk and harmonic solutions to the Bayesian\nformulation is proven. A general diffusion model is introduced that utilizes\nspatio-temporal relationships between vertices, and is used for a specific\nspace-time formulation that leads to significant performance improvements on\ncoordinated covert networks. This performance is demonstrated using a new\nhybrid mixed-membership blockmodel introduced to simulate random covert\nnetworks with realistic properties.",
        "year": 2013,
        "label": "cs.SI"
    },
    {
        "title": "Rerepresenting and Restructuring Domain Theories: A Constructive\n  Induction Approach",
        "authors": [
            "S. K. Donoho",
            "L. A. Rendell"
        ],
        "summary": "Theory revision integrates inductive learning and background knowledge by\ncombining training examples with a coarse domain theory to produce a more\naccurate theory. There are two challenges that theory revision and other\ntheory-guided systems face. First, a representation language appropriate for\nthe initial theory may be inappropriate for an improved theory. While the\noriginal representation may concisely express the initial theory, a more\naccurate theory forced to use that same representation may be bulky,\ncumbersome, and difficult to reach. Second, a theory structure suitable for a\ncoarse domain theory may be insufficient for a fine-tuned theory. Systems that\nproduce only small, local changes to a theory have limited value for\naccomplishing complex structural alterations that may be required.\nConsequently, advanced theory-guided learning systems require flexible\nrepresentation and flexible structure. An analysis of various theory revision\nsystems and theory-guided learning systems reveals specific strengths and\nweaknesses in terms of these two desired properties. Designed to capture the\nunderlying qualities of each system, a new system uses theory-guided\nconstructive induction. Experiments in three domains show improvement over\nprevious theory-guided systems. This leads to a study of the behavior,\nlimitations, and potential of theory-guided constructive induction.",
        "year": 1995,
        "label": "cs.AI"
    },
    {
        "title": "The Design and Experimental Analysis of Algorithms for Temporal\n  Reasoning",
        "authors": [
            "P. vanBeek",
            "D. W. Manchak"
        ],
        "summary": "Many applications -- from planning and scheduling to problems in molecular\nbiology -- rely heavily on a temporal reasoning component. In this paper, we\ndiscuss the design and empirical analysis of algorithms for a temporal\nreasoning system based on Allen's influential interval-based framework for\nrepresenting temporal information. At the core of the system are algorithms for\ndetermining whether the temporal information is consistent, and, if so, finding\none or more scenarios that are consistent with the temporal information. Two\nimportant algorithms for these tasks are a path consistency algorithm and a\nbacktracking algorithm. For the path consistency algorithm, we develop\ntechniques that can result in up to a ten-fold speedup over an already highly\noptimized implementation. For the backtracking algorithm, we develop variable\nand value ordering heuristics that are shown empirically to dramatically\nimprove the performance of the algorithm. As well, we show that a previously\nsuggested reformulation of the backtracking search problem can reduce the time\nand space requirements of the backtracking search. Taken together, the\ntechniques we develop allow a temporal reasoning component to solve problems\nthat are of practical size.",
        "year": 1996,
        "label": "cs.AI"
    },
    {
        "title": "A Divergence Critic for Inductive Proof",
        "authors": [
            "T. Walsh"
        ],
        "summary": "Inductive theorem provers often diverge. This paper describes a simple\ncritic, a computer program which monitors the construction of inductive proofs\nattempting to identify diverging proof attempts. Divergence is recognized by\nmeans of a ``difference matching'' procedure. The critic then proposes lemmas\nand generalizations which ``ripple'' these differences away so that the proof\ncan go through without divergence. The critic enables the theorem prover Spike\nto prove many theorems completely automatically from the definitions alone.",
        "year": 1996,
        "label": "cs.AI"
    },
    {
        "title": "Iterative Optimization and Simplification of Hierarchical Clusterings",
        "authors": [
            "D. Fisher"
        ],
        "summary": "Clustering is often used for discovering structure in data. Clustering\nsystems differ in the objective function used to evaluate clustering quality\nand the control strategy used to search the space of clusterings. Ideally, the\nsearch strategy should consistently construct clusterings of high quality, but\nbe computationally inexpensive as well. In general, we cannot have it both\nways, but we can partition the search so that a system inexpensively constructs\na `tentative' clustering for initial examination, followed by iterative\noptimization, which continues to search in background for improved clusterings.\nGiven this motivation, we evaluate an inexpensive strategy for creating initial\nclusterings, coupled with several control strategies for iterative\noptimization, each of which repeatedly modifies an initial clustering in search\nof a better one. One of these methods appears novel as an iterative\noptimization strategy in clustering contexts. Once a clustering has been\nconstructed it is judged by analysts -- often according to task-specific\ncriteria. Several authors have abstracted these criteria and posited a generic\nperformance task akin to pattern completion, where the error rate over\ncompleted patterns is used to `externally' judge clustering utility. Given this\nperformance task, we adapt resampling-based pruning strategies used by\nsupervised learning systems to the task of simplifying hierarchical\nclusterings, thus promising to ease post-clustering analysis. Finally, we\npropose a number of objective functions, based on attribute-selection measures\nfor decision-tree induction, that might perform well on the error rate and\nsimplicity dimensions.",
        "year": 1996,
        "label": "cs.AI"
    },
    {
        "title": "Accelerating Partial-Order Planners: Some Techniques for Effective\n  Search Control and Pruning",
        "authors": [
            "A. Gerevini",
            "L. Schubert"
        ],
        "summary": "We propose some domain-independent techniques for bringing well-founded\npartial-order planners closer to practicality. The first two techniques are\naimed at improving search control while keeping overhead costs low. One is\nbased on a simple adjustment to the default A* heuristic used by UCPOP to\nselect plans for refinement. The other is based on preferring ``zero\ncommitment'' (forced) plan refinements whenever possible, and using LIFO\nprioritization otherwise. A more radical technique is the use of operator\nparameter domains to prune search. These domains are initially computed from\nthe definitions of the operators and the initial and goal conditions, using a\npolynomial-time algorithm that propagates sets of constants through the\noperator graph, starting in the initial conditions. During planning, parameter\ndomains can be used to prune nonviable operator instances and to remove\nspurious clobbering threats. In experiments based on modifications of UCPOP,\nour improved plan and goal selection strategies gave speedups by factors\nranging from 5 to more than 1000 for a variety of problems that are nontrivial\nfor the unmodified version. Crucially, the hardest problems gave the greatest\nimprovements. The pruning technique based on parameter domains often gave\nspeedups by an order of magnitude or more for difficult problems, both with the\ndefault UCPOP search strategy and with our improved strategy. The Lisp code for\nour techniques and for the test problems is provided in on-line appendices.",
        "year": 1996,
        "label": "cs.AI"
    },
    {
        "title": "Mechanisms for Automated Negotiation in State Oriented Domains",
        "authors": [
            "G. Zlotkin",
            "J. S. Rosenschein"
        ],
        "summary": "This paper lays part of the groundwork for a domain theory of negotiation,\nthat is, a way of classifying interactions so that it is clear, given a domain,\nwhich negotiation mechanisms and strategies are appropriate. We define State\nOriented Domains, a general category of interaction. Necessary and sufficient\nconditions for cooperation are outlined. We use the notion of worth in an\naltered definition of utility, thus enabling agreements in a wider class of\njoint-goal reachable situations. An approach is offered for conflict\nresolution, and it is shown that even in a conflict situation, partial\ncooperative steps can be taken by interacting agents (that is, agents in\nfundamental conflict might still agree to cooperate up to a certain point). A\nUnified Negotiation Protocol (UNP) is developed that can be used in all types\nof encounters. It is shown that in certain borderline cooperative situations, a\npartial cooperative agreement (i.e., one that does not achieve all agents'\ngoals) might be preferred by all agents, even though there exists a rational\nagreement that would achieve all their goals. Finally, we analyze cases where\nagents have incomplete information on the goals and worth of other agents.\nFirst we consider the case where agents' goals are private information, and we\nanalyze what goal declaration strategies the agents might adopt to increase\ntheir utility. Then, we consider the situation where the agents' goals (and\ntherefore stand-alone costs) are common knowledge, but the worth they attach to\ntheir goals is private information. We introduce two mechanisms, one 'strict',\nthe other 'tolerant', and analyze their affects on the stability and efficiency\nof negotiation outcomes.",
        "year": 1996,
        "label": "cs.AI"
    },
    {
        "title": "Connectionist Theory Refinement: Genetically Searching the Space of\n  Network Topologies",
        "authors": [
            "D. W. Opitz",
            "J. W. Shavlik"
        ],
        "summary": "An algorithm that learns from a set of examples should ideally be able to\nexploit the available resources of (a) abundant computing power and (b)\ndomain-specific knowledge to improve its ability to generalize. Connectionist\ntheory-refinement systems, which use background knowledge to select a neural\nnetwork's topology and initial weights, have proven to be effective at\nexploiting domain-specific knowledge; however, most do not exploit available\ncomputing power. This weakness occurs because they lack the ability to refine\nthe topology of the neural networks they produce, thereby limiting\ngeneralization, especially when given impoverished domain theories. We present\nthe REGENT algorithm which uses (a) domain-specific knowledge to help create an\ninitial population of knowledge-based neural networks and (b) genetic operators\nof crossover and mutation (specifically designed for knowledge-based networks)\nto continually search for better network topologies. Experiments on three\nreal-world domains indicate that our new algorithm is able to significantly\nincrease generalization compared to a standard connectionist theory-refinement\nsystem, as well as our previous algorithm for growing knowledge-based networks.",
        "year": 1997,
        "label": "cs.AI"
    },
    {
        "title": "Dynamic Non-Bayesian Decision Making",
        "authors": [
            "D. Monderer",
            "M. Tennenholtz"
        ],
        "summary": "The model of a non-Bayesian agent who faces a repeated game with incomplete\ninformation against Nature is an appropriate tool for modeling general\nagent-environment interactions. In such a model the environment state\n(controlled by Nature) may change arbitrarily, and the feedback/reward function\nis initially unknown. The agent is not Bayesian, that is he does not form a\nprior probability neither on the state selection strategy of Nature, nor on his\nreward function. A policy for the agent is a function which assigns an action\nto every history of observations and actions. Two basic feedback structures are\nconsidered. In one of them -- the perfect monitoring case -- the agent is able\nto observe the previous environment state as part of his feedback, while in the\nother -- the imperfect monitoring case -- all that is available to the agent is\nthe reward obtained. Both of these settings refer to partially observable\nprocesses, where the current environment state is unknown. Our main result\nrefers to the competitive ratio criterion in the perfect monitoring case. We\nprove the existence of an efficient stochastic policy that ensures that the\ncompetitive ratio is obtained at almost all stages with an arbitrarily high\nprobability, where efficiency is measured in terms of rate of convergence. It\nis further shown that such an optimal policy does not exist in the imperfect\nmonitoring case. Moreover, it is proved that in the perfect monitoring case\nthere does not exist a deterministic policy that satisfies our long run\noptimality criterion. In addition, we discuss the maxmin criterion and prove\nthat a deterministic efficient optimal strategy does exist in the imperfect\nmonitoring case under this criterion. Finally we show that our approach to\nlong-run optimality can be viewed as qualitative, which distinguishes it from\nprevious work in this area.",
        "year": 1997,
        "label": "cs.AI"
    },
    {
        "title": "The Essence of Constraint Propagation",
        "authors": [
            "Krzysztof R. Apt"
        ],
        "summary": "We show that several constraint propagation algorithms (also called (local)\nconsistency, consistency enforcing, Waltz, filtering or narrowing algorithms)\nare instances of algorithms that deal with chaotic iteration. To this end we\npropose a simple abstract framework that allows us to classify and compare\nthese algorithms and to establish in a uniform way their basic properties.",
        "year": 1998,
        "label": "cs.AI"
    },
    {
        "title": "Fages' Theorem and Answer Set Programming",
        "authors": [
            "Yuliya Babovich",
            "Esra Erdem",
            "Vladimir Lifschitz"
        ],
        "summary": "We generalize a theorem by Francois Fages that describes the relationship\nbetween the completion semantics and the answer set semantics for logic\nprograms with negation as failure. The study of this relationship is important\nin connection with the emergence of answer set programming. Whenever the two\nsemantics are equivalent, answer sets can be computed by a satisfiability\nsolver, and the use of answer set solvers such as smodels and dlv is\nunnecessary. A logic programming representation of the blocks world due to\nIlkka Niemelae is discussed as an example.",
        "year": 2000,
        "label": "cs.AI"
    },
    {
        "title": "On the tractable counting of theory models and its application to belief\n  revision and truth maintenance",
        "authors": [
            "Adnan Darwiche"
        ],
        "summary": "We introduced decomposable negation normal form (DNNF) recently as a\ntractable form of propositional theories, and provided a number of powerful\nlogical operations that can be performed on it in polynomial time. We also\npresented an algorithm for compiling any conjunctive normal form (CNF) into\nDNNF and provided a structure-based guarantee on its space and time complexity.\nWe present in this paper a linear-time algorithm for converting an ordered\nbinary decision diagram (OBDD) representation of a propositional theory into an\nequivalent DNNF, showing that DNNFs scale as well as OBDDs. We also identify a\nsubclass of DNNF which we call deterministic DNNF, d-DNNF, and show that the\nprevious complexity guarantees on compiling DNNF continue to hold for this\nstricter subclass, which has stronger properties. In particular, we present a\nnew operation on d-DNNF which allows us to count its models under the\nassertion, retraction and flipping of every literal by traversing the d-DNNF\ntwice. That is, after such traversal, we can test in constant-time: the\nentailment of any literal by the d-DNNF, and the consistency of the d-DNNF\nunder the retraction or flipping of any literal. We demonstrate the\nsignificance of these new operations by showing how they allow us to implement\nlinear-time, complete truth maintenance systems and linear-time, complete\nbelief revision systems for two important classes of propositional theories.",
        "year": 2000,
        "label": "cs.AI"
    },
    {
        "title": "A Consistency-Based Model for Belief Change: Preliminary Report",
        "authors": [
            "James Delgrande",
            "Torsten Schaub"
        ],
        "summary": "We present a general, consistency-based framework for belief change.\nInformally, in revising K by A, we begin with A and incorporate as much of K as\nconsistently possible. Formally, a knowledge base K and sentence A are\nexpressed, via renaming propositions in K, in separate languages. Using a\nmaximization process, we assume the languages are the same insofar as\nconsistently possible. Lastly, we express the resultant knowledge base in a\nsingle language. There may be more than one way in which A can be so extended\nby K: in choice revision, one such ``extension'' represents the revised state;\nalternately revision consists of the intersection of all such extensions.\n  The most general formulation of our approach is flexible enough to express\nother approaches to revision and update, the merging of knowledge bases, and\nthe incorporation of static and dynamic integrity constraints. Our framework\ndiffers from work based on ordinal conditional functions, notably with respect\nto iterated revision. We argue that the approach is well-suited for\nimplementation: the choice revision operator gives better complexity results\nthan general revision; the approach can be expressed in terms of a finite\nknowledge base; and the scope of a revision can be restricted to just those\npropositions mentioned in the sentence for revision A.",
        "year": 2000,
        "label": "cs.AI"
    },
    {
        "title": "Some Remarks on Boolean Constraint Propagation",
        "authors": [
            "Krzysztof R. Apt"
        ],
        "summary": "We study here the well-known propagation rules for Boolean constraints. First\nwe propose a simple notion of completeness for sets of such rules and establish\na completeness result. Then we show an equivalence in an appropriate sense\nbetween Boolean constraint propagation and unit propagation, a form of\nresolution for propositional logic.\n  Subsequently we characterize one set of such rules by means of the notion of\nhyper-arc consistency introduced in (Mohr and Masini 1988). Also, we clarify\nthe status of a similar, though different, set of rules introduced in (Simonis\n1989a) and more fully in (Codognet and Diaz 1996).",
        "year": 2000,
        "label": "cs.AI"
    },
    {
        "title": "On the relationship between fuzzy logic and four-valued relevance logic",
        "authors": [
            "Umberto Straccia"
        ],
        "summary": "In fuzzy propositional logic, to a proposition a partial truth in [0,1] is\nassigned. It is well known that under certain circumstances, fuzzy logic\ncollapses to classical logic. In this paper, we will show that under dual\nconditions, fuzzy logic collapses to four-valued (relevance) logic, where\npropositions have truth-value true, false, unknown, or contradiction. As a\nconsequence, fuzzy entailment may be considered as ``in between'' four-valued\n(relevance) entailment and classical entailment.",
        "year": 2000,
        "label": "cs.AI"
    },
    {
        "title": "Enhancing Constraint Propagation with Composition Operators",
        "authors": [
            "Laurent Granvilliers",
            "Eric Monfroy"
        ],
        "summary": "Constraint propagation is a general algorithmic approach for pruning the\nsearch space of a CSP. In a uniform way, K. R. Apt has defined a computation as\nan iteration of reduction functions over a domain. He has also demonstrated the\nneed for integrating static properties of reduction functions (commutativity\nand semi-commutativity) to design specialized algorithms such as AC3 and DAC.\nWe introduce here a set of operators for modeling compositions of reduction\nfunctions. Two of the major goals are to tackle parallel computations, and\ndynamic behaviours (such as slow convergence).",
        "year": 2001,
        "label": "cs.AI"
    },
    {
        "title": "Updating beliefs with incomplete observations",
        "authors": [
            "Gert de Cooman",
            "Marco Zaffalon"
        ],
        "summary": "Currently, there is renewed interest in the problem, raised by Shafer in\n1985, of updating probabilities when observations are incomplete. This is a\nfundamental problem in general, and of particular interest for Bayesian\nnetworks. Recently, Grunwald and Halpern have shown that commonly used updating\nstrategies fail in this case, except under very special assumptions. In this\npaper we propose a new method for updating probabilities with incomplete\nobservations. Our approach is deliberately conservative: we make no assumptions\nabout the so-called incompleteness mechanism that associates complete with\nincomplete observations. We model our ignorance about this mechanism by a\nvacuous lower prevision, a tool from the theory of imprecise probabilities, and\nwe use only coherence arguments to turn prior into posterior probabilities. In\ngeneral, this new approach to updating produces lower and upper posterior\nprobabilities and expectations, as well as partially determinate decisions.\nThis is a logical consequence of the existing ignorance about the\nincompleteness mechanism. We apply the new approach to the problem of\nclassification of new evidence in probabilistic expert systems, where it leads\nto a new, so-called conservative updating rule. In the special case of Bayesian\nnetworks constructed using expert knowledge, we provide an exact algorithm for\nclassification based on our updating rule, which has linear-time complexity for\na class of networks wider than polytrees. This result is then extended to the\nmore general framework of credal networks, where computations are often much\nharder than with Bayesian nets. Using an example, we show that our rule appears\nto provide a solid basis for reliable updating with incomplete observations,\nwhen no strong assumptions about the incompleteness mechanism are justified.",
        "year": 2003,
        "label": "cs.AI"
    },
    {
        "title": "The Algebra of Utility Inference",
        "authors": [
            "Ali E. Abbas"
        ],
        "summary": "Richard Cox [1] set the axiomatic foundations of probable inference and the\nalgebra of propositions. He showed that consistency within these axioms\nrequires certain rules for updating belief. In this paper we use the analogy\nbetween probability and utility introduced in [2] to propose an axiomatic\nfoundation for utility inference and the algebra of preferences. We show that\nconsistency within these axioms requires certain rules for updating preference.\nWe discuss a class of utility functions that stems from the axioms of utility\ninference and show that this class is the basic building block for any general\nmultiattribute utility function. We use this class of utility functions\ntogether with the algebra of preferences to construct utility functions\nrepresented by logical operations on the attributes.",
        "year": 2003,
        "label": "cs.AI"
    },
    {
        "title": "An information theory for preferences",
        "authors": [
            "Ali E. Abbas"
        ],
        "summary": "Recent literature in the last Maximum Entropy workshop introduced an analogy\nbetween cumulative probability distributions and normalized utility functions.\nBased on this analogy, a utility density function can de defined as the\nderivative of a normalized utility function. A utility density function is\nnon-negative and integrates to unity. These two properties form the basis of a\ncorrespondence between utility and probability. A natural application of this\nanalogy is a maximum entropy principle to assign maximum entropy utility\nvalues. Maximum entropy utility interprets many of the common utility functions\nbased on the preference information needed for their assignment, and helps\nassign utility values based on partial preference information. This paper\nreviews maximum entropy utility and introduces further results that stem from\nthe duality between probability and utility.",
        "year": 2003,
        "label": "cs.AI"
    },
    {
        "title": "Propositional Defeasible Logic has Linear Complexity",
        "authors": [
            "Michael J. Maher"
        ],
        "summary": "Defeasible logic is a rule-based nonmonotonic logic, with both strict and\ndefeasible rules, and a priority relation on rules. We show that inference in\nthe propositional form of the logic can be performed in linear time. This\ncontrasts markedly with most other propositional nonmonotonic logics, in which\ninference is intractable.",
        "year": 2004,
        "label": "cs.AI"
    },
    {
        "title": "A Simple Proportional Conflict Redistribution Rule",
        "authors": [
            "Florentin Smarandache",
            "Jean Dezert"
        ],
        "summary": "One proposes a first alternative rule of combination to WAO (Weighted Average\nOperator) proposed recently by Josang, Daniel and Vannoorenberghe, called\nProportional Conflict Redistribution rule (denoted PCR1). PCR1 and WAO are\nparticular cases of WO (the Weighted Operator) because the conflicting mass is\nredistributed with respect to some weighting factors. In this first PCR rule,\nthe proportionalization is done for each non-empty set with respect to the\nnon-zero sum of its corresponding mass matrix - instead of its mass column\naverage as in WAO, but the results are the same as Ph. Smets has pointed out.\nAlso, we extend WAO (which herein gives no solution) for the degenerate case\nwhen all column sums of all non-empty sets are zero, and then the conflicting\nmass is transferred to the non-empty disjunctive form of all non-empty sets\ntogether; but if this disjunctive form happens to be empty, then one considers\nan open world (i.e. the frame of discernment might contain new hypotheses) and\nthus all conflicting mass is transferred to the empty set. In addition to WAO,\nwe propose a general formula for PCR1 (WAO for non-degenerate cases).",
        "year": 2004,
        "label": "cs.AI"
    },
    {
        "title": "An Algorithm for Quasi-Associative and Quasi-Markovian Rules of\n  Combination in Information Fusion",
        "authors": [
            "Florentin Smarandache",
            "Jean Dezert"
        ],
        "summary": "In this paper one proposes a simple algorithm of combining the fusion rules,\nthose rules which first use the conjunctive rule and then the transfer of\nconflicting mass to the non-empty sets, in such a way that they gain the\nproperty of associativity and fulfill the Markovian requirement for dynamic\nfusion. Also, a new rule, SDL-improved, is presented.",
        "year": 2004,
        "label": "cs.AI"
    },
    {
        "title": "Proportional Conflict Redistribution Rules for Information Fusion",
        "authors": [
            "Florentin Smarandache",
            "Jean Dezert"
        ],
        "summary": "In this paper we propose five versions of a Proportional Conflict\nRedistribution rule (PCR) for information fusion together with several\nexamples. From PCR1 to PCR2, PCR3, PCR4, PCR5 one increases the complexity of\nthe rules and also the exactitude of the redistribution of conflicting masses.\nPCR1 restricted from the hyper-power set to the power set and without\ndegenerate cases gives the same result as the Weighted Average Operator (WAO)\nproposed recently by J{\\o}sang, Daniel and Vannoorenberghe but does not satisfy\nthe neutrality property of vacuous belief assignment. That's why improved PCR\nrules are proposed in this paper. PCR4 is an improvement of minC and Dempster's\nrules. The PCR rules redistribute the conflicting mass, after the conjunctive\nrule has been applied, proportionally with some functions depending on the\nmasses assigned to their corresponding columns in the mass matrix. There are\ninfinitely many ways these functions (weighting factors) can be chosen\ndepending on the complexity one wants to deal with in specific applications and\nfusion systems. Any fusion combination rule is at some degree ad-hoc.",
        "year": 2004,
        "label": "cs.AI"
    },
    {
        "title": "Unification of Fusion Theories",
        "authors": [
            "Florentin Smarandache"
        ],
        "summary": "Since no fusion theory neither rule fully satisfy all needed applications,\nthe author proposes a Unification of Fusion Theories and a combination of\nfusion rules in solving problems/applications. For each particular application,\none selects the most appropriate model, rule(s), and algorithm of\nimplementation. We are working in the unification of the fusion theories and\nrules, which looks like a cooking recipe, better we'd say like a logical chart\nfor a computer programmer, but we don't see another method to comprise/unify\nall things. The unification scenario presented herein, which is now in an\nincipient form, should periodically be updated incorporating new discoveries\nfrom the fusion and engineering research.",
        "year": 2004,
        "label": "cs.AI"
    },
    {
        "title": "An In-Depth Look at Information Fusion Rules & the Unification of Fusion\n  Theories",
        "authors": [
            "Florentin Smarandache"
        ],
        "summary": "This paper may look like a glossary of the fusion rules and we also introduce\nnew ones presenting their formulas and examples: Conjunctive, Disjunctive,\nExclusive Disjunctive, Mixed Conjunctive-Disjunctive rules, Conditional rule,\nDempster's, Yager's, Smets' TBM rule, Dubois-Prade's, Dezert-Smarandache\nclassical and hybrid rules, Murphy's average rule,\nInagaki-Lefevre-Colot-Vannoorenberghe Unified Combination rules [and, as\nparticular cases: Iganaki's parameterized rule, Weighting Average Operator,\nminC (M. Daniel), and newly Proportional Conflict Redistribution rules\n(Smarandache-Dezert) among which PCR5 is the most exact way of redistribution\nof the conflicting mass to non-empty sets following the path of the conjunctive\nrule], Zhang's Center Combination rule, Convolutive x-Averaging, Consensus\nOperator (Josang), Cautious Rule (Smets), ?-junctions rules (Smets), etc. and\nthree new T-norm & T-conorm rules adjusted from fuzzy and neutrosophic sets to\ninformation fusion (Tchamova-Smarandache). Introducing the degree of union and\ndegree of inclusion with respect to the cardinal of sets not with the fuzzy set\npoint of view, besides that of intersection, many fusion rules can be improved.\nThere are corner cases where each rule might have difficulties working or may\nnot get an expected result.",
        "year": 2004,
        "label": "cs.AI"
    },
    {
        "title": "Generating Conditional Probabilities for Bayesian Networks: Easing the\n  Knowledge Acquisition Problem",
        "authors": [
            "Balaram Das"
        ],
        "summary": "The number of probability distributions required to populate a conditional\nprobability table (CPT) in a Bayesian network, grows exponentially with the\nnumber of parent-nodes associated with that table. If the table is to be\npopulated through knowledge elicited from a domain expert then the sheer\nmagnitude of the task forms a considerable cognitive barrier. In this paper we\ndevise an algorithm to populate the CPT while easing the extent of knowledge\nacquisition. The input to the algorithm consists of a set of weights that\nquantify the relative strengths of the influences of the parent-nodes on the\nchild-node, and a set of probability distributions the number of which grows\nonly linearly with the number of associated parent-nodes. These are elicited\nfrom the domain expert. The set of probabilities are obtained by taking into\nconsideration the heuristics that experts use while arriving at probabilistic\nestimations. The algorithm is used to populate the CPT by computing appropriate\nweighted sums of the elicited distributions. We invoke the methods of\ninformation geometry to demonstrate how these weighted sums capture the\nexpert's judgemental strategy.",
        "year": 2004,
        "label": "cs.AI"
    },
    {
        "title": "The Combination of Paradoxical, Uncertain, and Imprecise Sources of\n  Information based on DSmT and Neutro-Fuzzy Inference",
        "authors": [
            "Florentin Smarandache",
            "Jean Dezert"
        ],
        "summary": "The management and combination of uncertain, imprecise, fuzzy and even\nparadoxical or high conflicting sources of information has always been, and\nstill remains today, of primal importance for the development of reliable\nmodern information systems involving artificial reasoning. In this chapter, we\npresent a survey of our recent theory of plausible and paradoxical reasoning,\nknown as Dezert-Smarandache Theory (DSmT) in the literature, developed for\ndealing with imprecise, uncertain and paradoxical sources of information. We\nfocus our presentation here rather on the foundations of DSmT, and on the two\nimportant new rules of combination, than on browsing specific applications of\nDSmT available in literature. Several simple examples are given throughout the\npresentation to show the efficiency and the generality of this new approach.\nThe last part of this chapter concerns the presentation of the neutrosophic\nlogic, the neutro-fuzzy inference and its connection with DSmT. Fuzzy logic and\nneutrosophic logic are useful tools in decision making after fusioning the\ninformation using the DSm hybrid rule of combination of masses.",
        "year": 2004,
        "label": "cs.AI"
    },
    {
        "title": "Perspectives for Strong Artificial Life",
        "authors": [
            "J. -Ph Rennard"
        ],
        "summary": "This text introduces the twin deadlocks of strong artificial life.\nConceptualization of life is a deadlock both because of the existence of a\ncontinuum between the inert and the living, and because we only know one\ninstance of life. Computationalism is a second deadlock since it remains a\nmatter of faith. Nevertheless, artificial life realizations quickly progress\nand recent constructions embed an always growing set of the intuitive\nproperties of life. This growing gap between theory and realizations should\nsooner or later crystallize in some kind of paradigm shift and then give clues\nto break the twin deadlocks.",
        "year": 2005,
        "label": "cs.AI"
    },
    {
        "title": "A Study for the Feature Core of Dynamic Reduct",
        "authors": [
            "Jiayang Wang"
        ],
        "summary": "To the reduct problems of decision system, the paper proposes the notion of\ndynamic core according to the dynamic reduct model. It describes various formal\ndefinitions of dynamic core, and discusses some properties about dynamic core.\nAll of these show that dynamic core possesses the essential characters of the\nfeature core.",
        "year": 2005,
        "label": "cs.AI"
    },
    {
        "title": "Classifying Signals with Local Classifiers",
        "authors": [
            "Wit Jakuczun"
        ],
        "summary": "This paper deals with the problem of classifying signals. The new method for\nbuilding so called local classifiers and local features is presented. The\nmethod is a combination of the lifting scheme and the support vector machines.\nIts main aim is to produce effective and yet comprehensible classifiers that\nwould help in understanding processes hidden behind classified signals. To\nillustrate the method we present the results obtained on an artificial and a\nreal dataset.",
        "year": 2006,
        "label": "cs.AI"
    },
    {
        "title": "Can an Organism Adapt Itself to Unforeseen Circumstances?",
        "authors": [
            "Alexey V. Melkikh"
        ],
        "summary": "A model of an organism as an autonomous intelligent system has been proposed.\nThis model was used to analyze learning of an organism in various environmental\nconditions. Processes of learning were divided into two types: strong and weak\nprocesses taking place in the absence and the presence of aprioristic\ninformation about an object respectively. Weak learning is synonymous to\nadaptation when aprioristic programs already available in a system (an\norganism) are started. It was shown that strong learning is impossible for both\nan organism and any autonomous intelligent system. It was shown also that the\nknowledge base of an organism cannot be updated. Therefore, all behavior\nprograms of an organism are congenital. A model of a conditioned reflex as a\nseries of consecutive measurements of environmental parameters has been\nadvanced. Repeated measurements are necessary in this case to reduce the error\nduring decision making.",
        "year": 2006,
        "label": "cs.AI"
    },
    {
        "title": "Retraction and Generalized Extension of Computing with Words",
        "authors": [
            "Yongzhi Cao",
            "Mingsheng Ying",
            "Guoqing Chen"
        ],
        "summary": "Fuzzy automata, whose input alphabet is a set of numbers or symbols, are a\nformal model of computing with values. Motivated by Zadeh's paradigm of\ncomputing with words rather than numbers, Ying proposed a kind of fuzzy\nautomata, whose input alphabet consists of all fuzzy subsets of a set of\nsymbols, as a formal model of computing with all words. In this paper, we\nintroduce a somewhat general formal model of computing with (some special)\nwords. The new features of the model are that the input alphabet only comprises\nsome (not necessarily all) fuzzy subsets of a set of symbols and the fuzzy\ntransition function can be specified arbitrarily. By employing the methodology\nof fuzzy control, we establish a retraction principle from computing with words\nto computing with values for handling crisp inputs and a generalized extension\nprinciple from computing with words to computing with all words for handling\nfuzzy inputs. These principles show that computing with values and computing\nwith all words can be respectively implemented by computing with words. Some\nalgebraic properties of retractions and generalized extensions are addressed as\nwell.",
        "year": 2006,
        "label": "cs.AI"
    },
    {
        "title": "Belief Conditioning Rules (BCRs)",
        "authors": [
            "Florentin Smarandache",
            "Jean Dezert"
        ],
        "summary": "In this paper we propose a new family of Belief Conditioning Rules (BCRs) for\nbelief revision. These rules are not directly related with the fusion of\nseveral sources of evidence but with the revision of a belief assignment\navailable at a given time according to the new truth (i.e. conditioning\nconstraint) one has about the space of solutions of the problem.",
        "year": 2006,
        "label": "cs.AI"
    },
    {
        "title": "Fusion of qualitative beliefs using DSmT",
        "authors": [
            "Florentin Smarandache",
            "Jean Dezert"
        ],
        "summary": "This paper introduces the notion of qualitative belief assignment to model\nbeliefs of human experts expressed in natural language (with linguistic\nlabels). We show how qualitative beliefs can be efficiently combined using an\nextension of Dezert-Smarandache Theory (DSmT) of plausible and paradoxical\nquantitative reasoning to qualitative reasoning. We propose a new arithmetic on\nlinguistic labels which allows a direct extension of classical DSm fusion rule\nor DSm Hybrid rules. An approximate qualitative PCR5 rule is also proposed\njointly with a Qualitative Average Operator. We also show how crisp or interval\nmappings can be used to deal indirectly with linguistic labels. A very simple\nexample is provided to illustrate our qualitative fusion rules.",
        "year": 2006,
        "label": "cs.AI"
    },
    {
        "title": "An Introduction to the DSm Theory for the Combination of Paradoxical,\n  Uncertain, and Imprecise Sources of Information",
        "authors": [
            "Florentin Smarandache",
            "Jean Dezert"
        ],
        "summary": "The management and combination of uncertain, imprecise, fuzzy and even\nparadoxical or high conflicting sources of information has always been, and\nstill remains today, of primal importance for the development of reliable\nmodern information systems involving artificial reasoning. In this\nintroduction, we present a survey of our recent theory of plausible and\nparadoxical reasoning, known as Dezert-Smarandache Theory (DSmT) in the\nliterature, developed for dealing with imprecise, uncertain and paradoxical\nsources of information. We focus our presentation here rather on the\nfoundations of DSmT, and on the two important new rules of combination, than on\nbrowsing specific applications of DSmT available in literature. Several simple\nexamples are given throughout the presentation to show the efficiency and the\ngenerality of this new approach.",
        "year": 2006,
        "label": "cs.AI"
    },
    {
        "title": "Uniform and Partially Uniform Redistribution Rules",
        "authors": [
            "Florentin Smarandache",
            "Jean Dezert"
        ],
        "summary": "This short paper introduces two new fusion rules for combining quantitative\nbasic belief assignments. These rules although very simple have not been\nproposed in literature so far and could serve as useful alternatives because of\ntheir low computation cost with respect to the recent advanced Proportional\nConflict Redistribution rules developed in the DSmT framework.",
        "year": 2007,
        "label": "cs.AI"
    },
    {
        "title": "Case Base Mining for Adaptation Knowledge Acquisition",
        "authors": [
            "Mathieu D'Aquin",
            "Fadi Badra",
            "Sandrine Lafrogne",
            "Jean Lieber",
            "Amedeo Napoli",
            "Laszlo Szathmary"
        ],
        "summary": "In case-based reasoning, the adaptation of a source case in order to solve\nthe target problem is at the same time crucial and difficult to implement. The\nreason for this difficulty is that, in general, adaptation strongly depends on\ndomain-dependent knowledge. This fact motivates research on adaptation\nknowledge acquisition (AKA). This paper presents an approach to AKA based on\nthe principles and techniques of knowledge discovery from databases and\ndata-mining. It is implemented in CABAMAKA, a system that explores the\nvariations within the case base to elicit adaptation knowledge. This system has\nbeen successfully tested in an application of case-based reasoning to decision\nsupport in the domain of breast cancer treatment.",
        "year": 2007,
        "label": "cs.AI"
    },
    {
        "title": "Fault Classification in Cylinders Using Multilayer Perceptrons, Support\n  Vector Machines and Guassian Mixture Models",
        "authors": [
            "Tshilidzi Marwala",
            "Unathi Mahola",
            "Snehashish Chakraverty"
        ],
        "summary": "Gaussian mixture models (GMM) and support vector machines (SVM) are\nintroduced to classify faults in a population of cylindrical shells. The\nproposed procedures are tested on a population of 20 cylindrical shells and\ntheir performance is compared to the procedure, which uses multi-layer\nperceptrons (MLP). The modal properties extracted from vibration data are used\nto train the GMM, SVM and MLP. It is observed that the GMM produces 98%, SVM\nproduces 94% classification accuracy while the MLP produces 88% classification\nrates.",
        "year": 2007,
        "label": "cs.AI"
    },
    {
        "title": "A Leaf Recognition Algorithm for Plant Classification Using\n  Probabilistic Neural Network",
        "authors": [
            "Stephen Gang Wu",
            "Forrest Sheng Bao",
            "Eric You Xu",
            "Yu-Xuan Wang",
            "Yi-Fan Chang",
            "Qiao-Liang Xiang"
        ],
        "summary": "In this paper, we employ Probabilistic Neural Network (PNN) with image and\ndata processing techniques to implement a general purpose automated leaf\nrecognition algorithm. 12 leaf features are extracted and orthogonalized into 5\nprincipal variables which consist the input vector of the PNN. The PNN is\ntrained by 1800 leaves to classify 32 kinds of plants with an accuracy greater\nthan 90%. Compared with other approaches, our algorithm is an accurate\nartificial intelligence approach which is fast in execution and easy in\nimplementation.",
        "year": 2007,
        "label": "cs.AI"
    },
    {
        "title": "Qualitative Belief Conditioning Rules (QBCR)",
        "authors": [
            "Florentin Smarandache",
            "Jean Dezert"
        ],
        "summary": "In this paper we extend the new family of (quantitative) Belief Conditioning\nRules (BCR) recently developed in the Dezert-Smarandache Theory (DSmT) to their\nqualitative counterpart for belief revision. Since the revision of quantitative\nas well as qualitative belief assignment given the occurrence of a new event\n(the conditioning constraint) can be done in many possible ways, we present\nhere only what we consider as the most appealing Qualitative Belief\nConditioning Rules (QBCR) which allow to revise the belief directly with words\nand linguistic labels and thus avoids the introduction of ad-hoc translations\nof quantitative beliefs into quantitative ones for solving the problem.",
        "year": 2007,
        "label": "cs.AI"
    },
    {
        "title": "Fitness landscape of the cellular automata majority problem: View from\n  the Olympus",
        "authors": [
            "S\u00e9bastien Verel",
            "Philippe Collard",
            "Marco Tomassini",
            "Leonardo Vanneschi"
        ],
        "summary": "In this paper we study cellular automata (CAs) that perform the computational\nMajority task. This task is a good example of what the phenomenon of emergence\nin complex systems is. We take an interest in the reasons that make this\nparticular fitness landscape a difficult one. The first goal is to study the\nlandscape as such, and thus it is ideally independent from the actual\nheuristics used to search the space. However, a second goal is to understand\nthe features a good search technique for this particular problem space should\npossess. We statistically quantify in various ways the degree of difficulty of\nsearching this landscape. Due to neutrality, investigations based on sampling\ntechniques on the whole landscape are difficult to conduct. So, we go exploring\nthe landscape from the top. Although it has been proved that no CA can perform\nthe task perfectly, several efficient CAs for this task have been found.\nExploiting similarities between these CAs and symmetries in the landscape, we\ndefine the Olympus landscape which is regarded as the ''heavenly home'' of the\nbest local optima known (blok). Then we measure several properties of this\nsubspace. Although it is easier to find relevant CAs in this subspace than in\nthe overall landscape, there are structural reasons that prevent a searcher\nfrom finding overfitted CAs in the Olympus. Finally, we study dynamics and\nperformance of genetic algorithms on the Olympus in order to confirm our\nanalysis and to find efficient CAs for the Majority problem with low\ncomputational cost.",
        "year": 2007,
        "label": "cs.AI"
    },
    {
        "title": "Fusion for Evaluation of Image Classification in Uncertain Environments",
        "authors": [
            "Arnaud Martin"
        ],
        "summary": "We present in this article a new evaluation method for classification and\nsegmentation of textured images in uncertain environments. In uncertain\nenvironments, real classes and boundaries are known with only a partial\ncertainty given by the experts. Most of the time, in many presented papers,\nonly classification or only segmentation are considered and evaluated. Here, we\npropose to take into account both the classification and segmentation results\naccording to the certainty given by the experts. We present the results of this\nmethod on a fusion of classifiers of sonar images for a seabed\ncharacterization.",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "Belief decision support and reject for textured images characterization",
        "authors": [
            "Arnaud Martin"
        ],
        "summary": "The textured images' classification assumes to consider the images in terms\nof area with the same texture. In uncertain environment, it could be better to\ntake an imprecise decision or to reject the area corresponding to an unlearning\nclass. Moreover, on the areas that are the classification units, we can have\nmore than one texture. These considerations allows us to develop a belief\ndecision model permitting to reject an area as unlearning and to decide on\nunions and intersections of learning classes. The proposed approach finds all\nits justification in an application of seabed characterization from sonar\nimages, which contributes to an illustration.",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "Extension of Inagaki General Weighted Operators and A New Fusion Rule\n  Class of Proportional Redistribution of Intersection Masses",
        "authors": [
            "Florentin Smarandache"
        ],
        "summary": "In this paper we extend Inagaki Weighted Operators fusion rule (WO) in\ninformation fusion by doing redistribution of not only the conflicting mass,\nbut also of masses of non-empty intersections, that we call Double Weighted\nOperators (DWO). Then we propose a new fusion rule Class of Proportional\nRedistribution of Intersection Masses (CPRIM), which generates many interesting\nparticular fusion rules in information fusion. Both formulas are presented for\nany number of sources of information. An application and comparison with other\nfusion rules are given in the last section.",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "Implementing general belief function framework with a practical\n  codification for low complexity",
        "authors": [
            "Arnaud Martin"
        ],
        "summary": "In this chapter, we propose a new practical codification of the elements of\nthe Venn diagram in order to easily manipulate the focal elements. In order to\nreduce the complexity, the eventual constraints must be integrated in the\ncodification at the beginning. Hence, we only consider a reduced hyper power\nset $D_r^\\Theta$ that can be $2^\\Theta$ or $D^\\Theta$. We describe all the\nsteps of a general belief function framework. The step of decision is\nparticularly studied, indeed, when we can decide on intersections of the\nsingletons of the discernment space no actual decision functions are easily to\nuse. Hence, two approaches are proposed, an extension of previous one and an\napproach based on the specificity of the elements on which to decide. The\nprincipal goal of this chapter is to provide practical codes of a general\nbelief function framework for the researchers and users needing the belief\nfunction theory.",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "A new probabilistic transformation of belief mass assignment",
        "authors": [
            "Jean Dezert",
            "Florentin Smarandache"
        ],
        "summary": "In this paper, we propose in Dezert-Smarandache Theory (DSmT) framework, a\nnew probabilistic transformation, called DSmP, in order to build a subjective\nprobability measure from any basic belief assignment defined on any model of\nthe frame of discernment. Several examples are given to show how the DSmP\ntransformation works and we compare it to main existing transformations\nproposed in the literature so far. We show the advantages of DSmP over\nclassical transformations in term of Probabilistic Information Content (PIC).\nThe direct extension of this transformation for dealing with qualitative belief\nassignments is also presented.",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "Randomised Variable Neighbourhood Search for Multi Objective\n  Optimisation",
        "authors": [
            "Martin Josef Geiger"
        ],
        "summary": "Various local search approaches have recently been applied to machine\nscheduling problems under multiple objectives. Their foremost consideration is\nthe identification of the set of Pareto optimal alternatives. An important\naspect of successfully solving these problems lies in the definition of an\nappropriate neighbourhood structure. Unclear in this context remains, how\ninterdependencies within the fitness landscape affect the resolution of the\nproblem.\n  The paper presents a study of neighbourhood search operators for multiple\nobjective flow shop scheduling. Experiments have been carried out with twelve\ndifferent combinations of criteria. To derive exact conclusions, small problem\ninstances, for which the optimal solutions are known, have been chosen.\nStatistical tests show that no single neighbourhood operator is able to equally\nidentify all Pareto optimal alternatives. Significant improvements however have\nbeen obtained by hybridising the solution algorithm using a randomised variable\nneighbourhood search technique.",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "Foundations of the Pareto Iterated Local Search Metaheuristic",
        "authors": [
            "Martin Josef Geiger"
        ],
        "summary": "The paper describes the proposition and application of a local search\nmetaheuristic for multi-objective optimization problems. It is based on two\nmain principles of heuristic search, intensification through variable\nneighborhoods, and diversification through perturbations and successive\niterations in favorable regions of the search space. The concept is\nsuccessfully tested on permutation flow shop scheduling problems under multiple\nobjectives. While the obtained results are encouraging in terms of their\nquality, another positive attribute of the approach is its' simplicity as it\ndoes require the setting of only very few parameters. The implementation of the\nPareto Iterated Local Search metaheuristic is based on the MOOPPS computer\nsystem of local search heuristics for multi-objective scheduling which has been\nawarded the European Academic Software Award 2002 in Ronneby, Sweden\n(http://www.easa-award.net/, http://www.bth.se/llab/easa_2002.nsf)",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "A Computational Study of Genetic Crossover Operators for Multi-Objective\n  Vehicle Routing Problem with Soft Time Windows",
        "authors": [
            "Martin Josef Geiger"
        ],
        "summary": "The article describes an investigation of the effectiveness of genetic\nalgorithms for multi-objective combinatorial optimization (MOCO) by presenting\nan application for the vehicle routing problem with soft time windows. The work\nis motivated by the question, if and how the problem structure influences the\neffectiveness of different configurations of the genetic algorithm.\nComputational results are presented for different classes of vehicle routing\nproblems, varying in their coverage with time windows, time window size,\ndistribution and number of customers. The results are compared with a simple,\nbut effective local search approach for multi-objective combinatorial\noptimization problems.",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "Genetic Algorithms for multiple objective vehicle routing",
        "authors": [
            "Martin Josef Geiger"
        ],
        "summary": "The talk describes a general approach of a genetic algorithm for multiple\nobjective optimization problems. A particular dominance relation between the\nindividuals of the population is used to define a fitness operator, enabling\nthe genetic algorithm to adress even problems with efficient, but\nconvex-dominated alternatives. The algorithm is implemented in a multilingual\ncomputer program, solving vehicle routing problems with time windows under\nmultiple objectives. The graphical user interface of the program shows the\nprogress of the genetic algorithm and the main parameters of the approach can\nbe easily modified. In addition to that, the program provides powerful decision\nsupport to the decision maker. The software has proved it's excellence at the\nfinals of the European Academic Software Award EASA, held at the Keble college/\nUniversity of Oxford/ Great Britain.",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "Bin Packing Under Multiple Objectives - a Heuristic Approximation\n  Approach",
        "authors": [
            "Martin Josef Geiger"
        ],
        "summary": "The article proposes a heuristic approximation approach to the bin packing\nproblem under multiple objectives. In addition to the traditional objective of\nminimizing the number of bins, the heterogeneousness of the elements in each\nbin is minimized, leading to a biobjective formulation of the problem with a\ntradeoff between the number of bins and their heterogeneousness. An extension\nof the Best-Fit approximation algorithm is presented to solve the problem.\nExperimental investigations have been carried out on benchmark instances of\ndifferent size, ranging from 100 to 1000 items. Encouraging results have been\nobtained, showing the applicability of the heuristic approach to the described\nproblem.",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "An application of the Threshold Accepting metaheuristic for curriculum\n  based course timetabling",
        "authors": [
            "Martin Josef Geiger"
        ],
        "summary": "The article presents a local search approach for the solution of timetabling\nproblems in general, with a particular implementation for competition track 3\nof the International Timetabling Competition 2007 (ITC 2007). The heuristic\nsearch procedure is based on Threshold Accepting to overcome local optima. A\nstochastic neighborhood is proposed and implemented, randomly removing and\nreassigning events from the current solution.\n  The overall concept has been incrementally obtained from a series of\nexperiments, which we describe in each (sub)section of the paper. In result, we\nsuccessfully derived a potential candidate solution approach for the finals of\ntrack 3 of the ITC 2007.",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "N-norm and N-conorm in Neutrosophic Logic and Set, and the Neutrosophic\n  Topologies",
        "authors": [
            "Florentin Smarandache"
        ],
        "summary": "In this paper we present the N-norms/N-conorms in neutrosophic logic and set\nas extensions of T-norms/T-conorms in fuzzy logic and set. Also, as an\nextension of the Intuitionistic Fuzzy Topology we present the Neutrosophic\nTopologies.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "An improved axiomatic definition of information granulation",
        "authors": [
            "Ping Zhu"
        ],
        "summary": "To capture the uncertainty of information or knowledge in information\nsystems, various information granulations, also known as knowledge\ngranulations, have been proposed. Recently, several axiomatic definitions of\ninformation granulation have been introduced. In this paper, we try to improve\nthese axiomatic definitions and give a universal construction of information\ngranulation by relating information granulations with a class of functions of\nmultiple variables. We show that the improved axiomatic definition has some\nconcrete information granulations in the literature as instances.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Covering rough sets based on neighborhoods: An approach without using\n  neighborhoods",
        "authors": [
            "Ping Zhu"
        ],
        "summary": "Rough set theory, a mathematical tool to deal with inexact or uncertain\nknowledge in information systems, has originally described the indiscernibility\nof elements by equivalence relations. Covering rough sets are a natural\nextension of classical rough sets by relaxing the partitions arising from\nequivalence relations to coverings. Recently, some topological concepts such as\nneighborhood have been applied to covering rough sets. In this paper, we\nfurther investigate the covering rough sets based on neighborhoods by\napproximation operations. We show that the upper approximation based on\nneighborhoods can be defined equivalently without using neighborhoods. To\nanalyze the coverings themselves, we introduce unary and composition operations\non coverings. A notion of homomorphismis provided to relate two covering\napproximation spaces. We also examine the properties of approximations\npreserved by the operations and homomorphisms, respectively.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "An axiomatic approach to the roughness measure of rough sets",
        "authors": [
            "Ping Zhu"
        ],
        "summary": "In Pawlak's rough set theory, a set is approximated by a pair of lower and\nupper approximations. To measure numerically the roughness of an approximation,\nPawlak introduced a quantitative measure of roughness by using the ratio of the\ncardinalities of the lower and upper approximations. Although the roughness\nmeasure is effective, it has the drawback of not being strictly monotonic with\nrespect to the standard ordering on partitions. Recently, some improvements\nhave been made by taking into account the granularity of partitions. In this\npaper, we approach the roughness measure in an axiomatic way. After\naxiomatically defining roughness measure and partition measure, we provide a\nunified construction of roughness measure, called strong Pawlak roughness\nmeasure, and then explore the properties of this measure. We show that the\nimproved roughness measures in the literature are special instances of our\nstrong Pawlak roughness measure and introduce three more strong Pawlak\nroughness measures as well. The advantage of our axiomatic approach is that\nsome properties of a roughness measure follow immediately as soon as the\nmeasure satisfies the relevant axiomatic definition.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "A general approach to belief change in answer set programming",
        "authors": [
            "James Delgrande",
            "Torsten Schaub",
            "Hans Tompits",
            "Stefan Woltran"
        ],
        "summary": "We address the problem of belief change in (nonmonotonic) logic programming\nunder answer set semantics. Unlike previous approaches to belief change in\nlogic programming, our formal techniques are analogous to those of\ndistance-based belief revision in propositional logic. In developing our\nresults, we build upon the model theory of logic programs furnished by SE\nmodels. Since SE models provide a formal, monotonic characterisation of logic\nprograms, we can adapt techniques from the area of belief revision to belief\nchange in logic programs. We introduce methods for revising and merging logic\nprograms, respectively. For the former, we study both subset-based revision as\nwell as cardinality-based revision, and we show that they satisfy the majority\nof the AGM postulates for revision. For merging, we consider operators\nfollowing arbitration merging and IC merging, respectively. We also present\nencodings for computing the revision as well as the merging of logic programs\nwithin the same logic programming framework, giving rise to a direct\nimplementation of our approach in terms of off-the-shelf answer set solvers.\nThese encodings reflect in turn the fact that our change operators do not\nincrease the complexity of the base formalism.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "$\u03b1$-Discounting Multi-Criteria Decision Making ($\u03b1$-D MCDM)",
        "authors": [
            "Florentin Smarandache"
        ],
        "summary": "In this book we introduce a new procedure called \\alpha-Discounting Method\nfor Multi-Criteria Decision Making (\\alpha-D MCDM), which is as an alternative\nand extension of Saaty Analytical Hierarchy Process (AHP). It works for any\nnumber of preferences that can be transformed into a system of homogeneous\nlinear equations. A degree of consistency (and implicitly a degree of\ninconsistency) of a decision-making problem are defined. \\alpha-D MCDM is\nafterwards generalized to a set of preferences that can be transformed into a\nsystem of linear and or non-linear homogeneous and or non-homogeneous equations\nand or inequalities. The general idea of \\alpha-D MCDM is to assign non-null\npositive parameters \\alpha_1, \\alpha_2, and so on \\alpha_p to the coefficients\nin the right-hand side of each preference that diminish or increase them in\norder to transform the above linear homogeneous system of equations which has\nonly the null-solution, into a system having a particular non-null solution.\nAfter finding the general solution of this system, the principles used to\nassign particular values to all parameters \\alpha is the second important part\nof \\alpha-D, yet to be deeper investigated in the future. In the current book\nwe propose the Fairness Principle, i.e. each coefficient should be discounted\nwith the same percentage (we think this is fair: not making any favoritism or\nunfairness to any coefficient), but the reader can propose other principles.\nFor consistent decision-making problems with pairwise comparisons,\n\\alpha-Discounting Method together with the Fairness Principle give the same\nresult as AHP. But for weak inconsistent decision-making problem,\n\\alpha-Discounting together with the Fairness Principle give a different result\nfrom AHP. Many consistent, weak inconsistent, and strong inconsistent examples\nare given in this book.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "Dominion -- A constraint solver generator",
        "authors": [
            "Lars Kotthoff"
        ],
        "summary": "This paper proposes a design for a system to generate constraint solvers that\nare specialised for specific problem models. It describes the design in detail\nand gives preliminary experimental results showing the feasibility and\neffectiveness of the approach.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "Some improved results on communication between information systems",
        "authors": [
            "Ping Zhu",
            "Qiaoyan Wen"
        ],
        "summary": "To study the communication between information systems, Wang et al. [C. Wang,\nC. Wu, D. Chen, Q. Hu, and C. Wu, Communicating between information systems,\nInformation Sciences 178 (2008) 3228-3239] proposed two concepts of type-1 and\ntype-2 consistent functions. Some properties of such functions and induced\nrelation mappings have been investigated there. In this paper, we provide an\nimprovement of the aforementioned work by disclosing the symmetric relationship\nbetween type-1 and type-2 consistent functions. We present more properties of\nconsistent functions and induced relation mappings and improve upon several\ndeficient assertions in the original work. In particular, we unify and extend\ntype-1 and type-2 consistent functions into the so-called\nneighborhood-consistent functions. This provides a convenient means for\nstudying the communication between information systems based on various\nneighborhoods.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "Homomorphisms between fuzzy information systems revisited",
        "authors": [
            "Ping Zhu",
            "Qiaoyan Wen"
        ],
        "summary": "Recently, Wang et al. discussed the properties of fuzzy information systems\nunder homomorphisms in the paper [C. Wang, D. Chen, L. Zhu, Homomorphisms\nbetween fuzzy information systems, Applied Mathematics Letters 22 (2009)\n1045-1050], where homomorphisms are based upon the concepts of consistent\nfunctions and fuzzy relation mappings. In this paper, we classify consistent\nfunctions as predecessor-consistent and successor-consistent, and then proceed\nto present more properties of consistent functions. In addition, we improve\nsome characterizations of fuzzy relation mappings provided by Wang et al.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "Importance of Sources using the Repeated Fusion Method and the\n  Proportional Conflict Redistribution Rules #5 and #6",
        "authors": [
            "Florentin Smarandache",
            "Jean Dezert"
        ],
        "summary": "We present in this paper some examples of how to compute by hand the PCR5\nfusion rule for three sources, so the reader will better understand its\nmechanism. We also take into consideration the importance of sources, which is\ndifferent from the classical discounting of sources.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "On the comparison of plans: Proposition of an instability measure for\n  dynamic machine scheduling",
        "authors": [
            "Martin Josef Geiger"
        ],
        "summary": "On the basis of an analysis of previous research, we present a generalized\napproach for measuring the difference of plans with an exemplary application to\nmachine scheduling. Our work is motivated by the need for such measures, which\nare used in dynamic scheduling and planning situations. In this context,\nquantitative approaches are needed for the assessment of the robustness and\nstability of schedules. Obviously, any `robustness' or `stability' of plans has\nto be defined w. r. t. the particular situation and the requirements of the\nhuman decision maker. Besides the proposition of an instability measure, we\ntherefore discuss possibilities of obtaining meaningful information from the\ndecision maker for the implementation of the introduced approach.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "Symmetries of Symmetry Breaking Constraints",
        "authors": [
            "George Katsirelos",
            "Toby Walsh"
        ],
        "summary": "Symmetry is an important feature of many constraint programs. We show that\nany problem symmetry acting on a set of symmetry breaking constraints can be\nused to break symmetry. Different symmetries pick out different solutions in\neach symmetry class. This simple but powerful idea can be used in a number of\ndifferent ways. We describe one application within model restarts, a search\ntechnique designed to reduce the conflict between symmetry breaking and the\nbranching heuristic. In model restarts, we restart search periodically with a\nrandom symmetry of the symmetry breaking constraints. Experimental results show\nthat this symmetry breaking technique is effective in practice on some standard\nbenchmark problems.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "AI 3D Cybug Gaming",
        "authors": [
            "Zeeshan Ahmed"
        ],
        "summary": "In this short paper I briefly discuss 3D war Game based on artificial\nintelligence concepts called AI WAR. Going in to the details, I present the\nimportance of CAICL language and how this language is used in AI WAR. Moreover\nI also present a designed and implemented 3D War Cybug for AI WAR using CAICL\nand discus the implemented strategy to defeat its enemies during the game life.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "Reinforcement Learning in Partially Observable Markov Decision Processes\n  using Hybrid Probabilistic Logic Programs",
        "authors": [
            "Emad Saad"
        ],
        "summary": "We present a probabilistic logic programming framework to reinforcement\nlearning, by integrating reinforce-ment learning, in POMDP environments, with\nnormal hybrid probabilistic logic programs with probabilistic answer set\nseman-tics, that is capable of representing domain-specific knowledge. We\nformally prove the correctness of our approach. We show that the complexity of\nfinding a policy for a reinforcement learning problem in our approach is\nNP-complete. In addition, we show that any reinforcement learning problem can\nbe encoded as a classical logic program with answer set semantics. We also show\nthat a reinforcement learning problem can be encoded as a SAT problem. We\npresent a new high level action description language that allows the factored\nrepresentation of POMDP. Moreover, we modify the original model of POMDP so\nthat it be able to distinguish between knowledge producing actions and actions\nthat change the environment.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "Looking for plausibility",
        "authors": [
            "Wan Ahmad Tajuddin Wan Abdullah"
        ],
        "summary": "In the interpretation of experimental data, one is actually looking for\nplausible explanations. We look for a measure of plausibility, with which we\ncan compare different possible explanations, and which can be combined when\nthere are different sets of data. This is contrasted to the conventional\nmeasure for probabilities as well as to the proposed measure of possibilities.\nWe define what characteristics this measure of plausibility should have.\n  In getting to the conception of this measure, we explore the relation of\nplausibility to abductive reasoning, and to Bayesian probabilities. We also\ncompare with the Dempster-Schaefer theory of evidence, which also has its own\ndefinition for plausibility. Abduction can be associated with biconditionality\nin inference rules, and this provides a platform to relate to the\nCollins-Michalski theory of plausibility. Finally, using a formalism for wiring\nlogic onto Hopfield neural networks, we ask if this is relevant in obtaining\nthis measure.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "Information-theoretic measures associated with rough set approximations",
        "authors": [
            "Ping Zhu",
            "Qiaoyan Wen"
        ],
        "summary": "Although some information-theoretic measures of uncertainty or granularity\nhave been proposed in rough set theory, these measures are only dependent on\nthe underlying partition and the cardinality of the universe, independent of\nthe lower and upper approximations. It seems somewhat unreasonable since the\nbasic idea of rough set theory aims at describing vague concepts by the lower\nand upper approximations. In this paper, we thus define new\ninformation-theoretic entropy and co-entropy functions associated to the\npartition and the approximations to measure the uncertainty and granularity of\nan approximation space. After introducing the novel notions of entropy and\nco-entropy, we then examine their properties. In particular, we discuss the\nrelationship of co-entropies between different universes. The theoretical\ndevelopment is accompanied by illustrative numerical examples.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Practical inventory routing: A problem definition and an optimization\n  method",
        "authors": [
            "Martin Josef Geiger",
            "Marc Sevaux"
        ],
        "summary": "The global objective of this work is to provide practical optimization\nmethods to companies involved in inventory routing problems, taking into\naccount this new type of data. Also, companies are sometimes not able to deal\nwith changing plans every period and would like to adopt regular structures for\nserving customers.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Finding Shortest Path for Developed Cognitive Map Using Medial Axis",
        "authors": [
            "Hazim A. Farhan",
            "Hussein H. Owaied",
            "Suhaib I. Al-Ghazi"
        ],
        "summary": "this paper presents an enhancement of the medial axis algorithm to be used\nfor finding the optimal shortest path for developed cognitive map. The\ncognitive map has been developed, based on the architectural blueprint maps.\nThe idea for using the medial-axis is to find main path central pixels; each\ncenter pixel represents the center distance between two side boarder pixels.\nThe need for these pixels in the algorithm comes from the need of building a\nnetwork of nodes for the path, where each node represents a turning in the real\nworld (left, right, critical left, critical right...). The algorithm also\nignores from finding the center pixels paths that are too small for intelligent\nrobot navigation. The Idea of this algorithm is to find the possible shortest\npath between start and end points. The goal of this research is to extract a\nsimple, robust representation of the shape of the cognitive map together with\nthe optimal shortest path between start and end points. The intelligent robot\nwill use this algorithm in order to decrease the time that is needed for\nsweeping the targeted building.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Xapagy: a cognitive architecture for narrative reasoning",
        "authors": [
            "Ladislau B\u00f6l\u00f6ni"
        ],
        "summary": "We introduce the Xapagy cognitive architecture: a software system designed to\nperform narrative reasoning. The architecture has been designed from scratch to\nmodel and mimic the activities performed by humans when witnessing, reading,\nrecalling, narrating and talking about stories.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "The Ariadne's Clew Algorithm",
        "authors": [
            "J. M. Ahuactzin",
            "P. Bessiere",
            "E. Mazer"
        ],
        "summary": "We present a new approach to path planning, called the \"Ariadne's clew\nalgorithm\". It is designed to find paths in high-dimensional continuous spaces\nand applies to robots with many degrees of freedom in static, as well as\ndynamic environments - ones where obstacles may move. The Ariadne's clew\nalgorithm comprises two sub-algorithms, called Search and Explore, applied in\nan interleaved manner. Explore builds a representation of the accessible space\nwhile Search looks for the target. Both are posed as optimization problems. We\ndescribe a real implementation of the algorithm to plan paths for a six degrees\nof freedom arm in a dynamic environment where another six degrees of freedom\narm is used as a moving obstacle. Experimental results show that a path is\nfound in about one second without any pre-processing.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "The Automatic Inference of State Invariants in TIM",
        "authors": [
            "M. Fox",
            "D. Long"
        ],
        "summary": "As planning is applied to larger and richer domains the effort involved in\nconstructing domain descriptions increases and becomes a significant burden on\nthe human application designer. If general planners are to be applied\nsuccessfully to large and complex domains it is necessary to provide the domain\ndesigner with some assistance in building correctly encoded domains. One way of\ndoing this is to provide domain-independent techniques for extracting, from a\ndomain description, knowledge that is implicit in that description and that can\nassist domain designers in debugging domain descriptions. This knowledge can\nalso be exploited to improve the performance of planners: several researchers\nhave explored the potential of state invariants in speeding up the performance\nof domain-independent planners. In this paper we describe a process by which\nstate invariants can be extracted from the automatically inferred type\nstructure of a domain. These techniques are being developed for exploitation by\nSTAN, a Graphplan based planner that employs state analysis techniques to\nenhance its performance.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Efficient Implementation of the Plan Graph in STAN",
        "authors": [
            "M. Fox",
            "D. Long"
        ],
        "summary": "STAN is a Graphplan-based planner, so-called because it uses a variety of\nSTate ANalysis techniques to enhance its performance. STAN competed in the\nAIPS-98 planning competition where it compared well with the other competitors\nin terms of speed, finding solutions fastest to many of the problems posed.\nAlthough the domain analysis techniques STAN exploits are an important factor\nin its overall performance, we believe that the speed at which STAN solved the\ncompetition problems is largely due to the implementation of its plan graph.\nThe implementation is based on two insights: that many of the graph\nconstruction operations can be implemented as bit-level logical operations on\nbit vectors, and that the graph should not be explicitly constructed beyond the\nfix point. This paper describes the implementation of STAN's plan graph and\nprovides experimental results which demonstrate the circumstances under which\nadvantages can be obtained from using this implementation.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Decision-Theoretic Planning: Structural Assumptions and Computational\n  Leverage",
        "authors": [
            "C. Boutilier",
            "T. Dean",
            "S. Hanks"
        ],
        "summary": "Planning under uncertainty is a central problem in the study of automated\nsequential decision making, and has been addressed by researchers in many\ndifferent fields, including AI planning, decision analysis, operations\nresearch, control theory and economics. While the assumptions and perspectives\nadopted in these areas often differ in substantial ways, many planning problems\nof interest to researchers in these fields can be modeled as Markov decision\nprocesses (MDPs) and analyzed using the techniques of decision theory. This\npaper presents an overview and synthesis of MDP-related methods, showing how\nthey provide a unifying framework for modeling many classes of planning\nproblems studied in AI. It also describes structural properties of MDPs that,\nwhen exhibited by particular classes of problems, can be exploited in the\nconstruction of optimal or approximately optimal policies or plans. Planning\nproblems commonly possess structure in the reward and value functions used to\ndescribe performance criteria, in the functions used to describe state\ntransitions and observations, and in the relationships among features used to\ndescribe states, actions, rewards, and observations. Specialized\nrepresentations, and algorithms employing these representations, can achieve\ncomputational leverage by exploiting these various forms of structure. Certain\nAI techniques -- in particular those based on the use of structured,\nintensional representations -- can be viewed in this way. This paper surveys\nseveral types of representations for both classical and decision-theoretic\nplanning problems, and planning algorithms that exploit these representations\nin a number of different ways to ease the computational burden of constructing\npolicies or plans. It focuses primarily on abstraction, aggregation and\ndecomposition techniques based on AI-style representations.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Conformant Planning via Symbolic Model Checking",
        "authors": [
            "A. Cimatti",
            "M. Roveri"
        ],
        "summary": "We tackle the problem of planning in nondeterministic domains, by presenting\na new approach to conformant planning. Conformant planning is the problem of\nfinding a sequence of actions that is guaranteed to achieve the goal despite\nthe nondeterminism of the domain. Our approach is based on the representation\nof the planning domain as a finite state automaton. We use Symbolic Model\nChecking techniques, in particular Binary Decision Diagrams, to compactly\nrepresent and efficiently search the automaton. In this paper we make the\nfollowing contributions. First, we present a general planning algorithm for\nconformant planning, which applies to fully nondeterministic domains, with\nuncertainty in the initial condition and in action effects. The algorithm is\nbased on a breadth-first, backward search, and returns conformant plans of\nminimal length, if a solution to the planning problem exists, otherwise it\nterminates concluding that the problem admits no conformant solution. Second,\nwe provide a symbolic representation of the search space based on Binary\nDecision Diagrams (BDDs), which is the basis for search techniques derived from\nsymbolic model checking. The symbolic representation makes it possible to\nanalyze potentially large sets of states and transitions in a single\ncomputation step, thus providing for an efficient implementation. Third, we\npresent CMBP (Conformant Model Based Planner), an efficient implementation of\nthe data structures and algorithm described above, directly based on BDD\nmanipulations, which allows for a compact representation of the search layers\nand an efficient implementation of the search steps. Finally, we present an\nexperimental comparison of our approach with the state-of-the-art conformant\nplanners CGP, QBFPLAN and GPT. Our analysis includes all the planning problems\nfrom the distribution packages of these systems, plus other problems defined to\nstress a number of specific factors. Our approach appears to be the most\neffective: CMBP is strictly more expressive than QBFPLAN and CGP and, in all\nthe problems where a comparison is possible, CMBP outperforms its competitors,\nsometimes by orders of magnitude.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Accelerating Reinforcement Learning by Composing Solutions of\n  Automatically Identified Subtasks",
        "authors": [
            "C. Drummond"
        ],
        "summary": "This paper discusses a system that accelerates reinforcement learning by\nusing transfer from related tasks. Without such transfer, even if two tasks are\nvery similar at some abstract level, an extensive re-learning effort is\nrequired. The system achieves much of its power by transferring parts of\npreviously learned solutions rather than a single complete solution. The system\nexploits strong features in the multi-dimensional function produced by\nreinforcement learning in solving a particular task. These features are stable\nand easy to recognize early in the learning process. They generate a\npartitioning of the state space and thus the function. The partition is\nrepresented as a graph. This is used to index and compose functions stored in a\ncase base to form a close approximation to the solution of the new task.\nExperiments demonstrate that function composition often produces more than an\norder of magnitude increase in learning rate compared to a basic reinforcement\nlearning algorithm.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Finding a Path is Harder than Finding a Tree",
        "authors": [
            "C. Meek"
        ],
        "summary": "I consider the problem of learning an optimal path graphical model from data\nand show the problem to be NP-hard for the maximum likelihood and minimum\ndescription length approaches and a Bayesian approach. This hardness result\nholds despite the fact that the problem is a restriction of the polynomially\nsolvable problem of finding the optimal tree graphical model.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Rooting opinions in the minds: a cognitive model and a formal account of\n  opinions and their dynamics",
        "authors": [
            "Francesca Giardini",
            "Walter Quattrociocchi",
            "Rosaria Conte"
        ],
        "summary": "The study of opinions, their formation and change, is one of the defining\ntopics addressed by social psychology, but in recent years other disciplines,\nlike computer science and complexity, have tried to deal with this issue.\nDespite the flourishing of different models and theories in both fields,\nseveral key questions still remain unanswered. The understanding of how\nopinions change and the way they are affected by social influence are\nchallenging issues requiring a thorough analysis of opinion per se but also of\nthe way in which they travel between agents' minds and are modulated by these\nexchanges. To account for the two-faceted nature of opinions, which are mental\nentities undergoing complex social processes, we outline a preliminary model in\nwhich a cognitive theory of opinions is put forward and it is paired with a\nformal description of them and of their spreading among minds. Furthermore,\ninvestigating social influence also implies the necessity to account for the\nway in which people change their minds, as a consequence of interacting with\nother people, and the need to explain the higher or lower persistence of such\nchanges.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Understanding opinions. A cognitive and formal account",
        "authors": [
            "Francesca Giardini",
            "Walter Quattrociocchi",
            "Rosaria Conte"
        ],
        "summary": "The study of opinions, their formation and change, is one of the defining\ntopics addressed by social psychology, but in recent years other disciplines,\nas computer science and complexity, have addressed this challenge. Despite the\nflourishing of different models and theories in both fields, several key\nquestions still remain unanswered. The aim of this paper is to challenge the\ncurrent theories on opinion by putting forward a cognitively grounded model\nwhere opinions are described as specific mental representations whose main\nproperties are put forward. A comparison with reputation will be also\npresented.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "PDDL2.1: An Extension to PDDL for Expressing Temporal Planning Domains",
        "authors": [
            "M. Fox",
            "D. Long"
        ],
        "summary": "In recent years research in the planning community has moved increasingly\ntoward s application of planners to realistic problems involving both time and\nmany typ es of resources. For example, interest in planning demonstrated by the\nspace res earch community has inspired work in observation scheduling,\nplanetary rover ex ploration and spacecraft control domains. Other temporal and\nresource-intensive domains including logistics planning, plant control and\nmanufacturing have also helped to focus the community on the modelling and\nreasoning issues that must be confronted to make planning technology meet the\nchallenges of application. The International Planning Competitions have acted\nas an important motivating fo rce behind the progress that has been made in\nplanning since 1998. The third com petition (held in 2002) set the planning\ncommunity the challenge of handling tim e and numeric resources. This\nnecessitated the development of a modelling langua ge capable of expressing\ntemporal and numeric properties of planning domains. In this paper we describe\nthe language, PDDL2.1, that was used in the competition. We describe the syntax\nof the language, its formal semantics and the validation of concurrent plans.\nWe observe that PDDL2.1 has considerable modelling power --- exceeding the\ncapabilities of current planning technology --- and presents a number of\nimportant challenges to the research community.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Exploiting Reputation in Distributed Virtual Environments",
        "authors": [
            "Walter Quattrociocchi",
            "Rosaria Conte"
        ],
        "summary": "The cognitive research on reputation has shown several interesting properties\nthat can improve both the quality of services and the security in distributed\nelectronic environments. In this paper, the impact of reputation on\ndecision-making under scarcity of information will be shown. First, a cognitive\ntheory of reputation will be presented, then a selection of simulation\nexperimental results from different studies will be discussed. Such results\nconcern the benefits of reputation when agents need to find out good sellers in\na virtual market-place under uncertainty and informational cheating.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "The 3rd International Planning Competition: Results and Analysis",
        "authors": [
            "M. Fox",
            "D. Long"
        ],
        "summary": "This paper reports the outcome of the third in the series of biennial\ninternational planning competitions, held in association with the International\nConference on AI Planning and Scheduling (AIPS) in 2002. In addition to\ndescribing the domains, the planners and the objectives of the competition, the\npaper includes analysis of the results. The results are analysed from several\nperspectives, in order to address the questions of comparative performance\nbetween planners, comparative difficulty of domains, the degree of agreement\nbetween planners about the relative difficulty of individual problem instances\nand the question of how well planners scale relative to one another over\nincreasingly difficult problems. The paper addresses these questions through\nstatistical analysis of the raw results of the competition, in order to\ndetermine which results can be considered to be adequately supported by the\ndata. The paper concludes with a discussion of some challenges for the future\nof the competition series.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "A First Approach on Modelling Staff Proactiveness in Retail Simulation\n  Models",
        "authors": [
            "Peer-Olaf Siebers",
            "Uwe Aickelin"
        ],
        "summary": "There has been a noticeable shift in the relative composition of the industry\nin the developed countries in recent years; manufacturing is decreasing while\nthe service sector is becoming more important. However, currently most\nsimulation models for investigating service systems are still built in the same\nway as manufacturing simulation models, using a process-oriented world view,\ni.e. they model the flow of passive entities through a system. These kinds of\nmodels allow studying aspects of operational management but are not well suited\nfor studying the dynamics that appear in service systems due to human\nbehaviour. For these kinds of studies we require tools that allow modelling the\nsystem and entities using an object-oriented world view, where intelligent\nobjects serve as abstract \"actors\" that are goal directed and can behave\nproactively. In our work we combine process-oriented discrete event simulation\nmodelling and object-oriented agent based simulation modelling to investigate\nthe impact of people management practices on retail productivity. In this\npaper, we reveal in a series of experiments what impact considering proactivity\ncan have on the output accuracy of simulation models of human centric systems.\nThe model and data we use for this investigation are based on a case study in a\nUK department store. We show that considering proactivity positively influences\nthe validity of these kinds of models and therefore allows analysts to make\nbetter recommendations regarding strategies to apply people management\npractises.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Revisiting Epistemic Specifications",
        "authors": [
            "Miroslaw Truszczynski"
        ],
        "summary": "In 1991, Michael Gelfond introduced the language of epistemic specifications.\nThe goal was to develop tools for modeling problems that require some form of\nmeta-reasoning, that is, reasoning over multiple possible worlds. Despite their\nrelevance to knowledge representation, epistemic specifications have received\nrelatively little attention so far. In this paper, we revisit the formalism of\nepistemic specification. We offer a new definition of the formalism, propose\nseveral semantics (one of which, under syntactic restrictions we assume, turns\nout to be equivalent to the original semantics by Gelfond), derive some\ncomplexity results and, finally, show the effectiveness of the formalism for\nmodeling problems requiring meta-reasoning considered recently by Faber and\nWoltran. All these results show that epistemic specifications deserve much more\nattention that has been afforded to them so far.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Doing Better Than UCT: Rational Monte Carlo Sampling in Trees",
        "authors": [
            "David Tolpin",
            "Solomon Eyal Shimony"
        ],
        "summary": "UCT, a state-of-the art algorithm for Monte Carlo tree sampling (MCTS), is\nbased on UCB, a sampling policy for the Multi-armed Bandit Problem (MAB) that\nminimizes the accumulated regret. However, MCTS differs from MAB in that only\nthe final choice, rather than all arm pulls, brings a reward, that is, the\nsimple regret, as opposite to the cumulative regret, must be minimized. This\nongoing work aims at applying meta-reasoning techniques to MCTS, which is\nnon-trivial. We begin by introducing policies for multi-armed bandits with\nlower simple regret than UCB, and an algorithm for MCTS which combines\ncumulative and simple regret minimization and outperforms UCT. We also develop\na sampling scheme loosely based on a myopic version of perfect value of\ninformation. Finite-time and asymptotic analysis of the policies is provided,\nand the algorithms are compared empirically.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Modelling Mixed Discrete-Continuous Domains for Planning",
        "authors": [
            "M. Fox",
            "D. Long"
        ],
        "summary": "In this paper we present pddl+, a planning domain description language for\nmodelling mixed discrete-continuous planning domains. We describe the syntax\nand modelling style of pddl+, showing that the language makes convenient the\nmodelling of complex time-dependent effects. We provide a formal semantics for\npddl+ by mapping planning instances into constructs of hybrid automata. Using\nthe syntax of HAs as our semantic model we construct a semantic mapping to\nlabelled transition systems to complete the formal interpretation of pddl+\nplanning instances. An advantage of building a mapping from pddl+ to HA theory\nis that it forms a bridge between the Planning and Real Time Systems research\ncommunities. One consequence is that we can expect to make use of some of the\ntheoretical properties of HAs. For example, for a restricted class of HAs the\nReachability problem (which is equivalent to Plan Existence) is decidable.\npddl+ provides an alternative to the continuous durative action model of\npddl2.1, adding a more flexible and robust model of time-dependent behaviour.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Uncertainty in Soft Temporal Constraint Problems:A General Framework and\n  Controllability Algorithms forThe Fuzzy Case",
        "authors": [
            "F. Rossi",
            "K. B. Venable",
            "N. Yorke-Smith"
        ],
        "summary": "In real-life temporal scenarios, uncertainty and preferences are often\nessential and coexisting aspects. We present a formalism where quantitative\ntemporal constraints with both preferences and uncertainty can be defined. We\nshow how three classical notions of controllability (that is, strong, weak, and\ndynamic), which have been developed for uncertain temporal problems, can be\ngeneralized to handle preferences as well. After defining this general\nframework, we focus on problems where preferences follow the fuzzy approach,\nand with properties that assure tractability. For such problems, we propose\nalgorithms to check the presence of the controllability properties. In\nparticular, we show that in such a setting dealing simultaneously with\npreferences and uncertainty does not increase the complexity of controllability\ntesting. We also develop a dynamic execution algorithm, of polynomial\ncomplexity, that produces temporal plans under uncertainty that are optimal\nwith respect to fuzzy preferences.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Embedding Description Logic Programs into Default Logic",
        "authors": [
            "Yisong Wang",
            "Jia-Huai You",
            "Li Yan Yuan",
            "Yi-Dong Shen",
            "Thomas Eiter"
        ],
        "summary": "Description logic programs (dl-programs) under the answer set semantics\nformulated by Eiter {\\em et al.} have been considered as a prominent formalism\nfor integrating rules and ontology knowledge bases. A question of interest has\nbeen whether dl-programs can be captured in a general formalism of nonmonotonic\nlogic. In this paper, we study the possibility of embedding dl-programs into\ndefault logic. We show that dl-programs under the strong and weak answer set\nsemantics can be embedded in default logic by combining two translations, one\nof which eliminates the constraint operator from nonmonotonic dl-atoms and the\nother translates a dl-program into a default theory. For dl-programs without\nnonmonotonic dl-atoms but with the negation-as-failure operator, our embedding\nis polynomial, faithful, and modular. In addition, our default logic encoding\ncan be extended in a simple way to capture recently proposed weakly\nwell-supported answer set semantics, for arbitrary dl-programs. These results\nreinforce the argument that default logic can serve as a fruitful foundation\nfor query-based approaches to integrating ontology and rules. With its simple\nsyntax and intuitive semantics, plus available computational results, default\nlogic can be considered an attractive approach to integration of ontology and\nrules.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Principles of Solomonoff Induction and AIXI",
        "authors": [
            "Peter Sunehag",
            "Marcus Hutter"
        ],
        "summary": "We identify principles characterizing Solomonoff Induction by demands on an\nagent's external behaviour. Key concepts are rationality, computability,\nindifference and time consistency. Furthermore, we discuss extensions to the\nfull AI case to derive AIXI.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Constraint Propagation as Information Maximization",
        "authors": [
            "A. Nait Abdallah",
            "M. H. van Emden"
        ],
        "summary": "This paper draws on diverse areas of computer science to develop a unified\nview of computation:\n  (1) Optimization in operations research, where a numerical objective function\nis maximized under constraints, is generalized from the numerical total order\nto a non-numerical partial order that can be interpreted in terms of\ninformation. (2) Relations are generalized so that there are relations of which\nthe constituent tuples have numerical indexes, whereas in other relations these\nindexes are variables. The distinction is essential in our definition of\nconstraint satisfaction problems. (3) Constraint satisfaction problems are\nformulated in terms of semantics of conjunctions of atomic formulas of\npredicate logic. (4) Approximation structures, which are available for several\nimportant domains, are applied to solutions of constraint satisfaction\nproblems.\n  As application we treat constraint satisfaction problems over reals. These\ncover a large part of numerical analysis, most significantly nonlinear\nequations and inequalities. The chaotic algorithm analyzed in the paper\ncombines the efficiency of floating-point computation with the correctness\nguarantees of arising from our logico-mathematical model of\nconstraint-satisfaction problems.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Lifted Inference for Relational Continuous Models",
        "authors": [
            "Jaesik Choi",
            "Eyal Amir",
            "David J. Hill"
        ],
        "summary": "Relational Continuous Models (RCMs) represent joint probability densities\nover attributes of objects, when the attributes have continuous domains. With\nrelational representations, they can model joint probability distributions over\nlarge numbers of variables compactly in a natural way. This paper presents a\nnew exact lifted inference algorithm for RCMs, thus it scales up to large\nmodels of real world applications. The algorithm applies to Relational Pairwise\nModels which are (relational) products of potentials of arity 2. Our algorithm\nis unique in two ways. First, it substantially improves the efficiency of\nlifted inference with variables of continuous domains. When a relational model\nhas Gaussian potentials, it takes only linear-time compared to cubic time of\nprevious methods. Second, it is the first exact inference algorithm which\nhandles RCMs in a lifted way. The algorithm is illustrated over an example from\neconometrics. Experimental results show that our algorithm outperforms both a\ngroundlevel inference algorithm and an algorithm built with previously-known\nlifted methods.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "A Delayed Column Generation Strategy for Exact k-Bounded MAP Inference\n  in Markov Logic Networks",
        "authors": [
            "Mathias Niepert"
        ],
        "summary": "The paper introduces k-bounded MAP inference, a parameterization of MAP\ninference in Markov logic networks. k-Bounded MAP states are MAP states with at\nmost k active ground atoms of hidden (non-evidence) predicates. We present a\nnovel delayed column generation algorithm and provide empirical evidence that\nthe algorithm efficiently computes k-bounded MAP states for meaningful\nreal-world graph matching problems. The underlying idea is that, instead of\nsolving one large optimization problem, it is often more efficient to tackle\nseveral small ones.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Merging Knowledge Bases in Possibilistic Logic by Lexicographic\n  Aggregation",
        "authors": [
            "Guilin Qi",
            "Jianfeng Du",
            "Weiru Liu",
            "David A. Bell"
        ],
        "summary": "Belief merging is an important but difficult problem in Artificial\nIntelligence, especially when sources of information are pervaded with\nuncertainty. Many merging operators have been proposed to deal with this\nproblem in possibilistic logic, a weighted logic which is powerful for handling\ninconsistency and deal- ing with uncertainty. They often result in a\npossibilistic knowledge base which is a set of weighted formulas. Although\npossibilistic logic is inconsistency tolerant, it suers from the well-known\n\"drowning effect\". Therefore, we may still want to obtain a consistent possi-\nbilistic knowledge base as the result of merg- ing. In such a case, we argue\nthat it is not always necessary to keep weighted informa- tion after merging.\nIn this paper, we define a merging operator that maps a set of pos- sibilistic\nknowledge bases and a formula rep- resenting the integrity constraints to a\nclas- sical knowledge base by using lexicographic ordering. We show that it\nsatisfies nine pos- tulates that generalize basic postulates for propositional\nmerging given in [11]. These postulates capture the principle of minimal change\nin some sense. We then provide an algorithm for generating the resulting knowl-\nedge base of our merging operator. Finally, we discuss the compatibility of our\nmerging operator with propositional merging and es- tablish the advantage of\nour merging opera- tor over existing semantic merging operators in the\npropositional case.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "On how percolation threshold affects PSO performance",
        "authors": [
            "Blanca Cases",
            "Alicia D'Anjou",
            "Abdelmalik Moujahid"
        ],
        "summary": "Statistical evidence of the influence of neighborhood topology on the\nperformance of particle swarm optimization (PSO) algorithms has been shown in\nmany works. However, little has been done about the implications could have the\npercolation threshold in determining the topology of this neighborhood. This\nwork addresses this problem for individuals that, like robots, are able to\nsense in a limited neighborhood around them. Based on the concept of\npercolation threshold, and more precisely, the disk percolation model in 2D, we\nshow that better results are obtained for low values of radius, when\nindividuals occasionally ask others their best visited positions, with the\nconsequent decrease of computational complexity. On the other hand, since\npercolation threshold is a universal measure, it could have a great interest to\ncompare the performance of different hybrid PSO algorithms.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Solution Representations and Local Search for the bi-objective Inventory\n  Routing Problem",
        "authors": [
            "Thibaut Barth\u00e9lemy",
            "Martin Josef Geiger",
            "Marc Sevaux"
        ],
        "summary": "The solution of the biobjective IRP is rather challenging, even for\nmetaheuristics. We are still lacking a profound understanding of appropriate\nsolution representations and effective neighborhood structures. Clearly, both\nthe delivery volumes and the routing aspects of the alternatives need to be\nreflected in an encoding, and must be modified when searching by means of local\nsearch. Our work contributes to the better understanding of such solution\nrepresentations. On the basis of an experimental investigation, the advantages\nand drawbacks of two encodings are studied and compared.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Matroidal structure of generalized rough sets based on symmetric and\n  transitive relations",
        "authors": [
            "Bin Yang",
            "William Zhu"
        ],
        "summary": "Rough sets are efficient for data pre-process in data mining. Lower and upper\napproximations are two core concepts of rough sets. This paper studies\ngeneralized rough sets based on symmetric and transitive relations from the\noperator-oriented view by matroidal approaches. We firstly construct a\nmatroidal structure of generalized rough sets based on symmetric and transitive\nrelations, and provide an approach to study the matroid induced by a symmetric\nand transitive relation. Secondly, this paper establishes a close relationship\nbetween matroids and generalized rough sets. Approximation quality and\nroughness of generalized rough sets can be computed by the circuit of matroid\ntheory. At last, a symmetric and transitive relation can be constructed by a\nmatroid with some special properties.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Introducing Variable Importance Tradeoffs into CP-Nets",
        "authors": [
            "Ronen I. Brafman",
            "Carmel Domshlak"
        ],
        "summary": "The ability to make decisions and to assess potential courses of action is a\ncorner-stone of many AI applications, and usually this requires explicit\ninformation about the decision-maker s preferences. IN many applications,\npreference elicitation IS a serious bottleneck.The USER either does NOT have\nthe time, the knowledge, OR the expert support required TO specify complex\nmulti - attribute utility functions. IN such cases, a method that IS based ON\nintuitive, yet expressive, preference statements IS required. IN this paper we\nsuggest the USE OF TCP - nets, an enhancement OF CP - nets, AS a tool FOR\nrepresenting, AND reasoning about qualitative preference statements.We present\nAND motivate this framework, define its semantics, AND show how it can be used\nTO perform constrained optimization.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Value Function Approximation in Zero-Sum Markov Games",
        "authors": [
            "Michail Lagoudakis",
            "Ron Parr"
        ],
        "summary": "This paper investigates value function approximation in the context of\nzero-sum Markov games, which can be viewed as a generalization of the Markov\ndecision process (MDP) framework to the two-agent case. We generalize error\nbounds from MDPs to Markov games and describe generalizations of reinforcement\nlearning algorithms to Markov games. We present a generalization of the optimal\nstopping problem to a two-player simultaneous move Markov game. For this\nspecial problem, we provide stronger bounds and can guarantee convergence for\nLSTD and temporal difference learning with linear value function approximation.\nWe demonstrate the viability of value function approximation for Markov games\nby using the Least squares policy iteration (LSPI) algorithm to learn good\npolicies for a soccer domain and a flow control problem.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "On the Testable Implications of Causal Models with Hidden Variables",
        "authors": [
            "Jin Tian",
            "Judea Pearl"
        ],
        "summary": "The validity OF a causal model can be tested ONLY IF the model imposes\nconstraints ON the probability distribution that governs the generated data. IN\nthe presence OF unmeasured variables, causal models may impose two types OF\nconstraints : conditional independencies, AS READ through the d - separation\ncriterion, AND functional constraints, FOR which no general criterion IS\navailable.This paper offers a systematic way OF identifying functional\nconstraints AND, thus, facilitates the task OF testing causal models AS well AS\ninferring such models FROM data.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Translating NP-SPEC into ASP",
        "authors": [
            "Mario Alviano",
            "Wolfgang Faber"
        ],
        "summary": "NP-SPEC is a language for specifying problems in NP in a declarative way.\nDespite the fact that the semantics of the language was given by referring to\nDatalog with circumscription, which is very close to ASP, so far the only\nexisting implementations are by means of ECLiPSe Prolog and via Boolean\nsatisfiability solvers. In this paper, we present translations from NP-SPEC\ninto various forms of ASP and analyze them. We also argue that it might be\nuseful to incorporate certain language constructs of NP-SPEC into mainstream\nASP.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "A Forgetting-based Approach to Merging Knowledge Bases",
        "authors": [
            "Dai Xu",
            "Xiaowang Zhang",
            "Zuoquan Lin"
        ],
        "summary": "This paper presents a novel approach based on variable forgetting, which is a\nuseful tool in resolving contradictory by filtering some given variables, to\nmerging multiple knowledge bases. This paper first builds a relationship\nbetween belief merging and variable forgetting by using dilation. Variable\nforgetting is applied to capture belief merging operation. Finally, some new\nmerging operators are developed by modifying candidate variables to amend the\nshortage of traditional merging operators. Different from model selection of\ntraditional merging operators, as an alternative approach, variable selection\nin those new operators could provide intuitive information about an atom\nvariable among whole knowledge bases.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Enumerating Markov Equivalence Classes of Acyclic Digraph Models",
        "authors": [
            "Steven B. Gillispie",
            "Michael D. Perlman"
        ],
        "summary": "Graphical Markov models determined by acyclic digraphs (ADGs), also called\ndirected acyclic graphs (DAGs), are widely studied in statistics, computer\nscience (as Bayesian networks), operations research (as influence diagrams),\nand many related fields. Because different ADGs may determine the same Markov\nequivalence class, it long has been of interest to determine the efficiency\ngained in model specification and search by working directly with Markov\nequivalence classes of ADGs rather than with ADGs themselves. A computer\nprogram was written to enumerate the equivalence classes of ADG models as\nspecified by Pearl & Verma's equivalence criterion. The program counted\nequivalence classes for models up to and including 10 vertices. The ratio of\nnumber of classes to ADGs appears to approach an asymptote of about 0.267.\nClasses were analyzed according to number of edges and class size. By edges,\nthe distribution of number of classes approaches a Gaussian shape. By class\nsize, classes of size 1 are most common, with the proportions for larger sizes\ninitially decreasing but then following a more irregular pattern. The maximum\nnumber of classes generated by any undirected graph was found to increase\napproximately factorially. The program also includes a new variation of orderly\nalgorithm for generating undirected graphs.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Inference in Hybrid Networks: Theoretical Limits and Practical\n  Algorithms",
        "authors": [
            "Uri Lerner",
            "Ron Parr"
        ],
        "summary": "An important subclass of hybrid Bayesian networks are those that represent\nConditional Linear Gaussian (CLG) distributions --- a distribution with a\nmultivariate Gaussian component for each instantiation of the discrete\nvariables. In this paper we explore the problem of inference in CLGs. We show\nthat inference in CLGs can be significantly harder than inference in Bayes\nNets. In particular, we prove that even if the CLG is restricted to an\nextremely simple structure of a polytree in which every continuous node has at\nmost one discrete ancestor, the inference task is NP-hard.To deal with the\noften prohibitive computational cost of the exact inference algorithm for CLGs,\nwe explore several approximate inference algorithms. These algorithms try to\nfind a small subset of Gaussians which are a good approximation to the full\nmixture distribution. We consider two Monte Carlo approaches and a novel\napproach that enumerates mixture components in order of prior probability. We\ncompare these methods on a variety of problems and show that our novel\nalgorithm is very promising for large, hybrid diagnosis problems.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Vector-space Analysis of Belief-state Approximation for POMDPs",
        "authors": [
            "Pascal Poupart",
            "Craig Boutilier"
        ],
        "summary": "We propose a new approach to value-directed belief state approximation for\nPOMDPs. The value-directed model allows one to choose approximation methods for\nbelief state monitoring that have a small impact on decision quality. Using a\nvector space analysis of the problem, we devise two new search procedures for\nselecting an approximation scheme that have much better computational\nproperties than existing methods. Though these provide looser error bounds, we\nshow empirically that they have a similar impact on decision quality in\npractice, and run up to two orders of magnitude more quickly.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Causal Discovery from Changes",
        "authors": [
            "Jin Tian",
            "Judea Pearl"
        ],
        "summary": "We propose a new method of discovering causal structures, based on the\ndetection of local, spontaneous changes in the underlying data-generating\nmodel. We analyze the classes of structures that are equivalent relative to a\nstream of distributions produced by local changes, and devise algorithms that\noutput graphical representations of these equivalence classes. We present\nexperimental results, using simulated data, and examine the errors associated\nwith detection of changes and recovery of structures.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "A Complete Calculus for Possibilistic Logic Programming with Fuzzy\n  Propositional Variables",
        "authors": [
            "Teresa Alsinet",
            "Lluis Godo"
        ],
        "summary": "In this paper we present a propositional logic programming language for\nreasoning under possibilistic uncertainty and representing vague knowledge.\nFormulas are represented by pairs (A, c), where A is a many-valued proposition\nand c is value in the unit interval [0,1] which denotes a lower bound on the\nbelief on A in terms of necessity measures. Belief states are modeled by\npossibility distributions on the set of all many-valued interpretations. In\nthis framework, (i) we define a syntax and a semantics of the general\nunderlying uncertainty logic; (ii) we provide a modus ponens-style calculus for\na sublanguage of Horn-rules and we prove that it is complete for determining\nthe maximum degree of possibilistic belief with which a fuzzy propositional\nvariable can be entailed from a set of formulas; and finally, (iii) we show how\nthe computation of a partial matching between fuzzy propositional variables, in\nterms of necessity measures for fuzzy sets, can be included in our logic\nprogramming system.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Approximately Optimal Monitoring of Plan Preconditions",
        "authors": [
            "Craig Boutilier"
        ],
        "summary": "Monitoring plan preconditions can allow for replanning when a precondition\nfails, generally far in advance of the point in the plan where the precondition\nis relevant. However, monitoring is generally costly, and some precondition\nfailures have a very small impact on plan quality. We formulate a model for\noptimal precondition monitoring, using partially-observable Markov decisions\nprocesses, and describe methods for solving this model efficitively, though\napproximately. Specifically, we show that the single-precondition monitoring\nproblem is generally tractable, and the multiple-precondition monitoring\npolicies can be efficitively approximated using single-precondition soultions.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Separation Properties of Sets of Probability Measures",
        "authors": [
            "Fabio Gagliardi Cozman"
        ],
        "summary": "This paper analyzes independence concepts for sets of probability measures\nassociated with directed acyclic graphs. The paper shows that epistemic\nindependence and the standard Markov condition violate desirable separation\nproperties. The adoption of a contraction condition leads to d-separation but\nstill fails to guarantee a belief separation property. To overcome this\nunsatisfactory situation, a strong Markov condition is proposed, based on\nepistemic independence. The main result is that the strong Markov condition\nleads to strong independence and does enforce separation properties; this\nresult implies that (1) separation properties of Bayesian networks do extend to\nepistemic independence and sets of probability measures, and (2) strong\nindependence has a clear justification based on epistemic independence and the\nstrong Markov condition.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "A Differential Approach to Inference in Bayesian Networks",
        "authors": [
            "Adnan Darwiche"
        ],
        "summary": "We present a new approach for inference in Bayesian networks, which is mainly\nbased on partial differentiation. According to this approach, one compiles a\nBayesian network into a multivariate polynomial and then computes the partial\nderivatives of this polynomial with respect to each variable. We show that once\nsuch derivatives are made available, one can compute in constant-time answers\nto a large class of probabilistic queries, which are central to classical\ninference, parameter estimation, model validation and sensitivity analysis. We\npresent a number of complexity results relating to the compilation of such\npolynomials and to the computation of their partial derivatives. We argue that\nthe combined simplicity, comprehensiveness and computational complexity of the\npresented framework is unique among existing frameworks for inference in\nBayesian networks.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Any-Space Probabilistic Inference",
        "authors": [
            "Adnan Darwiche"
        ],
        "summary": "We have recently introduced an any-space algorithm for exact inference in\nBayesian networks, called Recursive Conditioning, RC, which allows one to trade\nspace with time at increments of X-bytes, where X is the number of bytes needed\nto cache a floating point number. In this paper, we present three key\nextensions of RC. First, we modify the algorithm so it applies to more general\nfactorization of probability distributions, including (but not limited to)\nBayesian network factorizations. Second, we present a forgetting mechanism\nwhich reduces the space requirements of RC considerably and then compare such\nrequirmenets with those of variable elimination on a number of realistic\nnetworks, showing orders of magnitude improvements in certain cases. Third, we\npresent a version of RC for computing maximum a posteriori hypotheses (MAP),\nwhich turns out to be the first MAP algorithm allowing a smooth time-space\ntradeoff. A key advantage of presented MAP algorithm is that it does not have\nto start from scratch each time a new query is presented, but can reuse some of\nits computations across multiple queries, leading to significant savings in\nceratain cases.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Maximum Entropy and the Glasses You Are Looking Through",
        "authors": [
            "Peter D. Grunwald"
        ],
        "summary": "We give an interpretation of the Maximum Entropy (MaxEnt) Principle in\ngame-theoretic terms. Based on this interpretation, we make a formal\ndistinction between different ways of {em applying/} Maximum Entropy\ndistributions. MaxEnt has frequently been criticized on the grounds that it\nleads to highly representation dependent results. Our distinction allows us to\navoid this problem in many cases.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Making Sensitivity Analysis Computationally Efficient",
        "authors": [
            "Uffe Kj\u00e6rulff",
            "Linda C. van der Gaag"
        ],
        "summary": "To investigate the robustness of the output probabilities of a Bayesian\nnetwork, a sensitivity analysis can be performed. A one-way sensitivity\nanalysis establishes, for each of the probability parameters of a network, a\nfunction expressing a posterior marginal probability of interest in terms of\nthe parameter. Current methods for computing the coefficients in such a\nfunction rely on a large number of network evaluations. In this paper, we\npresent a method that requires just a single outward propagation in a junction\ntree for establishing the coefficients in the functions for all possible\nparameters; in addition, an inward propagation is required for processing\nevidence. Conversely, the method requires a single outward propagation for\ncomputing the coefficients in the functions expressing all possible posterior\nmarginals in terms of a single parameter. We extend these results to an n-way\nsensitivity analysis in which sets of parameters are studied.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Policy Iteration for Factored MDPs",
        "authors": [
            "Daphne Koller",
            "Ron Parr"
        ],
        "summary": "Many large MDPs can be represented compactly using a dynamic Bayesian\nnetwork. Although the structure of the value function does not retain the\nstructure of the process, recent work has shown that value functions in\nfactored MDPs can often be approximated well using a decomposed value function:\na linear combination of <I>restricted</I> basis functions, each of which refers\nonly to a small subset of variables. An approximate value function for a\nparticular policy can be computed using approximate dynamic programming, but\nthis approach (and others) can only produce an approximation relative to a\ndistance metric which is weighted by the stationary distribution of the current\npolicy. This type of weighted projection is ill-suited to policy improvement.\nWe present a new approach to value determination, that uses a simple\nclosed-form computation to directly compute a least-squares decomposed\napproximation to the value function <I>for any weights</I>. We then use this\nvalue determination algorithm as a subroutine in a policy iteration process. We\nshow that, under reasonable restrictions, the policies induced by a factored\nvalue function are compactly represented, and can be manipulated efficiently in\na policy iteration process. We also present a method for computing error bounds\nfor decomposed value functions using a variable-elimination algorithm for\nfunction optimization. The complexity of all of our algorithms depends on the\nfactorization of system dynamics and of the approximate value function.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Representing and Solving Asymmetric Bayesian Decision Problems",
        "authors": [
            "Thomas D. Nielsen",
            "Finn Verner Jensen"
        ],
        "summary": "This paper deals with the representation and solution of asymmetric Bayesian\ndecision problems. We present a formal framework, termed asymmetric influence\ndiagrams, that is based on the influence diagram and allows an efficient\nrepresentation of asymmetric decision problems. As opposed to existing\nframeworks, the asymmetric influece diagram primarily encodes asymmetry at the\nqualitative level and it can therefore be read directly from the model. We give\nan algorithm for solving asymmetric influence diagrams. The algorithm initially\ndecomposes the asymmetric decision problem into a structure of symmetric\nsubproblems organized as a tree. A solution to the decision problem can then be\nfound by propagating from the leaves toward the root using existing evaluation\nmethods to solve the sub-problems.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Using ROBDDs for Inference in Bayesian Networks with Troubleshooting as\n  an Example",
        "authors": [
            "Thomas D. Nielsen",
            "Pierre-Henri Wuillemin",
            "Finn Verner Jensen",
            "Uffe Kj\u00e6rulff"
        ],
        "summary": "When using Bayesian networks for modelling the behavior of man-made\nmachinery, it usually happens that a large part of the model is deterministic.\nFor such Bayesian networks deterministic part of the model can be represented\nas a Boolean function, and a central part of belief updating reduces to the\ntask of calculating the number of satisfying configurations in a Boolean\nfunction. In this paper we explore how advances in the calculation of Boolean\nfunctions can be adopted for belief updating, in particular within the context\nof troubleshooting. We present experimental results indicating a substantial\nspeed-up compared to traditional junction tree propagation.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Value-Directed Belief State Approximation for POMDPs",
        "authors": [
            "Pascal Poupart",
            "Craig Boutilier"
        ],
        "summary": "We consider the problem belief-state monitoring for the purposes of\nimplementing a policy for a partially-observable Markov decision process\n(POMDP), specifically how one might approximate the belief state. Other schemes\nfor belief-state approximation (e.g., based on minimixing a measures such as\nKL-diveregence between the true and estimated state) are not necessarily\nappropriate for POMDPs. Instead we propose a framework for analyzing\nvalue-directed approximation schemes, where approximation quality is determined\nby the expected error in utility rather than by the error in the belief state\nitself. We propose heuristic methods for finding good projection schemes for\nbelief state estimation - exhibiting anytime characteristics - given a POMDP\nvalue fucntion. We also describe several algorithms for constructing bounds on\nthe error in decision quality (expected utility) associated with acting in\naccordance with a given belief state approximation.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Probabilities of Causation: Bounds and Identification",
        "authors": [
            "Jin Tian",
            "Judea Pearl"
        ],
        "summary": "This paper deals with the problem of estimating the probability that one\nevent was a cause of another in a given scenario. Using structural-semantical\ndefinitions of the probabilities of necessary or sufficient causation (or\nboth), we show how to optimally bound these quantities from data obtained in\nexperimental and observational studies, making minimal assumptions concerning\nthe data-generating process. In particular, we strengthen the results of Pearl\n(1999) by weakening the data-generation assumptions and deriving theoretically\nsharp bounds on the probabilities of causation. These results delineate\nprecisely how empirical data can be used both in settling questions of\nattribution and in solving attribution-related problems of decision making.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Proceedings of the Eighteenth Conference on Uncertainty in Artificial\n  Intelligence (2002)",
        "authors": [
            "Adnan Darwiche",
            "Nir Friedman"
        ],
        "summary": "This is the Proceedings of the Eighteenth Conference on Uncertainty in\nArtificial Intelligence, which was held in Alberta, Canada, August 1-4 2002",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Mini-Bucket Heuristics for Improved Search",
        "authors": [
            "Kalev Kask",
            "Rina Dechter"
        ],
        "summary": "The paper is a second in a series of two papers evaluating the power of a new\nscheme that generates search heuristics mechanically. The heuristics are\nextracted from an approximation scheme called mini-bucket elimination that was\nrecently introduced. The first paper introduced the idea and evaluated it\nwithin Branch-and-Bound search. In the current paper the idea is further\nextended and evaluated within Best-First search. The resulting algorithms are\ncompared on coding and medical diagnosis problems, using varying strength of\nthe mini-bucket heuristics.\n  Our results demonstrate an effective search scheme that permits controlled\ntradeoff between preprocessing (for heuristic generation) and search.\nBest-first search is shown to outperform Branch-and-Bound, when supplied with\ngood heuristics, and sufficient memory space.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "A General Algorithm for Approximate Inference and its Application to\n  Hybrid Bayes Nets",
        "authors": [
            "Daphne Koller",
            "Uri Lerner",
            "Dragomir Anguelov"
        ],
        "summary": "The clique tree algorithm is the standard method for doing inference in\nBayesian networks. It works by manipulating clique potentials - distributions\nover the variables in a clique. While this approach works well for many\nnetworks, it is limited by the need to maintain an exact representation of the\nclique potentials. This paper presents a new unified approach that combines\napproximate inference and the clique tree algorithm, thereby circumventing this\nlimitation. Many known approximate inference algorithms can be viewed as\ninstances of this approach. The algorithm essentially does clique tree\npropagation, using approximate inference to estimate the densities in each\nclique. In many settings, the computation of the approximate clique potential\ncan be done easily using statistical importance sampling. Iterations are used\nto gradually improve the quality of the estimation.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Welldefined Decision Scenarios",
        "authors": [
            "Thomas D. Nielsen",
            "Finn Verner Jensen"
        ],
        "summary": "Influence diagrams serve as a powerful tool for modelling symmetric decision\nproblems. When solving an influence diagram we determine a set of strategies\nfor the decisions involved. A strategy for a decision variable is in principle\na function over its past. However, some of the past may be irrelevant for the\ndecision, and for computational reasons it is important not to deal with\nredundant variables in the strategies. We show that current methods (e.g. the\n\"Decision Bayes-ball\" algorithm by Shachter UAI98) do not determine the\nrelevant past, and we present a complete algorithm.\n  Actually, this paper takes a more general outset: When formulating a decision\nscenario as an influence diagram, a linear temporal ordering of the decisions\nvariables is required. This constraint ensures that the decision scenario is\nwelldefined. However, the structure of a decision scenario often yields certain\ndecisions conditionally independent, and it is therefore unnecessary to impose\na linear temporal ordering on the decisions. In this paper we deal with partial\ninfluence diagrams i.e. influence diagrams with only a partial temporal\nordering specified. We present a set of conditions which are necessary and\nsufficient to ensure that a partial influence diagram is welldefined. These\nconditions are used as a basis for the construction of an algorithm for\ndetermining whether or not a partial influence diagram is welldefined.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Efficient Value of Information Computation",
        "authors": [
            "Ross D. Shachter"
        ],
        "summary": "One of the most useful sensitivity analysis techniques of decision analysis\nis the computation of value of information (or clairvoyance), the difference in\nvalue obtained by changing the decisions by which some of the uncertainties are\nobserved. In this paper, some simple but powerful extensions to previous\nalgorithms are introduced which allow an efficient value of information\ncalculation on the rooted cluster tree (or strong junction tree) used to solve\nthe original decision problem.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Practical Uses of Belief Functions",
        "authors": [
            "Philippe Smets"
        ],
        "summary": "We present examples where the use of belief functions provided sound and\nelegant solutions to real life problems. These are essentially characterized by\n?missing' information. The examples deal with 1) discriminant analysis using a\nlearning set where classes are only partially known; 2) an information\nretrieval systems handling inter-documents relationships; 3) the combination of\ndata from sensors competent on partially overlapping frames; 4) the\ndetermination of the number of sources in a multi-sensor environment by\nstudying the inter-sensors contradiction. The purpose of the paper is to report\non such applications where the use of belief functions provides a convenient\ntool to handle ?messy' data problems.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Irrelevance and Independence Relations in Quasi-Bayesian Networks",
        "authors": [
            "Fabio Gagliardi Cozman"
        ],
        "summary": "This paper analyzes irrelevance and independence relations in graphical\nmodels associated with convex sets of probability distributions (called\nQuasi-Bayesian networks). The basic question in Quasi-Bayesian networks is, How\ncan irrelevance/independence relations in Quasi-Bayesian networks be detected,\nenforced and exploited? This paper addresses these questions through Walley's\ndefinitions of irrelevance and independence. Novel algorithms and results are\npresented for inferences with the so-called natural extensions using fractional\nlinear programming, and the properties of the so-called type-1 extensions are\nclarified through a new generalization of d-separation.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Dynamic Jointrees",
        "authors": [
            "Adnan Darwiche"
        ],
        "summary": "It is well known that one can ignore parts of a belief network when computing\nanswers to certain probabilistic queries. It is also well known that the\nignorable parts (if any) depend on the specific query of interest and,\ntherefore, may change as the query changes. Algorithms based on jointrees,\nhowever, do not seem to take computational advantage of these facts given that\nthey typically construct jointrees for worst-case queries; that is, queries for\nwhich every part of the belief network is considered relevant. To address this\nlimitation, we propose in this paper a method for reconfiguring jointrees\ndynamically as the query changes. The reconfiguration process aims at\nmaintaining a jointree which corresponds to the underlying belief network after\nit has been pruned given the current query. Our reconfiguration method is\nmarked by three characteristics: (a) it is based on a non-classical definition\nof jointrees; (b) it is relatively efficient; and (c) it can reuse some of the\ncomputations performed before a jointree is reconfigured. We present\npreliminary experimental results which demonstrate significant savings over\nusing static jointrees when query changes are considerable.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Flexible Decomposition Algorithms for Weakly Coupled Markov Decision\n  Problems",
        "authors": [
            "Ron Parr"
        ],
        "summary": "This paper presents two new approaches to decomposing and solving large\nMarkov decision problems (MDPs), a partial decoupling method and a complete\ndecoupling method. In these approaches, a large, stochastic decision problem is\ndivided into smaller pieces. The first approach builds a cache of policies for\neach part of the problem independently, and then combines the pieces in a\nseparate, light-weight step. A second approach also divides the problem into\nsmaller pieces, but information is communicated between the different problem\npieces, allowing intelligent decisions to be made about which piece requires\nthe most attention. Both approaches can be used to find optimal policies or\napproximately optimal policies with provable bounds. These algorithms also\nprovide a framework for the efficient transfer of knowledge across problems\nthat share similar structure.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Empirical Evaluation of Approximation Algorithms for Probabilistic\n  Decoding",
        "authors": [
            "Irina Rish",
            "Kalev Kask",
            "Rina Dechter"
        ],
        "summary": "It was recently shown that the problem of decoding messages transmitted\nthrough a noisy channel can be formulated as a belief updating task over a\nprobabilistic network [McEliece]. Moreover, it was observed that iterative\napplication of the (linear time) Pearl's belief propagation algorithm designed\nfor polytrees outperformed state of the art decoding algorithms, even though\nthe corresponding networks may have many cycles. This paper demonstrates\nempirically that an approximation algorithm approx-mpe for solving the most\nprobable explanation (MPE) problem, developed within the recently proposed\nmini-bucket elimination framework [Dechter96], outperforms iterative belief\npropagation on classes of coding networks that have bounded induced width. Our\nexperiments suggest that approximate MPE decoders can be good competitors to\nthe approximate belief updating decoders.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Bayes-Ball: The Rational Pastime (for Determining Irrelevance and\n  Requisite Information in Belief Networks and Influence Diagrams)",
        "authors": [
            "Ross D. Shachter"
        ],
        "summary": "One of the benefits of belief networks and influence diagrams is that so much\nknowledge is captured in the graphical structure. In particular, statements of\nconditional irrelevance (or independence) can be verified in time linear in the\nsize of the graph. To resolve a particular inference query or decision problem,\nonly some of the possible states and probability distributions must be\nspecified, the \"requisite information.\"\n  This paper presents a new, simple, and efficient \"Bayes-ball\" algorithm which\nis well-suited to both new students of belief networks and state of the art\nimplementations. The Bayes-ball algorithm determines irrelevant sets and\nrequisite information more efficiently than existing methods, and is linear in\nthe size of the graph for belief networks and influence diagrams.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Flexible and Approximate Computation through State-Space Reduction",
        "authors": [
            "Weixiong Zhang"
        ],
        "summary": "In the real world, insufficient information, limited computation resources,\nand complex problem structures often force an autonomous agent to make a\ndecision in time less than that required to solve the problem at hand\ncompletely. Flexible and approximate computations are two approaches to\ndecision making under limited computation resources. Flexible computation helps\nan agent to flexibly allocate limited computation resources so that the overall\nsystem utility is maximized. Approximate computation enables an agent to find\nthe best satisfactory solution within a deadline. In this paper, we present two\nstate-space reduction methods for flexible and approximate computation:\nquantitative reduction to deal with inaccurate heuristic information, and\nstructural reduction to handle complex problem structures. These two methods\ncan be applied successively to continuously improve solution quality if more\ncomputation is available. Our results show that these reduction methods are\neffective and efficient, finding better solutions with less computation than\nsome existing well-known methods.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Managing Uncertainty in Rule Based Cognitive Models",
        "authors": [
            "Thomas R. Shultz"
        ],
        "summary": "An experiment replicated and extended recent findings on psychologically\nrealistic ways of modeling propagation of uncertainty in rule based reasoning.\nWithin a single production rule, the antecedent evidence can be summarized by\ntaking the maximum of disjunctively connected antecedents and the minimum of\nconjunctively connected antecedents. The maximum certainty factor attached to\neach of the rule's conclusions can be sealed down by multiplication with this\nsummarized antecedent certainty. Heckerman's modified certainty factor\ntechnique can be used to combine certainties for common conclusions across\nproduction rules.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Similarity Networks for the Construction of Multiple-Faults Belief\n  Networks",
        "authors": [
            "David Heckerman"
        ],
        "summary": "A similarity network is a tool for constructing belief networks for the\ndiagnosis of a single fault. In this paper, we examine modifications to the\nsimilarity-network representation that facilitate the construction of belief\nnetworks for the diagnosis of multiple coexisting faults.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Problem Formulation as the Reduction of a Decision Model",
        "authors": [
            "David Heckerman",
            "Eric J. Horvitz"
        ],
        "summary": "In this paper, we extend the QMRDT probabilistic model for the domain of\ninternal medicine to include decisions about treatments. In addition, we\ndescribe how we can use the comprehensive decision model to construct a simpler\ndecision model for a specific patient. In so doing, we transform the task of\nproblem formulation to that of narrowing of a larger problem.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Credibility Discounting in the Theory of Approximate Reasoning",
        "authors": [
            "Ronald R. Yager"
        ],
        "summary": "We are concerned with the problem of introducing credibility type information\ninto reasoning systems. The concept of credibility allows us to discount\ninformation provided by agents. An important characteristic of this kind of\nprocedure is that a complete lack of credibility rather than resulting in the\nnegation of the information provided results in the nullification of the\ninformation provided. We suggest a representational scheme for credibility\nqualification in the theory of approximate reasoning. We discuss the concept of\nrelative credibility. By this idea we mean to indicate situations in which the\ncredibility of a piece of evidence is determined by its compatibility with\nhigher priority evidence. This situation leads to structures very much in the\nspirit of nonmonotonic reasoning.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "The Transferable Belief Model and Other Interpretations of\n  Dempster-Shafer's Model",
        "authors": [
            "Philippe Smets"
        ],
        "summary": "Dempster-Shafer's model aims at quantifying degrees of belief But there are\nso many interpretations of Dempster-Shafer's theory in the literature that it\nseems useful to present the various contenders in order to clarify their\nrespective positions. We shall successively consider the classical probability\nmodel, the upper and lower probabilities model, Dempster's model, the\ntransferable belief model, the evidentiary value model, the provability or\nnecessity model. None of these models has received the qualification of\nDempster-Shafer. In fact the transferable belief model is our interpretation\nnot of Dempster's work but of Shafer's work as presented in his book (Shafer\n1976, Smets 1988). It is a ?purified' form of Dempster-Shafer's model in which\nany connection with probability concept has been deleted. Any model for belief\nhas at least two components: one static that describes our state of belief, the\nother dynamic that explains how to update our belief given new pieces of\ninformation. We insist on the fact that both components must be considered in\norder to study these models. Too many authors restrict themselves to the static\ncomponent and conclude that Dempster-Shafer theory is the same as some other\ntheory. But once the dynamic component is considered, these conclusions break\ndown. Any comparison based only on the static component is too restricted. The\ndynamic component must also be considered as the originality of the models\nbased on belief functions lies in its dynamic component.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "A Probabilistic Reasoning Environment",
        "authors": [
            "Kathryn Blackmond Laskey"
        ],
        "summary": "A framework is presented for a computational theory of probabilistic\nargument. The Probabilistic Reasoning Environment encodes knowledge at three\nlevels. At the deepest level are a set of schemata encoding the system's domain\nknowledge. This knowledge is used to build a set of second-level arguments,\nwhich are structured for efficient recapture of the knowledge used to construct\nthem. Finally, at the top level is a Bayesian network constructed from the\narguments. The system is designed to facilitate not just propagation of beliefs\nand assimilation of evidence, but also the dynamic process of constructing a\nbelief network, evaluating its adequacy, and revising it when necessary.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Fine-Grained Decision-Theoretic Search Control",
        "authors": [
            "Stuart Russell"
        ],
        "summary": "Decision-theoretic control of search has previously used as its basic unit.\nof computation the generation and evaluation of a complete set of successors.\nAlthough this simplifies analysis, it results in some lost opportunities for\npruning and satisficing. This paper therefore extends the analysis of the value\nof computation to cover individual successor evaluations. The analytic\ntechniques used may prove useful for control of reasoning in more general\nsettings. A formula is developed for the expected value of a node, k of whose n\nsuccessors have been evaluated. This formula is used to estimate the value of\nexpanding further successors, using a general formula for the value of a\ncomputation in game-playing developed in earlier work. We exhibit an improved\nversion of the MGSS* algorithm, giving empirical results for the game of\nOthello.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Computing Probability Intervals Under Independency Constraints",
        "authors": [
            "Linda C. van der Gaag"
        ],
        "summary": "Many AI researchers argue that probability theory is only capable of dealing\nwith uncertainty in situations where a full specification of a joint\nprobability distribution is available, and conclude that it is not suitable for\napplication in knowledge-based systems. Probability intervals, however,\nconstitute a means for expressing incompleteness of information. We present a\nmethod for computing such probability intervals for probabilities of interest\nfrom a partial specification of a joint probability distribution. Our method\nimproves on earlier approaches by allowing for independency relationships\nbetween statistical variables to be exploited.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Deciding Consistency of Databases Containing Defeasible and Strict\n  Information",
        "authors": [
            "Moises Goldszmidt",
            "Judea Pearl"
        ],
        "summary": "We propose a norm of consistency for a mixed set of defeasible and strict\nsentences, based on a probabilistic semantics. This norm establishes a clear\ndistinction between knowledge bases depicting exceptions and those containing\noutright contradictions. We then define a notion of entailment based also on\nprobabilistic considerations and provide a characterization of the relation\nbetween consistency and entailment. We derive necessary and sufficient\nconditions for consistency, and provide a simple decision procedure for testing\nconsistency and deciding whether a sentence is entailed by a database. Finally,\nit is shown that if al1 sentences are Horn clauses, consistency and entailment\ncan be tested in polynomial time.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "A Tractable Inference Algorithm for Diagnosing Multiple Diseases",
        "authors": [
            "David Heckerman"
        ],
        "summary": "We examine a probabilistic model for the diagnosis of multiple diseases. In\nthe model, diseases and findings are represented as binary variables. Also,\ndiseases are marginally independent, features are conditionally independent\ngiven disease instances, and diseases interact to produce findings via a noisy\nOR-gate. An algorithm for computing the posterior probability of each disease,\ngiven a set of observed findings, called quickscore, is presented. The time\ncomplexity of the algorithm is O(nm-2m+), where n is the number of diseases, m+\nis the number of positive findings and m- is the number of negative findings.\nAlthough the time complexity of quickscore i5 exponential in the number of\npositive findings, the algorithm is useful in practice because the number of\nobserved positive findings is usually far less than the number of diseases\nunder consideration. Performance results for quickscore applied to a\nprobabilistic version of Quick Medical Reference (QMR) are provided.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Evidence Absorption and Propagation through Evidence Reversals",
        "authors": [
            "Ross D. Shachter"
        ],
        "summary": "The arc reversal/node reduction approach to probabilistic inference is\nextended to include the case of instantiated evidence by an operation called\n\"evidence reversal.\" This not only provides a technique for computing posterior\njoint distributions on general belief networks, but also provides insight into\nthe methods of Pearl [1986b] and Lauritzen and Spiegelhalter [1988]. Although\nit is well understood that the latter two algorithms are closely related, in\nfact all three algorithms are identical whenever the belief network is a\nforest.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Decision under Uncertainty",
        "authors": [
            "Philippe Smets"
        ],
        "summary": "We derive axiomatically the probability function that should be used to make\ndecisions given any form of underlying uncertainty.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Normalization and the Representation of Nonmonotonic Knowledge in the\n  Theory of Evidence",
        "authors": [
            "Ronald R. Yager"
        ],
        "summary": "We discuss the Dempster-Shafer theory of evidence. We introduce a concept of\nmonotonicity which is related to the diminution of the range between belief and\nplausibility. We show that the accumulation of knowledge in this framework\nexhibits a nonmonotonic property. We show how the belief structure can be used\nto represent typical or commonsense knowledge.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Probability Aggregates in Probability Answer Set Programming",
        "authors": [
            "Emad Saad"
        ],
        "summary": "Probability answer set programming is a declarative programming that has been\nshown effective for representing and reasoning about a variety of probability\nreasoning tasks. However, the lack of probability aggregates, e.g. {\\em\nexpected values}, in the language of disjunctive hybrid probability logic\nprograms (DHPP) disallows the natural and concise representation of many\ninteresting problems. In this paper, we extend DHPP to allow arbitrary\nprobability aggregates. We introduce two types of probability aggregates; a\ntype that computes the expected value of a classical aggregate, e.g., the\nexpected value of the minimum, and a type that computes the probability of a\nclassical aggregate, e.g, the probability of sum of values. In addition, we\ndefine a probability answer set semantics for DHPP with arbitrary probability\naggregates including monotone, antimonotone, and nonmonotone probability\naggregates. We show that the proposed probability answer set semantics of DHPP\nsubsumes both the original probability answer set semantics of DHPP and the\nclassical answer set semantics of classical disjunctive logic programs with\nclassical aggregates, and consequently subsumes the classical answer set\nsemantics of the original disjunctive logic programs. We show that the proposed\nprobability answer sets of DHPP with probability aggregates are minimal\nprobability models and hence incomparable, which is an important property for\nnonmonotonic probability reasoning.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Fuzzy Aggregates in Fuzzy Answer Set Programming",
        "authors": [
            "Emad Saad"
        ],
        "summary": "Fuzzy answer set programming is a declarative framework for representing and\nreasoning about knowledge in fuzzy environments. However, the unavailability of\nfuzzy aggregates in disjunctive fuzzy logic programs, DFLP, with fuzzy answer\nset semantics prohibits the natural and concise representation of many\ninteresting problems. In this paper, we extend DFLP to allow arbitrary fuzzy\naggregates. We define fuzzy answer set semantics for DFLP with arbitrary fuzzy\naggregates including monotone, antimonotone, and nonmonotone fuzzy aggregates.\nWe show that the proposed fuzzy answer set semantics subsumes both the original\nfuzzy answer set semantics of DFLP and the classical answer set semantics of\nclassical disjunctive logic programs with classical aggregates, and\nconsequently subsumes the classical answer set semantics of classical\ndisjunctive logic programs. We show that the proposed fuzzy answer sets of DFLP\nwith fuzzy aggregates are minimal fuzzy models and hence incomparable, which is\nan important property for nonmonotonic fuzzy reasoning.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Process, Structure, and Modularity in Reasoning with Uncertainty",
        "authors": [
            "Bruce D'Ambrosio"
        ],
        "summary": "Computational mechanisms for uncertainty management must support interactive\nand incremental problem formulation, inference, hypothesis testing, and\ndecision making. However, most current uncertainty inference systems\nconcentrate primarily on inference, and provide no support for the larger\nissues. We present a computational approach to uncertainty management which\nprovides direct support for the dynamic, incremental aspect of this task, while\nat the same time permitting direct representation of the structure of\nevidential relationships. At the same time, we show that this approach responds\nto the modularity concerns of Heckerman and Horvitz [Heck87]. This paper\nemphasizes examples of the capabilities of this approach. Another paper\n[D'Am89] details the representations and algorithms involved.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "A Temporal Logic for Uncertain Events and An Outline of A Possible\n  Implementation in An Extension of PROLOG",
        "authors": [
            "Soumitra Dutta"
        ],
        "summary": "There is uncertainty associated with the occurrence of many events in real\nlife. In this paper we develop a temporal logic to deal with such uncertain\nevents and outline a possible implementation in an extension of PROLOG. Events\nare represented as fuzzy sets with the membership function giving the\npossibility of occurrence of the event in a given interval of time. The\ndeveloped temporal logic is simple but powerful. It can determine effectively\nthe various temporal relations between uncertain events or their combinations.\nPROLOG provides a uniform substrate on which to effectively implement such a\ntemporal logic for uncertain events",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "An Empirical Comparison of Three Inference Methods",
        "authors": [
            "David Heckerman"
        ],
        "summary": "In this paper, an empirical evaluation of three inference methods for\nuncertain reasoning is presented in the context of Pathfinder, a large expert\nsystem for the diagnosis of lymph-node pathology. The inference procedures\nevaluated are (1) Bayes' theorem, assuming evidence is conditionally\nindependent given each hypothesis; (2) odds-likelihood updating, assuming\nevidence is conditionally independent given each hypothesis and given the\nnegation of each hypothesis; and (3) a inference method related to the\nDempster-Shafer theory of belief. Both expert-rating and decision-theoretic\nmetrics are used to compare the diagnostic accuracy of the inference methods.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Probabilistic Semantics and Defaults",
        "authors": [
            "Eric Neufeld",
            "David L Poole"
        ],
        "summary": "There is much interest in providing probabilistic semantics for defaults but\nmost approaches seem to suffer from one of two problems: either they require\nnumbers, a problem defaults were intended to avoid, or they generate peculiar\nside effects. Rather than provide semantics for defaults, we address the\nproblem defaults were intended to solve: that of reasoning under uncertainty\nwhere numeric probability distributions are not available. We describe a\nnon-numeric formalism called an inference graph based on standard probability\ntheory, conditional independence and sentences of favouring where a favours b -\nfavours(a, b) - p(a|b) > p(a). The formalism seems to handle the examples from\nthe nonmonotonic literature. Most importantly, the sentences of our system can\nbe verified by performing an appropriate experiment in the semantic domain.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "A Linear Approximation Method for Probabilistic Inference",
        "authors": [
            "Ross D. Shachter"
        ],
        "summary": "An approximation method is presented for probabilistic inference with\ncontinuous random variables. These problems can arise in many practical\nproblems, in particular where there are \"second order\" probabilities. The\napproximation, based on the Gaussian influence diagram, iterates over linear\napproximations to the inference problem.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Generating Decision Structures and Causal Explanations for Decision\n  Making",
        "authors": [
            "Spencer Star"
        ],
        "summary": "This paper examines two related problems that are central to developing an\nautonomous decision-making agent, such as a robot. Both problems require\ngenerating structured representafions from a database of unstructured\ndeclarative knowledge that includes many facts and rules that are irrelevant in\nthe problem context. The first problem is how to generate a well structured\ndecision problem from such a database. The second problem is how to generate,\nfrom the same database, a well-structured explanation of why some possible\nworld occurred. In this paper it is shown that the problem of generating the\nappropriate decision structure or explanation is intractable without\nintroducing further constraints on the knowledge in the database. The paper\nproposes that the problem search space can be constrained by adding knowledge\nto the database about causal relafions between events. In order to determine\nthe causal knowledge that would be most useful, causal theories for\ndeterministic and indeterministic universes are proposed. A program that uses\nsome of these causal constraints has been used to generate explanations about\nfaulty plans. The program shows the expected increase in efficiency as the\ncausal constraints are introduced.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Nonmonotonic Reasoning via Possibility Theory",
        "authors": [
            "Ronald R. Yager"
        ],
        "summary": "We introduce the operation of possibility qualification and show how. this\nmodal-like operator can be used to represent \"typical\" or default knowledge in\na theory of nonmonotonic reasoning. We investigate the representational power\nof this approach by looking at a number of prototypical problems from the\nnonmonotonic reasoning literature. In particular we look at the so called Yale\nshooting problem and its relation to priority in default reasoning.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Logical Fuzzy Optimization",
        "authors": [
            "Emad Saad"
        ],
        "summary": "We present a logical framework to represent and reason about fuzzy\noptimization problems based on fuzzy answer set optimization programming. This\nis accomplished by allowing fuzzy optimization aggregates, e.g., minimum and\nmaximum in the language of fuzzy answer set optimization programming to allow\nminimization or maximization of some desired criteria under fuzzy environments.\nWe show the application of the proposed logical fuzzy optimization framework\nunder the fuzzy answer set optimization programming to the fuzzy water\nallocation optimization problem.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Symmetry-Aware Marginal Density Estimation",
        "authors": [
            "Mathias Niepert"
        ],
        "summary": "The Rao-Blackwell theorem is utilized to analyze and improve the scalability\nof inference in large probabilistic models that exhibit symmetries. A novel\nmarginal density estimator is introduced and shown both analytically and\nempirically to outperform standard estimators by several orders of magnitude.\nThe developed theory and algorithms apply to a broad class of probabilistic\nmodels including statistical relational models considered not susceptible to\nlifted probabilistic inference.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Belief in Belief Functions: An Examination of Shafer's Canonical\n  Examples",
        "authors": [
            "Kathryn Blackmond Laskey"
        ],
        "summary": "In the canonical examples underlying Shafer-Dempster theory, beliefs over the\nhypotheses of interest are derived from a probability model for a set of\nauxiliary hypotheses. Beliefs are derived via a compatibility relation\nconnecting the auxiliary hypotheses to subsets of the primary hypotheses. A\nbelief function differs from a Bayesian probability model in that one does not\ncondition on those parts of the evidence for which no probabilities are\nspecified. The significance of this difference in conditioning assumptions is\nillustrated with two examples giving rise to identical belief functions but\ndifferent Bayesian probability distributions.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Do We Need Higher-Order Probabilities and, If So, What Do They Mean?",
        "authors": [
            "Judea Pearl"
        ],
        "summary": "The apparent failure of individual probabilistic expressions to distinguish\nuncertainty about truths from uncertainty about probabilistic assessments have\nprompted researchers to seek formalisms where the two types of uncertainties\nare given notational distinction. This paper demonstrates that the desired\ndistinction is already a built-in feature of classical probabilistic models,\nthus, specialized notations are unnecessary.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Theory-Based Inductive Learning: An Integration of Symbolic and\n  Quantitative Methods",
        "authors": [
            "Spencer Star"
        ],
        "summary": "The objective of this paper is to propose a method that will generate a\ncausal explanation of observed events in an uncertain world and then make\ndecisions based on that explanation. Feedback can cause the explanation and\ndecisions to be modified. I call the method Theory-Based Inductive Learning\n(T-BIL). T-BIL integrates deductive learning, based on a technique called\nExplanation-Based Generalization (EBG) from the field of machine learning, with\ninductive learning methods from Bayesian decision theory. T-BIL takes as inputs\n(1) a decision problem involving a sequence of related decisions over time, (2)\na training example of a solution to the decision problem in one period, and (3)\nthe domain theory relevant to the decision problem. T-BIL uses these inputs to\nconstruct a probabilistic explanation of why the training example is an\ninstance of a solution to one stage of the sequential decision problem. This\nexplanation is then generalized to cover a more general class of instances and\nis used as the basis for making the next-stage decisions. As the outcomes of\neach decision are observed, the explanation is revised, which in turn affects\nthe subsequent decisions. A detailed example is presented that uses T-BIL to\nsolve a very general stochastic adaptive control problem for an autonomous\nmobile robot.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Towards Solving the Multiple Extension Problem: Combining Defaults and\n  Probabilities",
        "authors": [
            "Eric Neufeld",
            "David L Poole"
        ],
        "summary": "The multiple extension problem arises frequently in diagnostic and default\ninference. That is, we can often use any of a number of sets of defaults or\npossible hypotheses to explain observations or make Predictions. In default\ninference, some extensions seem to be simply wrong and we use qualitative\ntechniques to weed out the unwanted ones. In the area of diagnosis, however,\nthe multiple explanations may all seem reasonable, however improbable. Choosing\namong them is a matter of quantitative preference. Quantitative preference\nworks well in diagnosis when knowledge is modelled causally. Here we suggest a\nframework that combines probabilities and defaults in a single unified\nframework that retains the semantics of diagnosis as construction of\nexplanations from a fixed set of possible hypotheses. We can then compute\nprobabilities incrementally as we construct explanations. Here we describe a\nbranch and bound algorithm that maintains a set of all partial explanations\nwhile exploring a most promising one first. A most probable explanation is\nfound first if explanations are partially ordered.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Combining Symbolic and Numeric Approaches to Uncertainty Management",
        "authors": [
            "Bruce D'Ambrosio"
        ],
        "summary": "A complete approach to reasoning under uncertainty requires support for\nincremental and interactive formulation and revision of, as well as reasoning\nwith, models of the problem domain capable of representing our uncertainty. We\npresent a hybrid reasoning scheme which combines symbolic and numeric methods\nfor uncertainty management to provide efficient and effective support for each\nof these tasks. The hybrid is based on symbolic techniques adapted from\nAssumption-based Truth Maintenance systems (ATMS), combined with numeric\nmethods adapted from the Dempster/Shafer theory of evidence, as extended in\nBaldwin's Support Logic Programming system. The hybridization is achieved by\nviewing an ATMS as a symbolic algebra system for uncertainty calculations. This\ntechnique has several major advantages over conventional methods for performing\ninference with numeric certainty estimates in addition to the ability to\ndynamically determine hypothesis spaces, including improved management of\ndependent and partially independent evidence, faster run-time evaluation of\npropositional certainties, the ability to query the certainty value of a\nproposition from multiple perspectives, and the ability to incrementally extend\nor revise domain models.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Reasoning About Beliefs and Actions Under Computational Resource\n  Constraints",
        "authors": [
            "Eric J. Horvitz"
        ],
        "summary": "Although many investigators affirm a desire to build reasoning systems that\nbehave consistently with the axiomatic basis defined by probability theory and\nutility theory, limited resources for engineering and computation can make a\ncomplete normative analysis impossible. We attempt to move discussion beyond\nthe debate over the scope of problems that can be handled effectively to cases\nwhere it is clear that there are insufficient computational resources to\nperform an analysis deemed as complete. Under these conditions, we stress the\nimportance of considering the expected costs and benefits of applying\nalternative approximation procedures and heuristics for computation and\nknowledge acquisition. We discuss how knowledge about the structure of user\nutility can be used to control value tradeoffs for tailoring inference to\nalternative contexts. We address the notion of real-time rationality, focusing\non the application of knowledge about the expected timewise-refinement\nabilities of reasoning strategies to balance the benefits of additional\ncomputation with the costs of acting with a partial result. We discuss the\nbenefits of applying decision theory to control the solution of difficult\nproblems given limitations and uncertainty in reasoning resources.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Advantages and a Limitation of Using LEG Nets in a Real-TIme Problem",
        "authors": [
            "Thomas Slack"
        ],
        "summary": "After experimenting with a number of non-probabilistic methods for dealing\nwith uncertainty many researchers reaffirm a preference for probability methods\n[1] [2], although this remains controversial. The importance of being able to\nform decisions from incomplete data in diagnostic problems has highlighted\nprobabilistic methods [5] which compute posterior probabilities from prior\ndistributions in a way similar to Bayes Rule, and thus are called Bayesian\nmethods. This paper documents the use of a Bayesian method in a real time\nproblem which is similar to medical diagnosis in that there is a need to form\ndecisions and take some action without complete knowledge of conditions in the\nproblem domain. This particular method has a limitation which is discussed.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Logical Fuzzy Preferences",
        "authors": [
            "Emad Saad"
        ],
        "summary": "We present a unified logical framework for representing and reasoning about\nboth quantitative and qualitative preferences in fuzzy answer set programming,\ncalled fuzzy answer set optimization programs. The proposed framework is vital\nto allow defining quantitative preferences over the possible outcomes of\nqualitative preferences. We show the application of fuzzy answer set\noptimization programs to the course scheduling with fuzzy preferences problem.\nTo the best of our knowledge, this development is the first to consider a\nlogical framework for reasoning about quantitative preferences, in general, and\nreasoning about both quantitative and qualitative preferences in particular.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Nested Aggregates in Answer Sets: An Application to a Priori\n  Optimization",
        "authors": [
            "Emad Saad"
        ],
        "summary": "We allow representing and reasoning in the presence of nested multiple\naggregates over multiple variables and nested multiple aggregates over\nfunctions involving multiple variables in answer sets, precisely, in answer set\noptimization programming and in answer set programming. We show the\napplicability of the answer set optimization programming with nested multiple\naggregates and the answer set programming with nested multiple aggregates to\nthe Probabilistic Traveling Salesman Problem, a fundamental a priori\noptimization problem in Operation Research.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "The Myth of Modularity in Rule-Based Systems",
        "authors": [
            "David Heckerman",
            "Eric J. Horvitz"
        ],
        "summary": "In this paper, we examine the concept of modularity, an often cited advantage\nof the ruled-based representation methodology. We argue that the notion of\nmodularity consists of two distinct concepts which we call syntactic modularity\nand semantic modularity. We argue that when reasoning under certainty, it is\nreasonable to regard the rule-based approach as both syntactically and\nsemantically modular. However, we argue that in the case of plausible\nreasoning, rules are syntactically modular but are rarely semantically modular.\nTo illustrate this point, we examine a particular approach for managing\nuncertainty in rule-based systems called the MYCIN certainty factor model. We\nformally define the concept of semantic modularity with respect to the\ncertainty factor model and discuss logical consequences of the definition. We\nshow that the assumption of semantic modularity imposes strong restrictions on\nrules in a knowledge base. We argue that such restrictions are rarely valid in\npractical applications. Finally, we suggest how the concept of semantic\nmodularity can be relaxed in a manner that makes it appropriate for plausible\nreasoning.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "An Axiomatic Framework for Belief Updates",
        "authors": [
            "David Heckerman"
        ],
        "summary": "In the 1940's, a physicist named Cox provided the first formal justification\nfor the axioms of probability based on the subjective or Bayesian\ninterpretation. He showed that if a measure of belief satisfies several\nfundamental properties, then the measure must be some monotonic transformation\nof a probability. In this paper, measures of change in belief or belief updates\nare examined. In the spirit of Cox, properties for a measure of change in\nbelief are enumerated. It is shown that if a measure satisfies these\nproperties, it must satisfy other restrictive conditions. For example, it is\nshown that belief updates in a probabilistic context must be equal to some\nmonotonic transformation of a likelihood ratio. It is hoped that this formal\nexplication of the belief update paradigm will facilitate critical discussion\nand useful extensions of the approach.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Distributed Revision of Belief Commitment in Multi-Hypothesis\n  Interpretations",
        "authors": [
            "Judea Pearl"
        ],
        "summary": "This paper extends the applications of belief-networks to include the\nrevision of belief commitments, i.e., the categorical acceptance of a subset of\nhypotheses which, together, constitute the most satisfactory explanation of the\nevidence at hand. A coherent model of non-monotonic reasoning is established\nand distributed algorithms for belief revision are presented. We show that, in\nsingly connected networks, the most satisfactory explanation can be found in\nlinear time by a message-passing algorithm similar to the one used in belief\nupdating. In multiply-connected networks, the problem may be exponentially hard\nbut, if the network is sparse, topological considerations can be used to render\nthe interpretation task tractable. In general, finding the most probable\ncombination of hypotheses is no more complex than computing the degree of\nbelief for any individual hypothesis. Applications to medical diagnosis are\nillustrated.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Learning Link-Probabilities in Causal Trees",
        "authors": [
            "Igor Roizer",
            "Judea Pearl"
        ],
        "summary": "A learning algorithm is presented which given the structure of a causal tree,\nwill estimate its link probabilities by sequential measurements on the leaves\nonly. Internal nodes of the tree represent conceptual (hidden) variables\ninaccessible to observation. The method described is incremental, local,\nefficient, and remains robust to measurement imprecisions.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "A Backwards View for Assessment",
        "authors": [
            "Ross D. Shachter",
            "David Heckerman"
        ],
        "summary": "Much artificial intelligence research focuses on the problem of deducing the\nvalidity of unobservable propositions or hypotheses from observable evidence.!\nMany of the knowledge representation techniques designed for this problem\nencode the relationship between evidence and hypothesis in a directed manner.\nMoreover, the direction in which evidence is stored is typically from evidence\nto hypothesis.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "DAVID: Influence Diagram Processing System for the Macintosh",
        "authors": [
            "Ross D. Shachter"
        ],
        "summary": "Influence diagrams are a directed graph representation for uncertainties as\nprobabilities. The graph distinguishes between those variables which are under\nthe control of a decision maker (decisions, shown as rectangles) and those\nwhich are not (chances, shown as ovals), as well as explicitly denoting a goal\nfor solution (value, shown as a rounded rectangle.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "On Implementing Usual Values",
        "authors": [
            "Ronald R. Yager"
        ],
        "summary": "In many cases commonsense knowledge consists of knowledge of what is usual.\nIn this paper we develop a system for reasoning with usual information. This\nsystem is based upon the fact that these pieces of commonsense information\ninvolve both a probabilistic aspect and a granular aspect. We implement this\nsystem with the aid of possibility-probability granules.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Logical Probability Preferences",
        "authors": [
            "Emad Saad"
        ],
        "summary": "We present a unified logical framework for representing and reasoning about\nboth probability quantitative and qualitative preferences in probability answer\nset programming, called probability answer set optimization programs. The\nproposed framework is vital to allow defining probability quantitative\npreferences over the possible outcomes of qualitative preferences. We show the\napplication of probability answer set optimization programs to a variant of the\nwell-known nurse restoring problem, called the nurse restoring with probability\npreferences problem. To the best of our knowledge, this development is the\nfirst to consider a logical framework for reasoning about probability\nquantitative preferences, in general, and reasoning about both probability\nquantitative and qualitative preferences in particular.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Probabilistic Interpretations for MYCIN's Certainty Factors",
        "authors": [
            "David Heckerman"
        ],
        "summary": "This paper examines the quantities used by MYCIN to reason with uncertainty,\ncalled certainty factors. It is shown that the original definition of certainty\nfactors is inconsistent with the functions used in MYCIN to combine the\nquantities. This inconsistency is used to argue for a redefinition of certainty\nfactors in terms of the intuitively appealing desiderata associated with the\ncombining functions. It is shown that this redefinition accommodates an\nunlimited number of probabilistic interpretations. These interpretations are\nshown to be monotonic transformations of the likelihood ratio p(EIH)/p(El H).\nThe construction of these interpretations provides insight into the assumptions\nimplicit in the certainty factor model. In particular, it is shown that if\nuncertainty is to be propagated through an inference network in accordance with\nthe desiderata, evidence must be conditionally independent given the hypothesis\nand its negation and the inference network must have a tree structure. It is\nemphasized that assumptions implicit in the model are rarely true in practical\napplications. Methods for relaxing the assumptions are suggested.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "A Constraint Propagation Approach to Probabilistic Reasoning",
        "authors": [
            "Judea Pearl"
        ],
        "summary": "The paper demonstrates that strict adherence to probability theory does not\npreclude the use of concurrent, self-activated constraint-propagation\nmechanisms for managing uncertainty. Maintaining local records of\nsources-of-belief allows both predictive and diagnostic inferences to be\nactivated simultaneously and propagate harmoniously towards a stable\nequilibrium.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Intelligent Probabilistic Inference",
        "authors": [
            "Ross D. Shachter"
        ],
        "summary": "The analysis of practical probabilistic models on the computer demands a\nconvenient representation for the available knowledge and an efficient\nalgorithm to perform inference. An appealing representation is the influence\ndiagram, a network that makes explicit the random variables in a model and\ntheir probabilistic dependencies. Recent advances have developed solution\nprocedures based on the influence diagram. In this paper, we examine the\nfundamental properties that underlie those techniques, and the information\nabout the probabilistic structure that is available in the influence diagram\nrepresentation. The influence diagram is a convenient representation for\ncomputer processing while also being clear and non-mathematical. It displays\nprobabilistic dependence precisely, in a way that is intuitive for decision\nmakers and experts to understand and communicate. As a result, the same\ninfluence diagram can be used to build, assess and analyze a model,\nfacilitating changes in the formulation and feedback from sensitivity analysis.\nThe goal in this paper is to determine arbitrary conditional probability\ndistributions from a given probabilistic model. Given qualitative information\nabout the dependence of the random variables in the model we can, for a\nspecific conditional expression, specify precisely what quantitative\ninformation we need to be able to determine the desired conditional probability\ndistribution. It is also shown how we can find that probability distribution by\nperforming operations locally, that is, over subspaces of the joint\ndistribution. In this way, we can exploit the conditional independence present\nin the model to avoid having to construct or manipulate the full joint\ndistribution. These results are extended to include maximal processing when the\ninformation available is incomplete, and optimal decision making in an\nuncertain environment. Influence diagrams as a computer-aided modeling tool\nwere developed by Miller, Merkofer, and Howard [5] and extended by Howard and\nMatheson [2]. Good descriptions of how to use them in modeling are in Owen [7]\nand Howard and Matheson [2]. The notion of solving a decision problem through\ninfluence diagrams was examined by Olmsted [6] and such an algorithm was\ndeveloped by Shachter [8]. The latter paper also shows how influence diagrams\ncan be used to perform a variety of sensitivity analyses. This paper extends\nthose results by developing a theory of the properties of the diagram that are\nused by the algorithm, and the information needed to solve arbitrary\nprobability inference problems. Section 2 develops the notation and the\nframework for the paper and the relationship between influence diagrams and\njoint probability distributions. The general probabilistic inference problem is\nposed in Section 3. In Section 4 the transformations on the diagram are\ndeveloped and then put together into a solution procedure in Section 5. In\nSection 6, this procedure is used to calculate the information requirement to\nsolve an inference problem and the maximal processing that can be performed\nwith incomplete information. Section 7 contains a summary of results.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Logical Stochastic Optimization",
        "authors": [
            "Emad Saad"
        ],
        "summary": "We present a logical framework to represent and reason about stochastic\noptimization problems based on probability answer set programming. This is\nestablished by allowing probability optimization aggregates, e.g., minimum and\nmaximum in the language of probability answer set programming to allow\nminimization or maximization of some desired criteria under the probabilistic\nenvironments. We show the application of the proposed logical stochastic\noptimization framework under the probability answer set programming to two\nstages stochastic optimization problems with recourse.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Proceedings of the Sixteenth Conference on Uncertainty in Artificial\n  Intelligence (2000)",
        "authors": [
            "Craig Boutilier",
            "Moises Goldszmidt"
        ],
        "summary": "This is the Proceedings of the Sixteenth Conference on Uncertainty in\nArtificial Intelligence, which was held in San Francisco, CA, June 30 - July 3,\n2000",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Proceedings of the Seventh Conference on Uncertainty in Artificial\n  Intelligence (1991)",
        "authors": [
            "Piero Bonissone",
            "Bruce D'Ambrosio",
            "Philippe Smets"
        ],
        "summary": "This is the Proceedings of the Seventh Conference on Uncertainty in\nArtificial Intelligence, which was held in Los Angeles, CA, July 13-15, 1991",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Non Deterministic Logic Programs",
        "authors": [
            "Emad Saad"
        ],
        "summary": "Non deterministic applications arise in many domains, including, stochastic\noptimization, multi-objectives optimization, stochastic planning, contingent\nstochastic planning, reinforcement learning, reinforcement learning in\npartially observable Markov decision processes, and conditional planning. We\npresent a logic programming framework called non deterministic logic programs,\nalong with a declarative semantics and fixpoint semantics, to allow\nrepresenting and reasoning about inherently non deterministic real-world\napplications. The language of non deterministic logic programs framework is\nextended with non-monotonic negation, and two alternative semantics are\ndefined: the stable non deterministic model semantics and the well-founded non\ndeterministic model semantics as well as their relationship is studied. These\nsemantics subsume the deterministic stable model semantics and the\ndeterministic well-founded semantics of deterministic normal logic programs,\nand they reduce to the semantics of deterministic definite logic programs\nwithout negation. We show the application of the non deterministic logic\nprograms framework to a conditional planning problem.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "LLAMA: Leveraging Learning to Automatically Manage Algorithms",
        "authors": [
            "Lars Kotthoff"
        ],
        "summary": "Algorithm portfolio and selection approaches have achieved remarkable\nimprovements over single solvers. However, the implementation of such systems\nis often highly customised and specific to the problem domain. This makes it\ndifficult for researchers to explore different techniques for their specific\nproblems. We present LLAMA, a modular and extensible toolkit implemented as an\nR package that facilitates the exploration of a range of different portfolio\ntechniques on any problem domain. It implements the algorithm selection\napproaches most commonly used in the literature and leverages the extensive\nlibrary of machine learning algorithms and techniques in R. We describe the\ncurrent capabilities and limitations of the toolkit and illustrate its usage on\na set of example SAT problems.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Flexibly-bounded Rationality and Marginalization of Irrationality\n  Theories for Decision Making",
        "authors": [
            "Tshilidzi Marwala"
        ],
        "summary": "In this paper the theory of flexibly-bounded rationality which is an\nextension to the theory of bounded rationality is revisited. Rational decision\nmaking involves using information which is almost always imperfect and\nincomplete together with some intelligent machine which if it is a human being\nis inconsistent to make decisions. In bounded rationality, this decision is\nmade irrespective of the fact that the information to be used is incomplete and\nimperfect and that the human brain is inconsistent and thus this decision that\nis to be made is taken within the bounds of these limitations. In the theory of\nflexibly-bounded rationality, advanced information analysis is used, the\ncorrelation machine is applied to complete missing information and artificial\nintelligence is used to make more consistent decisions. Therefore\nflexibly-bounded rationality expands the bounds within which rationality is\nexercised. Because human decision making is essentially irrational, this paper\nproposes the theory of marginalization of irrationality in decision making to\ndeal with the problem of satisficing in the presence of irrationality.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Symmetries of Symmetry Breaking Constraints",
        "authors": [
            "George Katsirelos",
            "Toby Walsh"
        ],
        "summary": "Symmetry is an important feature of many constraint programs. We show that\nany symmetry acting on a set of symmetry breaking constraints can be used to\nbreak symmetry. Different symmetries pick out different solutions in each\nsymmetry class. We use these observations in two methods for eliminating\nsymmetry from a problem. These methods are designed to have many of the\nadvantages of symmetry breaking methods that post static symmetry breaking\nconstraint without some of the disadvantages. In particular, the two methods\nprune the search space using fast and efficient propagation of posted\nconstraints, whilst reducing the conflict between symmetry breaking and\nbranching heuristics. Experimental results show that the two methods perform\nwell on some standard benchmarks.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Flow-Based Propagators for the SEQUENCE and Related Global Constraints",
        "authors": [
            "Michael J. Maher",
            "Nina Narodytska",
            "Claude-Guy Quimper",
            "Toby Walsh"
        ],
        "summary": "We propose new filtering algorithms for the SEQUENCE constraint and some\nextensions of the SEQUENCE constraint based on network flows. We enforce domain\nconsistency on the SEQUENCE constraint in $O(n^2)$ time down a branch of the\nsearch tree. This improves upon the best existing domain consistency algorithm\nby a factor of $O(\\log n)$. The flows used in these algorithms are derived from\na linear program. Some of them differ from the flows used to propagate global\nconstraints like GCC since the domains of the variables are encoded as costs on\nthe edges rather than capacities. Such flows are efficient for maintaining\nbounds consistency over large domains and may be useful for other global\nconstraints.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "The Weighted CFG Constraint",
        "authors": [
            "George Katsirelos",
            "Nina Narodytska",
            "Toby Walsh"
        ],
        "summary": "We introduce the weighted CFG constraint and propose a propagation algorithm\nthat enforces domain consistency in $O(n^3|G|)$ time. We show that this\nalgorithm can be decomposed into a set of primitive arithmetic constraints\nwithout hindering propagation.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Dual Modelling of Permutation and Injection Problems",
        "authors": [
            "B. Hnich",
            "B. M. Smith",
            "T. Walsh"
        ],
        "summary": "When writing a constraint program, we have to choose which variables should\nbe the decision variables, and how to represent the constraints on these\nvariables. In many cases, there is considerable choice for the decision\nvariables. Consider, for example, permutation problems in which we have as many\nvalues as variables, and each variable takes an unique value. In such problems,\nwe can choose between a primal and a dual viewpoint. In the dual viewpoint,\neach dual variable represents one of the primal values, whilst each dual value\nrepresents one of the primal variables. Alternatively, by means of channelling\nconstraints to link the primal and dual variables, we can have a combined model\nwith both sets of variables. In this paper, we perform an extensive theoretical\nand empirical study of such primal, dual and combined models for two classes of\nproblems: permutation problems and injection problems. Our results show that it\noften be advantageous to use multiple viewpoints, and to have constraints which\nchannel between them to maintain consistency. They also illustrate a general\nmethodology for comparing different constraint models.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Proceedings of the Doctoral Consortium and Poster Session of the 5th\n  International Symposium on Rules (RuleML 2011@IJCAI)",
        "authors": [
            "Carlos Viegas Dam\u00e1sio",
            "Alun Preece",
            "Umberto Straccia"
        ],
        "summary": "This volume contains the papers presented at the first edition of the\nDoctoral Consortium of the 5th International Symposium on Rules (RuleML\n2011@IJCAI) held on July 19th, 2011 in Barcelona, as well as the poster session\npapers of the RuleML 2011@IJCAI main conference.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "NK landscapes difficulty and Negative Slope Coefficient: How Sampling\n  Influences the Results",
        "authors": [
            "Leonardo Vanneschi",
            "S\u00e9bastien Verel",
            "Philippe Collard",
            "Marco Tomassini"
        ],
        "summary": "Negative Slope Coefficient is an indicator of problem hardness that has been\nintroduced in 2004 and that has returned promising results on a large set of\nproblems. It is based on the concept of fitness cloud and works by partitioning\nthe cloud into a number of bins representing as many different regions of the\nfitness landscape. The measure is calculated by joining the bins centroids by\nsegments and summing all their negative slopes. In this paper, for the first\ntime, we point out a potential problem of the Negative Slope Coefficient: we\nstudy its value for different instances of the well known NK-landscapes and we\nshow how this indicator is dramatically influenced by the minimum number of\npoints contained into a bin. Successively, we formally justify this behavior of\nthe Negative Slope Coefficient and we discuss pros and cons of this measure.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Adaptation Knowledge Discovery from a Case Base",
        "authors": [
            "Mathieu D'Aquin",
            "Fadi Badra",
            "Sandrine Lafrogne",
            "Jean Lieber",
            "Amedeo Napoli",
            "Laszlo Szathmary"
        ],
        "summary": "In case-based reasoning, the adaptation step depends in general on\ndomain-dependent knowledge, which motivates studies on adaptation knowledge\nacquisition (AKA). CABAMAKA is an AKA system based on principles of knowledge\ndiscovery from databases. This system explores the variations within the case\nbase to elicit adaptation knowledge. It has been successfully tested in an\napplication of case-based decision support to breast cancer treatment.",
        "year": 2006,
        "label": "cs.AI"
    },
    {
        "title": "DSmT: A new paradigm shift for information fusion",
        "authors": [
            "Jean Dezert",
            "Florentin Smarandache"
        ],
        "summary": "The management and combination of uncertain, imprecise, fuzzy and even\nparadoxical or high conflicting sources of information has always been and\nstill remains of primal importance for the development of reliable information\nfusion systems. In this short survey paper, we present the theory of plausible\nand paradoxical reasoning, known as DSmT (Dezert-Smarandache Theory) in\nliterature, developed for dealing with imprecise, uncertain and potentially\nhighly conflicting sources of information. DSmT is a new paradigm shift for\ninformation fusion and recent publications have shown the interest and the\npotential ability of DSmT to solve fusion problems where Dempster's rule used\nin Dempster-Shafer Theory (DST) provides counter-intuitive results or fails to\nprovide useful result at all. This paper is focused on the foundations of DSmT\nand on its main rules of combination (classic, hybrid and Proportional Conflict\nRedistribution rules). Shafer's model on which is based DST appears as a\nparticular and specific case of DSm hybrid model which can be easily handled by\nDSmT as well. Several simple but illustrative examples are given throughout\nthis paper to show the interest and the generality of this new theory.",
        "year": 2006,
        "label": "cs.AI"
    },
    {
        "title": "Multiagent Approach for the Representation of Information in a Decision\n  Support System",
        "authors": [
            "Fahem Kebair",
            "Fr\u00e9d\u00e9ric Serin"
        ],
        "summary": "In an emergency situation, the actors need an assistance allowing them to\nreact swiftly and efficiently. In this prospect, we present in this paper a\ndecision support system that aims to prepare actors in a crisis situation\nthanks to a decision-making support. The global architecture of this system is\npresented in the first part. Then we focus on a part of this system which is\ndesigned to represent the information of the current situation. This part is\ncomposed of a multiagent system that is made of factual agents. Each agent\ncarries a semantic feature and aims to represent a partial part of a situation.\nThe agents develop thanks to their interactions by comparing their semantic\nfeatures using proximity measures and according to specific ontologies.",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "An introduction to DSmT",
        "authors": [
            "Jean Dezert",
            "Florentin Smarandache"
        ],
        "summary": "The management and combination of uncertain, imprecise, fuzzy and even\nparadoxical or high conflicting sources of information has always been, and\nstill remains today, of primal importance for the development of reliable\nmodern information systems involving artificial reasoning. In this\nintroduction, we present a survey of our recent theory of plausible and\nparadoxical reasoning, known as Dezert-Smarandache Theory (DSmT), developed for\ndealing with imprecise, uncertain and conflicting sources of information. We\nfocus our presentation on the foundations of DSmT and on its most important\nrules of combination, rather than on browsing specific applications of DSmT\navailable in literature. Several simple examples are given throughout this\npresentation to show the efficiency and the generality of this new approach.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Breaking Value Symmetry",
        "authors": [
            "Toby Walsh"
        ],
        "summary": "Symmetry is an important factor in solving many constraint satisfaction\nproblems. One common type of symmetry is when we have symmetric values. In a\nrecent series of papers, we have studied methods to break value symmetries. Our\nresults identify computational limits on eliminating value symmetry. For\ninstance, we prove that pruning all symmetric values is NP-hard in general.\nNevertheless, experiments show that much value symmetry can be broken in\npractice. These results may be useful to researchers in planning, scheduling\nand other areas as value symmetry occurs in many different domains.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Reformulating Global Grammar Constraints",
        "authors": [
            "George Katsirelos",
            "Nina Narodytska",
            "Toby Walsh"
        ],
        "summary": "An attractive mechanism to specify global constraints in rostering and other\ndomains is via formal languages. For instance, the Regular and Grammar\nconstraints specify constraints in terms of the languages accepted by an\nautomaton and a context-free grammar respectively. Taking advantage of the\nfixed length of the constraint, we give an algorithm to transform a\ncontext-free grammar into an automaton. We then study the use of minimization\ntechniques to reduce the size of such automata and speed up propagation. We\nshow that minimizing such automata after they have been unfolded and domains\ninitially reduced can give automata that are more compact than minimizing\nbefore unfolding and reducing. Experimental results show that such\ntransformations can improve the size of rostering problems that we can 'model\nand run'.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Combining Symmetry Breaking and Global Constraints",
        "authors": [
            "George Katsirelos",
            "Nina Narodytska",
            "Toby Walsh"
        ],
        "summary": "We propose a new family of constraints which combine together lexicographical\nordering constraints for symmetry breaking with other common global\nconstraints. We give a general purpose propagator for this family of\nconstraints, and show how to improve its complexity by exploiting properties of\nthe included global constraints.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Stochastic Constraint Programming",
        "authors": [
            "Toby Walsh"
        ],
        "summary": "To model combinatorial decision problems involving uncertainty and\nprobability, we introduce stochastic constraint programming. Stochastic\nconstraint programs contain both decision variables (which we can set) and\nstochastic variables (which follow a probability distribution). They combine\ntogether the best features of traditional constraint satisfaction, stochastic\ninteger programming, and stochastic satisfiability. We give a semantics for\nstochastic constraint programs, and propose a number of complete algorithms and\napproximation procedures. Finally, we discuss a number of extensions of\nstochastic constraint programming to relax various assumptions like the\nindependence between stochastic variables, and compare with other approaches\nfor decision making under uncertainty.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Semi-Myopic Sensing Plans for Value Optimization",
        "authors": [
            "David Tolpin",
            "Solomon Eyal Shimony"
        ],
        "summary": "We consider the following sequential decision problem. Given a set of items\nof unknown utility, we need to select one of as high a utility as possible\n(``the selection problem''). Measurements (possibly noisy) of item values prior\nto selection are allowed, at a known cost. The goal is to optimize the overall\nsequential decision process of measurements and selection.\n  Value of information (VOI) is a well-known scheme for selecting measurements,\nbut the intractability of the problem typically leads to using myopic VOI\nestimates. In the selection problem, myopic VOI frequently badly underestimates\nthe value of information, leading to inferior sensing plans. We relax the\nstrict myopic assumption into a scheme we term semi-myopic, providing a\nspectrum of methods that can improve the performance of sensing plans. In\nparticular, we propose the efficiently computable method of ``blinkered'' VOI,\nand examine theoretical bounds for special cases. Empirical evaluation of\n``blinkered'' VOI in the selection problem with normally distributed item\nvalues shows that is performs much better than pure myopic VOI.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "The Single Machine Total Weighted Tardiness Problem - Is it (for\n  Metaheuristics) a Solved Problem ?",
        "authors": [
            "Martin Josef Geiger"
        ],
        "summary": "The article presents a study of rather simple local search heuristics for the\nsingle machine total weighted tardiness problem (SMTWTP), namely hillclimbing\nand Variable Neighborhood Search. In particular, we revisit these approaches\nfor the SMTWTP as there appears to be a lack of appropriate/challenging\nbenchmark instances in this case. The obtained results are impressive indeed.\nOnly few instances remain unsolved, and even those are approximated within 1%\nof the optimal/best known solutions. Our experiments support the claim that\nmetaheuristics for the SMTWTP are very likely to lead to good results, and\nthat, before refining search strategies, more work must be done with regard to\nthe proposition of benchmark data. Some recommendations for the construction of\nsuch data sets are derived from our investigations.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Improvements for multi-objective flow shop scheduling by Pareto Iterated\n  Local Search",
        "authors": [
            "Martin Josef Geiger"
        ],
        "summary": "The article describes the proposition and application of a local search\nmetaheuristic for multi-objective optimization problems. It is based on two\nmain principles of heuristic search, intensification through variable\nneighborhoods, and diversification through perturbations and successive\niterations in favorable regions of the search space. The concept is\nsuccessfully tested on permutation flow shop scheduling problems under multiple\nobjectives and compared to other local search approaches. While the obtained\nresults are encouraging in terms of their quality, another positive attribute\nof the approach is its simplicity as it does require the setting of only very\nfew parameters.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Proceedings 6th International Workshop on Local Search Techniques in\n  Constraint Satisfaction",
        "authors": [
            "Yves Deville",
            "Christine Solnon"
        ],
        "summary": "LSCS is a satellite workshop of the international conference on principles\nand practice of Constraint Programming (CP), since 2004. It is devoted to local\nsearch techniques in constraint satisfaction, and focuses on all aspects of\nlocal search techniques, including: design and implementation of new\nalgorithms, hybrid stochastic-systematic search, reactive search optimization,\nadaptive search, modeling for local-search, global constraints, flexibility and\nrobustness, learning methods, and specific applications.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "A Fuzzy Petri Nets Model for Computing With Words",
        "authors": [
            "Yongzhi Cao",
            "Guoqing Chen"
        ],
        "summary": "Motivated by Zadeh's paradigm of computing with words rather than numbers,\nseveral formal models of computing with words have recently been proposed.\nThese models are based on automata and thus are not well-suited for concurrent\ncomputing. In this paper, we incorporate the well-known model of concurrent\ncomputing, Petri nets, together with fuzzy set theory and thereby establish a\nconcurrency model of computing with words--fuzzy Petri nets for computing with\nwords (FPNCWs). The new feature of such fuzzy Petri nets is that the labels of\ntransitions are some special words modeled by fuzzy sets. By employing the\nmethodology of fuzzy reasoning, we give a faithful extension of an FPNCW which\nmakes it possible for computing with more words. The language expressiveness of\nthe two formal models of computing with words, fuzzy automata for computing\nwith words and FPNCWs, is compared as well. A few small examples are provided\nto illustrate the theoretical development.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Rational Deployment of CSP Heuristics",
        "authors": [
            "David Tolpin",
            "Solomon Eyal Shimony"
        ],
        "summary": "Heuristics are crucial tools in decreasing search effort in varied fields of\nAI. In order to be effective, a heuristic must be efficient to compute, as well\nas provide useful information to the search algorithm. However, some well-known\nheuristics which do well in reducing backtracking are so heavy that the gain of\ndeploying them in a search algorithm might be outweighed by their overhead.\n  We propose a rational metareasoning approach to decide when to deploy\nheuristics, using CSP backtracking search as a case study. In particular, a\nvalue of information approach is taken to adaptive deployment of solution-count\nestimation heuristics for value ordering. Empirical results show that indeed\nthe proposed mechanism successfully balances the tradeoff between decreasing\nbacktracking and heuristic computational overhead, resulting in a significant\noverall search time reduction.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Generalized Belief Propagation on Tree Robust Structured Region Graphs",
        "authors": [
            "Andrew E. Gelfand",
            "Max Welling"
        ],
        "summary": "This paper provides some new guidance in the construction of region graphs\nfor Generalized Belief Propagation (GBP). We connect the problem of choosing\nthe outer regions of a LoopStructured Region Graph (SRG) to that of finding a\nfundamental cycle basis of the corresponding Markov network. We also define a\nnew class of tree-robust Loop-SRG for which GBP on any induced (spanning) tree\nof the Markov network, obtained by setting to zero the off-tree interactions,\nis exact. This class of SRG is then mapped to an equivalent class of\ntree-robust cycle bases on the Markov network. We show that a treerobust cycle\nbasis can be identified by proving that for every subset of cycles, the graph\nobtained from the edges that participate in a single cycle only, is multiply\nconnected. Using this we identify two classes of tree-robust cycle bases:\nplanar cycle bases and \"star\" cycle bases. In experiments we show that\ntree-robustness can be successfully exploited as a design principle to improve\nthe accuracy and convergence of GBP.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "A Cluster-Cumulant Expansion at the Fixed Points of Belief Propagation",
        "authors": [
            "Max Welling",
            "Andrew E. Gelfand",
            "Alexander T. Ihler"
        ],
        "summary": "We introduce a new cluster-cumulant expansion (CCE) based on the fixed points\nof iterative belief propagation (IBP). This expansion is similar in spirit to\nthe loop-series (LS) recently introduced in [1]. However, in contrast to the\nlatter, the CCE enjoys the following important qualities: 1) it is defined for\narbitrary state spaces 2) it is easily extended to fixed points of generalized\nbelief propagation (GBP), 3) disconnected groups of variables will not\ncontribute to the CCE and 4) the accuracy of the expansion empirically improves\nupon that of the LS. The CCE is based on the same M\\\"obius transform as the\nKikuchi approximation, but unlike GBP does not require storing the beliefs of\nthe GBP-clusters nor does it suffer from convergence issues during belief\nupdating.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "A Biomimetic Approach Based on Immune Systems for Classification of\n  Unstructured Data",
        "authors": [
            "Mohamed Hamou",
            "Abdelmalek Amine",
            "Ahmed Chaouki Lokbani"
        ],
        "summary": "In this paper we present the results of unstructured data clustering in this\ncase a textual data from Reuters 21578 corpus with a new biomimetic approach\nusing immune system. Before experimenting our immune system, we digitalized\ntextual data by the n-grams approach. The novelty lies on hybridization of\nn-grams and immune systems for clustering. The experimental results show that\nthe recommended ideas are promising and prove that this method can solve the\ntext clustering problem.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Algorithm Selection for Combinatorial Search Problems: A Survey",
        "authors": [
            "Lars Kotthoff"
        ],
        "summary": "The Algorithm Selection Problem is concerned with selecting the best\nalgorithm to solve a given problem on a case-by-case basis. It has become\nespecially relevant in the last decade, as researchers are increasingly\ninvestigating how to identify the most suitable existing algorithm for solving\na problem instead of developing new algorithms. This survey presents an\noverview of this work focusing on the contributions made in the area of\ncombinatorial search problems, where Algorithm Selection techniques have\nachieved significant performance improvements. We unify and organise the vast\nliterature according to criteria that determine Algorithm Selection systems in\npractice. The comprehensive classification of approaches identifies and\nanalyses the different directions from which Algorithm Selection has been\napproached. This paper contrasts and compares different methods for solving the\nproblem as well as ways of using these solutions. It closes by identifying\ndirections of current and future research.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Towards a Multiagent Decision Support System for crisis Management",
        "authors": [
            "Fahem Kebair",
            "Fr\u00e9d\u00e9ric Serin"
        ],
        "summary": "Crisis management is a complex problem raised by the scientific community\ncurrently. Decision support systems are a suitable solution for such issues,\nthey are indeed able to help emergency managers to prevent and to manage crisis\nin emergency situations. However, they should be enough flexible and adaptive\nin order to be reliable to solve complex problems that are plunged in dynamic\nand unpredictable environments. The approach we propose in this paper addresses\nthis challenge. We expose here a modelling of information for an emergency\nenvironment and an architecture of a multiagent decision support system that\ndeals with these information in order to prevent and to manage the occur of a\ncrisis in emergency situations. We focus on the first level of the system\nmechanism which intends to perceive and to reflect the evolution of the current\nsituation. The general approach and experimentations are provided here.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Introduction to Neutrosophic Statistics",
        "authors": [
            "Florentin Smarandache"
        ],
        "summary": "Neutrosophic Statistics means statistical analysis of population or sample\nthat has indeterminate (imprecise, ambiguous, vague, incomplete, unknown) data.\nFor example, the population or sample size might not be exactly determinate\nbecause of some individuals that partially belong to the population or sample,\nand partially they do not belong, or individuals whose appurtenance is\ncompletely unknown. Also, there are population or sample individuals whose data\ncould be indeterminate. In this book, we develop the 1995 notion of\nneutrosophic statistics. We present various practical examples. It is possible\nto define the neutrosophic statistics in many ways, because there are various\ntypes of indeterminacies, depending on the problem to solve.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "A bio-inspired algorithm for fuzzy user equilibrium problem by aid of\n  Physarum Polycephalum",
        "authors": [
            "Yang Liu",
            "Xiaoge Zhang",
            "Yong Deng"
        ],
        "summary": "The user equilibrium in traffic assignment problem is based on the fact that\ntravelers choose the minimum-cost path between every origin-destination pair\nand on the assumption that such a behavior will lead to an equilibrium of the\ntraffic network. In this paper, we consider this problem when the traffic\nnetwork links are fuzzy cost. Therefore, a Physarum-type algorithm is developed\nto unify the Physarum network and the traffic network for taking full of\nadvantage of Physarum Polycephalum's adaptivity in network design to solve the\nuser equilibrium problem. Eventually, some experiments are used to test the\nperformance of this method. The results demonstrate that our approach is\ncompetitive when compared with other existing algorithms.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Argument Ranking with Categoriser Function",
        "authors": [
            "Fuan Pu",
            "Jian Luo",
            "Yulai Zhang",
            "Guiming Luo"
        ],
        "summary": "Recently, ranking-based semantics is proposed to rank-order arguments from\nthe most acceptable to the weakest one(s), which provides a graded assessment\nto arguments. In general, the ranking on arguments is derived from the strength\nvalues of the arguments. Categoriser function is a common approach that assigns\na strength value to a tree of arguments. When it encounters an argument system\nwith cycles, then the categoriser strength is the solution of the non-linear\nequations. However, there is no detail about the existence and uniqueness of\nthe solution, and how to find the solution (if exists). In this paper, we will\ncope with these issues via fixed point technique. In addition, we define the\ncategoriser-based ranking semantics in light of categoriser strength, and\ninvestigate some general properties of it. Finally, the semantics is shown to\nsatisfy some of the axioms that a ranking-based semantics should satisfy.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "A Combinatorial Optimisation Approach to Designing Dual-Parented\n  Long-Reach Passive Optical Networks",
        "authors": [
            "Hadrien Cambazard",
            "Deepak Mehta",
            "Barry O'Sullivan",
            "Luis Quesada",
            "Marco Ruffini",
            "David Payne",
            "Linda Doyle"
        ],
        "summary": "We present an application focused on the design of resilient long-reach\npassive optical networks. We specifically consider dual-parented networks\nwhereby each customer must be connected to two metro sites via local exchange\nsites. An important property of such a placement is resilience to single metro\nnode failure. The objective of the application is to determine the optimal\nposition of a set of metro nodes such that the total optical fibre length is\nminimized. We prove that this problem is NP-Complete. We present two\nalternative combinatorial optimisation approaches to finding an optimal metro\nnode placement using: a mixed integer linear programming (MIP) formulation of\nthe problem; and, a hybrid approach that uses clustering as a preprocessing\nstep. We consider a detailed case-study based on a network for Ireland. The\nhybrid approach scales well and finds solutions that are close to optimal, with\na runtime that is two orders-of-magnitude better than the MIP model.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Integrating Learning from Examples into the Search for Diagnostic\n  Policies",
        "authors": [
            "V. Bayer-Zubek",
            "T. G. Dietterich"
        ],
        "summary": "This paper studies the problem of learning diagnostic policies from training\nexamples. A diagnostic policy is a complete description of the decision-making\nactions of a diagnostician (i.e., tests followed by a diagnostic decision) for\nall possible combinations of test results. An optimal diagnostic policy is one\nthat minimizes the expected total cost, which is the sum of measurement costs\nand misdiagnosis costs. In most diagnostic settings, there is a tradeoff\nbetween these two kinds of costs. This paper formalizes diagnostic decision\nmaking as a Markov Decision Process (MDP). The paper introduces a new family of\nsystematic search algorithms based on the AO* algorithm to solve this MDP. To\nmake AO* efficient, the paper describes an admissible heuristic that enables\nAO* to prune large parts of the search space. The paper also introduces several\ngreedy algorithms including some improvements over previously-published\nmethods. The paper then addresses the question of learning diagnostic policies\nfrom examples. When the probabilities of diseases and test results are computed\nfrom training data, there is a great danger of overfitting. To reduce\noverfitting, regularizers are integrated into the search algorithms. Finally,\nthe paper compares the proposed methods on five benchmark diagnostic data sets.\nThe studies show that in most cases the systematic search methods produce\nbetter diagnostic policies than the greedy methods. In addition, the studies\nshow that for training sets of realistic size, the systematic search algorithms\nare practical on todays desktop computers.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "On the use of reference points for the biobjective Inventory Routing\n  Problem",
        "authors": [
            "Martin Josef Geiger",
            "Marc Sevaux"
        ],
        "summary": "The article presents a study on the biobjective inventory routing problem.\nContrary to most previous research, the problem is treated as a true\nmulti-objective optimization problem, with the goal of identifying\nPareto-optimal solutions. Due to the hardness of the problem at hand, a\nreference point based optimization approach is presented and implemented into\nan optimization and decision support system, which allows for the computation\nof a true subset of the optimal outcomes. Experimental investigation involving\nlocal search metaheuristics are conducted on benchmark data, and numerical\nresults are reported and analyzed.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Asynchronous Partial Overlay: A New Algorithm for Solving Distributed\n  Constraint Satisfaction Problems",
        "authors": [
            "V. R. Lesser",
            "R. Mailler"
        ],
        "summary": "Distributed Constraint Satisfaction (DCSP) has long been considered an\nimportant problem in multi-agent systems research. This is because many\nreal-world problems can be represented as constraint satisfaction and these\nproblems often present themselves in a distributed form. In this article, we\npresent a new complete, distributed algorithm called Asynchronous Partial\nOverlay (APO) for solving DCSPs that is based on a cooperative mediation\nprocess. The primary ideas behind this algorithm are that agents, when acting\nas a mediator, centralize small, relevant portions of the DCSP, that these\ncentralized subproblems overlap, and that agents increase the size of their\nsubproblems along critical paths within the DCSP as the problem solving\nunfolds. We present empirical evidence that shows that APO outperforms other\nknown, complete DCSP techniques.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Cognitive Principles in Robust Multimodal Interpretation",
        "authors": [
            "J. Y. Chai",
            "Z. Prasov",
            "S. Qu"
        ],
        "summary": "Multimodal conversational interfaces provide a natural means for users to\ncommunicate with computer systems through multiple modalities such as speech\nand gesture. To build effective multimodal interfaces, automated interpretation\nof user multimodal inputs is important. Inspired by the previous investigation\non cognitive status in multimodal human machine interaction, we have developed\na greedy algorithm for interpreting user referring expressions (i.e.,\nmultimodal reference resolution). This algorithm incorporates the cognitive\nprinciples of Conversational Implicature and Givenness Hierarchy and applies\nconstraints from various sources (e.g., temporal, semantic, and contextual) to\nresolve references. Our empirical results have shown the advantage of this\nalgorithm in efficiently resolving a variety of user references. Because of its\nsimplicity and generality, this approach has the potential to improve the\nrobustness of multimodal input interpretation.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial\n  Intelligence (2010)",
        "authors": [
            "Peter Grunwald",
            "Peter Spirtes"
        ],
        "summary": "This is the Proceedings of the Twenty-Sixth Conference on Uncertainty in\nArtificial Intelligence, which was held on Catalina Island, CA, July 8 - 11\n2010.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Measuring Inconsistency in Probabilistic Knowledge Bases",
        "authors": [
            "Matthias Thimm"
        ],
        "summary": "This paper develops an inconsistency measure on conditional probabilistic\nknowledge bases. The measure is based on fundamental principles for\ninconsistency measures and thus provides a solid theoretical framework for the\ntreatment of inconsistencies in probabilistic expert systems. We illustrate its\nusefulness and immediate application on several examples and present some\nformal results. Building on this measure we use the Shapley value-a well-known\nsolution for coalition games-to define a sophisticated indicator that is not\nonly able to measure inconsistencies but to reveal the causes of\ninconsistencies in the knowledge base. Altogether these tools guide the\nknowledge engineer in his aim to restore consistency and therefore enable him\nto build a consistent and usable knowledge base that can be employed in\nprobabilistic expert systems.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Logical Inference Algorithms and Matrix Representations for\n  Probabilistic Conditional Independence",
        "authors": [
            "Mathias Niepert"
        ],
        "summary": "Logical inference algorithms for conditional independence (CI) statements\nhave important applications from testing consistency during knowledge\nelicitation to constraintbased structure learning of graphical models. We prove\nthat the implication problem for CI statements is decidable, given that the\nsize of the domains of the random variables is known and fixed. We will present\nan approximate logical inference algorithm which combines a falsification and a\nnovel validation algorithm. The validation algorithm represents each set of CI\nstatements as a sparse 0-1 matrix A and validates instances of the implication\nproblem by solving specific linear programs with constraint matrix A. We will\nshow experimentally that the algorithm is both effective and efficient in\nvalidating and falsifying instances of the probabilistic CI implication\nproblem.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Operations on soft sets revisited",
        "authors": [
            "Ping Zhu",
            "Qiaoyan Wen"
        ],
        "summary": "Soft sets, as a mathematical tool for dealing with uncertainty, have recently\ngained considerable attention, including some successful applications in\ninformation processing, decision, demand analysis, and forecasting. To\nconstruct new soft sets from given soft sets, some operations on soft sets have\nbeen proposed. Unfortunately, such operations cannot keep all classical\nset-theoretic laws true for soft sets. In this paper, we redefine the\nintersection, complement, and difference of soft sets and investigate the\nalgebraic properties of these operations along with a known union operation. We\nfind that the new operation system on soft sets inherits all basic properties\nof operations on classical sets, which justifies our definitions.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Machine Recognition of Hand Written Characters using Neural Networks",
        "authors": [
            "Yusuf Perwej",
            "Ashish Chaturvedi"
        ],
        "summary": "Even today in Twenty First Century Handwritten communication has its own\nstand and most of the times, in daily life it is globally using as means of\ncommunication and recording the information like to be shared with others.\nChallenges in handwritten characters recognition wholly lie in the variation\nand distortion of handwritten characters, since different people may use\ndifferent style of handwriting, and direction to draw the same shape of the\ncharacters of their known script. This paper demonstrates the nature of\nhandwritten characters, conversion of handwritten data into electronic data,\nand the neural network approach to make machine capable of recognizing hand\nwritten characters.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Alternative Restart Strategies for CMA-ES",
        "authors": [
            "Ilya Loshchilov",
            "Marc Schoenauer",
            "Mich\u00e8le Sebag"
        ],
        "summary": "This paper focuses on the restart strategy of CMA-ES on multi-modal\nfunctions. A first alternative strategy proceeds by decreasing the initial\nstep-size of the mutation while doubling the population size at each restart. A\nsecond strategy adaptively allocates the computational budget among the restart\nsettings in the BIPOP scheme. Both restart strategies are validated on the BBOB\nbenchmark; their generality is also demonstrated on an independent real-world\nproblem suite related to spacecraft trajectory optimization.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Cost Sensitive Reachability Heuristics for Handling State Uncertainty",
        "authors": [
            "Daniel Bryce",
            "Subbarao Kambhampati"
        ],
        "summary": "While POMDPs provide a general platform for non-deterministic conditional\nplanning under a variety of quality metrics they have limited scalability. On\nthe other hand, non-deterministic conditional planners scale very well, but\nmany lack the ability to optimize plan quality metrics. We present a novel\ngeneralization of planning graph based heuristics that helps conditional\nplanners both scale and generate high quality plans when using actions with\nnonuniform costs. We make empirical comparisons with two state of the art\nplanners to show the benefit of our techniques.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Exploiting Evidence in Probabilistic Inference",
        "authors": [
            "Mark Chavira",
            "David Allen",
            "Adnan Darwiche"
        ],
        "summary": "We define the notion of compiling a Bayesian network with evidence and\nprovide a specific approach for evidence-based compilation, which makes use of\nlogical processing. The approach is practical and advantageous in a number of\napplication areas-including maximum likelihood estimation, sensitivity\nanalysis, and MAP computations-and we provide specific empirical results in the\ndomain of genetic linkage analysis. We also show that the approach is\napplicable for networks that do not contain determinism, and show that it\nempirically subsumes the performance of the quickscore algorithm when applied\nto noisy-or networks.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "A Revision-Based Approach to Resolving Conflicting Information",
        "authors": [
            "Guilin Qi",
            "Weiru Liu",
            "David A. Bell"
        ],
        "summary": "In this paper, we propose a revision-based approach for conflict resolution\nby generalizing the Disjunctive Maxi-Adjustment (DMA) approach (Benferhat et\nal. 2004). Revision operators can be classified into two different families:\nthe model-based ones and the formula-based ones. So the revision-based approach\nhas two different versions according to which family of revision operators is\nchosen. Two particular revision operators are considered, one is the Dalal's\nrevision operator, which is a model-based revision operator, and the other is\nthe cardinality-maximal based revision operator, which is a formulabased\nrevision operator. When the Dalal's revision operator is chosen, the\nrevision-based approach is independent of the syntactic form in each stratum\nand it captures some notion of minimal change. When the cardinalitymaximal\nbased revision operator is chosen, the revision-based approach is equivalent to\nthe DMA approach. We also show that both approaches are computationally easier\nthan the DMA approach.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Point-Based POMDP Algorithms: Improved Analysis and Implementation",
        "authors": [
            "Trey Smith",
            "Reid Simmons"
        ],
        "summary": "Existing complexity bounds for point-based POMDP value iteration algorithms\nfocus either on the curse of dimensionality or the curse of history. We derive\na new bound that relies on both and uses the concept of discounted\nreachability; our conclusions may help guide future algorithm design. We also\ndiscuss recent improvements to our (point-based) heuristic search value\niteration algorithm. Our new implementation calculates tighter initial bounds,\navoids solving linear programs, and makes more effective use of sparsity.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "The SeqBin Constraint Revisited",
        "authors": [
            "George Katsirelos",
            "Nina Narodytska",
            "Toby Walsh"
        ],
        "summary": "We revisit the SeqBin constraint. This meta-constraint subsumes a number of\nimportant global constraints like Change, Smooth and IncreasingNValue. We show\nthat the previously proposed filtering algorithm for SeqBin has two drawbacks\neven under strong restrictions: it does not detect bounds disentailment and it\nis not idempotent. We identify the cause for these problems, and propose a new\npropagator that overcomes both issues. Our algorithm is based on a connection\nto the problem of finding a path of a given cost in a restricted $n$-partite\ngraph. Our propagator enforces domain consistency in O(nd^2) and, for special\ncases of SeqBin that include Change, Smooth and IncreasingNValue, in O(nd)\ntime.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Etude de Mod\u00e8les \u00e0 base de r\u00e9seaux Bay\u00e9siens pour l'aide au\n  diagnostic de tumeurs c\u00e9r\u00e9brales",
        "authors": [
            "Fradj Ben Lamine",
            "Karim Kalti",
            "Mohamed Ali Mahjoub"
        ],
        "summary": "This article describes different models based on Bayesian networks RB\nmodeling expertise in the diagnosis of brain tumors. Indeed, they are well\nadapted to the representation of the uncertainty in the process of diagnosis of\nthese tumors. In our work, we first tested several structures derived from the\nBayesian network reasoning performed by doctors on the one hand and structures\ngenerated automatically on the other. This step aims to find the best structure\nthat increases diagnostic accuracy. The machine learning algorithms relate\nMWST-EM algorithms, SEM and SEM + T. To estimate the parameters of the Bayesian\nnetwork from a database incomplete, we have proposed an extension of the EM\nalgorithm by adding a priori knowledge in the form of the thresholds calculated\nby the first phase of the algorithm RBE . The very encouraging results obtained\nare discussed at the end of the paper",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "A Logic Programming Framework for Possibilistic Argumentation with Vague\n  Knowledge",
        "authors": [
            "Carlos Chesnevar",
            "Guillermo Simari",
            "Teresa Alsinet",
            "Lluis Godo"
        ],
        "summary": "Defeasible argumentation frameworks have evolved to become a sound setting to\nformalize commonsense, qualitative reasoning from incomplete and potentially\ninconsistent knowledge. Defeasible Logic Programming (DeLP) is a defeasible\nargumentation formalism based on an extension of logic programming. Although\nDeLP has been successfully integrated in a number of different real-world\napplications, DeLP cannot deal with explicit uncertainty, nor with vague\nknowledge, as defeasibility is directly encoded in the object language. This\npaper introduces P-DeLP, a new logic programming language that extends original\nDeLP capabilities for qualitative reasoning by incorporating the treatment of\npossibilistic uncertainty and fuzzy knowledge. Such features will be formalized\non the basis of PGL, a possibilistic logic based on Godel fuzzy logic.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Monotonicity in Bayesian Networks",
        "authors": [
            "Linda C. van der Gaag",
            "Hans L. Bodlaender",
            "Ad Feelders"
        ],
        "summary": "For many real-life Bayesian networks, common knowledge dictates that the\noutput established for the main variable of interest increases with higher\nvalues for the observable variables. We define two concepts of monotonicity to\ncapture this type of knowledge. We say that a network is isotone in\ndistribution if the probability distribution computed for the output variable\ngiven specific observations is stochastically dominated by any such\ndistribution given higher-ordered observations; a network is isotone in mode if\na probability distribution given higher observations has a higher mode. We show\nthat establishing whether a network exhibits any of these properties of\nmonotonicity is coNPPP-complete in general, and remains coNP-complete for\npolytrees. We present an approximate algorithm for deciding whether a network\nis monotone in distribution and illustrate its application to a real-life\nnetwork in oncology.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Heuristic Search Value Iteration for POMDPs",
        "authors": [
            "Trey Smith",
            "Reid Simmons"
        ],
        "summary": "We present a novel POMDP planning algorithm called heuristic search value\niteration (HSVI).HSVI is an anytime algorithm that returns a policy and a\nprovable bound on its regret with respect to the optimal policy. HSVI gets its\npower by combining two well-known techniques: attention-focusing search\nheuristics and piecewise linear convex representations of the value function.\nHSVI's soundness and convergence have been proven. On some benchmark problems\nfrom the literature, HSVI displays speedups of greater than 100 with respect to\nother state-of-the-art POMDP value iteration algorithms. We also apply HSVI to\na new rover exploration problem 10 times larger than most POMDP problems in the\nliterature.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "From Conditional Oughts to Qualitative Decision Theory",
        "authors": [
            "Judea Pearl"
        ],
        "summary": "The primary theme of this investigation is a decision theoretic account of\nconditional ought statements (e.g., \"You ought to do A, if C\") that rectifies\nglaring deficiencies in classical deontic logic. The resulting account forms a\nsound basis for qualitative decision theory, thus providing a framework for\nqualitative planning under uncertainty. In particular, we show that adding\ncausal relationships (in the form of a single graph) as part of an epistemic\nstate is sufficient to facilitate the analysis of action sequences, their\nconsequences, their interaction with observations, their expected utilities\nand, hence, the synthesis of plans and strategies under uncertainty.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Causal Independence for Knowledge Acquisition and Inference",
        "authors": [
            "David Heckerman"
        ],
        "summary": "I introduce a temporal belief-network representation of causal independence\nthat a knowledge engineer can use to elicit probabilistic models. Like the\ncurrent, atemporal belief-network representation of causal independence, the\nnew representation makes knowledge acquisition tractable. Unlike the atemproal\nrepresentation, however, the temporal representation can simplify inference,\nand does not require the use of unobservable variables. The representation is\nless general than is the atemporal representation, but appears to be useful for\nmany practical applications.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Sensitivity Analysis for Probability Assessments in Bayesian Networks",
        "authors": [
            "Kathryn Blackmond Laskey"
        ],
        "summary": "When eliciting probability models from experts, knowledge engineers may\ncompare the results of the model with expert judgment on test scenarios, then\nadjust model parameters to bring the behavior of the model more in line with\nthe expert's intuition. This paper presents a methodology for analytic\ncomputation of sensitivity values to measure the impact of small changes in a\nnetwork parameter on a target probability value or distribution. These values\ncan be used to guide knowledge elicitation. They can also be used in a gradient\ndescent algorithm to estimate parameter values that maximize a measure of\ngoodness-of-fit to both local and holistic probability assessments.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Relevant Explanations: Allowing Disjunctive Assignments",
        "authors": [
            "Solomon Eyal Shimony"
        ],
        "summary": "Relevance-based explanation is a scheme in which partial assignments to\nBayesian belief network variables are explanations (abductive conclusions). We\nallow variables to remain unassigned in explanations as long as they are\nirrelevant to the explanation, where irrelevance is defined in terms of\nstatistical independence. When multiple-valued variables exist in the system,\nespecially when subsets of values correspond to natural types of events, the\nover specification problem, alleviated by independence-based explanation,\nresurfaces. As a solution to that, as well as for addressing the question of\nexplanation specificity, it is desirable to collapse such a subset of values\ninto a single value on the fly. The equivalent method, which is adopted here,\nis to generalize the notion of assignments to allow disjunctive assignments. We\nproceed to define generalized independence based explanations as maximum\nposterior probability independence based generalized assignments (GIB-MAPs).\nGIB assignments are shown to have certain properties that ease the design of\nalgorithms for computing GIB-MAPs. One such algorithm is discussed here, as\nwell as suggestions for how other algorithms may be adapted to compute\nGIB-MAPs. GIB-MAP explanations still suffer from instability, a problem which\nmay be addressed using ?approximate? conditional independence as a condition\nfor irrelevance.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Incremental Probabilistic Inference",
        "authors": [
            "Bruce D'Ambrosio"
        ],
        "summary": "Propositional representation services such as truth maintenance systems offer\npowerful support for incremental, interleaved, problem-model construction and\nevaluation. Probabilistic inference systems, in contrast, have lagged behind in\nsupporting this incrementality typically demanded by problem solvers. The\nproblem, we argue, is that the basic task of probabilistic inference is\ntypically formulated at too large a grain-size. We show how a system built\naround a smaller grain-size inference task can have the desired incrementality\nand serve as the basis for a low-level (propositional) probabilistic\nrepresentation service.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Argument Calculus and Networks",
        "authors": [
            "Adnan Darwiche"
        ],
        "summary": "A major reason behind the success of probability calculus is that it\npossesses a number of valuable tools, which are based on the notion of\nprobabilistic independence. In this paper, I identify a notion of logical\nindependence that makes some of these tools available to a class of\npropositional databases, called argument databases. Specifically, I suggest a\ngraphical representation of argument databases, called argument networks, which\nresemble Bayesian networks. I also suggest an algorithm for reasoning with\nargument networks, which resembles a basic algorithm for reasoning with\nBayesian networks. Finally, I show that argument networks have several\napplications: Nonmonotonic reasoning, truth maintenance, and diagnosis.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "The Probability of a Possibility: Adding Uncertainty to Default Rules",
        "authors": [
            "Craig Boutilier"
        ],
        "summary": "We present a semantics for adding uncertainty to conditional logics for\ndefault reasoning and belief revision. We are able to treat conditional\nsentences as statements of conditional probability, and express rules for\nrevision such as \"If A were believed, then B would be believed to degree p.\"\nThis method of revision extends conditionalization by allowing meaningful\nrevision by sentences whose probability is zero. This is achieved through the\nuse of counterfactual probabilities. Thus, our system accounts for the best\nproperties of qualitative methods of update (in particular, the AGM theory of\nrevision) and probabilistic methods. We also show how our system can be viewed\nas a unification of probability theory and possibility theory, highlighting\ntheir orthogonality and providing a means for expressing the probability of a\npossibility. We also demonstrate the connection to Lewis's method of imaging.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Jeffrey's rule of conditioning generalized to belief functions",
        "authors": [
            "Philippe Smets"
        ],
        "summary": "Jeffrey's rule of conditioning has been proposed in order to revise a\nprobability measure by another probability function. We generalize it within\nthe framework of the models based on belief functions. We show that several\nforms of Jeffrey's conditionings can be defined that correspond to the\ngeometrical rule of conditioning and to Dempster's rule of conditioning,\nrespectively.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Modal Logics for Qualitative Possibility and Beliefs",
        "authors": [
            "Craig Boutilier"
        ],
        "summary": "Possibilistic logic has been proposed as a numerical formalism for reasoning\nwith uncertainty. There has been interest in developing qualitative accounts of\npossibility, as well as an explanation of the relationship between possibility\nand modal logics. We present two modal logics that can be used to represent and\nreason with qualitative statements of possibility and necessity. Within this\nmodal framework, we are able to identify interesting relationships between\npossibilistic logic, beliefs and conditionals. In particular, the most natural\nconditional definable via possibilistic means for default reasoning is\nidentical to Pearl's conditional for e-semantics.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Structural Controllability and Observability in Influence Diagrams",
        "authors": [
            "Brian Y. Chan",
            "Ross D. Shachter"
        ],
        "summary": "Influence diagram is a graphical representation of belief networks with\nuncertainty. This article studies the structural properties of a probabilistic\nmodel in an influence diagram. In particular, structural controllability\ntheorems and structural observability theorems are developed and algorithms are\nformulated. Controllability and observability are fundamental concepts in\ndynamic systems (Luenberger 1979). Controllability corresponds to the ability\nto control a system while observability analyzes the inferability of its\nvariables. Both properties can be determined by the ranks of the system\nmatrices. Structural controllability and observability, on the other hand,\nanalyze the property of a system with its structure only, without the specific\nknowledge of the values of its elements (tin 1974, Shields and Pearson 1976).\nThe structural analysis explores the connection between the structure of a\nmodel and the functional dependence among its elements. It is useful in\ncomprehending problem and formulating solution by challenging the underlying\nintuitions and detecting inconsistency in a model. This type of qualitative\nreasoning can sometimes provide insight even when there is insufficient\nnumerical information in a model.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Objection-Based Causal Networks",
        "authors": [
            "Adnan Darwiche"
        ],
        "summary": "This paper introduces the notion of objection-based causal networks which\nresemble probabilistic causal networks except that they are quantified using\nobjections. An objection is a logical sentence and denotes a condition under\nwhich a, causal dependency does not exist. Objection-based causal networks\nenjoy almost all the properties that make probabilistic causal networks\npopular, with the added advantage that objections are, arguably more intuitive\nthan probabilities.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Reasoning With Qualitative Probabilities Can Be Tractable",
        "authors": [
            "Moises Goldszmidt",
            "Judea Pearl"
        ],
        "summary": "We recently described a formalism for reasoning with if-then rules that re\nexpressed with different levels of firmness [18]. The formalism interprets\nthese rules as extreme conditional probability statements, specifying orders of\nmagnitude of disbelief, which impose constraints over possible rankings of\nworlds. It was shown that, once we compute a priority function Z+ on the rules,\nthe degree to which a given query is confirmed or denied can be computed in\nO(log n`) propositional satisfiability tests, where n is the number of rules in\nthe knowledge base. In this paper, we show that computing Z+ requires O(n2 X\nlog n) satisfiability tests, not an exponential number as was conjectured in\n[18], which reduces to polynomial complexity in the case of Horn expressions.\nWe also show how reasoning with imprecise observations can be incorporated in\nour formalism and how the popular notions of belief revision and epistemic\nentrenchment are embodied naturally and tractably.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "A computational scheme for Reasoning in Dynamic Probabilistic Networks",
        "authors": [
            "Uffe Kj\u00e6rulff"
        ],
        "summary": "A computational scheme for reasoning about dynamic systems using (causal)\nprobabilistic networks is presented. The scheme is based on the framework of\nLauritzen and Spiegelhalter (1988), and may be viewed as a generalization of\nthe inference methods of classical time-series analysis in the sense that it\nallows description of non-linear, multivariate dynamic systems with complex\nconditional independence structures. Further, the scheme provides a method for\nefficient backward smoothing and possibilities for efficient, approximate\nforecasting methods. The scheme has been implemented on top of the HUGIN shell.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Bayesian Meta-Reasoning: Determining Model Adequacy from Within a Small\n  World",
        "authors": [
            "Kathryn Blackmond Laskey"
        ],
        "summary": "This paper presents a Bayesian framework for assessing the adequacy of a\nmodel without the necessity of explicitly enumerating a specific alternate\nmodel. A test statistic is developed for tracking the performance of the model\nacross repeated problem instances. Asymptotic methods are used to derive an\napproximate distribution for the test statistic. When the model is rejected,\nthe individual components of the test statistic can be used to guide search for\nan alternate model.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "The Bounded Bayesian",
        "authors": [
            "Kathryn Blackmond Laskey"
        ],
        "summary": "The ideal Bayesian agent reasons from a global probability model, but real\nagents are restricted to simplified models which they know to be adequate only\nin restricted circumstances. Very little formal theory has been developed to\nhelp fallibly rational agents manage the process of constructing and revising\nsmall world models. The goal of this paper is to present a theoretical\nframework for analyzing model management approaches. For a probability\nforecasting problem, a search process over small world models is analyzed as an\napproximation to a larger-world model which the agent cannot explicitly\nenumerate or compute. Conditions are given under which the sequence of\nsmall-world models converges to the larger-world probabilities.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "The Nature of the Unnormalized Beliefs Encountered in the Transferable\n  Belief Model",
        "authors": [
            "Philippe Smets"
        ],
        "summary": "Within the transferable belief model, positive basic belief masses can be\nallocated to the empty set, leading to unnormalized belief functions. The\nnature of these unnormalized beliefs is analyzed.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Local Expression Languages for Probabilistic Dependence: a Preliminary\n  Report",
        "authors": [
            "Bruce D'Ambrosio"
        ],
        "summary": "We present a generalization of the local expression language used in the\nSymbolic Probabilistic Inference (SPI) approach to inference in belief nets\n[1l, [8]. The local expression language in SPI is the language in which the\ndependence of a node on its antecedents is described. The original language\nrepresented the dependence as a single monolithic conditional probability\ndistribution. The extended language provides a set of operators (*, +, and -)\nwhich can be used to specify methods for combining partial conditional\ndistributions. As one instance of the utility of this extension, we show how\nthis extended language can be used to capture the semantics, representational\nadvantages, and inferential complexity advantages of the \"noisy or\"\nrelationship.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "An Approximate Nonmyopic Computation for Value of Information",
        "authors": [
            "David Heckerman",
            "Eric J. Horvitz",
            "Blackford Middleton"
        ],
        "summary": "Value-of-information analyses provide a straightforward means for selecting\nthe best next observation to make, and for determining whether it is better to\ngather additional information or to act immediately. Determining the next best\ntest to perform, given a state of uncertainty about the world, requires a\nconsideration of the value of making all possible sequences of observations. In\npractice, decision analysts and expert-system designers have avoided the\nintractability of exact computation of the value of information by relying on a\nmyopic approximation. Myopic analyses are based on the assumption that only one\nadditional test will be performed, even when there is an opportunity to make a\nlarge number of observations. We present a nonmyopic approximation for value of\ninformation that bypasses the traditional myopic analyses by exploiting the\nstatistical properties of large samples.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Conflict and Surprise: Heuristics for Model Revision",
        "authors": [
            "Kathryn Blackmond Laskey"
        ],
        "summary": "Any probabilistic model of a problem is based on assumptions which, if\nviolated, invalidate the model. Users of probability based decision aids need\nto be alerted when cases arise that are not covered by the aid's model.\nDiagnosis of model failure is also necessary to control dynamic model\nconstruction and revision. This paper presents a set of decision theoretically\nmotivated heuristics for diagnosing situations in which a model is likely to\nprovide an inadequate representation of the process being modeled.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Formal Model of Uncertainty for Possibilistic Rules",
        "authors": [
            "Arthur Ramer"
        ],
        "summary": "Given a universe of discourse X-a domain of possible outcomes-an experiment\nmay consist of selecting one of its elements, subject to the operation of\nchance, or of observing the elements, subject to imprecision. A priori\nuncertainty about the actual result of the experiment may be quantified,\nrepresenting either the likelihood of the choice of :r_X or the degree to which\nany such X would be suitable as a description of the outcome. The former case\ncorresponds to a probability distribution, while the latter gives a possibility\nassignment on X. The study of such assignments and their properties falls\nwithin the purview of possibility theory [DP88, Y80, Z783. It, like probability\ntheory, assigns values between 0 and 1 to express likelihoods of outcomes.\nHere, however, the similarity ends. Possibility theory uses the maximum and\nminimum functions to combine uncertainties, whereas probability theory uses the\nplus and times operations. This leads to very dissimilar theories in terms of\nanalytical framework, even though they share several semantic concepts. One of\nthe shared concepts consists of expressing quantitatively the uncertainty\nassociated with a given distribution. In probability theory its value\ncorresponds to the gain of information that would result from conducting an\nexperiment and ascertaining an actual result. This gain of information can\nequally well be viewed as a decrease in uncertainty about the outcome of an\nexperiment. In this case the standard measure of information, and thus\nuncertainty, is Shannon entropy [AD75, G77]. It enjoys several advantages-it is\ncharacterized uniquely by a few, very natural properties, and it can be\nconveniently used in decision processes. This application is based on the\nprinciple of maximum entropy; it has become a popular method of relating\ndecisions to uncertainty. This paper demonstrates that an equally integrated\ntheory can be built on the foundation of possibility theory. We first show how\nto define measures of in formation and uncertainty for possibility assignments.\nNext we construct an information-based metric on the space of all possibility\ndistributions defined on a given domain. It allows us to capture the notion of\nproximity in information content among the distributions. Lastly, we show that\nall the above constructions can be carried out for continuous\ndistributions-possibility assignments on arbitrary measurable domains. We\nconsider this step very significant-finite domains of discourse are but\napproximations of the real-life infinite domains. If possibility theory is to\nrepresent real world situations, it must handle continuous distributions both\ndirectly and through finite approximations. In the last section we discuss a\nprinciple of maximum uncertainty for possibility distributions. We show how\nsuch a principle could be formalized as an inference rule. We also suggest it\ncould be derived as a consequence of simple assumptions about combining\ninformation. We would like to mention that possibility assignments can be\nviewed as fuzzy sets and that every fuzzy set gives rise to an assignment of\npossibilities. This correspondence has far reaching consequences in logic and\nin control theory. Our treatment here is independent of any special\ninterpretation; in particular we speak of possibility distributions and\npossibility measures, defining them as measurable mappings into the interval\n[0, 1]. Our presentation is intended as a self-contained, albeit terse summary.\nTopics discussed were selected with care, to demonstrate both the completeness\nand a certain elegance of the theory. Proofs are not included; we only offer\nillustrative examples.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "A Graph-Based Inference Method for Conditional Independence",
        "authors": [
            "Ross D. Shachter"
        ],
        "summary": "The graphoid axioms for conditional independence, originally described by\nDawid [1979], are fundamental to probabilistic reasoning [Pearl, 19881. Such\naxioms provide a mechanism for manipulating conditional independence assertions\nwithout resorting to their numerical definition. This paper explores a\nrepresentation for independence statements using multiple undirected graphs and\nsome simple graphical transformations. The independence statements derivable in\nthis system are equivalent to those obtainable by the graphoid axioms.\nTherefore, this is a purely graphical proof technique for conditional\nindependence.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Algorithms for Irrelevance-Based Partial MAPs",
        "authors": [
            "Solomon Eyal Shimony"
        ],
        "summary": "Irrelevance-based partial MAPs are useful constructs for domain-independent\nexplanation using belief networks. We look at two definitions for such partial\nMAPs, and prove important properties that are useful in designing algorithms\nfor computing them effectively. We make use of these properties in modifying\nour standard MAP best-first algorithm, so as to handle irrelevance-based\npartial MAPs.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "About Updating",
        "authors": [
            "Philippe Smets"
        ],
        "summary": "Survey of several forms of updating, with a practical illustrative example.\nWe study several updating (conditioning) schemes that emerge naturally from a\ncommon scenarion to provide some insights into their meaning. Updating is a\nsubtle operation and there is no single method, no single 'good' rule. The\nchoice of the appropriate rule must always be given due consideration. Planchet\n(1989) presents a mathematical survey of many rules. We focus on the practical\nmeaning of these rules. After summarizing the several rules for conditioning,\nwe present an illustrative example in which the various forms of conditioning\ncan be explained.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Properties of Answer Set Programming with Convex Generalized Atoms",
        "authors": [
            "Mario Alviano",
            "Wolfgang Faber"
        ],
        "summary": "In recent years, Answer Set Programming (ASP), logic programming under the\nstable model or answer set semantics, has seen several extensions by\ngeneralizing the notion of an atom in these programs: be it aggregate atoms,\nHEX atoms, generalized quantifiers, or abstract constraints, the idea is to\nhave more complicated satisfaction patterns in the lattice of Herbrand\ninterpretations than traditional, simple atoms. In this paper we refer to any\nof these constructs as generalized atoms. Several semantics with differing\ncharacteristics have been proposed for these extensions, rendering the big\npicture somewhat blurry. In this paper, we analyze the class of programs that\nhave convex generalized atoms (originally proposed by Liu and Truszczynski in\n[10]) in rule bodies and show that for this class many of the proposed\nsemantics coincide. This is an interesting result, since recently it has been\nshown that this class is the precise complexity boundary for the FLP semantics.\nWe investigate whether similar results also hold for other semantics, and\ndiscuss the implications of our findings.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Bounded Rational Decision-Making in Changing Environments",
        "authors": [
            "Jordi Grau-Moya",
            "Daniel A. Braun"
        ],
        "summary": "A perfectly rational decision-maker chooses the best action with the highest\nutility gain from a set of possible actions. The optimality principles that\ndescribe such decision processes do not take into account the computational\ncosts of finding the optimal action. Bounded rational decision-making addresses\nthis problem by specifically trading off information-processing costs and\nexpected utility. Interestingly, a similar trade-off between energy and entropy\narises when describing changes in thermodynamic systems. This similarity has\nbeen recently used to describe bounded rational agents. Crucially, this\nframework assumes that the environment does not change while the decision-maker\nis computing the optimal policy. When this requirement is not fulfilled, the\ndecision-maker will suffer inefficiencies in utility, that arise because the\ncurrent policy is optimal for an environment in the past. Here we borrow\nconcepts from non-equilibrium thermodynamics to quantify these inefficiencies\nand illustrate with simulations its relationship with computational resources.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Bounded Recursive Self-Improvement",
        "authors": [
            "E. Nivel",
            "K. R. Th\u00f3risson",
            "B. R. Steunebrink",
            "H. Dindo",
            "G. Pezzulo",
            "M. Rodriguez",
            "C. Hernandez",
            "D. Ognibene",
            "J. Schmidhuber",
            "R. Sanz",
            "H. P. Helgason",
            "A. Chella",
            "G. K. Jonsson"
        ],
        "summary": "We have designed a machine that becomes increasingly better at behaving in\nunderspecified circumstances, in a goal-directed way, on the job, by modeling\nitself and its environment as experience accumulates. Based on principles of\nautocatalysis, endogeny, and reflectivity, the work provides an architectural\nblueprint for constructing systems with high levels of operational autonomy in\nunderspecified circumstances, starting from a small seed. Through value-driven\ndynamic priority scheduling controlling the parallel execution of a vast number\nof reasoning threads, the system achieves recursive self-improvement after it\nleaves the lab, within the boundaries imposed by its designers. A prototype\nsystem has been implemented and demonstrated to learn a complex real-world\ntask, real-time multimodal dialogue with humans, by on-line observation. Our\nwork presents solutions to several challenges that must be solved for achieving\nartificial general intelligence.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Applications of Algorithmic Probability to the Philosophy of Mind",
        "authors": [
            "Gabriel Leuenberger"
        ],
        "summary": "This paper presents formulae that can solve various seemingly hopeless\nphilosophical conundrums. We discuss the simulation argument, teleportation,\nmind-uploading, the rationality of utilitarianism, and the ethics of exploiting\nartificial general intelligence. Our approach arises from combining the\nessential ideas of formalisms such as algorithmic probability, the universal\nintelligence measure, space-time-embedded intelligence, and Hutter's observer\nlocalization. We argue that such universal models can yield the ultimate\nsolutions, but a novel research direction would be required in order to find\ncomputationally efficient approximations thereof.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Rational Counterfactuals",
        "authors": [
            "Tshilidzi Marwala"
        ],
        "summary": "This paper introduces the concept of rational countefactuals which is an idea\nof identifying a counterfactual from the factual (whether perceived or real)\nthat maximizes the attainment of the desired consequent. In counterfactual\nthinking if we have a factual statement like: Saddam Hussein invaded Kuwait and\nconsequently George Bush declared war on Iraq then its counterfactuals is: If\nSaddam Hussein did not invade Kuwait then George Bush would not have declared\nwar on Iraq. The theory of rational counterfactuals is applied to identify the\nantecedent that gives the desired consequent necessary for rational decision\nmaking. The rational countefactual theory is applied to identify the values of\nvariables Allies, Contingency, Distance, Major Power, Capability, Democracy, as\nwell as Economic Interdependency that gives the desired consequent Peace.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "On the Role of Canonicity in Bottom-up Knowledge Compilation",
        "authors": [
            "Guy Van den Broeck",
            "Adnan Darwiche"
        ],
        "summary": "We consider the problem of bottom-up compilation of knowledge bases, which is\nusually predicated on the existence of a polytime function for combining\ncompilations using Boolean operators (usually called an Apply function). While\nsuch a polytime Apply function is known to exist for certain languages (e.g.,\nOBDDs) and not exist for others (e.g., DNNF), its existence for certain\nlanguages remains unknown. Among the latter is the recently introduced language\nof Sentential Decision Diagrams (SDDs), for which a polytime Apply function\nexists for unreduced SDDs, but remains unknown for reduced ones (i.e. canonical\nSDDs). We resolve this open question in this paper and consider some of its\ntheoretical and practical implications. Some of the findings we report question\nthe common wisdom on the relationship between bottom-up compilation, language\ncanonicity and the complexity of the Apply function.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Generalized Evidence Theory",
        "authors": [
            "Yong Deng"
        ],
        "summary": "Conflict management is still an open issue in the application of Dempster\nShafer evidence theory. A lot of works have been presented to address this\nissue. In this paper, a new theory, called as generalized evidence theory\n(GET), is proposed. Compared with existing methods, GET assumes that the\ngeneral situation is in open world due to the uncertainty and incomplete\nknowledge. The conflicting evidence is handled under the framework of GET. It\nis shown that the new theory can explain and deal with the conflicting evidence\nin a more reasonable way.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "n-Valued Refined Neutrosophic Logic and Its Applications to Physics",
        "authors": [
            "Florentin Smarandache"
        ],
        "summary": "In this paper we present a short history of logics: from particular cases of\n2-symbol or numerical valued logic to the general case of n-symbol or numerical\nvalued logic. We show generalizations of 2-valued Boolean logic to fuzzy logic,\nalso from the Kleene and Lukasiewicz 3-symbol valued logics or Belnap 4-symbol\nvalued logic to the most general n-symbol or numerical valued refined\nneutrosophic logic. Two classes of neutrosophic norm (n-norm) and neutrosophic\nconorm (n-conorm) are defined. Examples of applications of neutrosophic logic\nto physics are listed in the last section. Similar generalizations can be done\nfor n-Valued Refined Neutrosophic Set, and respectively n- Valued Refined\nNeutrosopjhic Probability.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "One-Step or Two-Step Optimization and the Overfitting Phenomenon: A Case\n  Study on Time Series Classification",
        "authors": [
            "Muhammad Marwan Muhammad Fuad"
        ],
        "summary": "For the last few decades, optimization has been developing at a fast rate.\nBio-inspired optimization algorithms are metaheuristics inspired by nature.\nThese algorithms have been applied to solve different problems in engineering,\neconomics, and other domains. Bio-inspired algorithms have also been applied in\ndifferent branches of information technology such as networking and software\nengineering. Time series data mining is a field of information technology that\nhas its share of these applications too. In previous works we showed how\nbio-inspired algorithms such as the genetic algorithms and differential\nevolution can be used to find the locations of the breakpoints used in the\nsymbolic aggregate approximation of time series representation, and in another\nwork we showed how we can utilize the particle swarm optimization, one of the\nfamous bio-inspired algorithms, to set weights to the different segments in the\nsymbolic aggregate approximation representation. In this paper we present, in\ntwo different approaches, a new meta optimization process that produces optimal\nlocations of the breakpoints in addition to optimal weights of the segments.\nThe experiments of time series classification task that we conducted show an\ninteresting example of how the overfitting phenomenon, a frequently encountered\nproblem in data mining which happens when the model overfits the training set,\ncan interfere in the optimization process and hide the superior performance of\nan optimization algorithm.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Representing and Reasoning about Game Strategies",
        "authors": [
            "Dongmo Zhang",
            "Michael Thielsher"
        ],
        "summary": "As a contribution to the challenge of building game-playing AI systems, we\ndevelop and analyse a formal language for representing and reasoning about\nstrategies. Our logical language builds on the existing general Game\nDescription Language (GDL) and extends it by a standard modality for linear\ntime along with two dual connectives to express preferences when combining\nstrategies. The semantics of the language is provided by a standard\nstate-transition model. As such, problems that require reasoning about games\ncan be solved by the standard methods for reasoning about actions and change.\nWe also endow the language with a specific semantics by which strategy formulas\nare understood as move recommendations for a player. To illustrate how our\nformalism supports automated reasoning about strategies, we demonstrate two\nexample methods of implementation\\/: first, we formalise the semantic\ninterpretation of our language in conjunction with game rules and strategy\nrules in the Situation Calculus; second, we show how the reasoning problem can\nbe solved with Answer Set Programming.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Modular Belief Updates and Confusion about Measures of Certainty in\n  Artificial Intelligence Research",
        "authors": [
            "Eric J. Horvitz",
            "David Heckerman"
        ],
        "summary": "Over the last decade, there has been growing interest in the use or measures\nor change in belief for reasoning with uncertainty in artificial intelligence\nresearch. An important characteristic of several methodologies that reason with\nchanges in belief or belief updates, is a property that we term modularity. We\ncall updates that satisfy this property modular updates. Whereas probabilistic\nmeasures of belief update - which satisfy the modularity property were first\ndiscovered in the nineteenth century, knowledge and discussion of these\nquantities remains obscure in artificial intelligence research. We define\nmodular updates and discuss their inappropriate use in two influential expert\nsystems.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Committment-Based Data-Aware Multi-Agent-Contexts Systems",
        "authors": [
            "Stefania Costantini"
        ],
        "summary": "Communication and interaction among agents have been the subject of extensive\ninvestigation since many years. Commitment-based communication, where\ncommunicating agents are seen as a debtor agent who is committed to a creditor\nagent to bring about something (possibly under some conditions) is now very\nwell-established. The approach of DACMAS (Data-Aware Commitment-based MAS)\nlifts commitment-related approaches proposed in the literature from a\npropositional to a first-order setting via the adoption the DRL-Lite\nDescription Logic. Notably, DACMASs provide, beyond commitments, simple forms\nof inter-agent event-based communication. Yet, the aspect is missing of making\na MAS able to acquire knowledge from contexts which are not agents and which\nare external to the MAS. This topic is coped with in Managed MCSs (Managed\nMulti-Context Systems), where however exchanges are among knowledge bases and\nnot agents. In this paper, we propose the new approach of DACmMCMASs\n(Data-Aware Commitment-based managed Multi- Context MAS), so as to obtain a\ncommitment-based first-order agent system which is able to interact with\nheterogeneous external information sources. We show that DACmMCMASs retain the\nnice formal properties of the original approaches.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Justifying and Improving Meta-Agent Conflict-Based Search",
        "authors": [
            "David Tolpin"
        ],
        "summary": "The Meta-Agent Conflict-Based Search~(MA-CBS) is a recently proposed\nalgorithm for the multi-agent path finding problem. The algorithm is an\nextension of Conflict-Based Search~(CBS), which automatically merges\nconflicting agents into meta-agents if the number of conflicts exceeds a\ncertain threshold. However, the decision to merge agents is made according to\nan empirically chosen fixed threshold on the number of conflicts. The best\nthreshold depends both on the domain and on the number of agents, and the\nnature of the dependence is not clearly understood.\n  We suggest a justification for the use of a fixed threshold on the number of\nconflicts based on the analysis of a model problem. Following the suggested\njustification, we introduce new decision policies for the MA-CBS algorithm,\nwhich considerably improve the algorithm's performance. The improved variants\nof the algorithm are evaluated on several sets of problems, chosen to underline\ndifferent aspects of the algorithms.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Lifted Probabilistic Inference for Asymmetric Graphical Models",
        "authors": [
            "Guy Van den Broeck",
            "Mathias Niepert"
        ],
        "summary": "Lifted probabilistic inference algorithms have been successfully applied to a\nlarge number of symmetric graphical models. Unfortunately, the majority of\nreal-world graphical models is asymmetric. This is even the case for relational\nrepresentations when evidence is given. Therefore, more recent work in the\ncommunity moved to making the models symmetric and then applying existing\nlifted inference algorithms. However, this approach has two shortcomings.\nFirst, all existing over-symmetric approximations require a relational\nrepresentation such as Markov logic networks. Second, the induced symmetries\noften change the distribution significantly, making the computed probabilities\nhighly biased. We present a framework for probabilistic sampling-based\ninference that only uses the induced approximate symmetries to propose steps in\na Metropolis-Hastings style Markov chain. The framework, therefore, leads to\nimproved probability estimates while remaining unbiased. Experiments\ndemonstrate that the approach outperforms existing MCMC algorithms.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Decision-theoretic rough sets-based three-way approximations of\n  interval-valued fuzzy sets",
        "authors": [
            "Guangming Lang"
        ],
        "summary": "In practical situations, interval-valued fuzzy sets are frequently\nencountered. In this paper, firstly, we present shadowed sets for interpreting\nand understanding interval fuzzy sets. We also provide an analytic solution to\ncomputing the pair of thresholds by searching for a balance of uncertainty in\nthe framework of shadowed sets. Secondly, we construct errors-based three-way\napproximations of interval-valued fuzzy sets. We also provide an alternative\ndecision-theoretic formulation for calculating the pair of thresholds by\ntransforming interval-valued loss functions into single-valued loss functions,\nin which the required thresholds are computed by minimizing decision costs.\nThirdly, we compute errors-based three-way approximations of interval-valued\nfuzzy sets by using interval-valued loss functions. Finally, we employ several\nexamples to illustrate that how to take an action for an object with\ninterval-valued membership grade by using interval-valued loss functions.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Constraint-based sequence mining using constraint programming",
        "authors": [
            "Benjamin Negrevergne",
            "Tias Guns"
        ],
        "summary": "The goal of constraint-based sequence mining is to find sequences of symbols\nthat are included in a large number of input sequences and that satisfy some\nconstraints specified by the user. Many constraints have been proposed in the\nliterature, but a general framework is still missing. We investigate the use of\nconstraint programming as general framework for this task. We first identify\nfour categories of constraints that are applicable to sequence mining. We then\npropose two constraint programming formulations. The first formulation\nintroduces a new global constraint called exists-embedding. This formulation is\nthe most efficient but does not support one type of constraint. To support such\nconstraints, we develop a second formulation that is more general but incurs\nmore overhead. Both formulations can use the projected database technique used\nin specialised algorithms. Experiments demonstrate the flexibility towards\nconstraint-based settings and compare the approach to existing methods.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Int{\u00e9}gration d'une mesure d'ind{\u00e9}pendance pour la fusion\n  d'informations",
        "authors": [
            "Mouloud Kharoune",
            "Arnaud Martin"
        ],
        "summary": "Many information sources are considered into data fusion in order to improve\nthe decision in terms of uncertainty and imprecision. For each technique used\nfor data fusion, the asumption on independance is usually made. We propose in\nthis article an approach to take into acount an independance measure befor to\nmake the combination of information in the context of the theory of belief\nfunctions.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "On Generalized Rectangular Fuzzy Model for Assessment",
        "authors": [
            "Igor Yakov Subbotin"
        ],
        "summary": "The article is dedicated to the analysis of the existing models for\nassessment based of the fuzzy logic centroid technique. A new Generalized\nRectangular Model were developed. Some generalizations of the existing models\nare offered.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Knowledge reduction of dynamic covering decision information systems\n  with immigration of more objects",
        "authors": [
            "Guangming Lang"
        ],
        "summary": "In practical situations, it is of interest to investigate computing\napproximations of sets as an important step of knowledge reduction of dynamic\ncovering decision information systems. In this paper, we present incremental\napproaches to computing the type-1 and type-2 characteristic matrices of\ndynamic coverings whose cardinalities increase with immigration of more\nobjects. We also present the incremental algorithms of computing the second and\nsixth lower and upper approximations of sets in dynamic covering approximation\nspaces.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Quantitative Analysis of Whether Machine Intelligence Can Surpass Human\n  Intelligence",
        "authors": [
            "Feng Liu",
            "Yong Shi"
        ],
        "summary": "Whether the machine intelligence can surpass the human intelligence is a\ncontroversial issue. On the basis of traditional IQ, this article presents the\nUniversal IQ test method suitable for both the machine intelligence and the\nhuman intelligence. With the method, machine and human intelligences were\ndivided into 4 major categories and 15 subcategories. A total of 50 search\nengines across the world and 150 persons at different ages were subject to the\nrelevant test. And then, the Universal IQ ranking list of 2014 for the test\nobjects was obtained.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Attacker and Defender Counting Approach for Abstract Argumentation",
        "authors": [
            "Fuan Pu",
            "Jian Luo",
            "Yulai Zhang",
            "Guiming Luo"
        ],
        "summary": "In Dung's abstract argumentation, arguments are either acceptable or\nunacceptable, given a chosen notion of acceptability. This gives a coarse way\nto compare arguments. In this paper, we propose a counting approach for a more\nfine-gained assessment to arguments by counting the number of their respective\nattackers and defenders based on argument graph and argument game. An argument\nis more acceptable if the proponent puts forward more number of defenders for\nit and the opponent puts forward less number of attackers against it. We show\nthat our counting model has two well-behaved properties: normalization and\nconvergence. Then, we define a counting semantics based on this model, and\ninvestigate some general properties of the semantics.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Artificial general intelligence through recursive data compression and\n  grounded reasoning: a position paper",
        "authors": [
            "Arthur Franz"
        ],
        "summary": "This paper presents a tentative outline for the construction of an\nartificial, generally intelligent system (AGI). It is argued that building a\ngeneral data compression algorithm solving all problems up to a complexity\nthreshold should be the main thrust of research. A measure for partial progress\nin AGI is suggested. Although the details are far from being clear, some\ngeneral properties for a general compression algorithm are fleshed out. Its\ninductive bias should be flexible and adapt to the input data while constantly\nsearching for a simple, orthogonal and complete set of hypotheses explaining\nthe data. It should recursively reduce the size of its representations thereby\ncompressing the data increasingly at every iteration.\n  Abstract Based on that fundamental ability, a grounded reasoning system is\nproposed. It is argued how grounding and flexible feature bases made of\nhypotheses allow for resourceful thinking. While the simulation of\nrepresentation contents on the mental stage accounts for much of the power of\npropositional logic, compression leads to simple sets of hypotheses that allow\nthe detection and verification of universally quantified statements.\n  Abstract Together, it is highlighted how general compression and grounded\nreasoning could account for the birth and growth of first concepts about the\nworld and the commonsense reasoning about them.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Complexity and Compilation of GZ-Aggregates in Answer Set Programming",
        "authors": [
            "Mario Alviano",
            "Nicola Leone"
        ],
        "summary": "Gelfond and Zhang recently proposed a new stable model semantics based on\nVicious Circle Principle in order to improve the interpretation of logic\nprograms with aggregates. The paper focuses on this proposal, and analyzes the\ncomplexity of both coherence testing and cautious reasoning under the new\nsemantics. Some surprising results highlight similarities and differences\nversus mainstream stable model semantics for aggregates. Moreover, the paper\nreports on the design of compilation techniques for implementing the new\nsemantics on top of existing ASP solvers, which eventually lead to realize a\nprototype system that allows for experimenting with Gelfond-Zhang's aggregates.\n  To appear in Theory and Practice of Logic Programming (TPLP), Proceedings of\nICLP 2015.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Reinforcement Learning for the Unit Commitment Problem",
        "authors": [
            "Gal Dalal",
            "Shie Mannor"
        ],
        "summary": "In this work we solve the day-ahead unit commitment (UC) problem, by\nformulating it as a Markov decision process (MDP) and finding a low-cost policy\nfor generation scheduling. We present two reinforcement learning algorithms,\nand devise a third one. We compare our results to previous work that uses\nsimulated annealing (SA), and show a 27% improvement in operation costs, with\nrunning time of 2.5 minutes (compared to 2.5 hours of existing\nstate-of-the-art).",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Unification of Fusion Theories, Rules, Filters, Image Fusion and Target\n  Tracking Methods (UFT)",
        "authors": [
            "Florentin Smarandache"
        ],
        "summary": "The author has pledged in various papers, conference or seminar\npresentations, and scientific grant applications (between 2004-2015) for the\nunification of fusion theories, combinations of fusion rules, image fusion\nprocedures, filter algorithms, and target tracking methods for more accurate\napplications to our real world problems - since neither fusion theory nor\nfusion rule fully satisfy all needed applications. For each particular\napplication, one selects the most appropriate fusion space and fusion model,\nthen the fusion rules, and the algorithms of implementation. He has worked in\nthe Unification of the Fusion Theories (UFT), which looks like a cooking\nrecipe, better one could say like a logical chart for a computer programmer,\nbut one does not see another method to comprise/unify all things. The\nunification scenario presented herein, which is now in an incipient form,\nshould periodically be updated incorporating new discoveries from the fusion\nand engineering research.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Optimal estimates for short horizon travel time prediction in urban\n  areas",
        "authors": [
            "Indre Zliobaite",
            "Mikhail Khokhlov"
        ],
        "summary": "Increasing popularity of mobile route planning applications based on GPS\ntechnology provides opportunities for collecting traffic data in urban\nenvironments. One of the main challenges for travel time estimation and\nprediction in such a setting is how to aggregate data from vehicles that have\nfollowed different routes, and predict travel time for other routes of\ninterest. One approach is to predict travel times for route segments, and sum\nthose estimates to obtain a prediction for the whole route. We study how to\nobtain optimal predictions in this scenario. It appears that the optimal\nestimate, minimizing the expected mean absolute error, is a combination of the\nmean and the median travel times on each segment, where the combination\nfunction depends on the number of segments in the route of interest. We present\na methodology for obtaining such predictions, and demonstrate its effectiveness\nwith a case study using travel time data from a district of St. Petersburg\ncollected over one year. The proposed methodology can be applied for real-time\nprediction of expected travel times in an urban road network.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Causal Decision Trees",
        "authors": [
            "Jiuyong Li",
            "Saisai Ma",
            "Thuc Duy Le",
            "Lin Liu",
            "Jixue Liu"
        ],
        "summary": "Uncovering causal relationships in data is a major objective of data\nanalytics. Causal relationships are normally discovered with designed\nexperiments, e.g. randomised controlled trials, which, however are expensive or\ninfeasible to be conducted in many cases. Causal relationships can also be\nfound using some well designed observational studies, but they require domain\nexperts' knowledge and the process is normally time consuming. Hence there is a\nneed for scalable and automated methods for causal relationship exploration in\ndata. Classification methods are fast and they could be practical substitutes\nfor finding causal signals in data. However, classification methods are not\ndesigned for causal discovery and a classification method may find false causal\nsignals and miss the true ones. In this paper, we develop a causal decision\ntree where nodes have causal interpretations. Our method follows a well\nestablished causal inference framework and makes use of a classic statistical\ntest. The method is practical for finding causal signals in large data sets.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "From Observational Studies to Causal Rule Mining",
        "authors": [
            "Jiuyong Li",
            "Thuc Duy Le",
            "Lin Liu",
            "Jixue Liu",
            "Zhou Jin",
            "Bingyu Sun",
            "Saisai Ma"
        ],
        "summary": "Randomised controlled trials (RCTs) are the most effective approach to causal\ndiscovery, but in many circumstances it is impossible to conduct RCTs.\nTherefore observational studies based on passively observed data are widely\naccepted as an alternative to RCTs. However, in observational studies, prior\nknowledge is required to generate the hypotheses about the cause-effect\nrelationships to be tested, hence they can only be applied to problems with\navailable domain knowledge and a handful of variables. In practice, many data\nsets are of high dimensionality, which leaves observational studies out of the\nopportunities for causal discovery from such a wealth of data sources. In\nanother direction, many efficient data mining methods have been developed to\nidentify associations among variables in large data sets. The problem is,\ncausal relationships imply associations, but the reverse is not always true.\nHowever we can see the synergy between the two paradigms here. Specifically,\nassociation rule mining can be used to deal with the high-dimensionality\nproblem while observational studies can be utilised to eliminate non-causal\nassociations. In this paper we propose the concept of causal rules (CRs) and\ndevelop an algorithm for mining CRs in large data sets. We use the idea of\nretrospective cohort studies to detect CRs based on the results of association\nrule mining. Experiments with both synthetic and real world data sets have\ndemonstrated the effectiveness and efficiency of CR mining. In comparison with\nthe commonly used causal discovery methods, the proposed approach in general is\nfaster and has better or competitive performance in finding correct or sensible\ncauses. It is also capable of finding a cause consisting of multiple variables,\na feature that other causal discovery methods do not possess.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Efficient Computation of Exact IRV Margins",
        "authors": [
            "Michelle Blom",
            "Peter J. Stuckey",
            "Vanessa J. Teague",
            "Ron Tidhar"
        ],
        "summary": "The margin of victory is easy to compute for many election schemes but\ndifficult for Instant Runoff Voting (IRV). This is important because arguments\nabout the correctness of an election outcome usually rely on the size of the\nelectoral margin. For example, risk-limiting audits require a knowledge of the\nmargin of victory in order to determine how much auditing is necessary. This\npaper presents a practical branch-and-bound algorithm for exact IRV margin\ncomputation that substantially improves on the current best-known approach.\nAlthough exponential in the worst case, our algorithm runs efficiently in\npractice on all the real examples we could find. We can efficiently discover\nexact margins on election instances that cannot be solved by the current\nstate-of-the-art.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Mining Combined Causes in Large Data Sets",
        "authors": [
            "Saisai Ma",
            "Jiuyong Li",
            "Lin Liu",
            "Thuc Duy Le"
        ],
        "summary": "In recent years, many methods have been developed for detecting causal\nrelationships in observational data. Some of them have the potential to tackle\nlarge data sets. However, these methods fail to discover a combined cause, i.e.\na multi-factor cause consisting of two or more component variables which\nindividually are not causes. A straightforward approach to uncovering a\ncombined cause is to include both individual and combined variables in the\ncausal discovery using existing methods, but this scheme is computationally\ninfeasible due to the huge number of combined variables. In this paper, we\npropose a novel approach to address this practical causal discovery problem,\ni.e. mining combined causes in large data sets. The experiments with both\nsynthetic and real world data sets show that the proposed method can obtain\nhigh-quality causal discoveries with a high computational efficiency.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Some Supplementaries to The Counting Semantics for Abstract\n  Argumentation",
        "authors": [
            "Fuan Pu",
            "Jian Luo",
            "Guiming Luo"
        ],
        "summary": "Dung's abstract argumentation framework consists of a set of interacting\narguments and a series of semantics for evaluating them. Those semantics\npartition the powerset of the set of arguments into two classes: extensions and\nnon-extensions. In order to reason with a specific semantics, one needs to take\na credulous or skeptical approach, i.e. an argument is eventually accepted, if\nit is accepted in one or all extensions, respectively. In our previous work\n\\cite{ref-pu2015counting}, we have proposed a novel semantics, called\n\\emph{counting semantics}, which allows for a more fine-grained assessment to\narguments by counting the number of their respective attackers and defenders\nbased on argument graph and argument game. In this paper, we continue our\nprevious work by presenting some supplementaries about how to choose the\ndamaging factor for the counting semantics, and what relationships with some\nexisting approaches, such as Dung's classical semantics, generic gradual\nvaluations. Lastly, an axiomatic perspective on the ranking semantics induced\nby our counting semantics are presented.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "A Common-Factor Approach for Multivariate Data Cleaning with an\n  Application to Mars Phoenix Mission Data",
        "authors": [
            "Dongping Fang",
            "Elizabeth Oberlin",
            "Wei Ding",
            "Samuel P. Kounaves"
        ],
        "summary": "Data quality is fundamentally important to ensure the reliability of data for\nstakeholders to make decisions. In real world applications, such as scientific\nexploration of extreme environments, it is unrealistic to require raw data\ncollected to be perfect. As data miners, when it is infeasible to physically\nknow the why and the how in order to clean up the data, we propose to seek the\nintrinsic structure of the signal to identify the common factors of\nmultivariate data. Using our new data driven learning method, the common-factor\ndata cleaning approach, we address an interdisciplinary challenge on\nmultivariate data cleaning when complex external impacts appear to interfere\nwith multiple data measurements. Existing data analyses typically process one\nsignal measurement at a time without considering the associations among all\nsignals. We analyze all signal measurements simultaneously to find the hidden\ncommon factors that drive all measurements to vary together, but not as a\nresult of the true data measurements. We use common factors to reduce the\nvariations in the data without changing the base mean level of the data to\navoid altering the physical meaning.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Universal and Determined Constructors of Multisets of Objects",
        "authors": [
            "Dmytro Terletskyi"
        ],
        "summary": "This paper contains analysis of creation of sets and multisets as an approach\nfor modeling of some aspects of human thinking. The creation of sets is\nconsidered within constructive object-oriented version of set theory (COOST),\nfrom different sides, in particular classical set theory, object-oriented\nprogramming (OOP) and development of intelligent information systems (IIS). The\nmain feature of COOST in contrast to other versions of set theory is an\nopportunity to describe essences of objects more precisely, using their\nproperties and methods, which can be applied to them. That is why this version\nof set theory is object-oriented and close to OOP. Within COOST, the author\nproposes universal constructor of multisets of objects that gives us a\npossibility to create arbitrary multisets of objects. In addition, a few\ndetermined constructors of multisets of objects, which allow creating\nmultisets, using strictly defined schemas, also are proposed in the paper. Such\nconstructors are very useful in cases of very big cardinalities of multisets,\nbecause they give us an opportunity to calculate a multiplicity of each object\nand cardinality of multiset before its creation. The proposed constructors of\nmultisets of objects allow us to model in a sense corresponding processes of\nhuman thought, that in turn give us an opportunity to develop IIS, using these\ntools.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Exploiters-Based Knowledge Extraction in Object-Oriented Knowledge\n  Representation",
        "authors": [
            "Dmytro Terletskyi"
        ],
        "summary": "This paper contains the consideration of knowledge extraction mechanisms of\nsuch object-oriented knowledge representation models as frames, object-oriented\nprogramming and object-oriented dynamic networks. In addition, conception of\nuniversal exploiters within object-oriented dynamic networks is also discussed.\nThe main result of the paper is introduction of new exploiters-based knowledge\nextraction approach, which provides generation of a finite set of new classes\nof objects, based on the basic set of classes. The methods for calculation of\nquantity of new classes, which can be obtained using proposed approach, and of\nquantity of types, which each of them describes, are proposed. Proof that basic\nset of classes, extended according to proposed approach, together with union\nexploiter create upper semilattice is given. The approach always allows\ngenerating of finitely defined set of new classes of objects for any\nobject-oriented dynamic network. A quantity of these classes can be precisely\ncalculated before the generation. It allows saving of only basic set of classes\nin the knowledge base.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Inheritance in Object-Oriented Knowledge Representation",
        "authors": [
            "Dmytro Terletskyi"
        ],
        "summary": "This paper contains the consideration of inheritance mechanism in such\nknowledge representation models as object-oriented programming, frames and\nobject-oriented dynamic networks. In addition, inheritance within\nrepresentation of vague and imprecise knowledge are also discussed. New types\nof inheritance, general classification of all known inheritance types and\napproach, which allows avoiding in many cases problems with exceptions,\nredundancy and ambiguity within object-oriented dynamic networks and their\nfuzzy extension, are introduced in the paper. The proposed approach bases on\nconception of homogeneous and inhomogeneous or heterogeneous class of objects,\nwhich allow building of inheritance hierarchy more flexibly and efficiently.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "On the Computability of AIXI",
        "authors": [
            "Jan Leike",
            "Marcus Hutter"
        ],
        "summary": "How could we solve the machine learning and the artificial intelligence\nproblem if we had infinite computation? Solomonoff induction and the\nreinforcement learning agent AIXI are proposed answers to this question. Both\nare known to be incomputable. In this paper, we quantify this using the\narithmetical hierarchy, and prove upper and corresponding lower bounds for\nincomputability. We show that AIXI is not limit computable, thus it cannot be\napproximated using finite computation. Our main result is a limit-computable\n{\\epsilon}-optimal version of AIXI with infinite horizon that maximizes\nexpected rewards.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Automatic Synthesis of Geometry Problems for an Intelligent Tutoring\n  System",
        "authors": [
            "Chris Alvin",
            "Sumit Gulwani",
            "Rupak Majumdar",
            "Supratik Mukhopadhyay"
        ],
        "summary": "This paper presents an intelligent tutoring system, GeoTutor, for Euclidean\nGeometry that is automatically able to synthesize proof problems and their\nrespective solutions given a geometric figure together with a set of properties\ntrue of it. GeoTutor can provide personalized practice problems that address\nstudent deficiencies in the subject matter.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Adaptive information-theoretic bounded rational decision-making with\n  parametric priors",
        "authors": [
            "Jordi Grau-Moya",
            "Daniel A. Braun"
        ],
        "summary": "Deviations from rational decision-making due to limited computational\nresources have been studied in the field of bounded rationality, originally\nproposed by Herbert Simon. There have been a number of different approaches to\nmodel bounded rationality ranging from optimality principles to heuristics.\nHere we take an information-theoretic approach to bounded rationality, where\ninformation-processing costs are measured by the relative entropy between a\nposterior decision strategy and a given fixed prior strategy. In the case of\nmultiple environments, it can be shown that there is an optimal prior rendering\nthe bounded rationality problem equivalent to the rate distortion problem for\nlossy compression in information theory. Accordingly, the optimal prior and\nposterior strategies can be computed by the well-known Blahut-Arimoto algorithm\nwhich requires the computation of partition sums over all possible outcomes and\ncannot be applied straightforwardly to continuous problems. Here we derive a\nsampling-based alternative update rule for the adaptation of prior behaviors of\ndecision-makers and we show convergence to the optimal prior predicted by rate\ndistortion theory. Importantly, the update rule avoids typical infeasible\noperations such as the computation of partition sums. We show in simulations a\nproof of concept for discrete action and environment domains. This approach is\nnot only interesting as a generic computational method, but might also provide\na more realistic model of human decision-making processes occurring on a fast\nand a slow time scale.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "ICON Challenge on Algorithm Selection",
        "authors": [
            "Lars Kotthoff"
        ],
        "summary": "We present the results of the ICON Challenge on Algorithm Selection.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Symbolic Neutrosophic Theory",
        "authors": [
            "Florentin Smarandache"
        ],
        "summary": "Symbolic (or Literal) Neutrosophic Theory is referring to the use of abstract\nsymbols (i.e. the letters T, I, F, or their refined indexed letters Tj, Ik, Fl)\nin neutrosophics. We extend the dialectical triad thesis-antithesis-synthesis\nto the neutrosophic tetrad thesis-antithesis-neutrothesis-neutrosynthesis. The\nwe introduce the neutrosophic system that is a quasi or (t,i,f) classical\nsystem, in the sense that the neutrosophic system deals with quasi-terms\n(concepts, attributes, etc.). Then the notions of Neutrosophic Axiom,\nNeutrosophic Deducibility, Degree of Contradiction (Dissimilarity) of Two\nNeutrosophic Axioms, etc. Afterwards a new type of structures, called (t, i, f)\nNeutrosophic Structures, and we show particular cases of such structures in\ngeometry and in algebra. Also, a short history of the neutrosophic set,\nneutrosophic numerical components and neutrosophic literal components,\nneutrosophic numbers, etc. We construct examples of splitting the literal\nindeterminacy (I) into literal subindeterminacies (I1, I2, and so on, Ir), and\nto define a multiplication law of these literal subindeterminacies in order to\nbe able to build refined I neutrosophic algebraic structures. We define three\nneutrosophic actions and their properties. We then introduce the prevalence\norder on T,I,F with respect to a given neutrosophic operator. And the\nrefinement of neutrosophic entities A, neutA, and antiA. Then we extend the\nclassical logical operators to neutrosophic literal (symbolic) logical\noperators and to refined literal (symbolic) logical operators, and we define\nthe refinement neutrosophic literal (symbolic) space. We introduce the\nneutrosophic quadruple numbers (a+bT+cI+dF) and the refined neutrosophic\nquadruple numbers. Then we define an absorbance law, based on a prevalence\norder, in order to multiply the neutrosophic quadruple numbers.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "A Study on Artificial Intelligence IQ and Standard Intelligent Model",
        "authors": [
            "Feng Liu",
            "Yong Shi"
        ],
        "summary": "Currently, potential threats of artificial intelligence (AI) to human have\ntriggered a large controversy in society, behind which, the nature of the issue\nis whether the artificial intelligence (AI) system can be evaluated\nquantitatively. This article analyzes and evaluates the challenges that the AI\ndevelopment level is facing, and proposes that the evaluation methods for the\nhuman intelligence test and the AI system are not uniform; and the key reason\nfor which is that none of the models can uniformly describe the AI system and\nthe beings like human. Aiming at this problem, a standard intelligent system\nmodel is established in this study to describe the AI system and the beings\nlike human uniformly. Based on the model, the article makes an abstract\nmathematical description, and builds the standard intelligent machine\nmathematical model; expands the Von Neumann architecture and proposes the\nLiufeng - Shiyong architecture; gives the definition of the artificial\nintelligence IQ, and establishes the artificial intelligence scale and the\nevaluation method; conduct the test on 50 search engines and three human\nsubjects at different ages across the world, and finally obtains the ranking of\nthe absolute IQ and deviation IQ ranking for artificial intelligence IQ 2014.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "The Singularity May Never Be Near",
        "authors": [
            "Toby Walsh"
        ],
        "summary": "There is both much optimism and pessimism around artificial intelligence (AI)\ntoday. The optimists are investing millions of dollars, and even in some cases\nbillions of dollars into AI. The pessimists, on the other hand, predict that AI\nwill end many things: jobs, warfare, and even the human race. Both the\noptimists and the pessimists often appeal to the idea of a technological\nsingularity, a point in time where machine intelligence starts to run away, and\na new, more intelligent species starts to inhabit the earth. If the optimists\nare right, this will be a moment that fundamentally changes our economy and our\nsociety. If the pessimists are right, this will be a moment that also\nfundamentally changes our economy and our society. It is therefore very\nworthwhile spending some time deciding if either of them might be right.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Toward Game Level Generation from Gameplay Videos",
        "authors": [
            "Matthew Guzdial",
            "Mark Riedl"
        ],
        "summary": "Algorithms that generate computer game content require game design knowledge.\nWe present an approach to automatically learn game design knowledge for level\ndesign from gameplay videos. We further demonstrate how the acquired design\nknowledge can be used to generate sections of game levels. Our approach\ninvolves parsing video of people playing a game to detect the appearance of\npatterns of sprites and utilizing machine learning to build a probabilistic\nmodel of sprite placement. We show how rich game design information can be\nautomatically parsed from gameplay videos and represented as a set of\ngenerative probabilistic models. We use Super Mario Bros. as a proof of\nconcept. We evaluate our approach on a measure of playability and stylistic\nsimilarity to the original levels as represented in the gameplay videos.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Scalable Bayesian Rule Lists",
        "authors": [
            "Hongyu Yang",
            "Cynthia Rudin",
            "Margo Seltzer"
        ],
        "summary": "We present an algorithm for building probabilistic rule lists that is two\norders of magnitude faster than previous work. Rule list algorithms are\ncompetitors for decision tree algorithms. They are associative classifiers, in\nthat they are built from pre-mined association rules. They have a logical\nstructure that is a sequence of IF-THEN rules, identical to a decision list or\none-sided decision tree. Instead of using greedy splitting and pruning like\ndecision tree algorithms, we fully optimize over rule lists, striking a\npractical balance between accuracy, interpretability, and computational speed.\nThe algorithm presented here uses a mixture of theoretical bounds (tight enough\nto have practical implications as a screening or bounding procedure),\ncomputational reuse, and highly tuned language libraries to achieve\ncomputational efficiency. Currently, for many practical problems, this method\nachieves better accuracy and sparsity than decision trees; further, in many\ncases, the computational time is practical and often less than that of decision\ntrees. The result is a probabilistic classifier (which estimates P(y = 1|x) for\neach x) that optimizes the posterior of a Bayesian hierarchical model over rule\nlists.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Learning to Blend Computer Game Levels",
        "authors": [
            "Matthew Guzdial",
            "Mark Riedl"
        ],
        "summary": "We present an approach to generate novel computer game levels that blend\ndifferent game concepts in an unsupervised fashion. Our primary contribution is\nan analogical reasoning process to construct blends between level design models\nlearned from gameplay videos. The models represent probabilistic relationships\nbetween elements in the game. An analogical reasoning process maps features\nbetween two models to produce blended models that can then generate new level\nchunks. As a proof-of-concept we train our system on the classic platformer\ngame Super Mario Bros. due to its highly-regarded and well understood level\ndesign. We evaluate the extent to which the models represent stylistic level\ndesign knowledge and demonstrate the ability of our system to explain levels\nthat were blended by human expert designers.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Hierarchical Linearly-Solvable Markov Decision Problems",
        "authors": [
            "Anders Jonsson",
            "Vicen\u00e7 G\u00f3mez"
        ],
        "summary": "We present a hierarchical reinforcement learning framework that formulates\neach task in the hierarchy as a special type of Markov decision process for\nwhich the Bellman equation is linear and has analytical solution. Problems of\nthis type, called linearly-solvable MDPs (LMDPs) have interesting properties\nthat can be exploited in a hierarchical setting, such as efficient learning of\nthe optimal value function or task compositionality. The proposed hierarchical\napproach can also be seen as a novel alternative to solving LMDPs with large\nstate spaces. We derive a hierarchical version of the so-called Z-learning\nalgorithm that learns different tasks simultaneously and show empirically that\nit significantly outperforms the state-of-the-art learning methods in two\nclassical hierarchical reinforcement learning domains: the taxi domain and an\nautonomous guided vehicle task.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Verifiability of Argumentation Semantics",
        "authors": [
            "Ringo Baumann",
            "Thomas Linsbichler",
            "Stefan Woltran"
        ],
        "summary": "Dung's abstract argumentation theory is a widely used formalism to model\nconflicting information and to draw conclusions in such situations. Hereby, the\nknowledge is represented by so-called argumentation frameworks (AFs) and the\nreasoning is done via semantics extracting acceptable sets. All reasonable\nsemantics are based on the notion of conflict-freeness which means that\narguments are only jointly acceptable when they are not linked within the AF.\nIn this paper, we study the question which information on top of conflict-free\nsets is needed to compute extensions of a semantics at hand. We introduce a\nhierarchy of so-called verification classes specifying the required amount of\ninformation. We show that well-known standard semantics are exactly verifiable\nthrough a certain such class. Our framework also gives a means to study\nsemantics lying inbetween known semantics, thus contributing to a more abstract\nunderstanding of the different features argumentation semantics offer.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Consciousness is Pattern Recognition",
        "authors": [
            "Ray Van De Walker"
        ],
        "summary": "This is a proof of the strong AI hypothesis, i.e. that machines can be\nconscious. It is a phenomenological proof that pattern-recognition and\nsubjective consciousness are the same activity in different terms. Therefore,\nit proves that essential subjective processes of consciousness are computable,\nand identifies significant traits and requirements of a conscious system. Since\nHusserl, many philosophers have accepted that consciousness consists of\nmemories of logical connections between an ego and external objects. These\nconnections are called \"intentions.\" Pattern recognition systems are achievable\ntechnical artifacts. The proof links this respected introspective philosophical\ntheory of consciousness with technical art. The proof therefore endorses the\nstrong AI hypothesis and may therefore also enable a theoretically-grounded\nform of artificial intelligence called a \"synthetic intentionality,\" able to\nsynthesize, generalize, select and repeat intentions. If the pattern\nrecognition is reflexive, able to operate on the set of intentions, and\nflexible, with several methods of synthesizing intentions, an SI may be a\nparticularly strong form of AI. Similarities and possible applications to\nseveral AI paradigms are discussed. The article then addresses some problems:\nThe proof's limitations, reflexive cognition, Searles' Chinese room, and how an\nSI could \"understand\" \"meanings\" and \"be creative.\"",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "On Avoidance Learning with Partial Observability",
        "authors": [
            "Tom J. Ameloot"
        ],
        "summary": "We study a framework where agents have to avoid aversive signals. The agents\nare given only partial information, in the form of features that are\nprojections of task states. Additionally, the agents have to cope with\nnon-determinism, defined as unpredictability on the way that actions are\nexecuted. The goal of each agent is to define its behavior based on\nfeature-action pairs that reliably avoid aversive signals. We study a learning\nalgorithm, called A-learning, that exhibits fixpoint convergence, where the\nbelief of the allowed feature-action pairs eventually becomes fixed. A-learning\nis parameter-free and easy to implement.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Differences between Industrial Models of Autonomy and Systemic Models of\n  Autonomy",
        "authors": [
            "Aleksander Lodwich"
        ],
        "summary": "This paper discusses the idea of levels of autonomy of systems - be this\ntechnical or organic - and compares the insights with models employed by\nindustries used to describe maturity and capability of their products.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "How to avoid ethically relevant Machine Consciousness",
        "authors": [
            "Aleksander Lodwich"
        ],
        "summary": "This paper discusses the root cause of systems perceiving the self experience\nand how to exploit adaptive and learning features without introducing ethically\nproblematic system properties.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "The belief noisy-or model applied to network reliability analysis",
        "authors": [
            "Kuang Zhou",
            "Arnaud Martin",
            "Quan Pan"
        ],
        "summary": "One difficulty faced in knowledge engineering for Bayesian Network (BN) is\nthe quan-tification step where the Conditional Probability Tables (CPTs) are\ndetermined. The number of parameters included in CPTs increases exponentially\nwith the number of parent variables. The most common solution is the\napplication of the so-called canonical gates. The Noisy-OR (NOR) gate, which\ntakes advantage of the independence of causal interactions, provides a\nlogarithmic reduction of the number of parameters required to specify a CPT. In\nthis paper, an extension of NOR model based on the theory of belief functions,\nnamed Belief Noisy-OR (BNOR), is proposed. BNOR is capable of dealing with both\naleatory and epistemic uncertainty of the network. Compared with NOR, more rich\ninformation which is of great value for making decisions can be got when the\navailable knowledge is uncertain. Specially, when there is no epistemic\nuncertainty, BNOR degrades into NOR. Additionally, different structures of BNOR\nare presented in this paper in order to meet various needs of engineers. The\napplication of BNOR model on the reliability evaluation problem of networked\nsystems demonstrates its effectiveness.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "On the Semantic Relationship between Probabilistic Soft Logic and Markov\n  Logic",
        "authors": [
            "Joohyung Lee",
            "Yi Wang"
        ],
        "summary": "Markov Logic Networks (MLN) and Probabilistic Soft Logic (PSL) are widely\napplied formalisms in Statistical Relational Learning, an emerging area in\nArtificial Intelligence that is concerned with combining logical and\nstatistical AI. Despite their resemblance, the relationship has not been\nformally stated. In this paper, we describe the precise semantic relationship\nbetween them from a logical perspective. This is facilitated by first extending\nfuzzy logic to allow weights, which can be also viewed as a generalization of\nPSL, and then relate that generalization to MLN. We observe that the\nrelationship between PSL and MLN is analogous to the known relationship between\nfuzzy logic and Boolean logic, and furthermore the weight scheme of PSL is\nessentially a generalization of the weight scheme of MLN for the many-valued\nsetting.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Exploring high-level Perspectives on Self-Configuration Capabilities of\n  Systems",
        "authors": [
            "Aleksander Lodwich"
        ],
        "summary": "Optimization of product performance repetitively introduces the need to make\nproducts adaptive in a more general sense. This more general idea is often\ncaptured under the term 'self-configuration'. Despite the importance of such\ncapability, research work on this feature appears isolated by technical\ndomains. It is not easy to tell quickly whether the approaches chosen in\ndifferent technological domains introduce new ideas or whether the differences\njust reflect domain idiosyncrasies. For the sake of easy identification of key\ndifferences between systems with self-configuring capabilities, I will explore\nhigher level concepts for understanding self-configuration, such as the\n{\\Omega}-units, in order to provide theoretical instruments for connecting\ndifferent areas of technology and research.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Neutrosophic Overset, Neutrosophic Underset, and Neutrosophic Offset.\n  Similarly for Neutrosophic Over-/Under-/Off- Logic, Probability, and\n  Statistics",
        "authors": [
            "Florentin Smarandache"
        ],
        "summary": "Neutrosophic Over-/Under-/Off-Set and -Logic were defined by the author in\n1995 and published for the first time in 2007. We extended the neutrosophic set\nrespectively to Neutrosophic Overset {when some neutrosophic component is over\n1}, Neutrosophic Underset {when some neutrosophic component is below 0}, and to\nNeutrosophic Offset {when some neutrosophic components are off the interval [0,\n1], i.e. some neutrosophic component over 1 and other neutrosophic component\nbelow 0}. This is no surprise with respect to the classical fuzzy set/logic,\nintuitionistic fuzzy set/logic, or classical/imprecise probability, where the\nvalues are not allowed outside the interval [0, 1], since our real-world has\nnumerous examples and applications of over-/under-/off-neutrosophic components.\nFor example, person working overtime deserves a membership degree over 1, while\na person producing more damage than benefit to a company deserves a membership\nbelow 0. Then, similarly, the Neutrosophic Logic/Measure/Probability/Statistics\netc. were extended to respectively Neutrosophic Over-/Under-/Off-Logic,\n-Measure, -Probability, -Statistics etc. [Smarandache, 2007].",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Query Answering in Resource-Based Answer Set Semantics",
        "authors": [
            "Stefania Costantini",
            "Andrea Formisano"
        ],
        "summary": "In recent work we defined resource-based answer set semantics, which is an\nextension to answer set semantics stemming from the study of its relationship\nwith linear logic. In fact, the name of the new semantics comes from the fact\nthat in the linear-logic formulation every literal (including negative ones)\nwere considered as a resource. In this paper, we propose a query-answering\nprocedure reminiscent of Prolog for answer set programs under this extended\nsemantics as an extension of XSB-resolution for logic programs with negation.\nWe prove formal properties of the proposed procedure.\n  Under consideration for acceptance in TPLP.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Proceedings of the Second Summer School on Argumentation: Computational\n  and Linguistic Perspectives (SSA'16)",
        "authors": [
            "Sarah A. Gaggl",
            "Matthias Thimm"
        ],
        "summary": "This volume contains the thesis abstracts presented at the Second Summer\nSchool on Argumentation: Computational and Linguistic Perspectives (SSA'2016)\nheld on September 8-12 in Potsdam, Germany.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Open Problem: Approximate Planning of POMDPs in the class of Memoryless\n  Policies",
        "authors": [
            "Kamyar Azizzadenesheli",
            "Alessandro Lazaric",
            "Animashree Anandkumar"
        ],
        "summary": "Planning plays an important role in the broad class of decision theory.\nPlanning has drawn much attention in recent work in the robotics and sequential\ndecision making areas. Recently, Reinforcement Learning (RL), as an\nagent-environment interaction problem, has brought further attention to\nplanning methods. Generally in RL, one can assume a generative model, e.g.\ngraphical models, for the environment, and then the task for the RL agent is to\nlearn the model parameters and find the optimal strategy based on these learnt\nparameters. Based on environment behavior, the agent can assume various types\nof generative models, e.g. Multi Armed Bandit for a static environment, or\nMarkov Decision Process (MDP) for a dynamic environment. The advantage of these\npopular models is their simplicity, which results in tractable methods of\nlearning the parameters and finding the optimal policy. The drawback of these\nmodels is again their simplicity: these models usually underfit and\nunderestimate the actual environment behavior. For example, in robotics, the\nagent usually has noisy observations of the environment inner state and MDP is\nnot a suitable model.\n  More complex models like Partially Observable Markov Decision Process (POMDP)\ncan compensate for this drawback. Fitting this model to the environment, where\nthe partial observation is given to the agent, generally gives dramatic\nperformance improvement, sometimes unbounded improvement, compared to MDP. In\ngeneral, finding the optimal policy for the POMDP model is computationally\nintractable and fully non convex, even for the class of memoryless policies.\nThe open problem is to come up with a method to find an exact or an approximate\noptimal stochastic memoryless policy for POMDP models.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Effective Multi-step Temporal-Difference Learning for Non-Linear\n  Function Approximation",
        "authors": [
            "Harm van Seijen"
        ],
        "summary": "Multi-step temporal-difference (TD) learning, where the update targets\ncontain information from multiple time steps ahead, is one of the most popular\nforms of TD learning for linear function approximation. The reason is that\nmulti-step methods often yield substantially better performance than their\nsingle-step counter-parts, due to a lower bias of the update targets. For\nnon-linear function approximation, however, single-step methods appear to be\nthe norm. Part of the reason could be that on many domains the popular\nmulti-step methods TD($\\lambda$) and Sarsa($\\lambda$) do not perform well when\ncombined with non-linear function approximation. In particular, they are very\nsusceptible to divergence of value estimates. In this paper, we identify the\nreason behind this. Furthermore, based on our analysis, we propose a new\nmulti-step TD method for non-linear function approximation that addresses this\nissue. We confirm the effectiveness of our method using two benchmark tasks\nwith neural networks as function approximation.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Achievements in Answer Set Programming (Preliminary Report)",
        "authors": [
            "Vladimir Lifschitz"
        ],
        "summary": "This paper describes an approach to the methodology of answer set programming\n(ASP) that can facilitate the design of encodings that are easy to understand\nand provably correct. Under this approach, after appending a rule or a small\ngroup of rules to the emerging program we include a comment that states what\nhas been \"achieved\" so far. This strategy allows us to set out our\nunderstanding of the design of the program by describing the roles of small\nparts of the program in a mathematically precise way.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Unifying task specification in reinforcement learning",
        "authors": [
            "Martha White"
        ],
        "summary": "Reinforcement learning tasks are typically specified as Markov decision\nprocesses. This formalism has been highly successful, though specifications\noften couple the dynamics of the environment and the learning objective. This\nlack of modularity can complicate generalization of the task specification, as\nwell as obfuscate connections between different task settings, such as episodic\nand continuing. In this work, we introduce the RL task formalism, that provides\na unification through simple constructs including a generalization to\ntransition-based discounting. Through a series of examples, we demonstrate the\ngenerality and utility of this formalism. Finally, we extend standard learning\nconstructs, including Bellman operators, and extend some seminal theoretical\nresults, including approximation errors bounds. Overall, we provide a\nwell-understood and sound formalism on which to build theoretical results and\nsimplify algorithm use and development.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "TODIM and TOPSIS with Z-numbers",
        "authors": [
            "R. A. Krohling",
            "Artem dos Santos",
            "A. G. C. Pacheco"
        ],
        "summary": "In this paper, we present an approach that is able to handle with Z-numbers\nin the context of Multi-Criteria Decision Making (MCDM) problems. Z-numbers are\ncomposed of two parts, the first one is a restriction on the values that can be\nassumed, and the second part is the reliability of the information. As human\nbeings we communicate with other people by means of natural language using\nsentences like: the journey time from home to university takes about half hour,\nvery likely. Firstly, Z-numbers are converted to fuzzy numbers using a standard\nprocedure. Next, the Z-TODIM and Z-TOPSIS are presented as a direct extension\nof the fuzzy TODIM and fuzzy TOPSIS, respectively. The proposed methods are\napplied to two case studies and compared with the standard approach using crisp\nvalues. Results obtained show the feasibility of the approach. In addition, a\ngraphical interface was built to handle with both methods Z- TODIM and Z-TOPSIS\nallowing ease of use for user in other areas of knowledge.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "A computer program for simulating time travel and a possible 'solution'\n  for the grandfather paradox",
        "authors": [
            "Doron Friedman"
        ],
        "summary": "While the possibility of time travel in physics is still debated, the\nexplosive growth of virtual-reality simulations opens up new possibilities to\nrigorously explore such time travel and its consequences in the digital domain.\nHere we provide a computational model of time travel and a computer program\nthat allows exploring digital time travel. In order to explain our method we\nformalize a simplified version of the famous grandfather paradox, show how the\nsystem can allow the participant to go back in time, try to kill their\nancestors before they were born, and experience the consequences. The system\nhas even come up with scenarios that can be considered consistent \"solutions\"\nof the grandfather paradox. We discuss the conditions for digital time travel,\nwhich indicate that it has a large number of practical applications.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Towards the Design of Prospect-Theory based Human Decision Rules for\n  Hypothesis Testing",
        "authors": [
            "V. Sriram Siddhardh Nadendla",
            "Swastik Brahma",
            "Pramod K. Varshney"
        ],
        "summary": "Detection rules have traditionally been designed for rational agents that\nminimize the Bayes risk (average decision cost). With the advent of\ncrowd-sensing systems, there is a need to redesign binary hypothesis testing\nrules for behavioral agents, whose cognitive behavior is not captured by\ntraditional utility functions such as Bayes risk. In this paper, we adopt\nprospect theory based models for decision makers. We consider special agent\nmodels namely optimists and pessimists in this paper, and derive optimal\ndetection rules under different scenarios. Using an illustrative example, we\nalso show how the decision rule of a human agent deviates from the Bayesian\ndecision rule under various behavioral models, considered in this paper.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Situational Awareness by Risk-Conscious Skills",
        "authors": [
            "Daniel J. Mankowitz",
            "Aviv Tamar",
            "Shie Mannor"
        ],
        "summary": "Hierarchical Reinforcement Learning has been previously shown to speed up the\nconvergence rate of RL planning algorithms as well as mitigate feature-based\nmodel misspecification (Mankowitz et. al. 2016a,b, Bacon 2015). To do so, it\nutilizes hierarchical abstractions, also known as skills -- a type of\ntemporally extended action (Sutton et. al. 1999) to plan at a higher level,\nabstracting away from the lower-level details. We incorporate risk sensitivity,\nalso referred to as Situational Awareness (SA), into hierarchical RL for the\nfirst time by defining and learning risk aware skills in a Probabilistic Goal\nSemi-Markov Decision Process (PG-SMDP). This is achieved using our novel\nSituational Awareness by Risk-Conscious Skills (SARiCoS) algorithm which comes\nwith a theoretical convergence guarantee. We show in a RoboCup soccer domain\nthat the learned risk aware skills exhibit complex human behaviors such as\n`time-wasting' in a soccer game. In addition, the learned risk aware skills are\nable to mitigate reward-based model misspecification.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "VRPBench: A Vehicle Routing Benchmark Tool",
        "authors": [
            "Guilherme A. Zeni",
            "Mauro Menzori",
            "P. S. Martins",
            "Luis A. A. Meira"
        ],
        "summary": "The number of optimization techniques in the combinatorial domain is large\nand diversified. Nevertheless, there is still a lack of real benchmarks to\nvalidate optimization algorithms. In this work we introduce VRPBench, a tool to\ncreate instances and visualize solutions to the Vehicle Routing Problem (VRP)\nin a planar graph embedded in the Euclidean 2D space. We use VRPBench to model\na real-world mail delivery case of the city of Artur Nogueira. Such scenarios\nwere characterized as a multi-objective optimization of the VRP. We extracted a\nweighted graph from a digital map of the city to create a challenging benchmark\nfor the VRP. Each instance models one generic day of mail delivery with\nhundreds to thousands of delivery points, thus allowing both the comparison and\nvalidation of optimization algorithms for routing problems.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Process Discovery using Inductive Miner and Decomposition",
        "authors": [
            "Raji Ghawi"
        ],
        "summary": "This report presents a submission to the Process Discovery Contest. The\ncontest is dedicated to the assessment of tools and techniques that discover\nbusiness process models from event logs. The objective is to compare the\nefficiency of techniques to discover process models that provide a proper\nbalance between \"overfitting\" and \"underfitting\". In the context of the Process\nDiscovery Contest, process discovery is turned into a classification task with\na training set and a test set; where a process model needs to decide whether\ntraces are fitting or not. In this report, we first show how we use two\ndiscovery techniques, namely: Inductive Miner and Decomposition, to discover\nprocess models from the training set using ProM tool. Second, we show how we\nuse replay results to 1) check the rediscoverability of models, and to 2)\nclassify unseen traces (in test logs) as fitting or not. Then, we discuss the\nclassification results of validation logs, the complexity of discovered models,\nand their impact on the selection of models for submission. The report ends\nwith the pictures of the submitted process models.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Inferring Coupling of Distributed Dynamical Systems via Transfer Entropy",
        "authors": [
            "Oliver M. Cliff",
            "Mikhail Prokopenko",
            "Robert Fitch"
        ],
        "summary": "In this work, we are interested in structure learning for a set of spatially\ndistributed dynamical systems, where individual subsystems are coupled via\nlatent variables and observed through a filter. We represent this model as a\ndirected acyclic graph (DAG) that characterises the unidirectional coupling\nbetween subsystems. Standard approaches to structure learning are not\napplicable in this framework due to the hidden variables, however we can\nexploit the properties of certain dynamical systems to formulate exact methods\nbased on state space reconstruction. We approach the problem by using\nreconstruction theorems to analytically derive a tractable expression for the\nKL-divergence of a candidate DAG from the observed dataset. We show this\nmeasure can be decomposed as a function of two information-theoretic measures,\ntransfer entropy and stochastic interaction. We then present two mathematically\nrobust scoring functions based on transfer entropy and statistical independence\ntests. These results support the previously held conjecture that transfer\nentropy can be used to infer effective connectivity in complex networks.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Double-quantitative $\u03b3^{\\ast}-$fuzzy coverings approximation\n  operators",
        "authors": [
            "Guangming Lang"
        ],
        "summary": "In digital-based information boom, the fuzzy covering rough set model is an\nimportant mathematical tool for artificial intelligence, and how to build the\nbridge between the fuzzy covering rough set theory and Pawlak's model is\nbecoming a hot research topic. In this paper, we first present the\n$\\gamma-$fuzzy covering based probabilistic and grade approximation operators\nand double-quantitative approximation operators. We also study the\nrelationships among the three types of $\\gamma-$fuzzy covering based\napproximation operators. Second, we propose the $\\gamma^{\\ast}-$fuzzy coverings\nbased multi-granulation probabilistic and grade lower and upper approximation\noperators and multi-granulation double-quantitative lower and upper\napproximation operators. We also investigate the relationships among these\ntypes of $\\gamma-$fuzzy coverings based approximation operators. Finally, we\nemploy several examples to illustrate how to construct the lower and upper\napproximations of fuzzy sets with the absolute and relative quantitative\ninformation.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Nonparametric General Reinforcement Learning",
        "authors": [
            "Jan Leike"
        ],
        "summary": "Reinforcement learning (RL) problems are often phrased in terms of Markov\ndecision processes (MDPs). In this thesis we go beyond MDPs and consider RL in\nenvironments that are non-Markovian, non-ergodic and only partially observable.\nOur focus is not on practical algorithms, but rather on the fundamental\nunderlying problems: How do we balance exploration and exploitation? How do we\nexplore optimally? When is an agent optimal? We follow the nonparametric\nrealizable paradigm.\n  We establish negative results on Bayesian RL agents, in particular AIXI. We\nshow that unlucky or adversarial choices of the prior cause the agent to\nmisbehave drastically. Therefore Legg-Hutter intelligence and balanced Pareto\noptimality, which depend crucially on the choice of the prior, are entirely\nsubjective. Moreover, in the class of all computable environments every policy\nis Pareto optimal. This undermines all existing optimality properties for AIXI.\nHowever, there are Bayesian approaches to general RL that satisfy objective\noptimality guarantees: We prove that Thompson sampling is asymptotically\noptimal in stochastic environments in the sense that its value converges to the\nvalue of the optimal policy. We connect asymptotic optimality to regret given a\nrecoverability assumption on the environment that allows the agent to recover\nfrom mistakes. Hence Thompson sampling achieves sublinear regret in these\nenvironments.\n  Our results culminate in a formal solution to the grain of truth problem: A\nBayesian agent acting in a multi-agent environment learns to predict the other\nagents' policies if its prior assigns positive probability to them (the prior\ncontains a grain of truth). We construct a large but limit computable class\ncontaining a grain of truth and show that agents based on Thompson sampling\nover this class converge to play Nash equilibria in arbitrary unknown\ncomputable multi-agent environments.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Fuzzy finite element model updating using metaheuristic optimization\n  algorithms",
        "authors": [
            "I. Boulkaibet",
            "T. Marwala",
            "M. I. Friswell",
            "H. Haddad Khodaparast",
            "S. Adhikari"
        ],
        "summary": "In this paper, a non-probabilistic method based on fuzzy logic is used to\nupdate finite element models (FEMs). Model updating techniques use the measured\ndata to improve the accuracy of numerical models of structures. However, the\nmeasured data are contaminated with experimental noise and the models are\ninaccurate due to randomness in the parameters. This kind of aleatory\nuncertainty is irreducible, and may decrease the accuracy of the finite element\nmodel updating process. However, uncertainty quantification methods can be used\nto identify the uncertainty in the updating parameters. In this paper, the\nuncertainties associated with the modal parameters are defined as fuzzy\nmembership functions, while the model updating procedure is defined as an\noptimization problem at each {\\alpha}-cut level. To determine the membership\nfunctions of the updated parameters, an objective function is defined and\nminimized using two metaheuristic optimization algorithms: ant colony\noptimization (ACO) and particle swarm optimization (PSO). A structural example\nis used to investigate the accuracy of the fuzzy model updating strategy using\nthe PSO and ACO algorithms. Furthermore, the results obtained by the fuzzy\nfinite element model updating are compared with the Bayesian model updating\nresults.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Autonomous Braking System via Deep Reinforcement Learning",
        "authors": [
            "Hyunmin Chae",
            "Chang Mook Kang",
            "ByeoungDo Kim",
            "Jaekyum Kim",
            "Chung Choo Chung",
            "Jun Won Choi"
        ],
        "summary": "In this paper, we propose a new autonomous braking system based on deep\nreinforcement learning. The proposed autonomous braking system automatically\ndecides whether to apply the brake at each time step when confronting the risk\nof collision using the information on the obstacle obtained by the sensors. The\nproblem of designing brake control is formulated as searching for the optimal\npolicy in Markov decision process (MDP) model where the state is given by the\nrelative position of the obstacle and the vehicle's speed, and the action space\nis defined as whether brake is stepped or not. The policy used for brake\ncontrol is learned through computer simulations using the deep reinforcement\nlearning method called deep Q-network (DQN). In order to derive desirable\nbraking policy, we propose the reward function which balances the damage\nimposed to the obstacle in case of accident and the reward achieved when the\nvehicle runs out of risk as soon as possible. DQN is trained for the scenario\nwhere a vehicle is encountered with a pedestrian crossing the urban road.\nExperiments show that the control agent exhibits desirable control behavior and\navoids collision without any mistake in various uncertain environments.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "T-SKIRT: Online Estimation of Student Proficiency in an Adaptive\n  Learning System",
        "authors": [
            "Chaitanya Ekanadham",
            "Yan Karklin"
        ],
        "summary": "We develop T-SKIRT: a temporal, structured-knowledge, IRT-based method for\npredicting student responses online. By explicitly accounting for student\nlearning and employing a structured, multidimensional representation of student\nproficiencies, the model outperforms standard IRT-based methods on an online\nresponse prediction task when applied to real responses collected from students\ninteracting with diverse pools of educational content.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "An Integer Programming Model for Binary Knapsack Problem with\n  Value-Related Dependencies among Elements",
        "authors": [
            "Davoud Mougouei",
            "David M. W. Powers",
            "Asghar Moeini"
        ],
        "summary": "Binary Knapsack Problem (BKP) is to select a subset of an element (item) set\nwith the highest value while keeping the total weight within the capacity of\nthe knapsack. This paper presents an integer programming model for a variation\nof BKP where the value of each element may depend on selecting or ignoring\nother elements. Strengths of such Value-Related Dependencies are assumed to be\nimprecise and hard to specify. To capture this imprecision, we have proposed\nmodeling value-related dependencies using fuzzy graphs and their algebraic\nstructure.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Minimizing Maximum Regret in Commitment Constrained Sequential Decision\n  Making",
        "authors": [
            "Qi Zhang",
            "Satinder Singh",
            "Edmund Durfee"
        ],
        "summary": "In cooperative multiagent planning, it can often be beneficial for an agent\nto make commitments about aspects of its behavior to others, allowing them in\nturn to plan their own behaviors without taking the agent's detailed behavior\ninto account. Extending previous work in the Bayesian setting, we consider\ninstead a worst-case setting in which the agent has a set of possible\nenvironments (MDPs) it could be in, and develop a commitment semantics that\nallows for probabilistic guarantees on the agent's behavior in any of the\nenvironments it could end up facing. Crucially, an agent receives observations\n(of reward and state transitions) that allow it to potentially eliminate\npossible environments and thus obtain higher utility by adapting its policy to\nthe history of observations. We develop algorithms and provide theory and some\npreliminary empirical results showing that they ensure an agent meets its\ncommitments with history-dependent policies while minimizing maximum regret\nover the possible environments.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Evolving Game Skill-Depth using General Video Game AI Agents",
        "authors": [
            "Jialin Liu",
            "Julian Togelius",
            "Diego Perez-Liebana",
            "Simon M. Lucas"
        ],
        "summary": "Most games have, or can be generalised to have, a number of parameters that\nmay be varied in order to provide instances of games that lead to very\ndifferent player experiences. The space of possible parameter settings can be\nseen as a search space, and we can therefore use a Random Mutation Hill\nClimbing algorithm or other search methods to find the parameter settings that\ninduce the best games. One of the hardest parts of this approach is defining a\nsuitable fitness function. In this paper we explore the possibility of using\none of a growing set of General Video Game AI agents to perform automatic\nplay-testing. This enables a very general approach to game evaluation based on\nestimating the skill-depth of a game. Agent-based play-testing is\ncomputationally expensive, so we compare two simple but efficient optimisation\nalgorithms: the Random Mutation Hill-Climber and the Multi-Armed Bandit Random\nMutation Hill-Climber. For the test game we use a space-battle game in order to\nprovide a suitable balance between simulation speed and potential skill-depth.\nResults show that both algorithms are able to rapidly evolve game versions with\nsignificant skill-depth, but that choosing a suitable resampling number is\nessential in order to combat the effects of noise.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Universal Reasoning, Rational Argumentation and Human-Machine\n  Interaction",
        "authors": [
            "Christoph Benzm\u00fcller"
        ],
        "summary": "Classical higher-order logic, when utilized as a meta-logic in which various\nother (classical and non-classical) logics can be shallowly embedded, is well\nsuited for realising a universal logic reasoning approach. Universal logic\nreasoning in turn, as envisioned already by Leibniz, may support the rigorous\nformalisation and deep logical analysis of rational arguments within machines.\nA respective universal logic reasoning framework is described and a range of\nexemplary applications are discussed. In the future, universal logic reasoning\nin combination with appropriate, controlled forms of rational argumentation may\nserve as a communication layer between humans and intelligent machines.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Basic Formal Properties of A Relational Model of The Mathematical Theory\n  of Evidence",
        "authors": [
            "Mieczys\u0142aw A. K\u0142opotek",
            "S\u0142awomir T. Wierzcho\u0144"
        ],
        "summary": "The paper presents a novel view of the Dempster-Shafer belief function as a\nmeasure of diversity in relational data bases. It is demonstrated that under\nthe interpretation The Dempster rule of evidence combination corresponds to the\njoin operator of the relational database theory. This rough-set based\ninterpretation is qualitative in nature and can represent a number of belief\nfunction operators.\n  The interpretation has the property that Given a definition of the belief\nmeasure of objects in the interpretation domain we can perform operations in\nthis domain and the measure of the resulting object is derivable from measures\nof component objects via belief operator. We demonstrated this property for\nDempster rule of combination, marginalization, Shafer's conditioning,\nindependent variables, Shenoy's notion of conditional independence of\nvariables.\n  The interpretation is based on rough sets (in connection with decision\ntables), but differs from previous interpretations of this type in that it\ncounts the diversity rather than frequencies in a decision table.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Beliefs and Probability in Bacchus' l.p. Logic: A~3-Valued Logic\n  Solution to Apparent Counter-intuition",
        "authors": [
            "Mieczys\u0142aw A. K\u0142opotek"
        ],
        "summary": "Fundamental discrepancy between first order logic and statistical inference\n(global versus local properties of universe) is shown to be the obstacle for\nintegration of logic and probability in L.p. logic of Bacchus. To overcome the\ncounterintuitiveness of L.p. behaviour, a 3-valued logic is proposed.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Beliefs in Markov Trees - From Local Computations to Local Valuation",
        "authors": [
            "Mieczys\u0142aw A. K\u0142opotek"
        ],
        "summary": "This paper is devoted to expressiveness of hypergraphs for which uncertainty\npropagation by local computations via Shenoy/Shafer method applies. It is\ndemonstrated that for this propagation method for a given joint belief\ndistribution no valuation of hyperedges of a hypergraph may provide with\nsimpler hypergraph structure than valuation of hyperedges by conditional\ndistributions. This has vital implication that methods recovering belief\nnetworks from data have no better alternative for finding the simplest\nhypergraph structure for belief propagation. A method for recovery\ntree-structured belief networks has been developed and specialized for\nDempster-Shafer belief functions",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Synergy of all-purpose static solver and temporal reasoning tools in\n  dynamic integrated expert systems",
        "authors": [
            "Galina Rybina",
            "Alexey Mozgachev",
            "Dmitry Demidov"
        ],
        "summary": "The paper discusses scientific and technological problems of dynamic\nintegrated expert systems development. Extensions of problem-oriented\nmethodology for dynamic integrated expert systems development are considered.\nAttention is paid to the temporal knowledge representation and processing.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Analysis of Vanilla Rolling Horizon Evolution Parameters in General\n  Video Game Playing",
        "authors": [
            "Raluca D. Gaina",
            "Jialin Liu",
            "Simon M. Lucas",
            "Diego Perez-Liebana"
        ],
        "summary": "Monte Carlo Tree Search techniques have generally dominated General Video\nGame Playing, but recent research has started looking at Evolutionary\nAlgorithms and their potential at matching Tree Search level of play or even\noutperforming these methods. Online or Rolling Horizon Evolution is one of the\noptions available to evolve sequences of actions for planning in General Video\nGame Playing, but no research has been done up to date that explores the\ncapabilities of the vanilla version of this algorithm in multiple games. This\nstudy aims to critically analyse the different configurations regarding\npopulation size and individual length in a set of 20 games from the General\nVideo Game AI corpus. Distinctions are made between deterministic and\nstochastic games, and the implications of using superior time budgets are\nstudied. Results show that there is scope for the use of these techniques,\nwhich in some configurations outperform Monte Carlo Tree Search, and also\nsuggest that further research in these methods could boost their performance.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Intelligent Personal Assistant with Knowledge Navigation",
        "authors": [
            "Amit Kumar",
            "Rahul Dutta",
            "Harbhajan Rai"
        ],
        "summary": "An Intelligent Personal Agent (IPA) is an agent that has the purpose of\nhelping the user to gain information through reliable resources with the help\nof knowledge navigation techniques and saving time to search the best content.\nThe agent is also responsible for responding to the chat-based queries with the\nhelp of Conversation Corpus. We will be testing different methods for optimal\nquery generation. To felicitate the ease of usage of the application, the agent\nwill be able to accept the input through Text (Keyboard), Voice (Speech\nRecognition) and Server (Facebook) and output responses using the same method.\nExisting chat bots reply by making changes in the input, but we will give\nresponses based on multiple SRT files. The model will learn using the human\ndialogs dataset and will be able respond human-like. Responses to queries about\nfamous things (places, people, and words) can be provided using web scraping\nwhich will enable the bot to have knowledge navigation features. The agent will\neven learn from its past experiences supporting semi-supervised learning.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "The Bag Semantics of Ontology-Based Data Access",
        "authors": [
            "Charalampos Nikolaou",
            "Egor V. Kostylev",
            "George Konstantinidis",
            "Mark Kaminski",
            "Bernardo Cuenca Grau",
            "Ian Horrocks"
        ],
        "summary": "Ontology-based data access (OBDA) is a popular approach for integrating and\nquerying multiple data sources by means of a shared ontology. The ontology is\nlinked to the sources using mappings, which assign views over the data to\nontology predicates. Motivated by the need for OBDA systems supporting\ndatabase-style aggregate queries, we propose a bag semantics for OBDA, where\nduplicate tuples in the views defined by the mappings are retained, as is the\ncase in standard databases. We show that bag semantics makes conjunctive query\nanswering in OBDA coNP-hard in data complexity. To regain tractability, we\nconsider a rather general class of queries and show its rewritability to a\ngeneralisation of the relational calculus to bags.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "XOR-Sampling for Network Design with Correlated Stochastic Events",
        "authors": [
            "Xiaojian Wu",
            "Yexiang Xue",
            "Bart Selman",
            "Carla P. Gomes"
        ],
        "summary": "Many network optimization problems can be formulated as stochastic network\ndesign problems in which edges are present or absent stochastically.\nFurthermore, protective actions can guarantee that edges will remain present.\nWe consider the problem of finding the optimal protection strategy under a\nbudget limit in order to maximize some connectivity measurements of the\nnetwork. Previous approaches rely on the assumption that edges are independent.\nIn this paper, we consider a more realistic setting where multiple edges are\nnot independent due to natural disasters or regional events that make the\nstates of multiple edges stochastically correlated. We use Markov Random Fields\nto model the correlation and define a new stochastic network design framework.\nWe provide a novel algorithm based on Sample Average Approximation (SAA)\ncoupled with a Gibbs or XOR sampler. The experimental results on real road\nnetwork data show that the policies produced by SAA with the XOR sampler have\nhigher quality and lower variance compared to SAA with Gibbs sampler.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Learning to Schedule Deadline- and Operator-Sensitive Tasks",
        "authors": [
            "Hanan Rosemarin",
            "John P. Dickerson",
            "Sarit Kraus"
        ],
        "summary": "The use of semi-autonomous and autonomous robotic assistants to aid in care\nof the elderly is expected to ease the burden on human caretakers, with\nsmall-stage testing already occurring in a variety of countries. Yet, it is\nlikely that these robots will need to request human assistance via\nteleoperation when domain expertise is needed for a specific task. As\ndeployment of robotic assistants moves to scale, mapping these requests for\nhuman aid to the teleoperators themselves will be a difficult online\noptimization problem. In this paper, we design a system that allocates requests\nto a limited number of teleoperators, each with different specialities, in an\nonline fashion. We generalize a recent model of online job scheduling with a\nworst-case competitive-ratio bound to our setting. Next, we design a scalable\nmachine-learning-based teleoperator-aware task scheduling algorithm and show,\nexperimentally, that it performs well when compared to an omniscient optimal\nscheduling algorithm.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Expert and Non-Expert Opinion about Technological Unemployment",
        "authors": [
            "Toby Walsh"
        ],
        "summary": "There is significant concern that technological advances, especially in\nRobotics and Artificial Intelligence (AI), could lead to high levels of\nunemployment in the coming decades. Studies have estimated that around half of\nall current jobs are at risk of automation. To look into this issue in more\ndepth, we surveyed experts in Robotics and AI about the risk, and compared\ntheir views with those of non-experts. Whilst the experts predicted a\nsignificant number of occupations were at risk of automation in the next two\ndecades, they were more cautious than people outside the field in predicting\noccupations at risk. Their predictions were consistent with their estimates for\nwhen computers might be expected to reach human level performance across a wide\nrange of skills. These estimates were typically decades later than those of the\nnon-experts. Technological barriers may therefore provide society with more\ntime to prepare for an automated future than the public fear. In addition,\npublic expectations may need to be dampened about the speed of progress to be\nexpected in Robotics and AI.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Optimal choice: new machine learning problem and its solution",
        "authors": [
            "Marina Sapir"
        ],
        "summary": "The task of learning to pick a single preferred example out a finite set of\nexamples, an \"optimal choice problem\", is a supervised machine learning problem\nwith complex, structured input. Problems of optimal choice emerge often in\nvarious practical applications. We formalize the problem, show that it does not\nsatisfy the assumptions of statistical learning theory, yet it can be solved\nefficiently in some cases. We propose two approaches to solve the problem. Both\nof them reach good solutions on real life data from a signal processing\napplication.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Learning Knowledge Graph Embeddings with Type Regularizer",
        "authors": [
            "Bhushan Kotnis",
            "Vivi Nastase"
        ],
        "summary": "Learning relations based on evidence from knowledge bases relies on\nprocessing the available relation instances. Many relations, however, have\nclear domain and range, which we hypothesize could help learn a better, more\ngeneralizing, model. We include such information in the RESCAL model in the\nform of a regularization factor added to the loss function that takes into\naccount the types (categories) of the entities that appear as arguments to\nrelations in the knowledge base. We note increased performance compared to the\nbaseline model in terms of mean reciprocal rank and hits@N, N = 1, 3, 10.\nFurthermore, we discover scenarios that significantly impact the effectiveness\nof the type regularizer.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Restricted Causal Inference Algorithm",
        "authors": [
            "Mieczys\u0142aw A. K\u0142opotek"
        ],
        "summary": "This paper proposes a new algorithm for recovery of belief network structure\nfrom data handling hidden variables. It consists essentially in an extension of\nthe CI algorithm of Spirtes et al. by restricting the number of conditional\ndependencies checked up to k variables and in an extension of the original CI\nby additional steps transforming so called partial including path graph into a\nbelief network. Its correctness is demonstrated.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "A study of existing Ontologies in the IoT-domain",
        "authors": [
            "Garvita Bajaj",
            "Rachit Agarwal",
            "Pushpendra Singh",
            "Nikolaos Georgantas",
            "Valerie Issarny"
        ],
        "summary": "Several domains have adopted the increasing use of IoT-based devices to\ncollect sensor data for generating abstractions and perceptions of the real\nworld. This sensor data is multi-modal and heterogeneous in nature. This\nheterogeneity induces interoperability issues while developing cross-domain\napplications, thereby restricting the possibility of reusing sensor data to\ndevelop new applications. As a solution to this, semantic approaches have been\nproposed in the literature to tackle problems related to interoperability of\nsensor data. Several ontologies have been proposed to handle different aspects\nof IoT-based sensor data collection, ranging from discovering the IoT sensors\nfor data collection to applying reasoning on the collected sensor data for\ndrawing inferences. In this paper, we survey these existing semantic ontologies\nto provide an overview of the recent developments in this field. We highlight\nthe fundamental ontological concepts (e.g., sensor-capabilities and\ncontext-awareness) required for an IoT-based application, and survey the\nexisting ontologies which include these concepts. Based on our study, we also\nidentify the shortcomings of currently available ontologies, which serves as a\nstepping stone to state the need for a common unified ontology for the IoT\ndomain.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Model enumeration in propositional circumscription via unsatisfiable\n  core analysis",
        "authors": [
            "Mario Alviano"
        ],
        "summary": "Many practical problems are characterized by a preference relation over\nadmissible solutions, where preferred solutions are minimal in some sense. For\nexample, a preferred diagnosis usually comprises a minimal set of reasons that\nis sufficient to cause the observed anomaly. Alternatively, a minimal\ncorrection subset comprises a minimal set of reasons whose deletion is\nsufficient to eliminate the observed anomaly. Circumscription formalizes such\npreference relations by associating propositional theories with minimal models.\nThe resulting enumeration problem is addressed here by means of a new algorithm\ntaking advantage of unsatisfiable core analysis. Empirical evidence of the\nefficiency of the algorithm is given by comparing the performance of the\nresulting solver, CIRCUMSCRIPTINO, with HCLASP, CAMUS MCS, LBX and MCSLS on the\nenumeration of minimal models for problems originating from practical\napplications.\n  This paper is under consideration for acceptance in TPLP.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Independence, Conditionality and Structure of Dempster-Shafer Belief\n  Functions",
        "authors": [
            "Mieczys\u0142aw A. K\u0142opotek"
        ],
        "summary": "Several approaches of structuring (factorization, decomposition) of\nDempster-Shafer joint belief functions from literature are reviewed with\nspecial emphasis on their capability to capture independence from the point of\nview of the claim that belief functions generalize bayes notion of probability.\n  It is demonstrated that Zhu and Lee's {Zhu:93} logical networks and Smets'\n{Smets:93} directed acyclic graphs are unable to capture statistical\ndependence/independence of bayesian networks {Pearl:88}. On the other hand,\nthough Shenoy and Shafer's hypergraphs can explicitly represent bayesian\nnetwork factorization of bayesian belief functions, they disclaim any need for\nrepresentation of independence of variables in belief functions.\n  Cano et al. {Cano:93} reject the hypergraph representation of Shenoy and\nShafer just on grounds of missing representation of variable independence, but\nin their frameworks some belief functions factorizable in Shenoy/Shafer\nframework cannot be factored.\n  The approach in {Klopotek:93f} on the other hand combines the merits of both\nCano et al. and of Shenoy/Shafer approach in that for Shenoy/Shafer approach no\nsimpler factorization than that in {Klopotek:93f} approach exists and on the\nother hand all independences among variables captured in Cano et al. framework\nand many more are captured in {Klopotek:93f} approach.%",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Identification and Interpretation of Belief Structure in Dempster-Shafer\n  Theory",
        "authors": [
            "Mieczys\u0142aw A. K\u0142opotek"
        ],
        "summary": "Mathematical Theory of Evidence called also Dempster-Shafer Theory (DST) is\nknown as a foundation for reasoning when knowledge is expressed at various\nlevels of detail. Though much research effort has been committed to this theory\nsince its foundation, many questions remain open. One of the most important\nopen questions seems to be the relationship between frequencies and the\nMathematical Theory of Evidence. The theory is blamed to leave frequencies\noutside (or aside of) its framework. The seriousness of this accusation is\nobvious: (1) no experiment may be run to compare the performance of DST-based\nmodels of real world processes against real world data, (2) data may not serve\nas foundation for construction of an appropriate belief model.\n  In this paper we develop a frequentist interpretation of the DST bringing to\nfall the above argument against DST. An immediate consequence of it is the\npossibility to develop algorithms acquiring automatically DST belief models\nfrom data. We propose three such algorithms for various classes of belief model\nstructures: for tree structured belief networks, for poly-tree belief networks\nand for general type belief networks.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "A Formal Framework to Characterize Interpretability of Procedures",
        "authors": [
            "Amit Dhurandhar",
            "Vijay Iyengar",
            "Ronny Luss",
            "Karthikeyan Shanmugam"
        ],
        "summary": "We provide a novel notion of what it means to be interpretable, looking past\nthe usual association with human understanding. Our key insight is that\ninterpretability is not an absolute concept and so we define it relative to a\ntarget model, which may or may not be a human. We define a framework that\nallows for comparing interpretable procedures by linking it to important\npractical aspects such as accuracy and robustness. We characterize many of the\ncurrent state-of-the-art interpretable methods in our framework portraying its\ngeneral applicability.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "On (Anti)Conditional Independence in Dempster-Shafer Theory",
        "authors": [
            "Mieczys\u0142aw A. K\u0142opotek"
        ],
        "summary": "This paper verifies a result of {Shenoy:94} concerning graphoidal structure\nof Shenoy's notion of independence for Dempster-Shafer theory of belief\nfunctions. Shenoy proved that his notion of independence has graphoidal\nproperties for positive normal valuations.\n  The requirement of strict positive normal valuations as prerequisite for\napplication of graphoidal properties excludes a wide class of DS belief\nfunctions. It excludes especially so-called probabilistic belief functions. It\nis demonstrated that the requirement of positiveness of valuation may be\nweakened in that it may be required that commonality function is non-zero for\nsingleton sets instead, and the graphoidal properties for independence of\nbelief function variables are then preserved. This means especially that\nprobabilistic belief functions with all singleton sets as focal points possess\ngraphoidal properties for independence.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Fast Restricted Causal Inference",
        "authors": [
            "Mieczys\u0142aw A. K\u0142opotek"
        ],
        "summary": "Hidden variables are well known sources of disturbance when recovering belief\nnetworks from data based only on measurable variables. Hence models assuming\nexistence of hidden variables are under development.\n  This paper presents a new algorithm \"accelerating\" the known CI algorithm of\nSpirtes, Glymour and Scheines {Spirtes:93}. We prove that this algorithm does\nnot produces (conditional) independencies not present in the data if\nstatistical independence test is reliable.\n  This result is to be considered as non-trivial since e.g. the same claim\nfails to be true for FCI algorithm, another \"accelerator\" of CI, developed in\n{Spirtes:93}.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Mutual Alignment Transfer Learning",
        "authors": [
            "Markus Wulfmeier",
            "Ingmar Posner",
            "Pieter Abbeel"
        ],
        "summary": "Training robots for operation in the real world is a complex, time consuming\nand potentially expensive task. Despite significant success of reinforcement\nlearning in games and simulations, research in real robot applications has not\nbeen able to match similar progress. While sample complexity can be reduced by\ntraining policies in simulation, such policies can perform sub-optimally on the\nreal platform given imperfect calibration of model dynamics. We present an\napproach -- supplemental to fine tuning on the real robot -- to further benefit\nfrom parallel access to a simulator during training and reduce sample\nrequirements on the real robot. The developed approach harnesses auxiliary\nrewards to guide the exploration for the real world agent based on the\nproficiency of the agent in simulation and vice versa. In this context, we\ndemonstrate empirically that the reciprocal alignment for both agents provides\nfurther benefit as the agent in simulation can adjust to optimize its behaviour\nfor states commonly visited by the real-world agent.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Evidence combination for a large number of sources",
        "authors": [
            "Kuang Zhou",
            "Arnaud Martin",
            "Quan Pan"
        ],
        "summary": "The theory of belief functions is an effective tool to deal with the multiple\nuncertain information. In recent years, many evidence combination rules have\nbeen proposed in this framework, such as the conjunctive rule, the cautious\nrule, the PCR (Proportional Conflict Redistribution) rules and so on. These\nrules can be adopted for different types of sources. However, most of these\nrules are not applicable when the number of sources is large. This is due to\neither the complexity or the existence of an absorbing element (such as the\ntotal conflict mass function for the conjunctive-based rules when applied on\nunreliable evidence). In this paper, based on the assumption that the majority\nof sources are reliable, a combination rule for a large number of sources,\nnamed LNS (stands for Large Number of Sources), is proposed on the basis of a\nsimple idea: the more common ideas one source shares with others, the\nmorereliable the source is. This rule is adaptable for aggregating a large\nnumber of sources among which some are unreliable. It will keep the spirit of\nthe conjunctive rule to reinforce the belief on the focal elements with which\nthe sources are in agreement. The mass on the empty set will be kept as an\nindicator of the conflict. Moreover, it can be used to elicit the major opinion\namong the experts. The experimental results on synthetic mass functionsverify\nthat the rule can be effectively used to combine a large number of mass\nfunctions and to elicit the major opinion.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Understanding and Visualizing the District of Columbia Capital Bikeshare\n  System Using Data Analysis for Balancing Purposes",
        "authors": [
            "Kiana Roshan Zamir",
            "Ali Shafahi",
            "Ali Haghani"
        ],
        "summary": "Bike sharing systems' popularity has consistently been rising during the past\nyears. Managing and maintaining these emerging systems are indispensable parts\nof these systems. Visualizing the current operations can assist in getting a\nbetter grasp on the performance of the system. In this paper, a data mining\napproach is used to identify and visualize some important factors related to\nbike-share operations and management. To consolidate the data, we cluster\nstations that have a similar pickup and drop-off profiles during weekdays and\nweekends. We provide the temporal profile of the center of each cluster which\ncan be used as a simple and practical approach for approximating the number of\npickups and drop-offs of the stations. We also define two indices based on\nstations' shortages and surpluses that reflect the degree of balancing aid a\nstation needs. These indices can help stakeholders improve the quality of the\nbike-share user experience in at-least two ways. It can act as a complement to\nbalancing optimization efforts, and it can identify stations that need\nexpansion. We mine the District of Columbia's regional bike-share data and\ndiscuss the findings of this data set. We examine the bike-share system during\ndifferent quarters of the year and during both peak and non-peak hours.\nFindings reflect that on weekdays most of the pickups and drop-offs happen\nduring the morning and evening peaks whereas on weekends pickups and drop-offs\nare spread out throughout the day. We also show that throughout the day, more\nthan 40% of the stations are relatively self-balanced. Not worrying about these\nstations during ordinary days can allow the balancing efforts to focus on a\nfewer stations and therefore potentially improve the efficiency of the\nbalancing optimization models.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Analysis of the Impact of Negative Sampling on Link Prediction in\n  Knowledge Graphs",
        "authors": [
            "Bhushan Kotnis",
            "Vivi Nastase"
        ],
        "summary": "Knowledge graphs are large, useful, but incomplete knowledge repositories.\nThey encode knowledge through entities and relations which define each other\nthrough the connective structure of the graph. This has inspired methods for\nthe joint embedding of entities and relations in continuous low-dimensional\nvector spaces, that can be used to induce new edges in the graph, i.e., link\nprediction in knowledge graphs. Learning these representations relies on\ncontrasting positive instances with negative ones. Knowledge graphs include\nonly positive relation instances, leaving the door open for a variety of\nmethods for selecting negative examples. In this paper we present an empirical\nstudy on the impact of negative sampling on the learned embeddings, assessed\nthrough the task of link prediction. We use state-of-the-art knowledge graph\nembeddings -- \\rescal , TransE, DistMult and ComplEX -- and evaluate on\nbenchmark datasets -- FB15k and WN18. We compare well known methods for\nnegative sampling and additionally propose embedding based sampling methods. We\nnote a marked difference in the impact of these sampling methods on the two\ndatasets, with the \"traditional\" corrupting positives method leading to best\nresults on WN18, while embedding based methods benefiting the task on FB15k.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Deep Style Match for Complementary Recommendation",
        "authors": [
            "Kui Zhao",
            "Xia Hu",
            "Jiajun Bu",
            "Can Wang"
        ],
        "summary": "Humans develop a common sense of style compatibility between items based on\ntheir attributes. We seek to automatically answer questions like \"Does this\nshirt go well with that pair of jeans?\" In order to answer these kinds of\nquestions, we attempt to model human sense of style compatibility in this\npaper. The basic assumption of our approach is that most of the important\nattributes for a product in an online store are included in its title\ndescription. Therefore it is feasible to learn style compatibility from these\ndescriptions. We design a Siamese Convolutional Neural Network architecture and\nfeed it with title pairs of items, which are either compatible or incompatible.\nThose pairs will be mapped from the original space of symbolic words into some\nembedded style space. Our approach takes only words as the input with few\npreprocessing and there is no laborious and expensive feature engineering.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Object-Oriented Knowledge Extraction using Universal Exploiters",
        "authors": [
            "Dmytro Terletskyi"
        ],
        "summary": "This paper contains analysis and extension of exploiters-based knowledge\nextraction methods, which allow generation of new knowledge, based on the basic\nones. The main achievement of the paper is useful features of some universal\nexploiters proof, which allow extending set of basic classes and set of basic\nrelations by finite set of new classes of objects and relations among them,\nwhich allow creating of complete lattice. Proposed approach gives an\nopportunity to compute quantity of new classes, which can be generated using\nit, and quantity of different types, which each of obtained classes describes;\nconstructing of defined hierarchy of classes with determined subsumption\nrelation; avoidance of some problems of inheritance and more efficient\nrestoring of basic knowledge within the database.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Conflict management in information fusion with belief functions",
        "authors": [
            "Arnaud Martin"
        ],
        "summary": "In Information fusion, the conflict is an important concept. Indeed,\ncombining several imperfect experts or sources allows conflict. In the theory\nof belief functions, this notion has been discussed a lot. The mass appearing\non the empty set during the conjunctive combination rule is generally\nconsidered as conflict, but that is not really a conflict. Some measures of\nconflict have been proposed and some approaches have been proposed in order to\nmanage this conflict or to decide with conflicting mass functions. We recall in\nthis chapter some of them and we propose a discussion to consider the conflict\nin information fusion with the theory of belief functions.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Autonomous Extracting a Hierarchical Structure of Tasks in Reinforcement\n  Learning and Multi-task Reinforcement Learning",
        "authors": [
            "Behzad Ghazanfari",
            "Matthew E. Taylor"
        ],
        "summary": "Reinforcement learning (RL), while often powerful, can suffer from slow\nlearning speeds, particularly in high dimensional spaces. The autonomous\ndecomposition of tasks and use of hierarchical methods hold the potential to\nsignificantly speed up learning in such domains. This paper proposes a novel\npractical method that can autonomously decompose tasks, by leveraging\nassociation rule mining, which discovers hidden relationship among entities in\ndata mining. We introduce a novel method called ARM-HSTRL (Association Rule\nMining to extract Hierarchical Structure of Tasks in Reinforcement Learning).\nIt extracts temporal and structural relationships of sub-goals in RL, and\nmulti-task RL. In particular,it finds sub-goals and relationship among them. It\nis shown the significant efficiency and performance of the proposed method in\ntwo main topics of RL.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Object-Oriented Knowledge Representation and Data Storage Using\n  Inhomogeneous Classes",
        "authors": [
            "Dmytro Terletskyi"
        ],
        "summary": "This paper contains analysis of concept of a class within different\nobject-oriented knowledge representation models. The main attention is paid to\nstructure of the class and its efficiency in the context of data storage, using\nobject-relational mapping. The main achievement of the paper is extension of\nconcept of homogeneous class of objects by introducing concepts of single-core\nand multi-core inhomogeneous classes of objects, which allow simultaneous\ndefining of a few different types within one class of objects, avoiding\nduplication of properties and methods in representation of types, decreasing\nsizes of program codes and providing more efficient information storage in the\ndatabases. In addition, the paper contains results of experiment, which show\nthat data storage in relational database, using proposed extensions of the\nclass, in some cases is more efficient in contrast to usage of homogeneous\nclasses of objects.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Intelligence Quotient and Intelligence Grade of Artificial Intelligence",
        "authors": [
            "Feng Liu",
            "Yong Shi",
            "Ying Liu"
        ],
        "summary": "Although artificial intelligence is currently one of the most interesting\nareas in scientific research, the potential threats posed by emerging AI\nsystems remain a source of persistent controversy. To address the issue of AI\nthreat, this study proposes a standard intelligence model that unifies AI and\nhuman characteristics in terms of four aspects of knowledge, i.e., input,\noutput, mastery, and creation. Using this model, we observe three challenges,\nnamely, expanding of the von Neumann architecture; testing and ranking the\nintelligence quotient of naturally and artificially intelligent systems,\nincluding humans, Google, Bing, Baidu, and Siri; and finally, the dividing of\nartificially intelligent systems into seven grades from robots to Google Brain.\nBased on this, we conclude that AlphaGo belongs to the third grade.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Combinatorial Multi-armed Bandits for Real-Time Strategy Games",
        "authors": [
            "Santiago Onta\u00f1\u00f3n"
        ],
        "summary": "Games with large branching factors pose a significant challenge for game tree\nsearch algorithms. In this paper, we address this problem with a sampling\nstrategy for Monte Carlo Tree Search (MCTS) algorithms called {\\em na\\\"{i}ve\nsampling}, based on a variant of the Multi-armed Bandit problem called {\\em\nCombinatorial Multi-armed Bandits} (CMAB). We analyze the theoretical\nproperties of several variants of {\\em na\\\"{i}ve sampling}, and empirically\ncompare it against the other existing strategies in the literature for CMABs.\nWe then evaluate these strategies in the context of real-time strategy (RTS)\ngames, a genre of computer games characterized by their very large branching\nfactors. Our results show that as the branching factor grows, {\\em na\\\"{i}ve\nsampling} outperforms the other sampling strategies.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Network Model Selection Using Task-Focused Minimum Description Length",
        "authors": [
            "Ivan Brugere",
            "Tanya Y. Berger-Wolf"
        ],
        "summary": "Networks are fundamental models for data used in practically every\napplication domain. In most instances, several implicit or explicit choices\nabout the network definition impact the translation of underlying data to a\nnetwork representation, and the subsequent question(s) about the underlying\nsystem being represented. Users of downstream network data may not even be\naware of these choices or their impacts. We propose a task-focused network\nmodel selection methodology which addresses several key challenges. Our\napproach constructs network models from underlying data and uses minimum\ndescription length (MDL) criteria for selection. Our methodology measures\nefficiency, a general and comparable measure of the network's performance of a\nlocal (i.e. node-level) predictive task of interest. Selection on efficiency\nfavors parsimonious (e.g. sparse) models to avoid overfitting and can be\napplied across arbitrary tasks and representations. We show stability,\nsensitivity, and significance testing in our methodology.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Servant of Many Masters: Shifting priorities in Pareto-optimal\n  sequential decision-making",
        "authors": [
            "Andrew Critch",
            "Stuart Russell"
        ],
        "summary": "It is often argued that an agent making decisions on behalf of two or more\nprincipals who have different utility functions should adopt a {\\em\nPareto-optimal} policy, i.e., a policy that cannot be improved upon for one\nagent without making sacrifices for another. A famous theorem of Harsanyi shows\nthat, when the principals have a common prior on the outcome distributions of\nall policies, a Pareto-optimal policy for the agent is one that maximizes a\nfixed, weighted linear combination of the principals' utilities.\n  In this paper, we show that Harsanyi's theorem does not hold for principals\nwith different priors, and derive a more precise generalization which does\nhold, which constitutes our main result. In this more general case, the\nrelative weight given to each principal's utility should evolve over time\naccording to how well the agent's observations conform with that principal's\nprior. The result has implications for the design of contracts, treaties, joint\nventures, and robots.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Composing Meta-Policies for Autonomous Driving Using Hierarchical Deep\n  Reinforcement Learning",
        "authors": [
            "Richard Liaw",
            "Sanjay Krishnan",
            "Animesh Garg",
            "Daniel Crankshaw",
            "Joseph E. Gonzalez",
            "Ken Goldberg"
        ],
        "summary": "Rather than learning new control policies for each new task, it is possible,\nwhen tasks share some structure, to compose a \"meta-policy\" from previously\nlearned policies. This paper reports results from experiments using Deep\nReinforcement Learning on a continuous-state, discrete-action autonomous\ndriving simulator. We explore how Deep Neural Networks can represent\nmeta-policies that switch among a set of previously learned policies,\nspecifically in settings where the dynamics of a new scenario are composed of a\nmixture of previously learned dynamics and where the state observation is\npossibly corrupted by sensing noise. We also report the results of experiments\nvarying dynamics mixes, distractor policies, magnitudes/distributions of\nsensing noise, and obstacles. In a fully observed experiment, the meta-policy\nlearning algorithm achieves 2.6x the reward achieved by the next best policy\ncomposition technique with 80% less exploration. In a partially observed\nexperiment, the meta-policy learning algorithm converges after 50 iterations\nwhile a direct application of RL fails to converge even after 200 iterations.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Good and safe uses of AI Oracles",
        "authors": [
            "Stuart Armstrong"
        ],
        "summary": "An Oracle is a design for potentially high power artificial intelligences\n(AIs), where the AI is made safe by restricting it to only answer questions.\nUnfortunately most designs cause the Oracle to be motivated to manipulate\nhumans with the contents of their answers, and Oracles of potentially high\nintelligence might be very successful at this. Solving that problem, without\ncompromising the accuracy of the answer, is tricky. This paper reduces the\nissue to a cryptographic-style problem of Alice ensuring that her Oracle\nanswers her questions while not providing key information to an eavesdropping\nEve. Two Oracle designs solve this problem, one counterfactual (the Oracle\nanswers as if it expected its answer to never be read) and one on-policy, but\nlimited by the quantity of information it can transmit.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Related family-based attribute reduction of covering information systems\n  when varying attribute sets",
        "authors": [
            "Guangming Lang"
        ],
        "summary": "In practical situations, there are many dynamic covering information systems\nwith variations of attributes, but there are few studies on related\nfamily-based attribute reduction of dynamic covering information systems. In\nthis paper, we first investigate updated mechanisms of constructing attribute\nreducts for consistent and inconsistent covering information systems when\nvarying attribute sets by using related families. Then we employ examples to\nillustrate how to compute attribute reducts of dynamic covering information\nsystems with variations of attribute sets. Finally, the experimental results\nillustrates that the related family-based methods are effective to perform\nattribute reduction of dynamic covering information systems when attribute sets\nare varying with time.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Situationally Aware Options",
        "authors": [
            "Daniel J. Mankowitz",
            "Aviv Tamar",
            "Shie Mannor"
        ],
        "summary": "Hierarchical abstractions, also known as options -- a type of temporally\nextended action (Sutton et. al. 1999) that enables a reinforcement learning\nagent to plan at a higher level, abstracting away from the lower-level details.\nIn this work, we learn reusable options whose parameters can vary, encouraging\ndifferent behaviors, based on the current situation. In principle, these\nbehaviors can include vigor, defence or even risk-averseness. These are some\nexamples of what we refer to in the broader context as Situational Awareness\n(SA). We incorporate SA, in the form of vigor, into hierarchical RL by defining\nand learning situationally aware options in a Probabilistic Goal Semi-Markov\nDecision Process (PG-SMDP). This is achieved using our Situationally Aware\noPtions (SAP) policy gradient algorithm which comes with a theoretical\nconvergence guarantee. We learn reusable options in different scenarios in a\nRoboCup soccer domain (i.e., winning/losing). These options learn to execute\nwith different levels of vigor resulting in human-like behaviours such as\n`time-wasting' in the winning scenario. We show the potential of the agent to\nexit bad local optima using reusable options in RoboCup. Finally, using SAP,\nthe agent mitigates feature-based model misspecification in a Bottomless Pit of\nDeath domain.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Cascade Attribute Learning Network",
        "authors": [
            "Zhuo Xu",
            "Haonan Chang",
            "Masayoshi Tomizuka"
        ],
        "summary": "We propose the cascade attribute learning network (CALNet), which can learn\nattributes in a control task separately and assemble them together. Our\ncontribution is twofold: first we propose attribute learning in reinforcement\nlearning (RL). Attributes used to be modeled using constraint functions or\nterms in the objective function, making it hard to transfer. Attribute\nlearning, on the other hand, models these task properties as modules in the\npolicy network. We also propose using novel cascading compensative networks in\nthe CALNet to learn and assemble attributes. Using the CALNet, one can zero\nshoot an unseen task by separately learning all its attributes, and assembling\nthe attribute modules. We have validated the capacity of our model on a wide\nvariety of control problems with attributes in time, position, velocity and\nacceleration phases.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Diversity Constraints in Public Housing Allocation",
        "authors": [
            "Nawal Benabbou",
            "Mithun Chakraborty",
            "Vinh Ho Xuan",
            "Jakub Sliwinski",
            "Yair Zick"
        ],
        "summary": "The state of Singapore operates a national public housing program, accounting\nfor over 80% of its residential real estate. Singapore uses its housing\nallocation program to ensure ethnic diversity in its neighborhoods; it does so\nby imposing ethnic quotas: every ethnic group must not own more than a certain\npercentage in a housing project, thus ensuring that every neighborhood contains\nmembers from each ethnic group. However, imposing diversity constraints\nnaturally results in some welfare loss. Our work studies the tradeoff between\ndiversity and social welfare from the perspective of computational economics.\nWe model the problem as an extension of the classic assignment problem, with\nadditional diversity constraints. While the classic assignment program is\npoly-time computable, we show that adding diversity constraints makes the\nproblem computationally intractable; however, we identify a\n$\\tfrac{1}{2}$-approximation algorithm, as well as reasonable agent utility\nmodels which admit poly-time algorithms. In addition, we study the price of\ndiversity: this is the loss in welfare incurred by imposing diversity\nconstraints; we provide upper bounds on the price of diversity as a function of\nnatural problem parameters; next, we analyze public data from Singapore's\nHousing and Development Board, and create a simulated framework testing the\nwelfare loss due to diversity constraints in realistic large-scale scenarios.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Impossibility of deducing preferences and rationality from human policy",
        "authors": [
            "Stuart Armstrong",
            "S\u00f6ren Mindermann"
        ],
        "summary": "Inverse reinforcement learning (IRL) attempts to infer human rewards or\npreferences from observed behavior. Since human planning systematically\ndeviates from rationality, several approaches have been tried to account for\nspecific human shortcomings. However, there has been little analysis of the\ngeneral problem of inferring the reward of a human of unknown rationality. The\nobserved behavior can, in principle, be decomposed into two components: a\nreward function and a planning algorithm, both of which have to be inferred\nfrom behavior. This paper presents a No Free Lunch theorem, showing that,\nwithout making `normative' assumptions beyond the data, nothing about the human\nreward function can be deduced from human behavior. Unlike most No Free Lunch\ntheorems, this cannot be alleviated by regularising with simplicity\nassumptions. We show that the simplest hypotheses which explain the data are\ngenerally degenerate.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Towards a Deep Reinforcement Learning Approach for Tower Line Wars",
        "authors": [
            "Per-Arne Andersen",
            "Morten Goodwin",
            "Ole-Christoffer Granmo"
        ],
        "summary": "There have been numerous breakthroughs with reinforcement learning in the\nrecent years, perhaps most notably on Deep Reinforcement Learning successfully\nplaying and winning relatively advanced computer games. There is undoubtedly an\nanticipation that Deep Reinforcement Learning will play a major role when the\nfirst AI masters the complicated game plays needed to beat a professional\nReal-Time Strategy game player. For this to be possible, there needs to be a\ngame environment that targets and fosters AI research, and specifically Deep\nReinforcement Learning. Some game environments already exist, however, these\nare either overly simplistic such as Atari 2600 or complex such as Starcraft II\nfrom Blizzard Entertainment. We propose a game environment in between Atari\n2600 and Starcraft II, particularly targeting Deep Reinforcement Learning\nalgorithm research. The environment is a variant of Tower Line Wars from\nWarcraft III, Blizzard Entertainment. Further, as a proof of concept that the\nenvironment can harbor Deep Reinforcement algorithms, we propose and apply a\nDeep Q-Reinforcement architecture. The architecture simplifies the state space\nso that it is applicable to Q-learning, and in turn improves performance\ncompared to current state-of-the-art methods. Our experiments show that the\nproposed architecture can learn to play the environment well, and score 33%\nbetter than standard Deep Q-learning which in turn proves the usefulness of the\ngame environment.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "'Indifference' methods for managing agent rewards",
        "authors": [
            "Stuart Armstrong"
        ],
        "summary": "`Indifference' refers to a class of methods that are used to control a reward\nbased agent. These methods of control work even if the implications of the\nagent's reward are otherwise not fully understood. Though they all come out of\nsimilar ideas, indifference techniques can be classified as way of achieving\none or more of three distinct goals: rewards dependent on certain events (with\nno motivation for the agent to manipulate the probability of those events),\neffective disbelief that an event will ever occur, and seamless transition from\none behaviour to another. This paper analyses methods of achieving these goals\nin the POMDP setting, and establishes their uses, strengths, and limitations.\nIt aims to make the tools of indifference generally accessible and usable to\nagent designers.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Three IQs of AI Systems and their Testing Methods",
        "authors": [
            "Feng Liu",
            "Yong Shi",
            "Ying Liu"
        ],
        "summary": "The rapid development of artificial intelligence has brought the artificial\nintelligence threat theory as well as the problem about how to evaluate the\nintelligence level of intelligent products. Both need to find a quantitative\nmethod to evaluate the intelligence level of intelligence systems, including\nhuman intelligence. Based on the standard intelligence system and the extended\nVon Neumann architecture, this paper proposes General IQ, Service IQ and Value\nIQ evaluation methods for intelligence systems, depending on different\nevaluation purposes. Among them, the General IQ of intelligence systems is to\nanswer the question of whether the artificial intelligence can surpass the\nhuman intelligence, which is reflected in putting the intelligence systems on\nan equal status and conducting the unified evaluation. The Service IQ and Value\nIQ of intelligence systems are used to answer the question of how the\nintelligent products can better serve the human, reflecting the intelligence\nand required cost of each intelligence system as a product in the process of\nserving human.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "RedDwarfData: a simplified dataset of StarCraft matches",
        "authors": [
            "Juan J. Merelo-Guerv\u00f3s",
            "Antonio Fern\u00e1ndez-Ares",
            "Antonio \u00c1lvarez Caballero",
            "Pablo Garc\u00eda-S\u00e1nchez",
            "Victor Rivas"
        ],
        "summary": "The game Starcraft is one of the most interesting arenas to test new machine\nlearning and computational intelligence techniques; however, StarCraft matches\ntake a long time and creating a good dataset for training can be hard. Besides,\nanalyzing match logs to extract the main characteristics can also be done in\nmany different ways to the point that extracting and processing data itself can\ntake an inordinate amount of time and of course, depending on what you choose,\ncan bias learning algorithms. In this paper we present a simplified dataset\nextracted from the set of matches published by Robinson and Watson, which we\nhave called RedDwarfData, containing several thousand matches processed to\nframes, so that temporal studies can also be undertaken. This dataset is\navailable from GitHub under a free license. An initial analysis and appraisal\nof these matches is also made.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "DeepMind Control Suite",
        "authors": [
            "Yuval Tassa",
            "Yotam Doron",
            "Alistair Muldal",
            "Tom Erez",
            "Yazhe Li",
            "Diego de Las Casas",
            "David Budden",
            "Abbas Abdolmaleki",
            "Josh Merel",
            "Andrew Lefrancq",
            "Timothy Lillicrap",
            "Martin Riedmiller"
        ],
        "summary": "The DeepMind Control Suite is a set of continuous control tasks with a\nstandardised structure and interpretable rewards, intended to serve as\nperformance benchmarks for reinforcement learning agents. The tasks are written\nin Python and powered by the MuJoCo physics engine, making them easy to use and\nmodify. We include benchmarks for several learning algorithms. The Control\nSuite is publicly available at https://www.github.com/deepmind/dm_control . A\nvideo summary of all tasks is available at http://youtu.be/rAai4QzcYbs .",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "Intelligence Graph",
        "authors": [
            "Han Xiao"
        ],
        "summary": "In fact, there exist three genres of intelligence architectures: logics (e.g.\n\\textit{Random Forest, A$^*$ Searching}), neurons (e.g. \\textit{CNN, LSTM}) and\nprobabilities (e.g. \\textit{Naive Bayes, HMM}), all of which are incompatible\nto each other. However, to construct powerful intelligence systems with various\nmethods, we propose the intelligence graph (short as \\textbf{\\textit{iGraph}}),\nwhich is composed by both of neural and probabilistic graph, under the\nframework of forward-backward propagation. By the paradigm of iGraph, we design\na recommendation model with semantic principle. First, the probabilistic\ndistributions of categories are generated from the embedding representations of\nusers/items, in the manner of neurons. Second, the probabilistic graph infers\nthe distributions of features, in the manner of probabilities. Last, for the\nrecommendation diversity, we perform an expectation computation then conduct a\nlogic judgment, in the manner of logics. Experimentally, we beat the\nstate-of-the-art baselines and verify our conclusions.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "Entropy production rate as a criterion for inconsistency in decision\n  theory",
        "authors": [
            "Purushottam D. Dixit"
        ],
        "summary": "Evaluating pairwise comparisons breaks down complex decision problems into\ntractable ones. Pairwise comparison matrices (PCMs) are regularly used to solve\nmultiple-criteria decision-making (MCDM) problems using Saaty's analytic\nhierarchy process (AHP) framework. There are two significant drawbacks of using\nPCMs. First, humans evaluate PCM in an inconsistent manner. Second, PCMs of\nlarge problems often have missing entries. We address these two issues by first\nestablishing a novel connection between PCMs and time-irreversible Markov\nprocesses. Specifically, we show that every PCM induces a family of dissipative\nmaximum path entropy random walks (MERW) over the set of alternatives. We show\nthat only `consistent' PCMs correspond to detailed balanced MERWs. We identify\nthe non-equilibrium entropy production in the induced MERWs as a metric of\ninconsistency of the underlying PCMs. Notably, the entropy production satisfies\nall of the recently laid out criteria for reasonable consistency indices. We\nalso propose an approach to use incompletely filled PCMs in AHP. Potential\nfuture avenues are discussed as well.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "Distance formulas capable of unifying Euclidian space and probability\n  space",
        "authors": [
            "Zecang Gu",
            "Ling Dong"
        ],
        "summary": "For pattern recognition like image recognition, it has become clear that each\nmachine-learning dictionary data actually became data in probability space\nbelonging to Euclidean space. However, the distances in the Euclidean space and\nthe distances in the probability space are separated and ununified when machine\nlearning is introduced in the pattern recognition. There is still a problem\nthat it is impossible to directly calculate an accurate matching relation\nbetween the sampling data of the read image and the learned dictionary data. In\nthis research, we focused on the reason why the distance is changed and the\nextent of change when passing through the probability space from the original\nEuclidean distance among data belonging to multiple probability spaces\ncontaining Euclidean space. By finding the reason of the cause of the distance\nerror and finding the formula expressing the error quantitatively, a possible\ndistance formula to unify Euclidean space and probability space is found. Based\non the results of this research, the relationship between machine-learning\ndictionary data and sampling data was clearly understood for pattern\nrecognition. As a result, the calculation of collation among data and\nmachine-learning to compete mutually between data are cleared, and complicated\ncalculations became unnecessary. Finally, using actual pattern recognition\ndata, experimental demonstration of a possible distance formula to unify\nEuclidean space and probability space discovered by this research was carried\nout, and the effectiveness of the result was confirmed.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "Greenhouse: A Zero-Positive Machine Learning System for Time-Series\n  Anomaly Detection",
        "authors": [
            "Tae Jun Lee",
            "Justin Gottschlich",
            "Nesime Tatbul",
            "Eric Metcalf",
            "Stan Zdonik"
        ],
        "summary": "This short paper describes our ongoing research on Greenhouse - a\nzero-positive machine learning system for time-series anomaly detection.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "Precision and Recall for Range-Based Anomaly Detection",
        "authors": [
            "Tae Jun Lee",
            "Justin Gottschlich",
            "Nesime Tatbul",
            "Eric Metcalf",
            "Stan Zdonik"
        ],
        "summary": "Classical anomaly detection is principally concerned with point-based\nanomalies, anomalies that occur at a single data point. In this paper, we\npresent a new mathematical model to express range-based anomalies, anomalies\nthat occur over a range (or period) of time.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "Counterfactual equivalence for POMDPs, and underlying deterministic\n  environments",
        "authors": [
            "Stuart Armstrong"
        ],
        "summary": "Partially Observable Markov Decision Processes (POMDPs) are rich environments\noften used in machine learning. But the issue of information and causal\nstructures in POMDPs has been relatively little studied. This paper presents\nthe concepts of equivalent and counterfactually equivalent POMDPs, where agents\ncannot distinguish which environment they are in though any observations and\nactions. It shows that any POMDP is counterfactually equivalent, for any finite\nnumber of turns, to a deterministic POMDP with all uncertainty concentrated\ninto the initial state. This allows a better understanding of POMDP\nuncertainty, information, and learning.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "Recursive Feature Generation for Knowledge-based Learning",
        "authors": [
            "Lior Friedman",
            "Shaul Markovitch"
        ],
        "summary": "When humans perform inductive learning, they often enhance the process with\nbackground knowledge. With the increasing availability of well-formed\ncollaborative knowledge bases, the performance of learning algorithms could be\nsignificantly enhanced if a way were found to exploit these knowledge bases. In\nthis work, we present a novel algorithm for injecting external knowledge into\ninduction algorithms using feature generation. Given a feature, the algorithm\ndefines a new learning task over its set of values, and uses the knowledge base\nto solve the constructed learning task. The resulting classifier is then used\nas a new feature for the original problem. We have applied our algorithm to the\ndomain of text classification using large semantic knowledge bases. We have\nshown that the generated features significantly improve the performance of\nexisting learning algorithms.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "Augmented Artificial Intelligence: a Conceptual Framework",
        "authors": [
            "Alexander N. Gorban",
            "Bogdan Grechuk",
            "Ivan Y. Tyukin"
        ],
        "summary": "All artificial Intelligence (AI) systems make errors. These errors are\nunexpected, and differ often from the typical human mistakes (\"non-human\"\nerrors). The AI errors should be corrected without damage of existing skills\nand, hopefully, avoiding direct human expertise. This paper presents an initial\nsummary report of project taking new and systematic approach to improving the\nintellectual effectiveness of the individual AI by communities of AIs. We\ncombine some ideas of learning in heterogeneous multiagent systems with new and\noriginal mathematical approaches for non-iterative corrections of errors of\nlegacy AI systems. New stochastic separation theorems demonstrate that the\ncorrector technology can be used to handle errors in data flows with very\ngeneral probability distributions and far away from the classical i.i.d.\nhypothesis.In particular, in the analysis of mathematical foundations of AI\nnon-destructive correction, we answer one general problem published by Donoho\nand Tanner in 2009.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "Efficient Learning of Bounded-Treewidth Bayesian Networks from Complete\n  and Incomplete Data Sets",
        "authors": [
            "Mauro Scanagatta",
            "Giorgio Corani",
            "Marco Zaffalon",
            "Jaemin Yoo",
            "U Kang"
        ],
        "summary": "Learning a Bayesian networks with bounded treewidth is important for reducing\nthe complexity of the inferences. We present a novel anytime algorithm (k-MAX)\nmethod for this task, which scales up to thousands of variables. Through\nextensive experiments we show that it consistently yields higher-scoring\nstructures than its competitors on complete data sets. We then consider the\nproblem of structure learning from incomplete data sets. This can be addressed\nby structural EM, which however is computationally very demanding. We thus\nadopt the novel k-MAX algorithm in the maximization step of structural EM,\nobtaining an efficient computation of the expected sufficient statistics. We\ntest the resulting structural EM method on the task of imputing missing data,\ncomparing it against the state-of-the-art approach based on random forests. Our\napproach achieves the same imputation accuracy of the competitors, but in about\none tenth of the time. Furthermore we show that it has worst-case complexity\nlinear in the input size, and that it is easily parallelizable.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "A Machine Learning Approach to Air Traffic Route Choice Modelling",
        "authors": [
            "Rodrigo Marcos",
            "Oliva Garc\u00eda-Cant\u00fa",
            "Ricardo Herranz"
        ],
        "summary": "Air Traffic Flow and Capacity Management (ATFCM) is one of the constituent\nparts of Air Traffic Management (ATM). The goal of ATFCM is to make airport and\nairspace capacity meet traffic demand and, when capacity opportunities are\nexhausted, optimise traffic flows to meet the available capacity. One of the\nkey enablers of ATFCM is the accurate estimation of future traffic demand. The\navailable information (schedules, flight plans, etc.) and its associated level\nof uncertainty differ across the different ATFCM planning phases, leading to\nqualitative differences between the types of forecasting that are feasible at\neach time horizon. While abundant research has been conducted on tactical\ntrajectory prediction (i.e., during the day of operations), trajectory\nprediction in the pre-tactical phase, when few or no flight plans are\navailable, has received much less attention. As a consequence, the methods\ncurrently in use for pre-tactical traffic forecast are still rather\nrudimentary, often resulting in suboptimal ATFCM decision making. This paper\nproposes a machine learning approach for the prediction of airlines route\nchoices between two airports as a function of route characteristics, such as\nflight efficiency, air navigation charges and expected level of congestion.\nDifferent predictive models based on multinomial logistic regression and\ndecision trees are formulated and calibrated with historical traffic data, and\na critical evaluation of each model is conducted. We analyse the predictive\npower of each model in terms of its ability to forecast traffic volumes at the\nlevel of charging zones, proving significant potential to enhance pre-tactical\ntraffic forecast. We conclude by discussing the limitations and room for\nimprovement of the proposed approach, as well as the future developments\nrequired to produce reliable traffic forecasts at a higher spatial and temporal\nresolution.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "General Video Game AI: a Multi-Track Framework for Evaluating Agents,\n  Games and Content Generation Algorithms",
        "authors": [
            "Diego Perez-Liebana",
            "Jialin Liu",
            "Ahmed Khalifa",
            "Raluca D. Gaina",
            "Julian Togelius",
            "Simon M. Lucas"
        ],
        "summary": "General Video Game Playing (GVGP) aims at designing an agent that is capable\nof playing multiple video games with no human intervention. In 2014, The\nGeneral Video Game AI (GVGAI) competition framework was created and released\nwith the purpose of providing researchers a common open-source and easy to use\nplatform for testing their AI methods with potentially infinity of games\ncreated using Video Game Description Language (VGDL). The framework has been\nexpanded into several tracks during the last few years to meet the demand of\ndifferent research directions. The agents are required to either play multiples\nunknown games with or without access to game simulations, or to design new game\nlevels or rules. This survey paper presents the VGDL, the GVGAI framework,\nexisting tracks, and reviews the wide use of GVGAI framework in research,\neducation and competitions five years after its birth. A future plan of\nframework improvements is also described.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "Knowledge Base Relation Detection via Multi-View Matching",
        "authors": [
            "Yang Yu",
            "Kazi Saidul Hasan",
            "Mo Yu",
            "Wei Zhang",
            "Zhiguo Wang"
        ],
        "summary": "Relation detection is a core component for Knowledge Base Question Answering\n(KBQA). In this paper, we propose a KB relation detection model via multi-view\nmatching which utilizes more useful information extracted from question and KB.\nThe matching inside each view is through multiple perspectives to compare two\ninput texts thoroughly. All these components are designed in an end-to-end\ntrainable neural network model. Experiments on SimpleQuestions and WebQSP yield\nstate-of-the-art results.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "Global minimization of a quadratic functional: neural network approach",
        "authors": [
            "L. B. Litinskii",
            "B. M. Magomedov"
        ],
        "summary": "The problem of finding out the global minimum of a multiextremal functional\nis discussed. One frequently faces with such a functional in various\napplications. We propose a procedure, which depends on the dimensionality of\nthe problem polynomially. In our approach we use the eigenvalues and\neigenvectors of the connection matrix.",
        "year": 2004,
        "label": "cs.NE"
    },
    {
        "title": "Optimal estimation for Large-Eddy Simulation of turbulence and\n  application to the analysis of subgrid models",
        "authors": [
            "Antoine Moreau",
            "Olivier Teytaud",
            "Jean-Pierre Bertoglio"
        ],
        "summary": "The tools of optimal estimation are applied to the study of subgrid models\nfor Large-Eddy Simulation of turbulence. The concept of optimal estimator is\nintroduced and its properties are analyzed in the context of applications to a\npriori tests of subgrid models. Attention is focused on the Cook and Riley\nmodel in the case of a scalar field in isotropic turbulence. Using DNS data,\nthe relevance of the beta assumption is estimated by computing (i) generalized\noptimal estimators and (ii) the error brought by this assumption alone. Optimal\nestimators are computed for the subgrid variance using various sets of\nvariables and various techniques (histograms and neural networks). It is shown\nthat optimal estimators allow a thorough exploration of models. Neural networks\nare proved to be relevant and very efficient in this framework, and further\nusages are suggested.",
        "year": 2006,
        "label": "physics.class-ph"
    },
    {
        "title": "Evolution of central pattern generators for the control of a five-link\n  bipedal walking mechanism",
        "authors": [
            "Atilim Gunes Baydin"
        ],
        "summary": "Central pattern generators (CPGs), with a basis is neurophysiological\nstudies, are a type of neural network for the generation of rhythmic motion.\nWhile CPGs are being increasingly used in robot control, most applications are\nhand-tuned for a specific task and it is acknowledged in the field that generic\nmethods and design principles for creating individual networks for a given task\nare lacking. This study presents an approach where the connectivity and\noscillatory parameters of a CPG network are determined by an evolutionary\nalgorithm with fitness evaluations in a realistic simulation with accurate\nphysics. We apply this technique to a five-link planar walking mechanism to\ndemonstrate its feasibility and performance. In addition, to see whether\nresults from simulation can be acceptably transferred to real robot hardware,\nthe best evolved CPG network is also tested on a real mechanism. Our results\nalso confirm that the biologically inspired CPG model is well suited for legged\nlocomotion, since a diverse manifestation of networks have been observed to\nsucceed in fitness simulations during evolution.",
        "year": 2008,
        "label": "cs.NE"
    },
    {
        "title": "A Pyramidal Evolutionary Algorithm with Different Inter-Agent Partnering\n  Strategies for Scheduling Problems",
        "authors": [
            "Uwe Aickelin"
        ],
        "summary": "This paper combines the idea of a hierarchical distributed genetic algorithm\nwith different inter-agent partnering strategies. Cascading clusters of\nsub-populations are built from bottom up, with higher-level sub-populations\noptimising larger parts of the problem. Hence higher-level sub-populations\nsearch a larger search space with a lower resolution whilst lower-level\nsub-populations search a smaller search space with a higher resolution. The\neffects of different partner selection schemes amongst the agents on solution\nquality are examined for two multiple-choice optimisation problems. It is shown\nthat partnering strategies that exploit problem-specific knowledge are superior\nand can counter inappropriate (sub-) fitness measurements.",
        "year": 2008,
        "label": "cs.NE"
    },
    {
        "title": "Sensing Danger: Innate Immunology for Intrusion Detection",
        "authors": [
            "Uwe Aickelin",
            "Julie Greensmith"
        ],
        "summary": "The immune system provides an ideal metaphor for anomaly detection in general\nand computer security in particular. Based on this idea, artificial immune\nsystems have been used for a number of years for intrusion detection,\nunfortunately so far with little success. However, these previous systems were\nlargely based on immunological theory from the 1970s and 1980s and over the\nlast decade our understanding of immunological processes has vastly improved.\nIn this paper we present two new immune inspired algorithms based on the latest\nimmunological discoveries, such as the behaviour of Dendritic Cells. The\nresultant algorithms are applied to real world intrusion problems and show\nencouraging results. Overall, we believe there is a bright future for these\nnext generation artificial immune algorithms.",
        "year": 2008,
        "label": "cs.NE"
    },
    {
        "title": "Logic Mining Using Neural Networks",
        "authors": [
            "Saratha Sathasivam",
            "Wan Ahmad Tajuddin Wan Abdullah"
        ],
        "summary": "Knowledge could be gained from experts, specialists in the area of interest,\nor it can be gained by induction from sets of data. Automatic induction of\nknowledge from data sets, usually stored in large databases, is called data\nmining. Data mining methods are important in the management of complex systems.\nThere are many technologies available to data mining practitioners, including\nArtificial Neural Networks, Regression, and Decision Trees. Neural networks\nhave been successfully applied in wide range of supervised and unsupervised\nlearning applications. Neural network methods are not commonly used for data\nmining tasks, because they often produce incomprehensible models, and require\nlong training times. One way in which the collective properties of a neural\nnetwork may be used to implement a computational task is by way of the concept\nof energy minimization. The Hopfield network is well-known example of such an\napproach. The Hopfield network is useful as content addressable memory or an\nanalog computer for solving combinatorial-type optimization problems. Wan\nAbdullah [1] proposed a method of doing logic programming on a Hopfield neural\nnetwork. Optimization of logical inconsistency is carried out by the network\nafter the connection strengths are defined from the logic program; the network\nrelaxes to neural states corresponding to a valid interpretation. In this\narticle, we describe how Hopfield network is able to induce logical rules from\nlarge database by using reverse analysis method: given the values of the\nconnections of a network, we can hope to know what logical rules are entrenched\nin the database.",
        "year": 2008,
        "label": "cs.LO"
    },
    {
        "title": "Logic Learning in Hopfield Networks",
        "authors": [
            "Saratha Sathasivam",
            "Wan Ahmad Tajuddin Wan Abdullah"
        ],
        "summary": "Synaptic weights for neurons in logic programming can be calculated either by\nusing Hebbian learning or by Wan Abdullah's method. In other words, Hebbian\nlearning for governing events corresponding to some respective program clauses\nis equivalent with learning using Wan Abdullah's method for the same respective\nprogram clauses. In this paper we will evaluate experimentally the equivalence\nbetween these two types of learning through computer simulations.",
        "year": 2008,
        "label": "cs.LO"
    },
    {
        "title": "Flatness of the Energy Landscape for Horn Clauses",
        "authors": [
            "Saratha Sathasivam",
            "Wan Ahmad Tajuddin Wan Abdullah"
        ],
        "summary": "The Little-Hopfield neural network programmed with Horn clauses is studied.\nWe argue that the energy landscape of the system, corresponding to the\ninconsistency function for logical interpretations of the sets of Horn clauses,\nhas minimal ruggedness. This is supported by computer simulations.",
        "year": 2008,
        "label": "cond-mat.dis-nn"
    },
    {
        "title": "On Application of the Local Search and the Genetic Algorithms Techniques\n  to Some Combinatorial Optimization Problems",
        "authors": [
            "Anton Bondarenko"
        ],
        "summary": "In this paper the approach to solving several combinatorial optimization\nproblems using the local search and the genetic algorithm techniques is\nproposed. Initially this approach was developed in purpose to overcome some\ndifficulties inhibiting the application of above mentioned techniques to the\nproblems of the Questionnaire Theory. But when the algorithms were developed it\nbecame clear that them could be successfully applied also to the Minimum Set\nCover, the 0-1-Knapsack and probably to other combinatorial optimization\nproblems.",
        "year": 2010,
        "label": "cs.NE"
    },
    {
        "title": "Complex-Valued Autoencoders",
        "authors": [
            "Pierre Baldi",
            "Zhiqin Lu"
        ],
        "summary": "Autoencoders are unsupervised machine learning circuits whose learning goal\nis to minimize a distortion measure between inputs and outputs. Linear\nautoencoders can be defined over any field and only real-valued linear\nautoencoder have been studied so far. Here we study complex-valued linear\nautoencoders where the components of the training vectors and adjustable\nmatrices are defined over the complex field with the $L_2$ norm. We provide\nsimpler and more general proofs that unify the real-valued and complex-valued\ncases, showing that in both cases the landscape of the error function is\ninvariant under certain groups of transformations. The landscape has no local\nminima, a family of global minima associated with Principal Component Analysis,\nand many families of saddle points associated with orthogonal projections onto\nsub-space spanned by sub-optimal subsets of eigenvectors of the covariance\nmatrix. The theory yields several iterative, convergent, learning algorithms, a\nclear understanding of the generalization properties of the trained\nautoencoders, and can equally be applied to the hetero-associative case when\nexternal targets are provided. Partial results on deep architecture as well as\nthe differential geometry of autoencoders are also presented. The general\nframework described here is useful to classify autoencoders and identify\ngeneral common properties that ought to be investigated for each class,\nilluminating some of the connections between information theory, unsupervised\nlearning, clustering, Hebbian learning, and autoencoders.",
        "year": 2011,
        "label": "cs.NE"
    },
    {
        "title": "Evolution of Ideas: A Novel Memetic Algorithm Based on Semantic Networks",
        "authors": [
            "Atilim Gunes Baydin",
            "Ramon Lopez de Mantaras"
        ],
        "summary": "This paper presents a new type of evolutionary algorithm (EA) based on the\nconcept of \"meme\", where the individuals forming the population are represented\nby semantic networks and the fitness measure is defined as a function of the\nrepresented knowledge. Our work can be classified as a novel memetic algorithm\n(MA), given that (1) it is the units of culture, or information, that are\nundergoing variation, transmission, and selection, very close to the original\nsense of memetics as it was introduced by Dawkins; and (2) this is different\nfrom existing MA, where the idea of memetics has been utilized as a means of\nlocal refinement by individual learning after classical global sampling of EA.\nThe individual pieces of information are represented as simple semantic\nnetworks that are directed graphs of concepts and binary relations, going\nthrough variation by memetic versions of operators such as crossover and\nmutation, which utilize knowledge from commonsense knowledge bases. In\nevaluating this introductory work, as an interesting fitness measure, we focus\non using the structure mapping theory of analogical reasoning from psychology\nto evolve pieces of information that are analogous to a given base information.\nConsidering other possible fitness measures, the proposed representation and\nalgorithm can serve as a computational tool for modeling memetic theories of\nknowledge, such as evolutionary epistemology and cultural selection theory.",
        "year": 2012,
        "label": "cs.NE"
    },
    {
        "title": "Evolving Boolean Regulatory Networks with Epigenetic Control",
        "authors": [
            "Larry Bull"
        ],
        "summary": "The significant role of epigenetic mechanisms within natural systems has\nbecome increasingly clear. This paper uses a recently presented abstract,\ntunable Boolean genetic regulatory network model to explore aspects of\nepigenetics. It is shown how dynamically controlling transcription via a DNA\nmethylation-inspired mechanism can be selected for by simulated evolution under\nvarious single and multiple cell scenarios. Further, it is shown that the\neffects of such control can be inherited without detriment to fitness.",
        "year": 2013,
        "label": "cs.NE"
    },
    {
        "title": "What can we learn from slow self-avoiding adaptive walks by an infinite\n  radius search algorithm?",
        "authors": [
            "Susan Khor"
        ],
        "summary": "Slow self-avoiding adaptive walks by an infinite radius search algorithm\n(Limax) are analyzed as themselves, and as the network they form. The study is\nconducted on several NK problems and two HIFF problems. We find that\nexamination of such \"slacker\" walks and networks can indicate relative search\ndifficulty within a family of problems, help identify potential local optima,\nand detect presence of structure in fitness landscapes. Hierarchical walks are\nused to differentiate rugged landscapes which are hierarchical (e.g. HIFF) from\nthose which are anarchic (e.g. NK). The notion of node viscidity as a measure\nof local optimum potential is introduced and found quite successful although\nmore work needs to be done to improve its accuracy on problems with larger K.",
        "year": 2011,
        "label": "cs.NE"
    },
    {
        "title": "Introduction to Multi-Agent Simulation",
        "authors": [
            "Peer-Olaf Siebers",
            "Uwe Aickelin"
        ],
        "summary": "When designing systems that are complex, dynamic and stochastic in nature,\nsimulation is generally recognised as one of the best design support\ntechnologies, and a valuable aid in the strategic and tactical decision making\nprocess. A simulation model consists of a set of rules that define how a system\nchanges over time, given its current state. Unlike analytical models, a\nsimulation model is not solved but is run and the changes of system states can\nbe observed at any point in time. This provides an insight into system dynamics\nrather than just predicting the output of a system based on specific inputs.\nSimulation is not a decision making tool but a decision support tool, allowing\nbetter informed decisions to be made. Due to the complexity of the real world,\na simulation model can only be an approximation of the target system. The\nessence of the art of simulation modelling is abstraction and simplification.\nOnly those characteristics that are important for the study and analysis of the\ntarget system should be included in the simulation model.",
        "year": 2008,
        "label": "cs.NE"
    },
    {
        "title": "Ant Colony Algorithm for the Weighted Item Layout Optimization Problem",
        "authors": [
            "Yi-Chun Xu",
            "Fang-Min Dong",
            "Yong Liu",
            "Ren-Bin Xiao",
            "Martyn Amos"
        ],
        "summary": "This paper discusses the problem of placing weighted items in a circular\ncontainer in two-dimensional space. This problem is of great practical\nsignificance in various mechanical engineering domains, such as the design of\ncommunication satellites. Two constructive heuristics are proposed, one for\npacking circular items and the other for packing rectangular items. These work\nby first optimizing object placement order, and then optimizing object\npositioning. Based on these heuristics, an ant colony optimization (ACO)\nalgorithm is described to search first for optimal positioning order, and then\nfor the optimal layout. We describe the results of numerical experiments, in\nwhich we test two versions of our ACO algorithm alongside local search methods\npreviously described in the literature. Our results show that the constructive\nheuristic-based ACO performs better than existing methods on larger problem\ninstances.",
        "year": 2010,
        "label": "cs.NE"
    },
    {
        "title": "WebAL-1: Workshop on Artificial Life and the Web 2014 Proceedings",
        "authors": [
            "Tim Taylor"
        ],
        "summary": "Proceedings of WebAL-1: Workshop on Artificial Life and the Web 2014, held at\nthe 14th International Conference on the Synthesis and Simulation of Living\nSystems (ALIFE 14), New York, NY, 31 July 2014.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "Optimal Parameter Settings for the $(1+(\u03bb, \u03bb))$ Genetic\n  Algorithm",
        "authors": [
            "Benjamin Doerr"
        ],
        "summary": "The $(1+(\\lambda,\\lambda))$ genetic algorithm is one of the few algorithms\nfor which a super-constant speed-up through the use of crossover could be\nproven. So far, this algorithm has been used with parameters based also on\nintuitive considerations. In this work, we rigorously regard the whole\nparameter space and show that the asymptotic time complexity proven by Doerr\nand Doerr (GECCO 2015) for the intuitive choice is best possible among all\nsettings for population size, mutation probability, and crossover bias.",
        "year": 2016,
        "label": "cs.NE"
    },
    {
        "title": "The (1+1) Elitist Black-Box Complexity of LeadingOnes",
        "authors": [
            "Carola Doerr",
            "Johannes Lengler"
        ],
        "summary": "One important goal of black-box complexity theory is the development of\ncomplexity models allowing to derive meaningful lower bounds for whole classes\nof randomized search heuristics. Complementing classical runtime analysis,\nblack-box models help us understand how algorithmic choices such as the\npopulation size, the variation operators, or the selection rules influence the\noptimization time. One example for such a result is the $\\Omega(n \\log n)$\nlower bound for unary unbiased algorithms on functions with a unique global\noptimum [Lehre/Witt, GECCO 2010], which tells us that higher arity operators or\nbiased sampling strategies are needed when trying to beat this bound. In lack\nof analyzing techniques, almost no non-trivial bounds are known for other\nrestricted models. Proving such bounds therefore remains to be one of the main\nchallenges in black-box complexity theory.\n  With this paper we contribute to our technical toolbox for lower bound\ncomputations by proposing a new type of information-theoretic argument. We\nregard the permutation- and bit-invariant version of \\textsc{LeadingOnes} and\nprove that its (1+1) elitist black-box complexity is $\\Omega(n^2)$, a bound\nthat is matched by (1+1)-type evolutionary algorithms. The (1+1) elitist\ncomplexity of \\textsc{LeadingOnes} is thus considerably larger than its\nunrestricted one, which is known to be of order $n\\log\\log n$ [Afshani et al.,\n2013].",
        "year": 2016,
        "label": "cs.NE"
    },
    {
        "title": "The Right Mutation Strength for Multi-Valued Decision Variables",
        "authors": [
            "Benjamin Doerr",
            "Carola Doerr",
            "Timo K\u00f6tzing"
        ],
        "summary": "The most common representation in evolutionary computation are bit strings.\nThis is ideal to model binary decision variables, but less useful for variables\ntaking more values. With very little theoretical work existing on how to use\nevolutionary algorithms for such optimization problems, we study the run time\nof simple evolutionary algorithms on some OneMax-like functions defined over\n$\\Omega = \\{0, 1, \\dots, r-1\\}^n$. More precisely, we regard a variety of\nproblem classes requesting the component-wise minimization of the distance to\nan unknown target vector $z \\in \\Omega$. For such problems we see a crucial\ndifference in how we extend the standard-bit mutation operator to these\nmulti-valued domains. While it is natural to select each position of the\nsolution vector to be changed independently with probability $1/n$, there are\nvarious ways to then change such a position. If we change each selected\nposition to a random value different from the original one, we obtain an\nexpected run time of $\\Theta(nr \\log n)$. If we change each selected position\nby either $+1$ or $-1$ (random choice), the optimization time reduces to\n$\\Theta(nr + n\\log n)$. If we use a random mutation strength $i \\in\n\\{0,1,\\ldots,r-1\\}^n$ with probability inversely proportional to $i$ and change\nthe selected position by either $+i$ or $-i$ (random choice), then the\noptimization time becomes $\\Theta(n \\log(r)(\\log(n)+\\log(r)))$, bringing down\nthe dependence on $r$ from linear to polylogarithmic. One of our results\ndepends on a new variant of the lower bounding multiplicative drift theorem.",
        "year": 2016,
        "label": "cs.NE"
    },
    {
        "title": "A Weight-coded Evolutionary Algorithm for the Multidimensional Knapsack\n  Problem",
        "authors": [
            "Quan Yuan",
            "Zhixin Yang"
        ],
        "summary": "A revised weight-coded evolutionary algorithm (RWCEA) is proposed for solving\nmultidimensional knapsack problems. This RWCEA uses a new decoding method and\nincorporates a heuristic method in initialization. Computational results show\nthat the RWCEA performs better than a weight-coded evolutionary algorithm\nproposed by Raidl (1999) and to some existing benchmarks, it can yield better\nresults than the ones reported in the OR-library.",
        "year": 2013,
        "label": "cs.NE"
    },
    {
        "title": "On the performance of a hybrid genetic algorithm in dynamic environments",
        "authors": [
            "Quan Yuan",
            "Zhixin Yang"
        ],
        "summary": "The ability to track the optimum of dynamic environments is important in many\npractical applications. In this paper, the capability of a hybrid genetic\nalgorithm (HGA) to track the optimum in some dynamic environments is\ninvestigated for different functional dimensions, update frequencies, and\ndisplacement strengths in different types of dynamic environments. Experimental\nresults are reported by using the HGA and some other existing evolutionary\nalgorithms in the literature. The results show that the HGA has better\ncapability to track the dynamic optimum than some other existing algorithms.",
        "year": 2013,
        "label": "cs.NE"
    },
    {
        "title": "Real-world Transfer of Evolved Artificial Immune System Behaviours\n  between Small and Large Scale Robotic Platforms",
        "authors": [
            "Amanda Whitbrook",
            "Uwe Aickelin",
            "Jonathan M. Garibaldi"
        ],
        "summary": "In mobile robotics, a solid test for adaptation is the ability of a control\nsystem to function not only in a diverse number of physical environments, but\nalso on a number of different robotic platforms. This paper demonstrates that a\nset of behaviours evolved in simulation on a miniature robot (epuck) can be\ntransferred to a much larger-scale platform (Pioneer), both in simulation and\nin the real world. The chosen architecture uses artificial evolution of epuck\nbehaviours to obtain a genetic sequence, which is then employed to seed an\nidiotypic, artificial immune system (AIS) on the Pioneers. Despite numerous\nhardware and software differences between the platforms, navigation and\ntarget-finding experiments show that the evolved behaviours transfer very well\nto the larger robot when the idiotypic AIS technique is used. In contrast,\ntransferability is poor when reinforcement learning alone is used, which\nvalidates the adaptability of the chosen architecture.",
        "year": 2013,
        "label": "cs.NE"
    },
    {
        "title": "A Doubly Distributed Genetic Algorithm for Network Coding",
        "authors": [
            "Minkyu Kim",
            "Varun Aggarwal",
            "Una-May O'Reilly",
            "Muriel Medard"
        ],
        "summary": "We present a genetic algorithm which is distributed in two novel ways: along\ngenotype and temporal axes. Our algorithm first distributes, for every member\nof the population, a subset of the genotype to each network node, rather than a\nsubset of the population to each. This genotype distribution is shown to offer\na significant gain in running time. Then, for efficient use of the\ncomputational resources in the network, our algorithm divides the candidate\nsolutions into pipelined sets and thus the distribution is in the temporal\ndomain, rather that in the spatial domain. This temporal distribution may lead\nto temporal inconsistency in selection and replacement, however our experiments\nyield better efficiency in terms of the time to convergence without incurring\nsignificant penalties.",
        "year": 2007,
        "label": "cs.NE"
    },
    {
        "title": "The Transfer of Evolved Artificial Immune System Behaviours between\n  Small and Large Scale Robotic Platforms",
        "authors": [
            "Amanda Whitbrook",
            "Uwe Aickelin",
            "Jonathan M. Garibaldi"
        ],
        "summary": "This paper demonstrates that a set of behaviours evolved in simulation on a\nminiature robot (epuck) can be transferred to a much larger scale platform (a\nvirtual Pioneer P3-DX) that also differs in shape, sensor type, sensor\nconfiguration and programming interface. The chosen architecture uses a\nreinforcement learning-assisted genetic algorithm to evolve the epuck\nbehaviours, which are encoded as a genetic sequence. This sequence is then used\nby the Pioneers as part of an adaptive, idiotypic artificial immune system\n(AIS) control architecture. Testing in three different simulated worlds shows\nthat the Pioneer can use these behaviours to navigate and solve object-tracking\ntasks successfully, as long as its adaptive AIS mechanism is in place.",
        "year": 2010,
        "label": "cs.NE"
    },
    {
        "title": "Continuous On-line Evolution of Agent Behaviours with Cartesian Genetic\n  Programming",
        "authors": [
            "Davide Nunes",
            "Luis Antunes"
        ],
        "summary": "Evolutionary Computation has been successfully used to synthesise controllers\nfor embodied agents and multi-agent systems in general. Notwithstanding this,\ncontinuous on-line adaptation by the means of evolutionary algorithms is still\nunder-explored, especially outside the evolutionary robotics domain. In this\npaper, we present an on-line evolutionary programming algorithm that searches\nin the agent design space for the appropriate behavioural policies to cope with\nthe underlying environment. We discuss the current problems of continuous agent\nadaptation, present our on-line evolution testbed for evolutionary simulation.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "Artificial Life and the Web: WebAL Comes of Age",
        "authors": [
            "Tim Taylor"
        ],
        "summary": "A brief survey is presented of the first 18 years of web-based Artificial\nLife (\"WebAL\") research and applications, covering the period 1995-2013. The\nsurvey is followed by a short discussion of common methodologies employed and\ncurrent technologies relevant to WebAL research. The paper concludes with a\nquick look at what the future may hold for work in this exciting area.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "OneMax in Black-Box Models with Several Restrictions",
        "authors": [
            "Carola Doerr",
            "Johannes Lengler"
        ],
        "summary": "Black-box complexity studies lower bounds for the efficiency of\ngeneral-purpose black-box optimization algorithms such as evolutionary\nalgorithms and other search heuristics. Different models exist, each one being\ndesigned to analyze a different aspect of typical heuristics such as the memory\nsize or the variation operators in use. While most of the previous works focus\non one particular such aspect, we consider in this work how the combination of\nseveral algorithmic restrictions influence the black-box complexity. Our\ntestbed are so-called OneMax functions, a classical set of test functions that\nis intimately related to classic coin-weighing problems and to the board game\nMastermind.\n  We analyze in particular the combined memory-restricted ranking-based\nblack-box complexity of OneMax for different memory sizes. While its isolated\nmemory-restricted as well as its ranking-based black-box complexity for bit\nstrings of length $n$ is only of order $n/\\log n$, the combined model does not\nallow for algorithms being faster than linear in $n$, as can be seen by\nstandard information-theoretic considerations. We show that this linear bound\nis indeed asymptotically tight. Similar results are obtained for other memory-\nand offspring-sizes. Our results also apply to the (Monte Carlo) complexity of\nOneMax in the recently introduced elitist model, in which only the best-so-far\nsolution can be kept in the memory. Finally, we also provide improved lower\nbounds for the complexity of OneMax in the regarded models.\n  Our result enlivens the quest for natural evolutionary algorithms optimizing\nOneMax in $o(n \\log n)$ iterations.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "A CMOS Spiking Neuron for Dense Memristor-Synapse Connectivity for\n  Brain-Inspired Computing",
        "authors": [
            "Xinyu Wu",
            "Vishal Saxena",
            "Kehan Zhu"
        ],
        "summary": "Neuromorphic systems that densely integrate CMOS spiking neurons and\nnano-scale memristor synapses open a new avenue of brain-inspired computing.\nExisting silicon neurons have molded neural biophysical dynamics but are\nincompatible with memristor synapses, or used extra training circuitry thus\neliminating much of the density advantages gained by using memristors, or were\nenergy inefficient. Here we describe a novel CMOS spiking leaky\nintegrate-and-fire neuron circuit. Building on a reconfigurable architecture\nwith a single opamp, the described neuron accommodates a large number of\nmemristor synapses, and enables online spike timing dependent plasticity (STDP)\nlearning with optimized power consumption. Simulation results of an 180nm CMOS\ndesign showed 97% power efficiency metric when realizing STDP learning in\n10,000 memristor synapses with a nominal 1M{\\Omega} memristance, and only\n13{\\mu}A current consumption when integrating input spikes. Therefore, the\ndescribed CMOS neuron contributes a generalized building block for large-scale\nbrain-inspired neuromorphic systems.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "Requirements for Open-Ended Evolution in Natural and Artificial Systems",
        "authors": [
            "Tim Taylor"
        ],
        "summary": "Open-ended evolutionary dynamics remains an elusive goal for artificial\nevolutionary systems. Many ideas exist in the biological literature beyond the\nbasic Darwinian requirements of variation, differential reproduction and\ninheritance. I argue that these ideas can be seen as aspects of five\nfundamental requirements for open-ended evolution: (1) robustly reproductive\nindividuals, (2) a medium allowing the possible existence of a practically\nunlimited diversity of individuals and interactions, (3) individuals capable of\nproducing more complex offspring, (4) mutational pathways to other viable\nindividuals, and (5) drive for continued evolution. I briefly discuss\nimplications of this view for the design of artificial systems with greater\nevolutionary potential.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "Introducing Elitist Black-Box Models: When Does Elitist Selection Weaken\n  the Performance of Evolutionary Algorithms?",
        "authors": [
            "Carola Doerr",
            "Johannes Lengler"
        ],
        "summary": "Black-box complexity theory provides lower bounds for the runtime of\nblack-box optimizers like evolutionary algorithms and serves as an inspiration\nfor the design of new genetic algorithms. Several black-box models covering\ndifferent classes of algorithms exist, each highlighting a different aspect of\nthe algorithms under considerations. In this work we add to the existing\nblack-box notions a new \\emph{elitist black-box model}, in which algorithms are\nrequired to base all decisions solely on (a fixed number of) the best search\npoints sampled so far. Our model combines features of the ranking-based and the\nmemory-restricted black-box models with elitist selection.\n  We provide several examples for which the elitist black-box complexity is\nexponentially larger than that the respective complexities in all previous\nblack-box models, thus showing that the elitist black-box complexity can be\nmuch closer to the runtime of typical evolutionary algorithms.\n  We also introduce the concept of $p$-Monte Carlo black-box complexity, which\nmeasures the time it takes to optimize a problem with failure probability at\nmost $p$. Even for small~$p$, the $p$-Monte Carlo black-box complexity of a\nfunction class $\\mathcal F$ can be smaller by an exponential factor than its\ntypically regarded Las Vegas complexity (which measures the \\emph{expected}\ntime it takes to optimize $\\mathcal F$).",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "Nonlinear functional mapping of the human brain",
        "authors": [
            "Nicholas Allgaier",
            "Tobias Banaschewski",
            "Gareth Barker",
            "Arun L. W. Bokde",
            "Josh C. Bongard",
            "Uli Bromberg",
            "Christian B\u00fcchel",
            "Anna Cattrell",
            "Patricia J. Conrod",
            "Christopher M. Danforth",
            "Sylvane Desrivi\u00e8res",
            "Peter S. Dodds",
            "Herta Flor",
            "Vincent Frouin",
            "J\u00fcrgen Gallinat",
            "Penny Gowland",
            "Andreas Heinz",
            "Bernd Ittermann",
            "Scott Mackey",
            "Jean-Luc Martinot",
            "Kevin Murphy",
            "Frauke Nees",
            "Dimitri Papadopoulos-Orfanos",
            "Luise Poustka",
            "Michael N. Smolka",
            "Henrik Walter",
            "Robert Whelan",
            "Gunter Schumann",
            "Hugh Garavan",
            "IMAGEN Consortium"
        ],
        "summary": "The field of neuroimaging has truly become data rich, and novel analytical\nmethods capable of gleaning meaningful information from large stores of imaging\ndata are in high demand. Those methods that might also be applicable on the\nlevel of individual subjects, and thus potentially useful clinically, are of\nspecial interest. In the present study, we introduce just such a method, called\nnonlinear functional mapping (NFM), and demonstrate its application in the\nanalysis of resting state fMRI from a 242-subject subset of the IMAGEN project,\na European study of adolescents that includes longitudinal phenotypic,\nbehavioral, genetic, and neuroimaging data. NFM employs a computational\ntechnique inspired by biological evolution to discover and mathematically\ncharacterize interactions among ROI (regions of interest), without making\nlinear or univariate assumptions. We show that statistics of the resulting\ninteraction relationships comport with recent independent work, constituting a\npreliminary cross-validation. Furthermore, nonlinear terms are ubiquitous in\nthe models generated by NFM, suggesting that some of the interactions\ncharacterized here are not discoverable by standard linear methods of analysis.\nWe discuss one such nonlinear interaction in the context of a direct comparison\nwith a procedure involving pairwise correlation, designed to be an analogous\nlinear version of functional mapping. We find another such interaction that\nsuggests a novel distinction in brain function between drinking and\nnon-drinking adolescents: a tighter coupling of ROI associated with emotion,\nreward, and interoceptive processes such as thirst, among drinkers. Finally, we\noutline many improvements and extensions of the methodology to reduce\ncomputational expense, complement other analytical tools like graph-theoretic\nanalysis, and allow for voxel level NFM to eliminate the necessity of ROI\nselection.",
        "year": 2015,
        "label": "q-bio.NC"
    },
    {
        "title": "LM-CMA: an Alternative to L-BFGS for Large Scale Black-box Optimization",
        "authors": [
            "Ilya Loshchilov"
        ],
        "summary": "The limited memory BFGS method (L-BFGS) of Liu and Nocedal (1989) is often\nconsidered to be the method of choice for continuous optimization when first-\nand/or second- order information is available. However, the use of L-BFGS can\nbe complicated in a black-box scenario where gradient information is not\navailable and therefore should be numerically estimated. The accuracy of this\nestimation, obtained by finite difference methods, is often problem-dependent\nthat may lead to premature convergence of the algorithm.\n  In this paper, we demonstrate an alternative to L-BFGS, the limited memory\nCovariance Matrix Adaptation Evolution Strategy (LM-CMA) proposed by Loshchilov\n(2014). The LM-CMA is a stochastic derivative-free algorithm for numerical\noptimization of non-linear, non-convex optimization problems. Inspired by the\nL-BFGS, the LM-CMA samples candidate solutions according to a covariance matrix\nreproduced from $m$ direction vectors selected during the optimization process.\nThe decomposition of the covariance matrix into Cholesky factors allows to\nreduce the memory complexity to $O(mn)$, where $n$ is the number of decision\nvariables. The time complexity of sampling one candidate solution is also\n$O(mn)$, but scales as only about 25 scalar-vector multiplications in practice.\nThe algorithm has an important property of invariance w.r.t. strictly\nincreasing transformations of the objective function, such transformations do\nnot compromise its ability to approach the optimum. The LM-CMA outperforms the\noriginal CMA-ES and its large scale versions on non-separable ill-conditioned\nproblems with a factor increasing with problem dimension. Invariance properties\nof the algorithm do not prevent it from demonstrating a comparable performance\nto L-BFGS on non-trivial large scale smooth and nonsmooth optimization\nproblems.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "A Lower Bound Analysis of Population-based Evolutionary Algorithms for\n  Pseudo-Boolean Functions",
        "authors": [
            "Chao Qian",
            "Yang Yu",
            "Zhi-Hua Zhou"
        ],
        "summary": "Evolutionary algorithms (EAs) are population-based general-purpose\noptimization algorithms, and have been successfully applied in various\nreal-world optimization tasks. However, previous theoretical studies often\nemploy EAs with only a parent or offspring population and focus on specific\nproblems. Furthermore, they often only show upper bounds on the running time,\nwhile lower bounds are also necessary to get a complete understanding of an\nalgorithm. In this paper, we analyze the running time of the\n($\\mu$+$\\lambda$)-EA (a general population-based EA with mutation only) on the\nclass of pseudo-Boolean functions with a unique global optimum. By applying the\nrecently proposed switch analysis approach, we prove the lower bound $\\Omega(n\n\\ln n+ \\mu + \\lambda n\\ln\\ln n/ \\ln n)$ for the first time. Particularly on the\ntwo widely-studied problems, OneMax and LeadingOnes, the derived lower bound\ndiscloses that the ($\\mu$+$\\lambda$)-EA will be strictly slower than the\n(1+1)-EA when the population size $\\mu$ or $\\lambda$ is above a moderate order.\nOur results imply that the increase of population size, while usually desired\nin practice, bears the risk of increasing the lower bound of the running time\nand thus should be carefully considered.",
        "year": 2016,
        "label": "cs.NE"
    },
    {
        "title": "An Approach for Parallel Genetic Algorithms in the Cloud using Software\n  Containers",
        "authors": [
            "Pasquale Salza",
            "Filomena Ferrucci"
        ],
        "summary": "Genetic Algorithms (GAs) are a powerful technique to address hard\noptimisation problems. However, scalability issues might prevent them from\nbeing applied to real-world problems. Exploiting parallel GAs in the cloud\nmight be an affordable approach to get time efficient solutions that benefit of\nthe appealing features of the cloud, such as scalability, reliability,\nfault-tolerance and cost-effectiveness. Nevertheless, distributed computation\nis very prone to cause considerable overhead for communication and making GAs\ndistributed in an on-demand fashion is not trivial. Aiming to keep under\ncontrol the communication overhead and support GAs developers in the\nconstruction and deployment of parallel GAs in the cloud, in this paper we\npropose an approach to distribute GAs using the global parallelisation model,\nexploiting software containers and their cloud orchestration. We also devised a\nconceptual workflow covering each cloud GAs distribution phase, from resources\nallocation to actual deployment and execution, in a DevOps fashion.",
        "year": 2016,
        "label": "cs.NE"
    },
    {
        "title": "The Evolution of Sex through the Baldwin Effect",
        "authors": [
            "Larry Bull"
        ],
        "summary": "This paper suggests that the fundamental haploid-diploid cycle of eukaryotic\nsex exploits a rudimentary form of the Baldwin effect. With this explanation\nfor the basic cycle, the other associated phenomena can be explained as\nevolution tuning the amount and frequency of learning experienced by an\norganism. Using the well-known NK model of fitness landscapes it is shown that\nvarying landscape ruggedness varies the benefit of the haploid-diploid cycle,\nwhether based upon endomitosis or syngamy. The utility of pre-meiotic doubling\nand recombination during the cycle are also shown to vary with landscape\nruggedness. This view is suggested as underpinning, rather than contradicting,\nmany existing explanations for sex.",
        "year": 2016,
        "label": "cs.NE"
    },
    {
        "title": "Haploid-Diploid Evolutionary Algorithms",
        "authors": [
            "Larry Bull"
        ],
        "summary": "This paper uses the recent idea that the fundamental haploid-diploid\nlifecycle of eukaryotic organisms implements a rudimentary form of learning\nwithin evolution. A general approach for evolutionary computation is here\nderived that differs from all previous known work using diploid\nrepresentations. The primary role of recombination is also changed from that\npreviously considered in both natural and artificial evolution under the new\nview. Using well-known abstract tuneable models it is shown that varying\nfitness landscape ruggedness varies the benefit of the new approach.",
        "year": 2016,
        "label": "cs.NE"
    },
    {
        "title": "Proceedings of the Workshop on Brain Analysis using COnnectivity\n  Networks - BACON 2016",
        "authors": [
            "Sarah Parisot",
            "Jonathan Passerat-Palmbach",
            "Markus D. Schirmer",
            "Boris Gutman"
        ],
        "summary": "Understanding brain connectivity in a network-theoretic context has shown\nmuch promise in recent years. This type of analysis identifies brain\norganisational principles, bringing a new perspective to neuroscience. At the\nsame time, large public databases of connectomic data are now available.\nHowever, connectome analysis is still an emerging field and there is a crucial\nneed for robust computational methods to fully unravelits potential. This\nworkshop provides a platform to discuss the development of new analytic\ntechniques; methods for evaluating and validating commonly used approaches; as\nwell as the effects of variations in pre-processing steps.",
        "year": 2016,
        "label": "cs.NE"
    },
    {
        "title": "Temporal Overdrive Recurrent Neural Network",
        "authors": [
            "Filippo Maria Bianchi",
            "Michael Kampffmeyer",
            "Enrico Maiorino",
            "Robert Jenssen"
        ],
        "summary": "In this work we present a novel recurrent neural network architecture\ndesigned to model systems characterized by multiple characteristic timescales\nin their dynamics. The proposed network is composed by several recurrent groups\nof neurons that are trained to separately adapt to each timescale, in order to\nimprove the system identification process. We test our framework on time series\nprediction tasks and we show some promising, preliminary results achieved on\nsynthetic data. To evaluate the capabilities of our network, we compare the\nperformance with several state-of-the-art recurrent architectures.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "A Hybrid Approach for Secured Optimal Power Flow and Voltage Stability\n  with TCSC Placement",
        "authors": [
            "Sheila Mahapatra",
            "Nitin Malik"
        ],
        "summary": "This paper proposes a hybrid technique for secured optimal power flow coupled\nwith enhancing voltage stability with FACTS device installation. The hybrid\napproach of Improved Gravitational Search algorithm (IGSA) and Firefly\nalgorithm (FA) performance is analyzed by optimally placing TCSC controller.\nThe algorithm is implemented in MATLAB working platform and the power flow\nsecurity and voltage stability is evaluated with IEEE 30 bus transmission\nsystems. The optimal results generated are compared with those available in\nliterature and the superior performance of algorithm is depicted as minimum\ngeneration cost, reduced real power losses along with sustaining voltage\nstability.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "Exponential scaling of neural algorithms - a future beyond Moore's Law?",
        "authors": [
            "James B. Aimone"
        ],
        "summary": "Although the brain has long been considered a potential inspiration for\nfuture computing, Moore's Law - the scaling property that has seen revolutions\nin technologies ranging from supercomputers to smart phones - has largely been\ndriven by advances in materials science. As the ability to miniaturize\ntransistors is coming to an end, there is increasing attention on new\napproaches to computation, including renewed enthusiasm around the potential of\nneural computation. This paper describes how recent advances in\nneurotechnologies, many of which have been aided by computing's rapid\nprogression over recent decades, are now reigniting this opportunity to bring\nneural computation insights into broader computing applications. As we\nunderstand more about the brain, our ability to motivate new computing\nparadigms with continue to progress. These new approaches to computing, which\nwe are already seeing in techniques such as deep learning and neuromorphic\nhardware, will themselves improve our ability to learn about the brain and\naccordingly can be projected to give rise to even further insights. This paper\nwill describe how this positive feedback has the potential to change the\ncomplexion of how computing sciences and neurosciences interact, and suggests\nthat the next form of exponential scaling in computing may emerge from our\nprogressive understanding of the brain.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "Approximate Bayesian inference as a gauge theory",
        "authors": [
            "Biswa Sengupta",
            "Karl Friston"
        ],
        "summary": "In a published paper [Sengupta, 2016], we have proposed that the brain (and\nother self-organized biological and artificial systems) can be characterized\nvia the mathematical apparatus of a gauge theory. The picture that emerges from\nthis approach suggests that any biological system (from a neuron to an\norganism) can be cast as resolving uncertainty about its external milieu,\neither by changing its internal states or its relationship to the environment.\nUsing formal arguments, we have shown that a gauge theory for neuronal dynamics\n-- based on approximate Bayesian inference -- has the potential to shed new\nlight on phenomena that have thus far eluded a formal description, such as\nattention and the link between action and perception. Here, we describe the\ntechnical apparatus that enables such a variational inference on manifolds.\nParticularly, the novel contribution of this paper is an algorithm that utlizes\na Schild's ladder for parallel transport of sufficient statistics (means,\ncovariances, etc.) on a statistical manifold.",
        "year": 2017,
        "label": "q-bio.NC"
    },
    {
        "title": "Elephant Search with Deep Learning for Microarray Data Analysis",
        "authors": [
            "Mrutyunjaya Panda"
        ],
        "summary": "Even though there is a plethora of research in Microarray gene expression\ndata analysis, still, it poses challenges for researchers to effectively and\nefficiently analyze the large yet complex expression of genes. The feature\n(gene) selection method is of paramount importance for understanding the\ndifferences in biological and non-biological variation between samples. In\norder to address this problem, a novel elephant search (ES) based optimization\nis proposed to select best gene expressions from the large volume of microarray\ndata. Further, a promising machine learning method is envisioned to leverage\nsuch high dimensional and complex microarray dataset for extracting hidden\npatterns inside to make a meaningful prediction and most accurate\nclassification. In particular, stochastic gradient descent based Deep learning\n(DL) with softmax activation function is then used on the reduced features\n(genes) for better classification of different samples according to their gene\nexpression levels. The experiments are carried out on nine most popular Cancer\nmicroarray gene selection datasets, obtained from UCI machine learning\nrepository. The empirical results obtained by the proposed elephant search\nbased deep learning (ESDL) approach are compared with most recent published\narticle for its suitability in future Bioinformatics research.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "Enhanced Particle Swarm Optimization Algorithms for Multiple-Input\n  Multiple-Output System Modelling using Convolved Gaussian Process Models",
        "authors": [
            "Gang Cao",
            "Edmund M-K Lai",
            "Fakhrul Alam"
        ],
        "summary": "Convolved Gaussian Process (CGP) is able to capture the correlations not only\nbetween inputs and outputs but also among the outputs. This allows a superior\nperformance of using CGP than standard Gaussian Process (GP) in the modelling\nof Multiple-Input Multiple-Output (MIMO) systems when observations are missing\nfor some of outputs. Similar to standard GP, a key issue of CGP is the learning\nof hyperparameters from a set of input-output observations. It typically\nperformed by maximizing the Log-Likelihood (LL) function which leads to an\nunconstrained nonlinear and non-convex optimization problem. Algorithms such as\nConjugate Gradient (CG) or Broyden-Fletcher-Goldfarb-Shanno (BFGS) are commonly\nused but they often get stuck in local optima, especially for CGP where there\nare more hyperparameters. In addition, the LL value is not a reliable indicator\nfor judging the quality intermediate models in the optimization process. In\nthis paper, we propose to use enhanced Particle Swarm Optimization (PSO)\nalgorithms to solve this problem by minimizing the model output error instead.\nThis optimization criterion enables the quality of intermediate solutions to be\ndirectly observable during the optimization process. Two enhancements to the\nstandard PSO algorithm which make use of gradient information and the multi-\nstart technique are proposed. Simulation results on the modelling of both\nlinear and nonlinear systems demonstrate the effectiveness of minimizing the\nmodel output error to learn hyperparameters and the performance of using\nenhanced algorithms.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "Drift Analysis",
        "authors": [
            "Johannes Lengler"
        ],
        "summary": "Drift analysis is one of the major tools for analysing evolutionary\nalgorithms and nature-inspired search heuristics. In this chapter we give an\nintroduction to drift analysis and give some examples of how to use it for the\nanalysis of evolutionary algorithms.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "Dendritic-Inspired Processing Enables Bio-Plausible STDP in Compound\n  Binary Synapses",
        "authors": [
            "Xinyu Wu",
            "Vishal Saxena"
        ],
        "summary": "Brain-inspired learning mechanisms, e.g. spike timing dependent plasticity\n(STDP), enable agile and fast on-the-fly adaptation capability in a spiking\nneural network. When incorporating emerging nanoscale resistive non-volatile\nmemory (NVM) devices, with ultra-low power consumption and high-density\nintegration capability, a spiking neural network hardware would result in\nseveral orders of magnitude reduction in energy consumption at a very small\nform factor and potentially herald autonomous learning machines. However,\nactual memory devices have shown to be intrinsically binary with stochastic\nswitching, and thus impede the realization of ideal STDP with continuous analog\nvalues. In this work, a dendritic-inspired processing architecture is proposed\nin addition to novel CMOS neuron circuits. The utilization of spike\nattenuations and delays transforms the traditionally undesired stochastic\nbehavior of binary NVMs into a useful leverage that enables\nbiologically-plausible STDP learning. As a result, this work paves a pathway to\nadopt practical binary emerging NVM devices in brain-inspired neuromorphic\ncomputing.",
        "year": 2018,
        "label": "cs.NE"
    },
    {
        "title": "A Comparison of Constraint Handling Techniques for Dynamic Constrained\n  Optimization Problems",
        "authors": [
            "Maria-Yaneli Ameca-Alducin",
            "Maryam Hasani-Shoreh",
            "Wilson Blaikie",
            "Frank Neumann",
            "Efren Mezura-Montes"
        ],
        "summary": "Dynamic constrained optimization problems (DCOPs) have gained researchers\nattention in recent years because a vast majority of real world problems change\nover time. There are studies about the effect of constrained handling\ntechniques in static optimization problems. However, there lacks any\nsubstantial study in the behavior of the most popular constraint handling\ntechniques when dealing with DCOPs. In this paper we study the four most\npopular used constraint handling techniques and apply a simple Differential\nEvolution (DE) algorithm coupled with a change detection mechanism to observe\nthe behavior of these techniques. These behaviors were analyzed using a common\nbenchmark to determine which techniques are suitable for the most prevalent\ntypes of DCOPs. For the purpose of analysis, common measures in static\nenvironments were adapted to suit dynamic environments. While an overall\nsuperior technique could not be determined, certain techniques outperformed\nothers in different aspects like rate of optimization or reliability of\nsolutions.",
        "year": 2018,
        "label": "cs.NE"
    },
    {
        "title": "Sorting by Swaps with Noisy Comparisons",
        "authors": [
            "Tom\u00e1\u0161 Gaven\u010diak",
            "Barbara Geissmann",
            "Johannes Lengler"
        ],
        "summary": "We study sorting of permutations by random swaps if each comparison gives the\nwrong result with some fixed probability $p<1/2$. We use this process as\nprototype for the behaviour of randomized, comparison-based optimization\nheuristics in the presence of noisy comparisons. As quality measure, we compute\nthe expected fitness of the stationary distribution. To measure the runtime, we\ncompute the minimal number of steps after which the average fitness\napproximates the expected fitness of the stationary distribution.\n  We study the process where in each round a random pair of elements at\ndistance at most $r$ are compared. We give theoretical results for the extreme\ncases $r=1$ and $r=n$, and experimental results for the intermediate cases. We\nfind a trade-off between faster convergence (for large $r$) and better quality\nof the solution after convergence (for small $r$).",
        "year": 2018,
        "label": "cs.NE"
    },
    {
        "title": "RDF Knowledge Graph Visualization From a Knowledge Extraction System",
        "authors": [
            "Fadhela Kerdjoudj",
            "Olivier Cur\u00e9"
        ],
        "summary": "In this paper, we present a system to visualize RDF knowledge graphs. These\ngraphs are obtained from a knowledge extraction system designed by\nGEOLSemantics. This extraction is performed using natural language processing\nand trigger detection. The user can visualize subgraphs by selecting some\nontology features like concepts or individuals. The system is also\nmultilingual, with the use of the annotated ontology in English, French, Arabic\nand Chinese.",
        "year": 2015,
        "label": "cs.HC"
    },
    {
        "title": "The Role of Word Length in Semantic Topology",
        "authors": [
            "Francesco Fumarola"
        ],
        "summary": "A topological argument is presented concering the structure of semantic\nspace, based on the negative correlation between polysemy and word length. The\nresulting graph structure is applied to the modeling of free-recall\nexperiments, resulting in predictions on the comparative values of recall\nprobabilities. Associative recall is found to favor longer words whereas\nsequential recall is found to favor shorter words. Data from the PEERS\nexperiments of Lohnas et al. (2015) and Healey and Kahana (2016) confirm both\npredictons, with correlation coefficients $r_{seq}= -0.17$ and $r_{ass}=\n+0.17$. The argument is then applied to predicting global properties of list\nrecall, which leads to a novel explanation for the word-length effect based on\nthe optimization of retrieval strategies.",
        "year": 2016,
        "label": "q-bio.NC"
    },
    {
        "title": "A theory of interpretive clustering in free recall",
        "authors": [
            "Francesco Fumarola"
        ],
        "summary": "A stochastic model of short-term verbal memory is proposed, in which the\npsychological state of the subject is encoded as the instantaneous position of\na particle diffusing over a semantic graph with a probabilistic structure. The\nmodel is particularly suitable for studying the dependence of free-recall\nobservables on semantic properties of the words to be recalled. Besides\npredicting some well-known experimental features (contiguity effect, forward\nasymmetry, word-length effect), a novel prediction is obtained on the\nrelationship between the contiguity effect and the syllabic length of words;\nshorter words, by way of their wider semantic range, are predicted to be\ncharacterized by stronger forward contiguity. A fresh analysis of archival data\nallows to confirm this prediction.",
        "year": 2016,
        "label": "q-bio.NC"
    },
    {
        "title": "Active learning in annotating micro-blogs dealing with e-reputation",
        "authors": [
            "Jean-Val\u00e8re Cossu",
            "Alejandro Molina-Villegas",
            "Mariana Tello-Signoret"
        ],
        "summary": "Elections unleash strong political views on Twitter, but what do people\nreally think about politics? Opinion and trend mining on micro blogs dealing\nwith politics has recently attracted researchers in several fields including\nInformation Retrieval and Machine Learning (ML). Since the performance of ML\nand Natural Language Processing (NLP) approaches are limited by the amount and\nquality of data available, one promising alternative for some tasks is the\nautomatic propagation of expert annotations. This paper intends to develop a\nso-called active learning process for automatically annotating French language\ntweets that deal with the image (i.e., representation, web reputation) of\npoliticians. Our main focus is on the methodology followed to build an original\nannotated dataset expressing opinion from two French politicians over time. We\ntherefore review state of the art NLP-based ML algorithms to automatically\nannotate tweets using a manual initiation step as bootstrap. This paper focuses\non key issues about active learning while building a large annotated data set\nfrom noise. This will be introduced by human annotators, abundance of data and\nthe label distribution across data and entities. In turn, we show that Twitter\ncharacteristics such as the author's name or hashtags can be considered as the\nbearing point to not only improve automatic systems for Opinion Mining (OM) and\nTopic Classification but also to reduce noise in human annotations. However, a\nlater thorough analysis shows that reducing noise might induce the loss of\ncrucial information.",
        "year": 2017,
        "label": "cs.SI"
    },
    {
        "title": "Evolutionary multi-stage financial scenario tree generation",
        "authors": [
            "Ronald Hochreiter"
        ],
        "summary": "Multi-stage financial decision optimization under uncertainty depends on a\ncareful numerical approximation of the underlying stochastic process, which\ndescribes the future returns of the selected assets or asset categories.\nVarious approaches towards an optimal generation of discrete-time,\ndiscrete-state approximations (represented as scenario trees) have been\nsuggested in the literature. In this paper, a new evolutionary algorithm to\ncreate scenario trees for multi-stage financial optimization models will be\npresented. Numerical results and implementation details conclude the paper.",
        "year": 2009,
        "label": "cs.NE"
    },
    {
        "title": "Spike Synchronization Dynamics of Small-World Networks",
        "authors": [
            "Derek Harter"
        ],
        "summary": "In this research report, we examine the effects of small-world network\norganization on spike synchronization dynamics in networks of Izhikevich\nspiking units. We interpolate network organizations from regular ring lattices,\nthrough the small-world region, to random networks, and measure global spike\nsynchronization dynamics. We examine how average path length and clustering\neffect the dynamics of global and neighborhood clique spike organization and\npropagation. We show that the emergence of global synchronization undergoes a\nphase transition in the small-world region, between the clustering and path\nlength phase transitions that are known to exist. We add additional realistic\nconstraints on the dynamics by introducing propagation delays of spiking\nsignals proportional to wiring length. The addition of delays interferes with\nthe ability of random networks to sustain global synchronization, in relation\nto the breakdown of clustering in the networks. The addition of delays further\nenhances the finding that small-world organization is beneficial for balancing\nneighborhood synchronized waves of organization with global synchronization\ndynamics.",
        "year": 2013,
        "label": "cs.NE"
    },
    {
        "title": "Evolving Boolean Networks with RNA Editing",
        "authors": [
            "Larry Bull"
        ],
        "summary": "The editing of transcribed RNA by other molecules such that the form of the\nfinal product differs from that specified in the corresponding DNA sequence is\nubiquitous. This paper uses an abstract, tunable Boolean genetic regulatory\nnetwork model to explore aspects of RNA editing. In particular, it is shown how\ndynamically altering expressed sequences via a guide RNA-inspired mechanism can\nbe selected for by simulated evolution under various single and multicellular\nscenarios.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "A single hidden layer feedforward network with only one neuron in the\n  hidden layer can approximate any univariate function",
        "authors": [
            "Namig J. Guliyev",
            "Vugar E. Ismailov"
        ],
        "summary": "The possibility of approximating a continuous function on a compact subset of\nthe real line by a feedforward single hidden layer neural network with a\nsigmoidal activation function has been studied in many papers. Such networks\ncan approximate an arbitrary continuous function provided that an unlimited\nnumber of neurons in a hidden layer is permitted. In this paper, we consider\nconstructive approximation on any finite interval of $\\mathbb{R}$ by neural\nnetworks with only one neuron in the hidden layer. We construct algorithmically\na smooth, sigmoidal, almost monotone activation function $\\sigma$ providing\napproximation to an arbitrary continuous function within any degree of\naccuracy. This algorithm is implemented in a computer program, which computes\nthe value of $\\sigma$ at any reasonable point of the real axis.",
        "year": 2015,
        "label": "cs.NE"
    },
    {
        "title": "Non-Associative Learning Representation in the Nervous System of the\n  Nematode Caenorhabditis elegans",
        "authors": [
            "Ramin M. Hasani",
            "Magdalena Fuchs",
            "Victoria Beneder",
            "Radu Grosu"
        ],
        "summary": "Caenorhabditis elegans (C. elegans) illustrated remarkable behavioral\nplasticities including complex non-associative and associative learning\nrepresentations. Understanding the principles of such mechanisms presumably\nleads to constructive inspirations for the design of efficient learning\nalgorithms. In the present study, we postulate a novel approach on modeling\nsingle neurons and synapses to study the mechanisms underlying learning in the\nC. elegans nervous system. In this regard, we construct a precise mathematical\nmodel of sensory neurons where we include multi-scale details from genes, ion\nchannels and ion pumps, together with a dynamic model of synapses comprised of\nneurotransmitters and receptors kinetics. We recapitulate mechanosensory\nhabituation mechanism, a non-associative learning process, in which elements of\nthe neural network tune their parameters as a result of repeated input stimuli.\nAccordingly, we quantitatively demonstrate the roots of such plasticity in the\nneuronal and synaptic-level representations. Our findings can potentially give\nrise to the development of new bio-inspired learning algorithms.",
        "year": 2017,
        "label": "q-bio.NC"
    },
    {
        "title": "On the approximation by single hidden layer feedforward neural networks\n  with fixed weights",
        "authors": [
            "Namig J. Guliyev",
            "Vugar E. Ismailov"
        ],
        "summary": "Feedforward neural networks have wide applicability in various disciplines of\nscience due to their universal approximation property. Some authors have shown\nthat single hidden layer feedforward neural networks (SLFNs) with fixed weights\nstill possess the universal approximation property provided that approximated\nfunctions are univariate. But this phenomenon does not lay any restrictions on\nthe number of neurons in the hidden layer. The more this number, the more the\nprobability of the considered network to give precise results. In this note, we\nconstructively prove that SLFNs with the fixed weight $1$ and two neurons in\nthe hidden layer can approximate any continuous function on a compact subset of\nthe real line. The applicability of this result is demonstrated in various\nnumerical examples. Finally, we show that SLFNs with fixed weights cannot\napproximate all continuous multivariate functions.",
        "year": 2017,
        "label": "cs.NE"
    },
    {
        "title": "A Proof Theoretic View of Constraint Programming",
        "authors": [
            "Krzysztof R. Apt"
        ],
        "summary": "We provide here a proof theoretic account of constraint programming that\nattempts to capture the essential ingredients of this programming style. We\nexemplify it by presenting proof rules for linear constraints over interval\ndomains, and illustrate their use by analyzing the constraint propagation\nprocess for the {\\tt SEND + MORE = MONEY} puzzle. We also show how this\napproach allows one to build new constraint solvers.",
        "year": 1998,
        "label": "cs.AI"
    },
    {
        "title": "The Rough Guide to Constraint Propagation",
        "authors": [
            "Krzysztof R. Apt"
        ],
        "summary": "We provide here a simple, yet very general framework that allows us to\nexplain several constraint propagation algorithms in a systematic way. In\nparticular, using the notions commutativity and semi-commutativity, we show how\nthe well-known AC-3, PC-2, DAC and DPC algorithms are instances of a single\ngeneric algorithm. The work reported here extends and simplifies that of Apt,\ncs.AI/9811024.",
        "year": 1999,
        "label": "cs.AI"
    },
    {
        "title": "Automatic Generation of Constraint Propagation Algorithms for Small\n  Finite Domains",
        "authors": [
            "Krzysztof R. Apt",
            "Eric Monfroy"
        ],
        "summary": "We study here constraint satisfaction problems that are based on predefined,\nexplicitly given finite constraints. To solve them we propose a notion of rule\nconsistency that can be expressed in terms of rules derived from the explicit\nrepresentation of the initial constraints.\n  This notion of local consistency is weaker than arc consistency for\nconstraints of arbitrary arity but coincides with it when all domains are unary\nor binary. For Boolean constraints rule consistency coincides with the closure\nunder the well-known propagation rules for Boolean constraints.\n  By generalizing the format of the rules we obtain a characterization of arc\nconsistency in terms of so-called inclusion rules. The advantage of rule\nconsistency and this rule based characterization of the arc consistency is that\nthe algorithms that enforce both notions can be automatically generated, as CHR\nrules. So these algorithms could be integrated into constraint logic\nprogramming systems such as Eclipse.\n  We illustrate the usefulness of this approach to constraint propagation by\ndiscussing the implementations of both algorithms and their use on various\nexamples, including Boolean constraints, three valued logic of Kleene,\nconstraints dealing with Waltz's language for describing polyhedreal scenes,\nand Allen's qualitative approach to temporal logic.",
        "year": 1999,
        "label": "cs.AI"
    },
    {
        "title": "Computing large and small stable models",
        "authors": [
            "Miroslaw Truszczynski"
        ],
        "summary": "In this paper, we focus on the problem of existence and computing of small\nand large stable models. We show that for every fixed integer k, there is a\nlinear-time algorithm to decide the problem LSM (large stable models problem):\ndoes a logic program P have a stable model of size at least |P|-k. In contrast,\nwe show that the problem SSM (small stable models problem) to decide whether a\nlogic program P has a stable model of size at most k is much harder. We present\ntwo algorithms for this problem but their running time is given by polynomials\nof order depending on k. We show that the problem SSM is fixed-parameter\nintractable by demonstrating that it is W[2]-hard. This result implies that it\nis unlikely, an algorithm exists to compute stable models of size at most k\nthat would run in time O(n^c), where c is a constant independent of k. We also\nprovide an upper bound on the fixed-parameter complexity of the problem SSM by\nshowing that it belongs to the class W[3].",
        "year": 2000,
        "label": "cs.LO"
    },
    {
        "title": "SLT-Resolution for the Well-Founded Semantics",
        "authors": [
            "Yi-Dong Shen",
            "Li-Yan Yuan",
            "Jia-Huai You"
        ],
        "summary": "Global SLS-resolution and SLG-resolution are two representative mechanisms\nfor top-down evaluation of the well-founded semantics of general logic\nprograms. Global SLS-resolution is linear for query evaluation but suffers from\ninfinite loops and redundant computations. In contrast, SLG-resolution resolves\ninfinite loops and redundant computations by means of tabling, but it is not\nlinear. The principal disadvantage of a non-linear approach is that it cannot\nbe implemented using a simple, efficient stack-based memory structure nor can\nit be easily extended to handle some strictly sequential operators such as cuts\nin Prolog.\n  In this paper, we present a linear tabling method, called SLT-resolution, for\ntop-down evaluation of the well-founded semantics. SLT-resolution is a\nsubstantial extension of SLDNF-resolution with tabling. Its main features\ninclude: (1) It resolves infinite loops and redundant computations while\npreserving the linearity. (2) It is terminating, and sound and complete w.r.t.\nthe well-founded semantics for programs with the bounded-term-size property\nwith non-floundering queries. Its time complexity is comparable with\nSLG-resolution and polynomial for function-free logic programs. (3) Because of\nits linearity for query evaluation, SLT-resolution bridges the gap between the\nwell-founded semantics and standard Prolog implementation techniques. It can be\nimplemented by an extension to any existing Prolog abstract machines such as\nWAM or ATOAM.",
        "year": 2000,
        "label": "cs.AI"
    },
    {
        "title": "Automatic Belief Revision in SNePS",
        "authors": [
            "Stuart C. Shapiro",
            "Frances L. Johnson"
        ],
        "summary": "SNePS is a logic- and network- based knowledge representation, reasoning, and\nacting system, based on a monotonic, paraconsistent, first-order term logic,\nwith compositional intensional semantics. It has an ATMS-style facility for\nbelief contraction, and an acting component, including a well-defined syntax\nand semantics for primitive and composite acts, as well as for ``rules'' that\nallow for acting in support of reasoning and reasoning in support of acting.\nSNePS has been designed to support natural language competent cognitive agents.\n  When the current version of SNePS detects an explicit contradiction, it\ninteracts with the user, providing information that helps the user decide what\nto remove from the knowledge base in order to remove the contradiction. The\nforthcoming SNePS 2.6 will also do automatic belief contraction if the\ninformation in the knowledge base warrents it.",
        "year": 2000,
        "label": "cs.AI"
    },
    {
        "title": "Extending Classical Logic with Inductive Definitions",
        "authors": [
            "Marc Denecker"
        ],
        "summary": "The goal of this paper is to extend classical logic with a generalized notion\nof inductive definition supporting positive and negative induction, to\ninvestigate the properties of this logic, its relationships to other logics in\nthe area of non-monotonic reasoning, logic programming and deductive databases,\nand to show its application for knowledge representation by giving a typology\nof definitional knowledge.",
        "year": 2000,
        "label": "cs.LO"
    },
    {
        "title": "Logic Programming for Describing and Solving Planning Problems",
        "authors": [
            "Maurice Bruynooghe"
        ],
        "summary": "A logic programming paradigm which expresses solutions to problems as stable\nmodels has recently been promoted as a declarative approach to solving various\ncombinatorial and search problems, including planning problems. In this\nparadigm, all program rules are considered as constraints and solutions are\nstable models of the rule set. This is a rather radical departure from the\nstandard paradigm of logic programming. In this paper we revisit abductive\nlogic programming and argue that it allows a programming style which is as\ndeclarative as programming based on stable models. However, within abductive\nlogic programming, one has two kinds of rules. On the one hand predicate\ndefinitions (which may depend on the abducibles) which are nothing else than\nstandard logic programs (with their non-monotonic semantics when containing\nwith negation); on the other hand rules which constrain the models for the\nabducibles. In this sense abductive logic programming is a smooth extension of\nthe standard paradigm of logic programming, not a radical departure.",
        "year": 2000,
        "label": "cs.AI"
    },
    {
        "title": "Implementing Integrity Constraints in an Existing Belief Revision System",
        "authors": [
            "Frances L. Johnson",
            "Stuart C. Shapiro"
        ],
        "summary": "SNePS is a mature knowledge representation, reasoning, and acting system that\nhas long contained a belief revision subsystem, called SNeBR. SNeBR is\ntriggered when an explicit contradiction is introduced into the SNePS belief\nspace, either because of a user's new assertion, or because of a user's query.\nSNeBR then makes the user decide what belief to remove from the belief space in\norder to restore consistency, although it provides information to help the user\nin making that decision. We have recently added automatic belief revision to\nSNeBR, by which, under certain circumstances, SNeBR decides by itself which\nbelief to remove, and then informs the user of the decision and its\nconsequences. We have used the well-known belief revision integrity constraints\nas a guide in designing automatic belief revision, taking into account,\nhowever, that SNePS's belief space is not deductively closed, and that it would\nbe infeasible to form the deductive closure in order to decide what belief to\nremove. This paper briefly describes SNeBR both before and after this revision,\ndiscusses how we adapted the integrity constraints for this purpose, and gives\nan example of the new SNeBR in action.",
        "year": 2000,
        "label": "cs.AI"
    },
    {
        "title": "Linear Tabulated Resolution Based on Prolog Control Strategy",
        "authors": [
            "Yi-Dong Shen",
            "Li-Yan Yuan",
            "Jia-Huai You",
            "Neng-Fa Zhou"
        ],
        "summary": "Infinite loops and redundant computations are long recognized open problems\nin Prolog. Two ways have been explored to resolve these problems: loop checking\nand tabling. Loop checking can cut infinite loops, but it cannot be both sound\nand complete even for function-free logic programs. Tabling seems to be an\neffective way to resolve infinite loops and redundant computations. However,\nexisting tabulated resolutions, such as OLDT-resolution, SLG- resolution, and\nTabulated SLS-resolution, are non-linear because they rely on the\nsolution-lookup mode in formulating tabling. The principal disadvantage of\nnon-linear resolutions is that they cannot be implemented using a simple\nstack-based memory structure like that in Prolog. Moreover, some strictly\nsequential operators such as cuts may not be handled as easily as in Prolog.\n  In this paper, we propose a hybrid method to resolve infinite loops and\nredundant computations. We combine the ideas of loop checking and tabling to\nestablish a linear tabulated resolution called TP-resolution. TP-resolution has\ntwo distinctive features: (1) It makes linear tabulated derivations in the same\nway as Prolog except that infinite loops are broken and redundant computations\nare reduced. It handles cuts as effectively as Prolog. (2) It is sound and\ncomplete for positive logic programs with the bounded-term-size property. The\nunderlying algorithm can be implemented by an extension to any existing Prolog\nabstract machines such as WAM or ATOAM.",
        "year": 2000,
        "label": "cs.AI"
    },
    {
        "title": "A note on the Declarative reading(s) of Logic Programming",
        "authors": [
            "Marc Denecker"
        ],
        "summary": "This paper analyses the declarative readings of logic programming. Logic\nprogramming - and negation as failure - has no unique declarative reading. One\ncommon view is that logic programming is a logic for default reasoning, a\nsub-formalism of default logic or autoepistemic logic. In this view, negation\nas failure is a modal operator. In an alternative view, a logic program is\ninterpreted as a definition. In this view, negation as failure is classical\nobjective negation. From a commonsense point of view, there is definitely a\ndifference between these views. Surprisingly though, both types of declarative\nreadings lead to grosso modo the same model semantics. This note investigates\nthe causes for this.",
        "year": 2000,
        "label": "cs.LO"
    },
    {
        "title": "Constraint Programming viewed as Rule-based Programming",
        "authors": [
            "Krzysztof R. Apt",
            "Eric Monfroy"
        ],
        "summary": "We study here a natural situation when constraint programming can be entirely\nreduced to rule-based programming. To this end we explain first how one can\ncompute on constraint satisfaction problems using rules represented by simple\nfirst-order formulas. Then we consider constraint satisfaction problems that\nare based on predefined, explicitly given constraints. To solve them we first\nderive rules from these explicitly given constraints and limit the computation\nprocess to a repeated application of these rules, combined with labeling.We\nconsider here two types of rules. The first type, that we call equality rules,\nleads to a new notion of local consistency, called {\\em rule consistency} that\nturns out to be weaker than arc consistency for constraints of arbitrary arity\n(called hyper-arc consistency in \\cite{MS98b}). For Boolean constraints rule\nconsistency coincides with the closure under the well-known propagation rules\nfor Boolean constraints. The second type of rules, that we call membership\nrules, yields a rule-based characterization of arc consistency. To show\nfeasibility of this rule-based approach to constraint programming we show how\nboth types of rules can be automatically generated, as {\\tt CHR} rules of\n\\cite{fruhwirth-constraint-95}. This yields an implementation of this approach\nto programming by means of constraint logic programming. We illustrate the\nusefulness of this approach to constraint programming by discussing various\nexamples, including Boolean constraints, two typical examples of many valued\nlogics, constraints dealing with Waltz's language for describing polyhedral\nscenes, and Allen's qualitative approach to temporal logic.",
        "year": 2000,
        "label": "cs.AI"
    },
    {
        "title": "Verifying Termination of General Logic Programs with Concrete Queries",
        "authors": [
            "Yi-Dong Shen",
            "Li-Yan Yuan",
            "Jia-Huai You"
        ],
        "summary": "We introduce a method of verifying termination of logic programs with respect\nto concrete queries (instead of abstract query patterns). A necessary and\nsufficient condition is established and an algorithm for automatic verification\nis developed. In contrast to existing query pattern-based approaches, our\nmethod has the following features: (1) It applies to all general logic programs\nwith non-floundering queries. (2) It is very easy to automate because it does\nnot need to search for a level mapping or a model, nor does it need to compute\nan interargument relation based on additional mode or type information. (3) It\nbridges termination analysis with loop checking, the two problems that have\nbeen studied separately in the past despite their close technical relation with\neach other.",
        "year": 2000,
        "label": "cs.AI"
    },
    {
        "title": "The temporal calculus of conditional objects and conditional events",
        "authors": [
            "Jerzy Tyszkiewicz",
            "Arthur Ramer",
            "Achim Hoffmann"
        ],
        "summary": "We consider the problem of defining conditional objects (a|b), which would\nallow one to regard the conditional probability Pr(a|b) as a probability of a\nwell-defined event rather than as a shorthand for Pr(ab)/Pr(b). The next issue\nis to define boolean combinations of conditional objects, and possibly also the\noperator of further conditioning. These questions have been investigated at\nleast since the times of George Boole, leading to a number of formalisms\nproposed for conditional objects, mostly of syntactical, proof-theoretic vein.\n  We propose a unifying, semantical approach, in which conditional events are\n(projections of) Markov chains, definable in the three-valued extension of the\npast tense fragment of propositional linear time logic, or, equivalently, by\nthree-valued counter-free Moore machines. Thus our conditional objects are\nindeed stochastic processes, one of the central notions of modern probability\ntheory.\n  Our model fulfills early ideas of Bruno de Finetti and, moreover, as we show\nin a separate paper, all the previously proposed algebras of conditional events\ncan be isomorphically embedded in our model.",
        "year": 2001,
        "label": "cs.AI"
    },
    {
        "title": "Embedding conditional event algebras into temporal calculus of\n  conditionals",
        "authors": [
            "Jerzy Tyszkiewicz",
            "Achim Hoffmann",
            "Arthur Ramer"
        ],
        "summary": "In this paper we prove that all the existing conditional event algebras embed\ninto a three-valued extension of temporal logic of discrete past time, which\nthe authors of this paper have proposed in anothe paper as a general model of\nconditional events.\n  First of all, we discuss the descriptive incompleteness of the cea's. In this\ndirection, we show that some important notions, like independence of\nconditional events, cannot be properly addressed in the framework of\nconditional event algebras, while they can be precisely formulated and analyzed\nin the temporal setting.\n  We also demonstrate that the embeddings allow one to use Markov chain\nalgorithms (suitable for the temporal calculus) for computing probabilities of\ncomplex conditional expressions of the embedded conditional event algebras, and\nthat these algorithms can outperform those previously known.",
        "year": 2001,
        "label": "cs.AI"
    },
    {
        "title": "Computing Preferred Answer Sets by Meta-Interpretation in Answer Set\n  Programming",
        "authors": [
            "Thomas Eiter",
            "Wolfgang Faber",
            "Nicola Leone",
            "Gerald Pfeifer"
        ],
        "summary": "Most recently, Answer Set Programming (ASP) is attracting interest as a new\nparadigm for problem solving. An important aspect which needs to be supported\nis the handling of preferences between rules, for which several approaches have\nbeen presented. In this paper, we consider the problem of implementing\npreference handling approaches by means of meta-interpreters in Answer Set\nProgramming. In particular, we consider the preferred answer set approaches by\nBrewka and Eiter, by Delgrande, Schaub and Tompits, and by Wang, Zhou and Lin.\nWe present suitable meta-interpreters for these semantics using DLV, which is\nan efficient engine for ASP. Moreover, we also present a meta-interpreter for\nthe weakly preferred answer set approach by Brewka and Eiter, which uses the\nweak constraint feature of DLV as a tool for expressing and solving an\nunderlying optimization problem. We also consider advanced meta-interpreters,\nwhich make use of graph-based characterizations and often allow for more\nefficient computations. Our approach shows the suitability of ASP in general\nand of DLV in particular for fast prototyping. This can be fruitfully exploited\nfor experimenting with new languages and knowledge-representation formalisms.",
        "year": 2002,
        "label": "cs.LO"
    },
    {
        "title": "Well-Founded Argumentation Semantics for Extended Logic Programming",
        "authors": [
            "Ralf Schweimeier",
            "Michael Schroeder"
        ],
        "summary": "This paper defines an argumentation semantics for extended logic programming\nand shows its equivalence to the well-founded semantics with explicit negation.\nWe set up a general framework in which we extensively compare this semantics to\nother argumentation semantics, including those of Dung, and Prakken and Sartor.\nWe present a general dialectical proof theory for these argumentation\nsemantics.",
        "year": 2002,
        "label": "cs.LO"
    },
    {
        "title": "Interpolation Theorems for Nonmonotonic Reasoning Systems",
        "authors": [
            "Eyal Amir"
        ],
        "summary": "Craig's interpolation theorem (Craig 1957) is an important theorem known for\npropositional logic and first-order logic. It says that if a logical formula\n$\\beta$ logically follows from a formula $\\alpha$, then there is a formula\n$\\gamma$, including only symbols that appear in both $\\alpha,\\beta$, such that\n$\\beta$ logically follows from $\\gamma$ and $\\gamma$ logically follows from\n$\\alpha$. Such theorems are important and useful for understanding those logics\nin which they hold as well as for speeding up reasoning with theories in those\nlogics. In this paper we present interpolation theorems in this spirit for\nthree nonmonotonic systems: circumscription, default logic and logic programs\nwith the stable models semantics (a.k.a. answer set semantics). These results\ngive us better understanding of those logics, especially in contrast to their\nnonmonotonic characteristics. They suggest that some \\emph{monotonicity}\nprinciple holds despite the failure of classic monotonicity for these logics.\nAlso, they sometimes allow us to use methods for the decomposition of reasoning\nfor these systems, possibly increasing their applicability and tractability.\nFinally, they allow us to build structured representations that use those\nlogics.",
        "year": 2002,
        "label": "cs.AI"
    },
    {
        "title": "Tight Logic Programs",
        "authors": [
            "Esra Erdem",
            "Vladimir Lifschitz"
        ],
        "summary": "This note is about the relationship between two theories of negation as\nfailure -- one based on program completion, the other based on stable models,\nor answer sets. Francois Fages showed that if a logic program satisfies a\ncertain syntactic condition, which is now called ``tightness,'' then its stable\nmodels can be characterized as the models of its completion. We extend the\ndefinition of tightness and Fages' theorem to programs with nested expressions\nin the bodies of rules, and study tight logic programs containing the\ndefinition of the transitive closure of a predicate.",
        "year": 2003,
        "label": "cs.AI"
    },
    {
        "title": "Enhancing a Search Algorithm to Perform Intelligent Backtracking",
        "authors": [
            "Maurice Bruynooghe"
        ],
        "summary": "This paper illustrates how a Prolog program, using chronological backtracking\nto find a solution in some search space, can be enhanced to perform intelligent\nbacktracking. The enhancement crucially relies on the impurity of Prolog that\nallows a program to store information when a dead end is reached. To illustrate\nthe technique, a simple search program is enhanced.\n  To appear in Theory and Practice of Logic Programming.\n  Keywords: intelligent backtracking, dependency-directed backtracking,\nbackjumping, conflict-directed backjumping, nogood sets, look-back.",
        "year": 2003,
        "label": "cs.AI"
    },
    {
        "title": "A Parameterised Hierarchy of Argumentation Semantics for Extended Logic\n  Programming and its Application to the Well-founded Semantics",
        "authors": [
            "Ralf Schweimeier",
            "Michael Schroeder"
        ],
        "summary": "Argumentation has proved a useful tool in defining formal semantics for\nassumption-based reasoning by viewing a proof as a process in which proponents\nand opponents attack each others arguments by undercuts (attack to an\nargument's premise) and rebuts (attack to an argument's conclusion). In this\npaper, we formulate a variety of notions of attack for extended logic programs\nfrom combinations of undercuts and rebuts and define a general hierarchy of\nargumentation semantics parameterised by the notions of attack chosen by\nproponent and opponent. We prove the equivalence and subset relationships\nbetween the semantics and examine some essential properties concerning\nconsistency and the coherence principle, which relates default negation and\nexplicit negation. Most significantly, we place existing semantics put forward\nin the literature in our hierarchy and identify a particular argumentation\nsemantics for which we prove equivalence to the paraconsistent well-founded\nsemantics with explicit negation, WFSX$_p$. Finally, we present a general proof\ntheory, based on dialogue trees, and show that it is sound and complete with\nrespect to the argumentation semantics.",
        "year": 2003,
        "label": "cs.LO"
    },
    {
        "title": "A Framework for Combining Defeasible Argumentation with Labeled\n  Deduction",
        "authors": [
            "Carlos Iv\u00e1n Ches\u00f1evar",
            "Guillermo Ricardo Simari"
        ],
        "summary": "In the last years, there has been an increasing demand of a variety of\nlogical systems, prompted mostly by applications of logic in AI and other\nrelated areas. Labeled Deductive Systems (LDS) were developed as a flexible\nmethodology to formalize such a kind of complex logical systems. Defeasible\nargumentation has proven to be a successful approach to formalizing commonsense\nreasoning, encompassing many other alternative formalisms for defeasible\nreasoning. Argument-based frameworks share some common notions (such as the\nconcept of argument, defeater, etc.) along with a number of particular features\nwhich make it difficult to compare them with each other from a logical\nviewpoint. This paper introduces LDSar, a LDS for defeasible argumentation in\nwhich many important issues concerning defeasible argumentation are captured\nwithin a unified logical framework. We also discuss some logical properties and\nextensions that emerge from the proposed framework.",
        "year": 2004,
        "label": "cs.AI"
    },
    {
        "title": "On the existence of stable models of non-stratified logic programs",
        "authors": [
            "Stefania Costantini"
        ],
        "summary": "This paper introduces a fundamental result, which is relevant for Answer Set\nprogramming, and planning. For the first time since the definition of the\nstable model semantics, the class of logic programs for which a stable model\nexists is given a syntactic characterization. This condition may have a\npractical importance both for defining new algorithms for checking consistency\nand computing answer sets, and for improving the existing systems. The approach\nof this paper is to introduce a new canonical form (to which any logic program\ncan be reduced to), to focus the attention on cyclic dependencies. The\ntechnical result is then given in terms of programs in canonical form\n(canonical programs), without loss of generality. The result is based on\nidentifying the cycles contained in the program, showing that stable models of\nthe overall program are composed of stable models of suitable sub-programs,\ncorresponding to the cycles, and on defining the Cycle Graph. Each vertex of\nthis graph corresponds to one cycle, and each edge corresponds to onehandle,\nwhich is a literal containing an atom that, occurring in both cycles, actually\ndetermines a connection between them. In fact, the truth value of the handle in\nthe cycle where it appears as the head of a rule, influences the truth value of\nthe atoms of the cycle(s) where it occurs in the body. We can therefore\nintroduce the concept of a handle path, connecting different cycles. If for\nevery odd cycle we can find a handle path with certain properties, then the\nexistence of stable model is guaranteed.",
        "year": 2004,
        "label": "cs.AI"
    },
    {
        "title": "Enhancing Global SLS-Resolution with Loop Cutting and Tabling Mechanisms",
        "authors": [
            "Yi-Dong Shen",
            "Jia-Huai You",
            "Li-Yan Yuan"
        ],
        "summary": "Global SLS-resolution is a well-known procedural semantics for top-down\ncomputation of queries under the well-founded model. It inherits from\nSLDNF-resolution the {\\em linearity} property of derivations, which makes it\neasy and efficient to implement using a simple stack-based memory structure.\nHowever, like SLDNF-resolution it suffers from the problem of infinite loops\nand redundant computations. To resolve this problem, in this paper we develop a\nnew procedural semantics, called {\\em SLTNF-resolution}, by enhancing Global\nSLS-resolution with loop cutting and tabling mechanisms. SLTNF-resolution is\nsound and complete w.r.t. the well-founded semantics for logic programs with\nthe bounded-term-size property, and is superior to existing linear tabling\nprocedural semantics such as SLT-resolution.",
        "year": 2005,
        "label": "cs.LO"
    },
    {
        "title": "LPAR-05 Workshop: Empirically Successfull Automated Reasoning in\n  Higher-Order Logic (ESHOL)",
        "authors": [
            "Christoph Benzmueller",
            "John Harrison",
            "Carsten Schuermann"
        ],
        "summary": "This workshop brings together practioners and researchers who are involved in\nthe everyday aspects of logical systems based on higher-order logic. We hope to\ncreate a friendly and highly interactive setting for discussions around the\nfollowing four topics. Implementation and development of proof assistants based\non any notion of impredicativity, automated theorem proving tools for\nhigher-order logic reasoning systems, logical framework technology for the\nrepresentation of proofs in higher-order logic, formal digital libraries for\nstoring, maintaining and querying databases of proofs.\n  We envision attendees that are interested in fostering the development and\nvisibility of reasoning systems for higher-order logics. We are particularly\ninterested in a discusssion on the development of a higher-order version of the\nTPTP and in comparisons of the practical strengths of automated higher-order\nreasoning systems. Additionally, the workshop includes system demonstrations.\n  ESHOL is the successor of the ESCAR and ESFOR workshops held at CADE 2005 and\nIJCAR 2004.",
        "year": 2006,
        "label": "cs.AI"
    },
    {
        "title": "Using Domain Knowledge in Evolutionary System Identification",
        "authors": [
            "Marc Schoenauer",
            "Mich\u00e8le Sebag"
        ],
        "summary": "Two example of Evolutionary System Identification are presented to highlight\nthe importance of incorporating Domain Knowledge: the discovery of an\nanalytical indentation law in Structural Mechanics using constrained Genetic\nProgramming, and the identification of the repartition of underground\nvelocities in Seismic Prospection. Critical issues for sucessful ESI are\ndiscussed in the light of these results.",
        "year": 2006,
        "label": "cs.AI"
    },
    {
        "title": "Yet Another Efficient Unification Algorithm",
        "authors": [
            "Alin Suciu"
        ],
        "summary": "The unification algorithm is at the core of the logic programming paradigm,\nthe first unification algorithm being developed by Robinson [5]. More efficient\nalgorithms were developed later [3] and I introduce here yet another efficient\nunification algorithm centered on a specific data structure, called the\nUnification Table.",
        "year": 2006,
        "label": "cs.LO"
    },
    {
        "title": "An Analysis of Arithmetic Constraints on Integer Intervals",
        "authors": [
            "Krzysztof R. Apt",
            "Peter Zoeteweij"
        ],
        "summary": "Arithmetic constraints on integer intervals are supported in many constraint\nprogramming systems. We study here a number of approaches to implement\nconstraint propagation for these constraints. To describe them we introduce\ninteger interval arithmetic. Each approach is explained using appropriate proof\nrules that reduce the variable domains. We compare these approaches using a set\nof benchmarks. For the most promising approach we provide results that\ncharacterize the effect of constraint propagation. This is a full version of\nour earlier paper, cs.PL/0403016.",
        "year": 2006,
        "label": "cs.AI"
    },
    {
        "title": "Modeling Computations in a Semantic Network",
        "authors": [
            "Marko A. Rodriguez",
            "Johan Bollen"
        ],
        "summary": "Semantic network research has seen a resurgence from its early history in the\ncognitive sciences with the inception of the Semantic Web initiative. The\nSemantic Web effort has brought forth an array of technologies that support the\nencoding, storage, and querying of the semantic network data structure at the\nworld stage. Currently, the popular conception of the Semantic Web is that of a\ndata modeling medium where real and conceptual entities are related in\nsemantically meaningful ways. However, new models have emerged that explicitly\nencode procedural information within the semantic network substrate. With these\nnew technologies, the Semantic Web has evolved from a data modeling medium to a\ncomputational medium. This article provides a classification of existing\ncomputational modeling efforts and the requirements of supporting technologies\nthat will aid in the further growth of this burgeoning domain.",
        "year": 2007,
        "label": "cs.AI"
    },
    {
        "title": "A Common View on Strong, Uniform, and Other Notions of Equivalence in\n  Answer-Set Programming",
        "authors": [
            "Stefan Woltran"
        ],
        "summary": "Logic programming under the answer-set semantics nowadays deals with numerous\ndifferent notions of program equivalence. This is due to the fact that\nequivalence for substitution (known as strong equivalence) and ordinary\nequivalence are different concepts. The former holds, given programs P and Q,\niff P can be faithfully replaced by Q within any context R, while the latter\nholds iff P and Q provide the same output, that is, they have the same answer\nsets. Notions in between strong and ordinary equivalence have been introduced\nas theoretical tools to compare incomplete programs and are defined by either\nrestricting the syntactic structure of the considered context programs R or by\nbounding the set A of atoms allowed to occur in R (relativized equivalence).For\nthe latter approach, different A yield properly different equivalence notions,\nin general. For the former approach, however, it turned out that any\n``reasonable'' syntactic restriction to R coincides with either ordinary,\nstrong, or uniform equivalence. In this paper, we propose a parameterization\nfor equivalence notions which takes care of both such kinds of restrictions\nsimultaneously by bounding, on the one hand, the atoms which are allowed to\noccur in the rule heads of the context and, on the other hand, the atoms which\nare allowed to occur in the rule bodies of the context. We introduce a general\nsemantical characterization which includes known ones as SE-models (for strong\nequivalence) or UE-models (for uniform equivalence) as special cases.\nMoreover,we provide complexity bounds for the problem in question and sketch a\npossible implementation method.\n  To appear in Theory and Practice of Logic Programming (TPLP).",
        "year": 2007,
        "label": "cs.AI"
    },
    {
        "title": "Design and Implementation of Aggregate Functions in the DLV System",
        "authors": [
            "Wolfgang Faber",
            "Gerald Pfeifer",
            "Nicola Leone",
            "Tina Dell'Armi",
            "Giuseppe Ielpa"
        ],
        "summary": "Disjunctive Logic Programming (DLP) is a very expressive formalism: it allows\nfor expressing every property of finite structures that is decidable in the\ncomplexity class SigmaP2 (= NP^NP). Despite this high expressiveness, there are\nsome simple properties, often arising in real-world applications, which cannot\nbe encoded in a simple and natural manner. Especially properties that require\nthe use of arithmetic operators (like sum, times, or count) on a set or\nmultiset of elements, which satisfy some conditions, cannot be naturally\nexpressed in classic DLP.\n  To overcome this deficiency, we extend DLP by aggregate functions in a\nconservative way. In particular, we avoid the introduction of constructs with\ndisputed semantics, by requiring aggregates to be stratified. We formally\ndefine the semantics of the extended language (called DLP^A), and illustrate\nhow it can be profitably used for representing knowledge. Furthermore, we\nanalyze the computational complexity of DLP^A, showing that the addition of\naggregates does not bring a higher cost in that respect. Finally, we provide an\nimplementation of DLP^A in DLV -- a state-of-the-art DLP system -- and report\non experiments which confirm the usefulness of the proposed extension also for\nthe efficiency of computation.",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "Distributed Self Management for Distributed Security Systems",
        "authors": [
            "Michael Hilker"
        ],
        "summary": "Distributed system as e.g. artificial immune systems, complex adaptive\nsystems, or multi-agent systems are widely used in Computer Science, e.g. for\nnetwork security, optimisations, or simulations. In these systems, small\nentities move through the network and perform certain tasks. At some time, the\nentities move to another place and require therefore information where to move\nis most profitable. Common used systems do not provide any information or use a\ncentralised approach where a center delegates the entities. This article\ndiscusses whether small information about the neighbours enhances the\nperformance of the overall system or not. Therefore, two information-protocols\nare introduced and analysed. In addition, the protocols are implemented and\ntested using the artificial immune system SANA that protects a network against\nintrusions.",
        "year": 2008,
        "label": "cs.MA"
    },
    {
        "title": "Next Challenges in Bringing Artificial Immune Systems to Production in\n  Network Security",
        "authors": [
            "Michael Hilker"
        ],
        "summary": "The human immune system protects the human body against various pathogens\nlike e.g. biological viruses and bacteria. Artificial immune systems reuse the\narchitecture, organization, and workflows of the human immune system for\nvarious problems in computer science. In the network security, the artificial\nimmune system is used to secure a network and its nodes against intrusions like\nviruses, worms, and trojans. However, these approaches are far away from\nproduction where they are academic proof-of-concept implementations or use only\na small part to protect against a certain intrusion. This article discusses the\nrequired steps to bring artificial immune systems into production in the\nnetwork security domain. It furthermore figures out the challenges and provides\nthe description and results of the prototype of an artificial immune system,\nwhich is SANA called.",
        "year": 2008,
        "label": "cs.MA"
    },
    {
        "title": "A Distributed Process Infrastructure for a Distributed Data Structure",
        "authors": [
            "Marko A. Rodriguez"
        ],
        "summary": "The Resource Description Framework (RDF) is continuing to grow outside the\nbounds of its initial function as a metadata framework and into the domain of\ngeneral-purpose data modeling. This expansion has been facilitated by the\ncontinued increase in the capacity and speed of RDF database repositories known\nas triple-stores. High-end RDF triple-stores can hold and process on the order\nof 10 billion triples. In an effort to provide a seamless integration of the\ndata contained in RDF repositories, the Linked Data community is providing\nspecifications for linking RDF data sets into a universal distributed graph\nthat can be traversed by both man and machine. While the seamless integration\nof RDF data sets is important, at the scale of the data sets that currently\nexist and will ultimately grow to become, the \"download and index\" philosophy\nof the World Wide Web will not so easily map over to the Semantic Web. This\nessay discusses the importance of adding a distributed RDF process\ninfrastructure to the current distributed RDF data structure.",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "Proposition of the Interactive Pareto Iterated Local Search Procedure -\n  Elements and Initial Experiments",
        "authors": [
            "Martin Josef Geiger"
        ],
        "summary": "The article presents an approach to interactively solve multi-objective\noptimization problems. While the identification of efficient solutions is\nsupported by computational intelligence techniques on the basis of local\nsearch, the search is directed by partial preference information obtained from\nthe decision maker.\n  An application of the approach to biobjective portfolio optimization, modeled\nas the well-known knapsack problem, is reported, and experimental results are\nreported for benchmark instances taken from the literature. In brief, we obtain\nencouraging results that show the applicability of the approach to the\ndescribed problem.",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "MOOPPS: An Optimization System for Multi Objective Scheduling",
        "authors": [
            "Martin Josef Geiger"
        ],
        "summary": "In the current paper, we present an optimization system solving multi\nobjective production scheduling problems (MOOPPS). The identification of Pareto\noptimal alternatives or at least a close approximation of them is possible by a\nset of implemented metaheuristics. Necessary control parameters can easily be\nadjusted by the decision maker as the whole software is fully menu driven. This\nallows the comparison of different metaheuristic algorithms for the considered\nproblem instances. Results are visualized by a graphical user interface showing\nthe distribution of solutions in outcome space as well as their corresponding\nGantt chart representation.\n  The identification of a most preferred solution from the set of efficient\nsolutions is supported by a module based on the aspiration interactive method\n(AIM). The decision maker successively defines aspiration levels until a single\nsolution is chosen.\n  After successfully competing in the finals in Ronneby, Sweden, the MOOPPS\nsoftware has been awarded the European Academic Software Award 2002\n(http://www.bth.se/llab/easa_2002.nsf)",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "Automating Access Control Logics in Simple Type Theory with LEO-II",
        "authors": [
            "Christoph Benzmueller"
        ],
        "summary": "Garg and Abadi recently proved that prominent access control logics can be\ntranslated in a sound and complete way into modal logic S4. We have previously\noutlined how normal multimodal logics, including monomodal logics K and S4, can\nbe embedded in simple type theory (which is also known as higher-order logic)\nand we have demonstrated that the higher-order theorem prover LEO-II can\nautomate reasoning in and about them. In this paper we combine these results\nand describe a sound and complete embedding of different access control logics\nin simple type theory. Employing this framework we show that the off the shelf\ntheorem prover LEO-II can be applied to automate reasoning in prominent access\ncontrol logics.",
        "year": 2009,
        "label": "cs.LO"
    },
    {
        "title": "A remark on higher order RUE-resolution with EXTRUE",
        "authors": [
            "Christoph Benzmueller"
        ],
        "summary": "We show that a prominent counterexample for the completeness of first order\nRUE-resolution does not apply to the higher order RUE-resolution approach\nEXTRUE.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Writing Positive/Negative-Conditional Equations Conveniently",
        "authors": [
            "Claus-Peter Wirth",
            "Ruediger Lunde"
        ],
        "summary": "We present a convenient notation for positive/negative-conditional equations.\nThe idea is to merge rules specifying the same function by using case-, if-,\nmatch-, and let-expressions. Based on the presented macro-rule-construct,\npositive/negative-conditional equational specifications can be written on a\nhigher level. A rewrite system translates the macro-rule-constructs into\npositive/negative-conditional equations.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "ASF+ --- eine ASF-aehnliche Spezifikationssprache",
        "authors": [
            "Ruediger Lunde",
            "Claus-Peter Wirth"
        ],
        "summary": "Maintaining the main aspects of the algebraic specification language ASF as\npresented in [Bergstra&al.89] we have extend ASF with the following concepts:\nWhile once exported names in ASF must stay visible up to the top the module\nhierarchy, ASF+ permits a more sophisticated hiding of signature names. The\nerroneous merging of distinct structures that occurs when importing different\nactualizations of the same parameterized module in ASF is avoided in ASF+ by a\nmore adequate form of parameter binding. The new ``Namensraum''-concept of ASF+\npermits the specifier on the one hand directly to identify the origin of hidden\nnames and on the other to decide whether an imported module is only to be\naccessed or whether an important property of it is to be modified. In the first\ncase he can access one single globally provided version; in the second he has\nto import a copy of the module. Finally ASF+ permits semantic conditions on\nparameters and the specification of tasks for a theorem prover.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Progress in Computer-Assisted Inductive Theorem Proving by\n  Human-Orientedness and Descente Infinie?",
        "authors": [
            "Claus-Peter Wirth"
        ],
        "summary": "In this short position paper we briefly review the development history of\nautomated inductive theorem proving and computer-assisted mathematical\ninduction. We think that the current low expectations on progress in this field\nresult from a faulty narrow-scope historical projection. Our main motivation is\nto explain--on an abstract but hopefully sufficiently descriptive level--why we\nbelieve that future progress in the field is to result from human-orientedness\nand descente infinie.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Syntactic Confluence Criteria for Positive/Negative-Conditional Term\n  Rewriting Systems",
        "authors": [
            "Claus-Peter Wirth"
        ],
        "summary": "We study the combination of the following already known ideas for showing\nconfluence of unconditional or conditional term rewriting systems into\npractically more useful confluence criteria for conditional systems: Our\nsyntactical separation into constructor and non-constructor symbols, Huet's\nintroduction and Toyama's generalization of parallel closedness for\nnon-noetherian unconditional systems, the use of shallow confluence for proving\nconfluence of noetherian and non-noetherian conditional systems, the idea that\ncertain kinds of limited confluence can be assumed for checking the\nfulfilledness or infeasibility of the conditions of conditional critical pairs,\nand the idea that (when termination is given) only prime superpositions have to\nbe considered and certain normalization restrictions can be applied for the\nsubstitutions fulfilling the conditions of conditional critical pairs. Besides\ncombining and improving already known methods, we present the following new\nideas and results: We strengthen the criterion for overlay joinable noetherian\nsystems, and, by using the expressiveness of our syntactical separation into\nconstructor and non-constructor symbols, we are able to present criteria for\nlevel confluence that are not criteria for shallow confluence actually and also\nable to weaken the severe requirement of normality (stiffened with\nleft-linearity) in the criteria for shallow confluence of noetherian and\nnon-noetherian conditional systems to the easily satisfied requirement of\nquasi-normality. Finally, the whole paper may also give a practically useful\noverview of the syntactical means for showing confluence of conditional term\nrewriting systems.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "A Self-Contained and Easily Accessible Discussion of the Method of\n  Descente Infinie and Fermat's Only Explicitly Known Proof by Descente Infinie",
        "authors": [
            "Claus-Peter Wirth"
        ],
        "summary": "We present the only proof of Pierre Fermat by descente infinie that is known\nto exist today. As the text of its Latin original requires active mathematical\ninterpretation, it is more a proof sketch than a proper mathematical proof. We\ndiscuss descente infinie from the mathematical, logical, historical,\nlinguistic, and refined logic-historical points of view. We provide the\nrequired preliminaries from number theory and develop a self-contained proof in\na modern form, which nevertheless is intended to follow Fermat's ideas closely.\nWe then annotate an English translation of Fermat's original proof with terms\nfrom the modern proof. Including all important facts, we present a concise and\nself-contained discussion of Fermat's proof sketch, which is easily accessible\nto laymen in number theory as well as to laymen in the history of mathematics,\nand which provides new clarification of the Method of Descente Infinie to the\nexperts in these fields. Last but not least, this paper fills a gap regarding\nthe easy accessibility of the subject.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "lim+, delta+, and Non-Permutability of beta-Steps",
        "authors": [
            "Claus-Peter Wirth"
        ],
        "summary": "Using a human-oriented formal example proof of the (lim+) theorem, i.e. that\nthe sum of limits is the limit of the sum, which is of value for reference on\nits own, we exhibit a non-permutability of beta-steps and delta+-steps\n(according to Smullyan's classification), which is not visible with\nnon-liberalized delta-rules and not serious with further liberalized\ndelta-rules, such as the delta++-rule. Besides a careful presentation of the\nsearch for a proof of (lim+) with several pedagogical intentions, the main\nsubject is to explain why the order of beta-steps plays such a practically\nimportant role in some calculi.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Full First-Order Sequent and Tableau Calculi With Preservation of\n  Solutions and the Liberalized delta-Rule but Without Skolemization",
        "authors": [
            "Claus-Peter Wirth"
        ],
        "summary": "We present a combination of raising, explicit variable dependency\nrepresentation, the liberalized delta-rule, and preservation of solutions for\nfirst-order deductive theorem proving. Our main motivation is to provide the\nfoundation for our work on inductive theorem proving, where the preservation of\nsolutions is indispensable.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Hilbert's epsilon as an Operator of Indefinite Committed Choice",
        "authors": [
            "Claus-Peter Wirth"
        ],
        "summary": "Paul Bernays and David Hilbert carefully avoided overspecification of\nHilbert's epsilon-operator and axiomatized only what was relevant for their\nproof-theoretic investigations. Semantically, this left the epsilon-operator\nunderspecified. In the meanwhile, there have been several suggestions for\nsemantics of the epsilon as a choice operator. After reviewing the literature\non semantics of Hilbert's epsilon operator, we propose a new semantics with the\nfollowing features: We avoid overspecification (such as right-uniqueness), but\nadmit indefinite choice, committed choice, and classical logics. Moreover, our\nsemantics for the epsilon supports proof search optimally and is natural in the\nsense that it does not only mirror some cases of referential interpretation of\nindefinite articles in natural language, but may also contribute to philosophy\nof language. Finally, we ask the question whether our epsilon within our\nfree-variable framework can serve as a paradigm useful in the specification and\ncomputation of semantics of discourses in natural language.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Interpretations of the Web of Data",
        "authors": [
            "Marko A. Rodriguez"
        ],
        "summary": "The emerging Web of Data utilizes the web infrastructure to represent and\ninterrelate data. The foundational standards of the Web of Data include the\nUniform Resource Identifier (URI) and the Resource Description Framework (RDF).\nURIs are used to identify resources and RDF is used to relate resources. While\nRDF has been posited as a logic language designed specifically for knowledge\nrepresentation and reasoning, it is more generally useful if it can\nconveniently support other models of computing. In order to realize the Web of\nData as a general-purpose medium for storing and processing the world's data,\nit is necessary to separate RDF from its logic language legacy and frame it\nsimply as a data model. Moreover, there is significant advantage in seeing the\nSemantic Web as a particular interpretation of the Web of Data that is focused\nspecifically on knowledge representation and reasoning. By doing so, other\ninterpretations of the Web of Data are exposed that realize RDF in different\ncapacities and in support of different computing models.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Where are the really hard manipulation problems? The phase transition in\n  manipulating the veto rule",
        "authors": [
            "Toby Walsh"
        ],
        "summary": "Voting is a simple mechanism to aggregate the preferences of agents. Many\nvoting rules have been shown to be NP-hard to manipulate. However, a number of\nrecent theoretical results suggest that this complexity may only be in the\nworst-case since manipulation is often easy in practice. In this paper, we show\nthat empirical studies are useful in improving our understanding of this issue.\nWe demonstrate that there is a smooth transition in the probability that a\ncoalition can elect a desired candidate using the veto rule as the size of the\nmanipulating coalition increases. We show that a rescaled probability curve\ndisplays a simple and universal form independent of the size of the problem. We\nargue that manipulation of the veto rule is asymptotically easy for many\nindependent and identically distributed votes even when the coalition of\nmanipulators is critical in size. Based on this argument, we identify a\nsituation in which manipulation is computationally hard. This is when votes are\nhighly correlated and the election is \"hung\". We show, however, that even a\nsingle uncorrelated voter is enough to make manipulation easy again.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Automating Quantified Multimodal Logics in Simple Type Theory -- A Case\n  Study",
        "authors": [
            "Christoph Benzmueller"
        ],
        "summary": "In a case study we investigate whether off the shelf higher-order theorem\nprovers and model generators can be employed to automate reasoning in and about\nquantified multimodal logics. In our experiments we exploit the new TPTP\ninfrastructure for classical higher-order logic.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "A Multi-stage Probabilistic Algorithm for Dynamic Path-Planning",
        "authors": [
            "Nicolas A. Barriga",
            "Mauricio Araya-L\u00f3pez"
        ],
        "summary": "Probabilistic sampling methods have become very popular to solve single-shot\npath planning problems. Rapidly-exploring Random Trees (RRTs) in particular\nhave been shown to be efficient in solving high dimensional problems. Even\nthough several RRT variants have been proposed for dynamic replanning, these\nmethods only perform well in environments with infrequent changes. This paper\naddresses the dynamic path planning problem by combining simple techniques in a\nmulti-stage probabilistic algorithm. This algorithm uses RRTs for initial\nplanning and informed local search for navigation. We show that this\ncombination of simple techniques provides better responses to highly dynamic\nenvironments than the RRT extensions.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Single-Agent On-line Path Planning in Continuous, Unpredictable and\n  Highly Dynamic Environments",
        "authors": [
            "Nicolas A. Barriga"
        ],
        "summary": "This document is a thesis on the subject of single-agent on-line path\nplanning in continuous,unpredictable and highly dynamic environments. The\nproblem is finding and traversing a collision-free path for a holonomic robot,\nwithout kinodynamic restrictions, moving in an environment with several\nunpredictably moving obstacles or adversaries. The availability of perfect\ninformation of the environment at all times is assumed.\n  Several static and dynamic variants of the Rapidly Exploring Random Trees\n(RRT) algorithm are explored, as well as an evolutionary algorithm for planning\nin dynamic environments called the Evolutionary Planner/Navigator. A\ncombination of both kinds of algorithms is proposed to overcome shortcomings in\nboth, and then a combination of a RRT variant for initial planning and informed\nlocal search for navigation, plus a simple greedy heuristic for optimization.\nWe show that this combination of simple techniques provides better responses to\nhighly dynamic environments than the RRT extensions.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Constraint solvers: An empirical evaluation of design decisions",
        "authors": [
            "Lars Kotthoff"
        ],
        "summary": "This paper presents an evaluation of the design decisions made in four\nstate-of-the-art constraint solvers; Choco, ECLiPSe, Gecode, and Minion. To\nassess the impact of design decisions, instances of the five problem classes\nn-Queens, Golomb Ruler, Magic Square, Social Golfers, and Balanced Incomplete\nBlock Design are modelled and solved with each solver. The results of the\nexperiments are not meant to give an indication of the performance of a solver,\nbut rather investigate what influence the choice of algorithms and data\nstructures has.\n  The analysis of the impact of the design decisions focuses on the different\nways of memory management, behaviour with increasing problem size, and\nspecialised algorithms for specific types of variables. It also briefly\nconsiders other, less significant decisions.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "System Dynamics Modelling of the Processes Involving the Maintenance of\n  the Naive T Cell Repertoire",
        "authors": [
            "Grazziela P. Figueredo",
            "Uwe Aickelin",
            "Amanda Whitbrook"
        ],
        "summary": "The study of immune system aging, i.e. immunosenescence, is a relatively new\nresearch topic. It deals with understanding the processes of immunodegradation\nthat indicate signs of functionality loss possibly leading to death. Even\nthough it is not possible to prevent immunosenescence, there is great benefit\nin comprehending its causes, which may help to reverse some of the damage done\nand thus improve life expectancy. One of the main factors influencing the\nprocess of immunosenescence is the number and phenotypical variety of naive T\ncells in an individual. This work presents a review of immunosenescence,\nproposes system dynamics modelling of the processes involving the maintenance\nof the naive T cell repertoire and presents some preliminary results.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "Simple Type Theory as Framework for Combining Logics",
        "authors": [
            "Christoph Benzmueller"
        ],
        "summary": "Simple type theory is suited as framework for combining classical and\nnon-classical logics. This claim is based on the observation that various\nprominent logics, including (quantified) multimodal logics and intuitionistic\nlogics, can be elegantly embedded in simple type theory. Furthermore, simple\ntype theory is sufficiently expressive to model combinations of embedded logics\nand it has a well understood semantics. Off-the-shelf reasoning systems for\nsimple type theory exist that can be uniformly employed for reasoning within\nand about combinations of logics.",
        "year": 2010,
        "label": "cs.LO"
    },
    {
        "title": "Parameterized Complexity Results in Symmetry Breaking",
        "authors": [
            "Toby Walsh"
        ],
        "summary": "Symmetry is a common feature of many combinatorial problems. Unfortunately\neliminating all symmetry from a problem is often computationally intractable.\nThis paper argues that recent parameterized complexity results provide insight\ninto that intractability and help identify special cases in which symmetry can\nbe dealt with more tractably",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "Analysis Of Cancer Omics Data In A Semantic Web Framework",
        "authors": [
            "Matt Holford",
            "James McCusker",
            "Kei Cheung",
            "Michael Krauthammer"
        ],
        "summary": "Our work concerns the elucidation of the cancer (epi)genome, transcriptome\nand proteome to better understand the complex interplay between a cancer cell's\nmolecular state and its response to anti-cancer therapy. To study the problem,\nwe have previously focused on data warehousing technologies and statistical\ndata integration. In this paper, we present recent work on extending our\nanalytical capabilities using Semantic Web technology. A key new component\npresented here is a SPARQL endpoint to our existing data warehouse. This\nendpoint allows the merging of observed quantitative data with existing data\nfrom semantic knowledge sources such as Gene Ontology (GO). We show how such\nvariegated quantitative and functional data can be integrated and accessed in a\nuniversal manner using Semantic Web tools. We also demonstrate how Description\nLogic (DL) reasoning can be used to infer previously unstated conclusions from\nexisting knowledge bases. As proof of concept, we illustrate the ability of our\nsetup to answer complex queries on resistance of cancer cells to Decitabine, a\ndemethylating agent.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "Interactive Execution Monitoring of Agent Teams",
        "authors": [
            "P. Berry",
            "T. J. Lee",
            "D. E. Wilkins"
        ],
        "summary": "There is an increasing need for automated support for humans monitoring the\nactivity of distributed teams of cooperating agents, both human and machine. We\ncharacterize the domain-independent challenges posed by this problem, and\ndescribe how properties of domains influence the challenges and their\nsolutions. We will concentrate on dynamic, data-rich domains where humans are\nultimately responsible for team behavior. Thus, the automated aid should\ninteractively support effective and timely decision making by the human. We\npresent a domain-independent categorization of the types of alerts a plan-based\nmonitoring system might issue to a user, where each type generally requires\ndifferent monitoring techniques. We describe a monitoring framework for\nintegrating many domain-specific and task-specific monitoring techniques and\nthen using the concept of value of an alert to avoid operator overload. We use\nthis framework to describe an execution monitoring approach we have used to\nimplement Execution Assistants (EAs) in two different dynamic, data-rich,\nreal-world domains to assist a human in monitoring team behavior. One domain\n(Army small unit operations) has hundreds of mobile, geographically distributed\nagents, a combination of humans, robots, and vehicles. The other domain (teams\nof unmanned ground and air vehicles) has a handful of cooperating robots. Both\ndomains involve unpredictable adversaries in the vicinity. Our approach\ncustomizes monitoring behavior for each specific task, plan, and situation, as\nwell as for user preferences. Our EAs alert the human controller when reported\nevents threaten plan execution or physically threaten team members. Alerts were\ngenerated in a timely manner without inundating the user with too many alerts\n(less than 10 percent of alerts are unwanted, as judged by domain experts).",
        "year": 2011,
        "label": "cs.MA"
    },
    {
        "title": "Computing with Logic as Operator Elimination: The ToyElim System",
        "authors": [
            "Christoph Wernhard"
        ],
        "summary": "A prototype system is described whose core functionality is, based on\npropositional logic, the elimination of second-order operators, such as Boolean\nquantifiers and operators for projection, forgetting and circumscription. This\napproach allows to express many representational and computational tasks in\nknowledge representation - for example computation of abductive explanations\nand models with respect to logic programming semantics - in a uniform\noperational system, backed by a uniform classical semantic framework.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "Task Interaction in an HTN Planner",
        "authors": [
            "Il\u010de Georgievski",
            "Alexander Lazovik",
            "Marco Aiello"
        ],
        "summary": "Hierarchical Task Network (HTN) planning uses task decomposition to plan for\nan executable sequence of actions as a solution to a problem. In order to\nreason effectively, an HTN planner needs expressive domain knowledge. For\ninstance, a simplified HTN planning system such as JSHOP2 uses such\nexpressivity and avoids some task interactions due to the increased complexity\nof the planning process. We address the possibility of simplifying the domain\nrepresentation needed for an HTN planner to find good solutions, especially in\nreal-world domains describing home and building automation environments. We\nextend the JSHOP2 planner to reason about task interaction that happens when\ntask's effects are already achieved by other tasks. The planner then prunes\nsome of the redundant searches that can occur due to the planning process's\ninterleaving nature. We evaluate the original and our improved planner on two\nbenchmark domains. We show that our planner behaves better by using simplified\ndomain knowledge and outperforms JSHOP2 in a number of relevant cases.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "BEEM : Bucket Elimination with External Memory",
        "authors": [
            "Kalev Kask",
            "Rina Dechter",
            "Andrew E. Gelfand"
        ],
        "summary": "A major limitation of exact inference algorithms for probabilistic graphical\nmodels is their extensive memory usage, which often puts real-world problems\nout of their reach. In this paper we show how we can extend inference\nalgorithms, particularly Bucket Elimination, a special case of cluster (join)\ntree decomposition, to utilize disk memory. We provide the underlying ideas and\nshow promising empirical results of exactly solving large problems not solvable\nbefore.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "The Initial Conditions of the Universe from Constrained Simulations",
        "authors": [
            "Francisco-Shu Kitaura"
        ],
        "summary": "I present a new approach to recover the primordial density fluctuations and\nthe cosmic web structure underlying a galaxy distribution. The method is based\non sampling Gaussian fields which are compatible with a galaxy distribution and\na structure formation model. This is achieved by splitting the inversion\nproblem into two Gibbs-sampling steps: the first being a Gaussianisation step\ntransforming a distribution of point sources at Lagrangian positions -which are\nnot a priori given- into a linear alias-free Gaussian field. This step is based\non Hamiltonian sampling with a Gaussian-Poisson model. The second step consists\non a likelihood comparison in which the set of matter tracers at the initial\nconditions is constrained on the galaxy distribution and the assumed structure\nformation model. For computational reasons second order Lagrangian Perturbation\nTheory is used. However, the presented approach is flexible to adopt any\nstructure formation model. A semi-analytic halo-model based galaxy mock catalog\nis taken to demonstrate that the recovered initial conditions are closely\nunbiased with respect to the actual ones from the corresponding N-body\nsimulation down to scales of a ~ 5 Mpc/h. The cross-correlation between them\nshows a substantial gain of information, being at k ~ 0.3 h/Mpc more than\ndoubled. In addition the initial conditions are extremely well Gaussian\ndistributed and the power-spectra follow the shape of the linear power-spectrum\nbeing very close to the actual one from the simulation down to scales of k ~ 1\nh/Mpc.",
        "year": 2012,
        "label": "astro-ph.CO"
    },
    {
        "title": "Symmetry Breaking Constraints: Recent Results",
        "authors": [
            "Toby Walsh"
        ],
        "summary": "Symmetry is an important problem in many combinatorial problems. One way of\ndealing with symmetry is to add constraints that eliminate symmetric solutions.\nWe survey recent results in this area, focusing especially on two common and\nuseful cases: symmetry breaking constraints for row and column symmetry, and\nsymmetry breaking constraints for eliminating value symmetry",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Magic Sets for Disjunctive Datalog Programs",
        "authors": [
            "Mario Alviano",
            "Wolfgang Faber",
            "Gianluigi Greco",
            "Nicola Leone"
        ],
        "summary": "In this paper, a new technique for the optimization of (partially) bound\nqueries over disjunctive Datalog programs with stratified negation is\npresented. The technique exploits the propagation of query bindings and extends\nthe Magic Set (MS) optimization technique.\n  An important feature of disjunctive Datalog is nonmonotonicity, which calls\nfor nondeterministic implementations, such as backtracking search. A\ndistinguishing characteristic of the new method is that the optimization can be\nexploited also during the nondeterministic phase. In particular, after some\nassumptions have been made during the computation, parts of the program may\nbecome irrelevant to a query under these assumptions. This allows for dynamic\npruning of the search space. In contrast, the effect of the previously defined\nMS methods for disjunctive Datalog is limited to the deterministic portion of\nthe process. In this way, the potential performance gain by using the proposed\nmethod can be exponential, as could be observed empirically.\n  The correctness of MS is established thanks to a strong relationship between\nMS and unfounded sets that has not been studied in the literature before. This\nknowledge allows for extending the method also to programs with stratified\nnegation in a natural way.\n  The proposed method has been implemented in DLV and various experiments have\nbeen conducted. Experimental results on synthetic data confirm the utility of\nMS for disjunctive Datalog, and they highlight the computational gain that may\nbe obtained by the new method w.r.t. the previously proposed MS methods for\ndisjunctive Datalog programs. Further experiments on real-world data show the\nbenefits of MS within an application scenario that has received considerable\nattention in recent years, the problem of answering user queries over possibly\ninconsistent databases originating from integration of autonomous sources of\ninformation.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Direct and Indirect Effects",
        "authors": [
            "Judea Pearl"
        ],
        "summary": "The direct effect of one eventon another can be defined and measured\nbyholding constant all intermediate variables between the two.Indirect effects\npresent conceptual andpractical difficulties (in nonlinear models), because\nthey cannot be isolated by holding certain variablesconstant. This paper shows\na way of defining any path-specific effectthat does not invoke blocking the\nremainingpaths.This permits the assessment of a more naturaltype of direct and\nindirect effects, one thatis applicable in both linear and nonlinear models.\nThe paper establishesconditions under which such assessments can be estimated\nconsistentlyfrom experimental and nonexperimental data,and thus extends\npath-analytic techniques tononlinear and nonparametric models.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Entanglement Zoo I: Foundational and Structural Aspects",
        "authors": [
            "Diederik Aerts",
            "Sandro Sozzo"
        ],
        "summary": "We put forward a general classification for a structural description of the\nentanglement present in compound entities experimentally violating Bell's\ninequalities, making use of a new entanglement scheme that we developed\nrecently. Our scheme, although different from the traditional one, is\ncompletely compatible with standard quantum theory, and enables quantum\nmodeling in complex Hilbert space for different types of situations. Namely,\nsituations where entangled states and product measurements appear ('customary\nquantum modeling'), and situations where states and measurements and evolutions\nbetween measurements are entangled ('nonlocal box modeling', 'nonlocal\nnon-marginal box modeling'). The role played by Tsirelson's bound and marginal\ndistribution law is emphasized. Specific quantum models are worked out in\ndetail in complex Hilbert space within this new entanglement scheme.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Entanglement Zoo II: Examples in Physics and Cognition",
        "authors": [
            "Diederik Aerts",
            "Sandro Sozzo"
        ],
        "summary": "We have recently presented a general scheme enabling quantum modeling of\ndifferent types of situations that violate Bell's inequalities. In this paper,\nwe specify this scheme for a combination of two concepts. We work out a quantum\nHilbert space model where 'entangled measurements' occur in addition to the\nexpected 'entanglement between the component concepts', or 'state\nentanglement'. We extend this result to a macroscopic physical entity, the\n'connected vessels of water', which maximally violates Bell's inequalities. We\nenlighten the structural and conceptual analogies between the cognitive and\nphysical situations which are both examples of a nonlocal non-marginal box\nmodeling in our classification.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Narrative based Postdictive Reasoning for Cognitive Robotics",
        "authors": [
            "Manfred Eppe",
            "Mehul Bhatt"
        ],
        "summary": "Making sense of incomplete and conflicting narrative knowledge in the\npresence of abnormalities, unobservable processes, and other real world\nconsiderations is a challenge and crucial requirement for cognitive robotics\nsystems. An added challenge, even when suitably specialised action languages\nand reasoning systems exist, is practical integration and application within\nlarge-scale robot control frameworks.\n  In the backdrop of an autonomous wheelchair robot control task, we report on\napplication-driven work to realise postdiction triggered abnormality detection\nand re-planning for real-time robot control: (a) Narrative-based knowledge\nabout the environment is obtained via a larger smart environment framework; and\n(b) abnormalities are postdicted from stable-models of an answer-set program\ncorresponding to the robot's epistemic model. The overall reasoning is\nperformed in the context of an approximate epistemic action theory based\nplanner implemented via a translation to answer-set programming.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Penetration Testing == POMDP Solving?",
        "authors": [
            "Carlos Sarraute",
            "Olivier Buffet",
            "Joerg Hoffmann"
        ],
        "summary": "Penetration Testing is a methodology for assessing network security, by\ngenerating and executing possible attacks. Doing so automatically allows for\nregular and systematic testing without a prohibitive amount of human labor. A\nkey question then is how to generate the attacks. This is naturally formulated\nas a planning problem. Previous work (Lucangeli et al. 2010) used classical\nplanning and hence ignores all the incomplete knowledge that characterizes\nhacking. More recent work (Sarraute et al. 2011) makes strong independence\nassumptions for the sake of scaling, and lacks a clear formal concept of what\nthe attack planning problem actually is. Herein, we model that problem in terms\nof partially observable Markov decision processes (POMDP). This grounds\npenetration testing in a well-researched formalism, highlighting important\naspects of this problem's nature. POMDPs allow to model information gathering\nas an integral part of the problem, thus providing for the first time a means\nto intelligently mix scanning actions with actual exploits.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Breaking Symmetry with Different Orderings",
        "authors": [
            "Nina Narodytska",
            "Toby Walsh"
        ],
        "summary": "We can break symmetry by eliminating solutions within each symmetry class.\nFor instance, the Lex-Leader method eliminates all but the smallest solution in\nthe lexicographical ordering. Unfortunately, the Lex-Leader method is\nintractable in general. We prove that, under modest assumptions, we cannot\nreduce the worst case complexity of breaking symmetry by using other orderings\non solutions. We also prove that a common type of symmetry, where rows and\ncolumns in a matrix of decision variables are interchangeable, is intractable\nto break when we use two promising alternatives to the lexicographical\nordering: the Gray code ordering (which uses a different ordering on\nsolutions), and the Snake-Lex ordering (which is a variant of the\nlexicographical ordering that re-orders the variables). Nevertheless, we show\nexperimentally that using other orderings like the Gray code to break symmetry\ncan be beneficial in practice as they may better align with the objective\nfunction and branching heuristic.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Breaking Generator Symmetry",
        "authors": [
            "George Katsirelos",
            "Nina Narodytska",
            "Toby Walsh"
        ],
        "summary": "Dealing with large numbers of symmetries is often problematic. One solution\nis to focus on just symmetries that generate the symmetry group. Whilst there\nare special cases where breaking just the symmetries in a generating set is\ncomplete, there are also cases where no irredundant generating set eliminates\nall symmetry. However, focusing on just generators improves tractability. We\nprove that it is polynomial in the size of the generating set to eliminate all\nsymmetric solutions, but NP-hard to prune all symmetric values. Our proof\nconsiders row and column symmetry, a common type of symmetry in matrix models\nwhere breaking just generator symmetries is very effective. We show that\npropagating a conjunction of lexicographical ordering constraints on the rows\nand columns of a matrix of decision variables is NP-hard.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "A Hypergraph-Partitioned Vertex Programming Approach for Large-scale\n  Consensus Optimization",
        "authors": [
            "Hui Miao",
            "Xiangyang Liu",
            "Bert Huang",
            "Lise Getoor"
        ],
        "summary": "In modern data science problems, techniques for extracting value from big\ndata require performing large-scale optimization over heterogenous, irregularly\nstructured data. Much of this data is best represented as multi-relational\ngraphs, making vertex programming abstractions such as those of Pregel and\nGraphLab ideal fits for modern large-scale data analysis. In this paper, we\ndescribe a vertex-programming implementation of a popular consensus\noptimization technique known as the alternating direction of multipliers\n(ADMM). ADMM consensus optimization allows elegant solution of complex\nobjectives such as inference in rich probabilistic models. We also introduce a\nnovel hypergraph partitioning technique that improves over state-of-the-art\npartitioning techniques for vertex programming and significantly reduces the\ncommunication cost by reducing the number of replicated nodes up to an order of\nmagnitude. We implemented our algorithm in GraphLab and measure scaling\nperformance on a variety of realistic bipartite graph distributions and a large\nsynthetic voter-opinion analysis application. In our experiments, we are able\nto achieve a 50% improvement in runtime over the current state-of-the-art\nGraphLab partitioning scheme.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Reuse of designs: Desperately seeking an interdisciplinary cognitive\n  approach",
        "authors": [
            "Willemien Visser",
            "Brigitte Trousse"
        ],
        "summary": "This text analyses the papers accepted for the workshop \"Reuse of designs: an\ninterdisciplinary cognitive approach\". Several dimensions and questions\nconsidered as important (by the authors and/or by us) are addressed: What about\nthe \"interdisciplinary cognitive\" character of the approaches adopted by the\nauthors? Is design indeed a domain where the use of CBR is particularly\nsuitable? Are there important distinctions between CBR and other approaches?\nWhich types of knowledge -other than cases- is being, or might be, used in CBR\nsystems? With respect to cases: are there different \"types\" of case and\ndifferent types of case use? which formats are adopted for their\nrepresentation? do cases have \"components\"? how are cases organised in the case\nmemory? Concerning their retrieval: which types of index are used? on which\ntypes of relation is retrieval based? how does one retrieve only a selected\nnumber of cases, i.e., how does one retrieve only the \"best\" cases? which\nprocesses and strategies are used, by the system and by its user? Finally, some\nimportant aspects of CBR system development are shortly discussed: should CBR\nsystems be assistance or autonomous systems? how can case knowledge be\n\"acquired\"? what about the empirical evaluation of CBR systems? The conclusion\npoints out some lacking points: not much attention is paid to the user, and few\npapers have indeed adopted an interdisciplinary cognitive approach.",
        "year": 2006,
        "label": "cs.HC"
    },
    {
        "title": "Grammar-Based Random Walkers in Semantic Networks",
        "authors": [
            "Marko A. Rodriguez"
        ],
        "summary": "Semantic networks qualify the meaning of an edge relating any two vertices.\nDetermining which vertices are most \"central\" in a semantic network is\ndifficult because one relationship type may be deemed subjectively more\nimportant than another. For this reason, research into semantic network metrics\nhas focused primarily on context-based rankings (i.e. user prescribed\ncontexts). Moreover, many of the current semantic network metrics rank semantic\nassociations (i.e. directed paths between two vertices) and not the vertices\nthemselves. This article presents a framework for calculating semantically\nmeaningful primary eigenvector-based metrics such as eigenvector centrality and\nPageRank in semantic networks using a modified version of the random walker\nmodel of Markov chain analysis. Random walkers, in the context of this article,\nare constrained by a grammar, where the grammar is a user defined data\nstructure that determines the meaning of the final vertex ranking. The ideas in\nthis article are presented within the context of the Resource Description\nFramework (RDF) of the Semantic Web initiative.",
        "year": 2008,
        "label": "cs.AI"
    },
    {
        "title": "Accelerating and Evaluation of Syntactic Parsing in Natural Language\n  Question Answering Systems",
        "authors": [
            "Zhe Chen",
            "Dunwei Wen"
        ],
        "summary": "With the development of Natural Language Processing (NLP), more and more\nsystems want to adopt NLP in User Interface Module to process user input, in\norder to communicate with user in a natural way. However, this raises a speed\nproblem. That is, if NLP module can not process sentences in durable time\ndelay, users will never use the system. As a result, systems which are strict\nwith processing time, such as dialogue systems, web search systems, automatic\ncustomer service systems, especially real-time systems, have to abandon NLP\nmodule in order to get a faster system response. This paper aims to solve the\nspeed problem. In this paper, at first, the construction of a syntactic parser\nwhich is based on corpus machine learning and statistics model is introduced,\nand then a speed problem analysis is performed on the parser and its\nalgorithms. Based on the analysis, two accelerating methods, Compressed POS Set\nand Syntactic Patterns Pruning, are proposed, which can effectively improve the\ntime efficiency of parsing in NLP module. To evaluate different parameters in\nthe accelerating algorithms, two new factors, PT and RT, are introduced and\nexplained in detail. Experiments are also completed to prove and test these\nmethods, which will surely contribute to the application of NLP.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Decompositions of Grammar Constraints",
        "authors": [
            "Claude-Guy Quimper",
            "Toby Walsh"
        ],
        "summary": "A wide range of constraints can be compactly specified using automata or\nformal languages. In a sequence of recent papers, we have shown that an\neffective means to reason with such specifications is to decompose them into\nprimitive constraints. We can then, for instance, use state of the art SAT\nsolvers and profit from their advanced features like fast unit propagation,\nclause learning, and conflict-based search heuristics. This approach holds\npromise for solving combinatorial problems in scheduling, rostering, and\nconfiguration, as well as problems in more diverse areas like bioinformatics,\nsoftware testing and natural language processing. In addition, decomposition\nmay be an effective method to propagate other global constraints.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Symmetry Breaking Using Value Precedence",
        "authors": [
            "Toby Walsh"
        ],
        "summary": "We present a comprehensive study of the use of value precedence constraints\nto break value symmetry. We first give a simple encoding of value precedence\ninto ternary constraints that is both efficient and effective at breaking\nsymmetry. We then extend value precedence to deal with a number of\ngeneralizations like wreath value and partial interchangeability. We also show\nthat value precedence is closely related to lexicographical ordering. Finally,\nwe consider the interaction between value precedence and symmetry breaking\nconstraints for variable symmetries.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Breaking Value Symmetry",
        "authors": [
            "Toby Walsh"
        ],
        "summary": "One common type of symmetry is when values are symmetric. For example, if we\nare assigning colours (values) to nodes (variables) in a graph colouring\nproblem then we can uniformly interchange the colours throughout a colouring.\nFor a problem with value symmetries, all symmetric solutions can be eliminated\nin polynomial time. However, as we show here, both static and dynamic methods\nto deal with symmetry have computational limitations. With static methods,\npruning all symmetric values is NP-hard in general. With dynamic methods, we\ncan take exponential time on problems which static methods solve without\nsearch.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "Contracting preference relations for database applications",
        "authors": [
            "Denis Mindolin",
            "Jan Chomicki"
        ],
        "summary": "The binary relation framework has been shown to be applicable to many\nreal-life preference handling scenarios. Here we study preference contraction:\nthe problem of discarding selected preferences. We argue that the property of\nminimality and the preservation of strict partial orders are crucial for\ncontractions. Contractions can be further constrained by specifying which\npreferences should be protected. We consider two classes of preference\nrelations: finite and finitely representable. We present algorithms for\ncomputing minimal and preference-protecting minimal contractions for finite as\nwell as finitely representable preference relations. We study relationships\nbetween preference change in the binary relation framework and belief change in\nthe belief revision theory. We also introduce some preference query\noptimization techniques which can be used in the presence of contraction. We\nevaluate the proposed algorithms experimentally and present the results.",
        "year": 2009,
        "label": "cs.AI"
    },
    {
        "title": "A Simplified and Improved Free-Variable Framework for Hilbert's epsilon\n  as an Operator of Indefinite Committed Choice",
        "authors": [
            "Claus-Peter Wirth"
        ],
        "summary": "Free variables occur frequently in mathematics and computer science with ad\nhoc and altering semantics. We present the most recent version of our\nfree-variable framework for two-valued logics with properly improved\nfunctionality, but only two kinds of free variables left (instead of three):\nimplicitly universally and implicitly existentially quantified ones, now simply\ncalled \"free atoms\" and \"free variables\", respectively. The quantificational\nexpressiveness and the problem-solving facilities of our framework exceed\nstandard first-order and even higher-order modal logics, and directly support\nFermat's descente infinie. With the improved version of our framework, we can\nnow model also Henkin quantification, neither using quantifiers (binders) nor\nraising (Skolemization). We propose a new semantics for Hilbert's epsilon as a\nchoice operator with the following features: We avoid overspecification (such\nas right-uniqueness), but admit indefinite choice, committed choice, and\nclassical logics. Moreover, our semantics for the epsilon supports reductive\nproof search optimally.",
        "year": 2011,
        "label": "cs.AI"
    },
    {
        "title": "The Do-Calculus Revisited",
        "authors": [
            "Judea Pearl"
        ],
        "summary": "The do-calculus was developed in 1995 to facilitate the identification of\ncausal effects in non-parametric models. The completeness proofs of [Huang and\nValtorta, 2006] and [Shpitser and Pearl, 2006] and the graphical criteria of\n[Tian and Shpitser, 2010] have laid this identification problem to rest. Recent\nexplorations unveil the usefulness of the do-calculus in three additional\nareas: mediation analysis [Pearl, 2012], transportability [Pearl and\nBareinboim, 2011] and metasynthesis. Meta-synthesis (freshly coined) is the\ntask of fusing empirical results from several diverse studies, conducted on\nheterogeneous populations and under different conditions, so as to synthesize\nan estimate of a causal relation in some target environment, potentially\ndifferent from those under study. The talk surveys these results with emphasis\non the challenges posed by meta-synthesis. For background material, see\nhttp://bayes.cs.ucla.edu/csl_papers.html",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Probability and Asset Updating using Bayesian Networks for Combinatorial\n  Prediction Markets",
        "authors": [
            "Wei Sun",
            "Robin Hanson",
            "Kathryn Blackmond Laskey",
            "Charles Twardy"
        ],
        "summary": "A market-maker-based prediction market lets forecasters aggregate information\nby editing a consensus probability distribution either directly or by trading\nsecurities that pay off contingent on an event of interest. Combinatorial\nprediction markets allow trading on any event that can be specified as a\ncombination of a base set of events. However, explicitly representing the full\njoint distribution is infeasible for markets with more than a few base events.\nA factored representation such as a Bayesian network (BN) can achieve tractable\ncomputation for problems with many related variables. Standard BN inference\nalgorithms, such as the junction tree algorithm, can be used to update a\nrepresentation of the entire joint distribution given a change to any local\nconditional probability. However, in order to let traders reuse assets from\nprior trades while never allowing assets to become negative, a BN based\nprediction market also needs to update a representation of each user's assets\nand find the conditional state in which a user has minimum assets. Users also\nfind it useful to see their expected assets given an edit outcome. We show how\nto generalize the junction tree algorithm to perform all these computations.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Conjunction and Negation of Natural Concepts: A Quantum-theoretic\n  Modeling",
        "authors": [
            "Sandro Sozzo"
        ],
        "summary": "We perform two experiments with the aim to investigate the effects of\nnegation on the combination of natural concepts. In the first experiment, we\ntest the membership weights of a list of exemplars with respect to two\nconcepts, e.g., {\\it Fruits} and {\\it Vegetables}, and their conjunction {\\it\nFruits And Vegetables}. In the second experiment, we test the membership\nweights of the same list of exemplars with respect to the same two concepts,\nbut negating the second, e.g., {\\it Fruits} and {\\it Not Vegetables}, and again\ntheir conjunction {\\it Fruits And Not Vegetables}. The collected data confirm\nexisting results on conceptual combination, namely, they show dramatic\ndeviations from the predictions of classical (fuzzy set) logic and probability\ntheory. More precisely, they exhibit conceptual vagueness, gradeness of\nmembership, overextension and double overextension of membership weights with\nrespect to the given conjunctions. Then, we show that the quantum probability\nmodel in Fock space recently elaborated to model Hampton's data on concept\nconjunction (Hampton, 1988a) and disjunction (Hampton, 1988b) faithfully\naccords with the collected data. Our quantum-theoretic modeling enables to\ndescribe these non-classical effects in terms of genuine quantum effects,\nnamely `contextuality', `superposition', `interference' and `emergence'. The\nobtained results confirm and strenghten the analysis in Aerts (2009a) and Sozzo\n(2014) on the identification of quantum aspects in experiments on conceptual\nvagueness. Our results can be inserted within the general research on the\nidentification of quantum structures in cognitive and decision processes.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Unstructuring User Preferences: Efficient Non-Parametric Utility\n  Revelation",
        "authors": [
            "Carmel Domshlak",
            "Thorsten Joachims"
        ],
        "summary": "Tackling the problem of ordinal preference revelation and reasoning, we\npropose a novel methodology for generating an ordinal utility function from a\nset of qualitative preference statements. To the best of our knowledge, our\nproposal constitutes the first nonparametric solution for this problem that is\nboth efficient and semantically sound. Our initial experiments provide strong\nevidence for practical effectiveness of our approach.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Description Logics with Fuzzy Concrete Domains",
        "authors": [
            "Umberto Straccia"
        ],
        "summary": "We present a fuzzy version of description logics with concrete domains. Main\nfeatures are: (i) concept constructors are based on t-norm, t-conorm, negation\nand implication; (ii) concrete domains are fuzzy sets; (iii) fuzzy modifiers\nare allowed; and (iv) the reasoning algorithm is based on a mixture of\ncompletion rules and bounded mixed integer programming.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Minimal Proof Search for Modal Logic K Model Checking",
        "authors": [
            "Abdallah Saffidine"
        ],
        "summary": "Most modal logics such as S5, LTL, or ATL are extensions of Modal Logic K.\nWhile the model checking problems for LTL and to a lesser extent ATL have been\nvery active research areas for the past decades, the model checking problem for\nthe more basic Multi-agent Modal Logic K (MMLK) has important applications as a\nformal framework for perfect information multi-player games on its own.\n  We present Minimal Proof Search (MPS), an effort number based algorithm\nsolving the model checking problem for MMLK. We prove two important properties\nfor MPS beyond its correctness. The (dis)proof exhibited by MPS is of minimal\ncost for a general definition of cost, and MPS is an optimal algorithm for\nfinding (dis)proofs of minimal cost. Optimality means that any comparable\nalgorithm either needs to explore a bigger or equal state space than MPS, or is\nnot guaranteed to find a (dis)proof of minimal cost on every input.\n  As such, our work relates to A* and AO* in heuristic search, to Proof Number\nSearch and DFPN+ in two-player games, and to counterexample minimization in\nsoftware model checking.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Identifying Conditional Causal Effects",
        "authors": [
            "Jin Tian"
        ],
        "summary": "This paper concerns the assessment of the effects of actions from a\ncombination of nonexperimental data and causal assumptions encoded in the form\nof a directed acyclic graph in which some variables are presumed to be\nunobserved. We provide a procedure that systematically identifies cause effects\nbetween two sets of variables conditioned on some other variables, in time\npolynomial in the number of variables in the graph. The identifiable\nconditional causal effects are expressed in terms of the observed joint\ndistribution.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Robustness of Causal Claims",
        "authors": [
            "Judea Pearl"
        ],
        "summary": "A causal claim is any assertion that invokes causal relationships between\nvariables, for example that a drug has a certain effect on preventing a\ndisease. Causal claims are established through a combination of data and a set\nof causal assumptions called a causal model. A claim is robust when it is\ninsensitive to violations of some of the causal assumptions embodied in the\nmodel. This paper gives a formal definition of this notion of robustness and\nestablishes a graphical condition for quantifying the degree of robustness of a\ngiven causal claim. Algorithms for computing the degree of robustness are also\npresented.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Predicate Logic as a Modeling Language: Modeling and Solving some\n  Machine Learning and Data Mining Problems with IDP3",
        "authors": [
            "Maurice Bruynooghe",
            "Hendrik Blockeel",
            "Bart Bogaerts",
            "Broes De Cat",
            "Stef De Pooter",
            "Joachim Jansen",
            "Anthony Labarre",
            "Jan Ramon",
            "Marc Denecker",
            "Sicco Verwer"
        ],
        "summary": "This paper provides a gentle introduction to problem solving with the IDP3\nsystem. The core of IDP3 is a finite model generator that supports first order\nlogic enriched with types, inductive definitions, aggregates and partial\nfunctions. It offers its users a modeling language that is a slight extension\nof predicate logic and allows them to solve a wide range of search problems.\nApart from a small introductory example, applications are selected from\nproblems that arose within machine learning and data mining research. These\nresearch areas have recently shown a strong interest in declarative modeling\nand constraint solving as opposed to algorithmic approaches. The paper\nillustrates that the IDP3 system can be a valuable tool for researchers with\nsuch an interest.\n  The first problem is in the domain of stemmatology, a domain of philology\nconcerned with the relationship between surviving variant versions of text. The\nsecond problem is about a somewhat related problem within biology where\nphylogenetic trees are used to represent the evolution of species. The third\nand final problem concerns the classical problem of learning a minimal\nautomaton consistent with a given set of strings. For this last problem, we\nshow that the performance of our solution comes very close to that of a\nstate-of-the art solution. For each of these applications, we analyze the\nproblem, illustrate the development of a logic-based model and explore how\nalternatives can affect the performance.",
        "year": 2013,
        "label": "cs.LO"
    },
    {
        "title": "DistMS: A Non-Portfolio Distributed Solver for Maximum Satisfiability",
        "authors": [
            "Miguel Neves",
            "In\u00eas Lynce",
            "Vasco Manquinho"
        ],
        "summary": "The most successful parallel SAT and MaxSAT solvers follow a portfolio\napproach, where each thread applies a different algorithm (or the same\nalgorithm configured differently) to solve a given problem instance. The main\ngoal of building a portfolio is to diversify the search process being carried\nout by each thread. As soon as one thread finishes, the instance can be deemed\nsolved. In this paper we present a new open source distributed solver for\nMaxSAT solving that addresses two issues commonly found in multicore parallel\nsolvers, namely memory contention and scalability. Preliminary results show\nthat our non-portfolio distributed MaxSAT solver outperforms its sequential\nversion and is able to solve more instances as the number of processes\nincreases.",
        "year": 2015,
        "label": "cs.LO"
    },
    {
        "title": "A survey of SMS based Information Systems",
        "authors": [
            "Manish R. Joshi",
            "Varsha M. Pathak"
        ],
        "summary": "Short Message Service (SMS) based Information Systems (SMSbIS) provide an\nexcellent alternative to a traditional approach of obtaining specific\ninformation by direct (through phone) or indirect (IVRS, Web, Email) probing.\nInformation and communication technology and far reaching mobile penetration\nhas opened this new research trend Number of key players in Search industry\nincluding Microsoft and Google are attracted by the expected increase in volume\nof use of such applications. The wide range of applications and their public\nacceptance has motivated researchers to work in this research domain. Several\napplications such as SMS based information access using database management\nservices, SMS based information retrieval through internet (search engine), SMS\nbased information extraction, question answering, image retrieval etc. have\nbeen emerged. With the aim to understand the functionality involved in these\nsystems, an extensive review of a few of these SMSbISs has been planned and\nexecuted by us. These systems are classified into four categories based on the\nobjectives and domains of the applications. As a result of this study a well\nstructured functional model is presented here. The model is evaluated in\ndifferent dimensions, which is presented in this paper. In addition to this a\nchronological progress with respect to research and development in this\nupcoming field is compiled in this paper. Such an extensive review presented in\nthis paper would definitely help the researchers and developers to understand\nthe technical aspects of this field. The functional framework presented here\nwould be useful to the system designers to design and develop an SMS based\nInformation System of any specific domain.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Can Intelligence Explode?",
        "authors": [
            "Marcus Hutter"
        ],
        "summary": "The technological singularity refers to a hypothetical scenario in which\ntechnological advances virtually explode. The most popular scenario is the\ncreation of super-intelligent algorithms that recursively create ever higher\nintelligences. It took many decades for these ideas to spread from science\nfiction to popular science magazines and finally to attract the attention of\nserious philosophers. David Chalmers' (JCS 2010) article is the first\ncomprehensive philosophical analysis of the singularity in a respected\nphilosophy journal. The motivation of my article is to augment Chalmers' and to\ndiscuss some issues not addressed by him, in particular what it could mean for\nintelligence to explode. In this course, I will (have to) provide a more\ncareful treatment of what intelligence actually is, separate speed from\nintelligence explosion, compare what super-intelligent participants and\nclassical human observers might experience and do, discuss immediate\nimplications for the diversity and value of life, consider possible bounds on\nintelligence, and contemplate intelligences right at the singularity.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "The observational roots of reference of the semantic web",
        "authors": [
            "Simon Scheider",
            "Krzysztof Janowicz",
            "Benjamin Adams"
        ],
        "summary": "Shared reference is an essential aspect of meaning. It is also indispensable\nfor the semantic web, since it enables to weave the global graph, i.e., it\nallows different users to contribute to an identical referent. For example, an\nessential kind of referent is a geographic place, to which users may contribute\nobservations. We argue for a human-centric, operational approach towards\nreference, based on respective human competences. These competences encompass\nperceptual, cognitive as well as technical ones, and together they allow humans\nto inter-subjectively refer to a phenomenon in their environment. The\ntechnology stack of the semantic web should be extended by such operations.\nThis would allow establishing new kinds of observation-based reference systems\nthat help constrain and integrate the semantic web bottom-up.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Semi-bounded Rationality: A model for decision making",
        "authors": [
            "Tshilidzi Marwala"
        ],
        "summary": "In this paper the theory of semi-bounded rationality is proposed as an\nextension of the theory of bounded rationality. In particular, it is proposed\nthat a decision making process involves two components and these are the\ncorrelation machine, which estimates missing values, and the causal machine,\nwhich relates the cause to the effect. Rational decision making involves using\ninformation which is almost always imperfect and incomplete as well as some\nintelligent machine which if it is a human being is inconsistent to make\ndecisions. In the theory of bounded rationality this decision is made\nirrespective of the fact that the information to be used is incomplete and\nimperfect and the human brain is inconsistent and thus this decision that is to\nbe made is taken within the bounds of these limitations. In the theory of\nsemi-bounded rationality, signal processing is used to filter noise and\noutliers in the information and the correlation machine is applied to complete\nthe missing information and artificial intelligence is used to make more\nconsistent decisions.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "The DL-Lite Family and Relations",
        "authors": [
            "Alessandro Artale",
            "Diego Calvanese",
            "Roman Kontchakov",
            "Michael Zakharyaschev"
        ],
        "summary": "The recently introduced series of description logics under the common moniker\nDL-Lite has attracted attention of the description logic and semantic web\ncommunities due to the low computational complexity of inference, on the one\nhand, and the ability to represent conceptual modeling formalisms, on the\nother. The main aim of this article is to carry out a thorough and systematic\ninvestigation of inference in extensions of the original DL-Lite logics along\nfive axes: by (i) adding the Boolean connectives and (ii) number restrictions\nto concept constructs, (iii) allowing role hierarchies, (iv) allowing role\ndisjointness, symmetry, asymmetry, reflexivity, irreflexivity and transitivity\nconstraints, and (v) adopting or dropping the unique same assumption. We\nanalyze the combined complexity of satisfiability for the resulting logics, as\nwell as the data complexity of instance checking and answering positive\nexistential queries. Our approach is based on embedding DL-Lite logics in\nsuitable fragments of the one-variable first-order logic, which provides useful\ninsights into their properties and, in particular, computational behavior.",
        "year": 2014,
        "label": "cs.LO"
    },
    {
        "title": "Modeling Concept Combinations in a Quantum-theoretic Framework",
        "authors": [
            "Diederik Aerts",
            "Sandro Sozzo"
        ],
        "summary": "We present modeling for conceptual combinations which uses the mathematical\nformalism of quantum theory. Our model faithfully describes a large amount of\nexperimental data collected by different scholars on concept conjunctions and\ndisjunctions. Furthermore, our approach sheds a new light on long standing\ndrawbacks connected with vagueness, or fuzziness, of concepts, and puts forward\na completely novel possible solution to the 'combination problem' in concept\ntheory. Additionally, we introduce an explanation for the occurrence of quantum\nstructures in the mechanisms and dynamics of concepts and, more generally, in\ncognitive and decision processes, according to which human thought is a well\nstructured superposition of a 'logical thought' and a 'conceptual thought', and\nthe latter usually prevails over the former, at variance with some widespread\nbeliefs",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Logical Foundations of RDF(S) with Datatypes",
        "authors": [
            "Jos de Bruijn",
            "Stijn Heymans"
        ],
        "summary": "The Resource Description Framework (RDF) is a Semantic Web standard that\nprovides a data language, simply called RDF, as well as a lightweight ontology\nlanguage, called RDF Schema. We investigate embeddings of RDF in logic and show\nhow standard logic programming and description logic technology can be used for\nreasoning with RDF. We subsequently consider extensions of RDF with datatype\nsupport, considering D entailment, defined in the RDF semantics specification,\nand D* entailment, a semantic weakening of D entailment, introduced by ter\nHorst. We use the embeddings and properties of the logics to establish novel\nupper bounds for the complexity of deciding entailment. We subsequently\nestablish two novel lower bounds, establishing that RDFS entailment is\nPTime-complete and that simple-D entailment is coNP-hard, when considering\narbitrary datatypes, both in the size of the entailing graph. The results\nindicate that RDFS may not be as lightweight as one may expect.",
        "year": 2014,
        "label": "cs.LO"
    },
    {
        "title": "Belief-Rule-Based Expert Systems for Evaluation of E- Government: A Case\n  Study",
        "authors": [
            "Shahadat Hossein",
            "Par-Ola Zander",
            "Md. Kamal",
            "Linkon Chowdhury"
        ],
        "summary": "Little knowledge exists on the impact and results associated with\ne-government projects in many specific use domains. Therefore it is necessary\nto evaluate the efficiency and effectiveness of e-government systems. Since the\ndevelopment of e-government is a continuous process of improvement, it requires\ncontinuous evaluation of the overall e-government system as well as evaluation\nof its various dimensions such as determinants, characteristics and results.\nE-government development is often complex with multiple stakeholders, large\nuser bases and complex goals. Consequently, even experts have difficulties in\nevaluating these systems, especially in an integrated and comprehensive way as\nwell as on an aggregate level. Expert systems are a candidate solution to\nevaluate such complex e-government systems. However, it is difficult for expert\nsystems to cope with uncertain evaluation data that are vague, inconsistent,\nhighly subjective or in other ways challenging to formalize. This paper\npresents an approach that can handle uncertainty in e-government evaluation:\nThe combination of Belief Rule Base (BRB) knowledge representation and\nEvidential Reasoning (ES). This approach is illustrated with a concrete\nprototype, known as Belief Rule Based Expert System (BRBES) and put to use in\nthe local e-government of Bangladesh. The results have been compared with a\nrecently developed method of evaluating e-Government, and it is shown that the\nresults of BRBES are more accurate and reliable. BRBES can be used to identify\nthe factors that need to be improved to achieve the overall aim of an\ne-government project. In addition, various \"what if\" scenarios can be generated\nand developers and managers can get a forecast of the outcomes. In this way,\nthe system can be used to facilitate decision making processes under\nuncertainty.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "The PeerRank Method for Peer Assessment",
        "authors": [
            "Toby Walsh"
        ],
        "summary": "We propose the PeerRank method for peer assessment. This constructs a grade\nfor an agent based on the grades proposed by the agents evaluating the agent.\nSince the grade of an agent is a measure of their ability to grade correctly,\nthe PeerRank method weights grades by the grades of the grading agent. The\nPeerRank method also provides an incentive for agents to grade correctly. As\nthe grades of an agent depend on the grades of the grading agents, and as these\ngrades themselves depend on the grades of other agents, we define the PeerRank\nmethod by a fixed point equation similar to the PageRank method for ranking\nweb-pages. We identify some formal properties of the PeerRank method (for\nexample, it satisfies axioms of unanimity, no dummy, no discrimination and\nsymmetry), discuss some examples, compare with related work and evaluate the\nperformance on some synthetic data. Our results show considerable promise,\nreducing the error in grade predictions by a factor of 2 or more in many cases\nover the natural baseline of averaging peer grades.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "A Multistage Stochastic Programming Approach to the Dynamic and\n  Stochastic VRPTW - Extended version",
        "authors": [
            "Michael Saint-Guillain",
            "Yves Deville",
            "Christine Solnon"
        ],
        "summary": "We consider a dynamic vehicle routing problem with time windows and\nstochastic customers (DS-VRPTW), such that customers may request for services\nas vehicles have already started their tours. To solve this problem, the goal\nis to provide a decision rule for choosing, at each time step, the next action\nto perform in light of known requests and probabilistic knowledge on requests\nlikelihood. We introduce a new decision rule, called Global Stochastic\nAssessment (GSA) rule for the DS-VRPTW, and we compare it with existing\ndecision rules, such as MSA. In particular, we show that GSA fully integrates\nnonanticipativity constraints so that it leads to better decisions in our\nstochastic context. We describe a new heuristic approach for efficiently\napproximating our GSA rule. We introduce a new waiting strategy. Experiments on\ndynamic and stochastic benchmarks, which include instances of different degrees\nof dynamism, show that not only our approach is competitive with\nstate-of-the-art methods, but also enables to compute meaningful offline\nsolutions to fully dynamic problems where absolutely no a priori customer\nrequest is provided.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Quantum Structure in Cognition, Origins, Developments, Successes and\n  Expectations",
        "authors": [
            "Diederik Aerts",
            "Sandro Sozzo"
        ],
        "summary": "We provide an overview of the results we have attained in the last decade on\nthe identification of quantum structures in cognition and, more specifically,\nin the formalization and representation of natural concepts. We firstly discuss\nthe quantum foundational reasons that led us to investigate the mechanisms of\nformation and combination of concepts in human reasoning, starting from the\nempirically observed deviations from classical logical and probabilistic\nstructures. We then develop our quantum-theoretic perspective in Fock space\nwhich allows successful modeling of various sets of cognitive experiments\ncollected by different scientists, including ourselves. In addition, we\nformulate a unified explanatory hypothesis for the presence of quantum\nstructures in cognitive processes, and discuss our recent discovery of further\nquantum aspects in concept combinations, namely, 'entanglement' and\n'indistinguishability'. We finally illustrate perspectives for future research.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Exploration of the scalability of LocFaults approach for error\n  localization with While-loops programs",
        "authors": [
            "Mohammed Bekkouche"
        ],
        "summary": "A model checker can produce a trace of counterexample, for an erroneous\nprogram, which is often long and difficult to understand. In general, the part\nabout the loops is the largest among the instructions in this trace. This makes\nthe location of errors in loops critical, to analyze errors in the overall\nprogram. In this paper, we explore the scala-bility capabilities of LocFaults,\nour error localization approach exploiting paths of CFG(Control Flow Graph)\nfrom a counterexample to calculate the MCDs (Minimal Correction Deviations),\nand MCSs (Minimal Correction Subsets) from each found MCD. We present the times\nof our approach on programs with While-loops unfolded b times, and a number of\ndeviated conditions ranging from 0 to n. Our preliminary results show that the\ntimes of our approach, constraint-based and flow-driven, are better compared to\nBugAssist which is based on SAT and transforms the entire program to a Boolean\nformula, and further the information provided by LocFaults is more expressive\nfor the user.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Exploration of the scalability of LocFaults",
        "authors": [
            "Mohammed Bekkouche"
        ],
        "summary": "A model checker can produce a trace of counterexample, for an erroneous\nprogram, which is often long and difficult to understand. In general, the part\nabout the loops is the largest among the instructions in this trace. This makes\nthe location of errors in loops critical, to analyze errors in the overall\nprogram. In this paper, we explore the scalability capabilities of LocFaults,\nour error localization approach exploiting paths of CFG(Control Flow Graph)\nfrom a counterexample to calculate the MCDs (Minimal Correction Deviations),\nand MCSs (Minimal Correction Subsets) from each found MCD. We present the times\nof our approach on programs with While-loops unfolded b times, and a number of\ndeviated conditions ranging from 0 to n. Our preliminary results show that the\ntimes of our approach, constraint-based and flow-driven, are better compared to\nBugAssist which is based on SAT and transforms the entire program to a Boolean\nformula, and further the information provided by LocFaults is more expressive\nfor the user.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "General-Purpose Computing on a Semantic Network Substrate",
        "authors": [
            "Marko A. Rodriguez"
        ],
        "summary": "This article presents a model of general-purpose computing on a semantic\nnetwork substrate. The concepts presented are applicable to any semantic\nnetwork representation. However, due to the standards and technological\ninfrastructure devoted to the Semantic Web effort, this article is presented\nfrom this point of view. In the proposed model of computing, the application\nprogramming interface, the run-time program, and the state of the computing\nvirtual machine are all represented in the Resource Description Framework\n(RDF). The implementation of the concepts presented provides a practical\ncomputing paradigm that leverages the highly-distributed and standardized\nrepresentational-layer of the Semantic Web.",
        "year": 2007,
        "label": "cs.AI"
    },
    {
        "title": "On The Complexity and Completeness of Static Constraints for Breaking\n  Row and Column Symmetry",
        "authors": [
            "George Katsirelos",
            "Nina Narodytska",
            "Toby Walsh"
        ],
        "summary": "We consider a common type of symmetry where we have a matrix of decision\nvariables with interchangeable rows and columns. A simple and efficient method\nto deal with such row and column symmetry is to post symmetry breaking\nconstraints like DOUBLELEX and SNAKELEX. We provide a number of positive and\nnegative results on posting such symmetry breaking constraints. On the positive\nside, we prove that we can compute in polynomial time a unique representative\nof an equivalence class in a matrix model with row and column symmetry if the\nnumber of rows (or of columns) is bounded and in a number of other special\ncases. On the negative side, we show that whilst DOUBLELEX and SNAKELEX are\noften effective in practice, they can leave a large number of symmetric\nsolutions in the worst case. In addition, we prove that propagating DOUBLELEX\ncompletely is NP-hard. Finally we consider how to break row, column and value\nsymmetry, correcting a result in the literature about the safeness of combining\ndifferent symmetry breaking constraints. We end with the first experimental\nstudy on how much symmetry is left by DOUBLELEX and SNAKELEX on some benchmark\nproblems.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "Loop Formulas for Description Logic Programs",
        "authors": [
            "Yisong Wang",
            "Jia-Huai You",
            "Li Yan Yuan",
            "Yi-Dong Shen"
        ],
        "summary": "Description Logic Programs (dl-programs) proposed by Eiter et al. constitute\nan elegant yet powerful formalism for the integration of answer set programming\nwith description logics, for the Semantic Web. In this paper, we generalize the\nnotions of completion and loop formulas of logic programs to description logic\nprograms and show that the answer sets of a dl-program can be precisely\ncaptured by the models of its completion and loop formulas. Furthermore, we\npropose a new, alternative semantics for dl-programs, called the {\\em canonical\nanswer set semantics}, which is defined by the models of completion that\nsatisfy what are called canonical loop formulas. A desirable property of\ncanonical answer sets is that they are free of circular justifications. Some\nproperties of canonical answer sets are also explored.",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "Mod\u00e9lisation d'une analyse pragma-linguistique d'un forum de\n  discussion",
        "authors": [
            "Nada Matta",
            "Karima Sidoumou",
            "Goritsa Ninova",
            "Hassan Atifi"
        ],
        "summary": "We present in this paper, a modelling of an expertise in pragmatics. We\nfollow knowledge engineering techniques and observe the expert when he analyses\na social discussion forum. Then a number of models are defined. These models\nemphasises the process followed by the expert and a number of criteria used in\nhis analysis. Results can be used as guides that help to understand and\nannotate discussion forum. We aim at modelling other pragmatics analysis in\norder to complete the base of guides; criteria, process, etc. of discussion\nanalysis",
        "year": 2010,
        "label": "cs.AI"
    },
    {
        "title": "Student Modeling using Case-Based Reasoning in Conventional Learning\n  System",
        "authors": [
            "Indriana Hidayah",
            "Alvi Syahrina",
            "Adhistya Erna Permanasari"
        ],
        "summary": "Conventional face-to-face classrooms are still the main learning system\napplied in Indonesia. In assisting such conventional learning towards an\noptimal learning, formative evaluations are needed to monitor the progress of\nthe class. This task can be very hard when the size of the class is large.\nHence, this research attempted to create a classroom monitoring system based on\nstudent data of Department of Electrical Engineering and Information\nTechnology. In order to achieve the goal, a student modeling using Case-Based\nReasoning was proposed. A generic student model based on a framework was\ndeveloped. The model represented student knowledge of a subject. The result\nshowed that the system was able to store and retrieve student data for\nsuggestion of the current situation and formative evaluation for one of the\nsubject in the Department.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Visualization and clustering by 3D cellular automata: Application to\n  unstructured data",
        "authors": [
            "Reda Mohamed Hamou",
            "Abdelmalek Amine",
            "Ahmed Chaouki Lokbani",
            "Michel Simonet"
        ],
        "summary": "Given the limited performance of 2D cellular automata in terms of space when\nthe number of documents increases and in terms of visualization clusters, our\nmotivation was to experiment these cellular automata by increasing the size to\nview the impact of size on quality of results. The representation of textual\ndata was carried out by a vector model whose components are derived from the\noverall balancing of the used corpus, Term Frequency Inverse Document Frequency\n(TF-IDF). The WorldNet thesaurus has been used to address the problem of the\nlemmatization of the words because the representation used in this study is\nthat of the bags of words. Another independent method of the language was used\nto represent textual records is that of the n-grams. Several measures of\nsimilarity have been tested. To validate the classification we have used two\nmeasures of assessment based on the recall and precision (f-measure and\nentropy). The results are promising and confirm the idea to increase the\ndimension to the problem of the spatiality of the classes. The results obtained\nin terms of purity class (i.e. the minimum value of entropy) shows that the\nnumber of documents over longer believes the results are better for 3D cellular\nautomata, which was not obvious to the 2D dimension. In terms of spatial\nnavigation, cellular automata provide very good 3D performance visualization\nthan 2D cellular automata.",
        "year": 2012,
        "label": "cs.AI"
    },
    {
        "title": "Automated Attack Planning",
        "authors": [
            "Carlos Sarraute"
        ],
        "summary": "Penetration Testing is a methodology for assessing network security, by\ngenerating and executing possible attacks. Doing so automatically allows for\nregular and systematic testing. A key question then is how to automatically\ngenerate the attacks. A natural way to address this issue is as an attack\nplanning problem. In this thesis, we are concerned with the specific context of\nregular automated pentesting, and use the term \"attack planning\" in that sense.\nThe following three research directions are investigated.\n  First, we introduce a conceptual model of computer network attacks, based on\nan analysis of the penetration testing practices. We study how this attack\nmodel can be represented in the PDDL language. Then we describe an\nimplementation that integrates a classical planner with a penetration testing\ntool. This allows us to automatically generate attack paths for real world\npentesting scenarios, and to validate these attacks by executing them.\n  Secondly, we present efficient probabilistic planning algorithms,\nspecifically designed for this problem, that achieve industrial-scale runtime\nperformance (able to solve scenarios with several hundred hosts and exploits).\nThese algorithms take into account the probability of success of the actions\nand their expected cost (for example in terms of execution time, or network\ntraffic generated).\n  Finally, we take a different direction: instead of trying to improve the\nefficiency of the solutions developed, we focus on improving the model of the\nattacker. We model the attack planning problem in terms of partially observable\nMarkov decision processes (POMDP). This grounds penetration testing in a\nwell-researched formalism. POMDPs allow the modelling of information gathering\nas an integral part of the problem, thus providing for the first time a means\nto intelligently mix scanning actions with actual exploits.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Les POMDP font de meilleurs hackers: Tenir compte de l'incertitude dans\n  les tests de penetration",
        "authors": [
            "Carlos Sarraute",
            "Olivier Buffet",
            "Joerg Hoffmann"
        ],
        "summary": "Penetration Testing is a methodology for assessing network security, by\ngenerating and executing possible hacking attacks. Doing so automatically\nallows for regular and systematic testing. A key question is how to generate\nthe attacks. This is naturally formulated as planning under uncertainty, i.e.,\nunder incomplete knowledge about the network configuration. Previous work uses\nclassical planning, and requires costly pre-processes reducing this uncertainty\nby extensive application of scanning methods. By contrast, we herein model the\nattack planning problem in terms of partially observable Markov decision\nprocesses (POMDP). This allows to reason about the knowledge available, and to\nintelligently employ scanning actions as part of the attack. As one would\nexpect, this accurate solution does not scale. We devise a method that relies\non POMDPs to find good attacks on individual machines, which are then composed\ninto an attack on the network as a whole. This decomposition exploits network\nstructure to the extent possible, making targeted approximations (only) where\nneeded. Evaluating this method on a suitably adapted industrial test suite, we\ndemonstrate its effectiveness in both runtime and solution quality.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "POMDPs Make Better Hackers: Accounting for Uncertainty in Penetration\n  Testing",
        "authors": [
            "Carlos Sarraute",
            "Olivier Buffet",
            "Joerg Hoffmann"
        ],
        "summary": "Penetration Testing is a methodology for assessing network security, by\ngenerating and executing possible hacking attacks. Doing so automatically\nallows for regular and systematic testing. A key question is how to generate\nthe attacks. This is naturally formulated as planning under uncertainty, i.e.,\nunder incomplete knowledge about the network configuration. Previous work uses\nclassical planning, and requires costly pre-processes reducing this uncertainty\nby extensive application of scanning methods. By contrast, we herein model the\nattack planning problem in terms of partially observable Markov decision\nprocesses (POMDP). This allows to reason about the knowledge available, and to\nintelligently employ scanning actions as part of the attack. As one would\nexpect, this accurate solution does not scale. We devise a method that relies\non POMDPs to find good attacks on individual machines, which are then composed\ninto an attack on the network as a whole. This decomposition exploits network\nstructure to the extent possible, making targeted approximations (only) where\nneeded. Evaluating this method on a suitably adapted industrial test suite, we\ndemonstrate its effectiveness in both runtime and solution quality.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "A novel local search based on variable-focusing for random K-SAT",
        "authors": [
            "R\u00e9mi Lemoy",
            "Mikko Alava",
            "Erik Aurell"
        ],
        "summary": "We introduce a new local search algorithm for satisfiability problems. Usual\napproaches focus uniformly on unsatisfied clauses. The new method works by\npicking uniformly random variables in unsatisfied clauses. A Variable-based\nFocused Metropolis Search (V-FMS) is then applied to random 3-SAT. We show that\nit is quite comparable in performance to the clause-based FMS. Consequences for\nalgorithmic design are discussed.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Inferring Multilateral Relations from Dynamic Pairwise Interactions",
        "authors": [
            "Aaron Schein",
            "Juston Moore",
            "Hanna Wallach"
        ],
        "summary": "Correlations between anomalous activity patterns can yield pertinent\ninformation about complex social processes: a significant deviation from normal\nbehavior, exhibited simultaneously by multiple pairs of actors, provides\nevidence for some underlying relationship involving those pairs---i.e., a\nmultilateral relation. We introduce a new nonparametric Bayesian latent\nvariable model that explicitly captures correlations between anomalous\ninteraction counts and uses these shared deviations from normal activity\npatterns to identify and characterize multilateral relations. We showcase our\nmodel's capabilities using the newly curated Global Database of Events,\nLocation, and Tone, a dataset that has seen considerable interest in the social\nsciences and the popular press, but which has is largely unexplored by the\nmachine learning community. We provide a detailed analysis of the latent\nstructure inferred by our model and show that the multilateral relations\ncorrespond to major international events and long-term international\nrelationships. These findings lead us to recommend our model for any\ndata-driven analysis of interaction networks where dynamic interactions over\nthe edges provide evidence for latent social structure.",
        "year": 2013,
        "label": "cs.AI"
    },
    {
        "title": "Team Behavior in Interactive Dynamic Influence Diagrams with\n  Applications to Ad Hoc Teams",
        "authors": [
            "Muthukumaran Chandrasekaran",
            "Prashant Doshi",
            "Yifeng Zeng",
            "Yingke Chen"
        ],
        "summary": "Planning for ad hoc teamwork is challenging because it involves agents\ncollaborating without any prior coordination or communication. The focus is on\nprincipled methods for a single agent to cooperate with others. This motivates\ninvestigating the ad hoc teamwork problem in the context of individual decision\nmaking frameworks. However, individual decision making in multiagent settings\nfaces the task of having to reason about other agents' actions, which in turn\ninvolves reasoning about others. An established approximation that\noperationalizes this approach is to bound the infinite nesting from below by\nintroducing level 0 models. We show that a consequence of the finitely-nested\nmodeling is that we may not obtain optimal team solutions in cooperative\nsettings. We address this limitation by including models at level 0 whose\nsolutions involve learning. We demonstrate that the learning integrated into\nplanning in the context of interactive dynamic influence diagrams facilitates\noptimal team behavior, and is applicable to ad hoc teamwork.",
        "year": 2014,
        "label": "cs.MA"
    },
    {
        "title": "A CSP implementation of the bigraph embedding problem",
        "authors": [
            "Marino Miculan",
            "Marco Peressotti"
        ],
        "summary": "A crucial problem for many results and tools about bigraphs and bigraphical\nreactive systems is bigraph embedding. An embedding is more informative than a\nbigraph matching, since it keeps track of the correspondence between the\nvarious components of the redex (guest) within the agent (host). In this paper,\nwe present an algorithm for computing embeddings based on a reduction to a\nconstraint satisfaction problem. This algorithm, that we prove to be sound and\ncomplete, has been successfully implemented in LibBig, a library for\nmanipulating bigraphical reactive systems. This library can be used for\nimplementing a wide range of tools, and it can be adapted to various extensions\nof bigraphs.",
        "year": 2014,
        "label": "cs.LO"
    },
    {
        "title": "Worst-case Optimal Query Answering for Greedy Sets of Existential Rules\n  and Their Subclasses",
        "authors": [
            "Sebastian Rudolph",
            "Micha\u00ebl Thomazo",
            "Jean-Fran\u00e7ois Baget",
            "Marie-Laure Mugnier"
        ],
        "summary": "The need for an ontological layer on top of data, associated with advanced\nreasoning mechanisms able to exploit the semantics encoded in ontologies, has\nbeen acknowledged both in the database and knowledge representation\ncommunities. We focus in this paper on the ontological query answering problem,\nwhich consists of querying data while taking ontological knowledge into\naccount. More specifically, we establish complexities of the conjunctive query\nentailment problem for classes of existential rules (also called\ntuple-generating dependencies, Datalog+/- rules, or forall-exists-rules. Our\ncontribution is twofold. First, we introduce the class of greedy\nbounded-treewidth sets (gbts) of rules, which covers guarded rules, and their\nmost well-known generalizations. We provide a generic algorithm for query\nentailment under gbts, which is worst-case optimal for combined complexity with\nor without bounded predicate arity, as well as for data complexity and query\ncomplexity. Secondly, we classify several gbts classes, whose complexity was\nunknown, with respect to combined complexity (with both unbounded and bounded\npredicate arity) and data complexity to obtain a comprehensive picture of the\ncomplexity of existential rule fragments that are based on diverse guardedness\nnotions. Upper bounds are provided by showing that the proposed algorithm is\noptimal for all of them.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Quantifying Natural and Artificial Intelligence in Robots and Natural\n  Systems with an Algorithmic Behavioural Test",
        "authors": [
            "Hector Zenil"
        ],
        "summary": "One of the most important aims of the fields of robotics, artificial\nintelligence and artificial life is the design and construction of systems and\nmachines as versatile and as reliable as living organisms at performing high\nlevel human-like tasks. But how are we to evaluate artificial systems if we are\nnot certain how to measure these capacities in living systems, let alone how to\ndefine life or intelligence? Here I survey a concrete metric towards measuring\nabstract properties of natural and artificial systems, such as the ability to\nreact to the environment and to control one's own behaviour.",
        "year": 2014,
        "label": "cs.AI"
    },
    {
        "title": "Evidential-EM Algorithm Applied to Progressively Censored Observations",
        "authors": [
            "Kuang Zhou",
            "Arnaud Martin",
            "Quan Pan"
        ],
        "summary": "Evidential-EM (E2M) algorithm is an effective approach for computing maximum\nlikelihood estimations under finite mixture models, especially when there is\nuncertain information about data. In this paper we present an extension of the\nE2M method in a particular case of incom-plete data, where the loss of\ninformation is due to both mixture models and censored observations. The prior\nuncertain information is expressed by belief functions, while the\npseudo-likelihood function is derived based on imprecise observations and prior\nknowledge. Then E2M method is evoked to maximize the generalized likelihood\nfunction to obtain the optimal estimation of parameters. Numerical examples\nshow that the proposed method could effectively integrate the uncertain prior\ninfor-mation with the current imprecise knowledge conveyed by the observed\ndata.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Belief Approach for Social Networks",
        "authors": [
            "Salma Ben Dhaou",
            "Mouloud Kharoune",
            "Arnaud Martin",
            "Boutheina Ben Yaghlane"
        ],
        "summary": "Nowadays, social networks became essential in information exchange between\nindividuals. Indeed, as users of these networks, we can send messages to other\npeople according to the links connecting us. Moreover, given the large volume\nof exchanged messages, detecting the true nature of the received message\nbecomes a challenge. For this purpose, it is interesting to consider this new\ntendency with reasoning under uncertainty by using the theory of belief\nfunctions. In this paper, we tried to model a social network as being a network\nof fusion of information and determine the true nature of the received message\nin a well-defined node by proposing a new model: the belief social network.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "What do we learn about development from baby robots?",
        "authors": [
            "Pierre-Yves Oudeyer"
        ],
        "summary": "Understanding infant development is one of the greatest scientific challenges\nof contemporary science. A large source of difficulty comes from the fact that\nthe development of skills in infants results from the interactions of multiple\nmechanisms at multiple spatio-temporal scales. The concepts of \"innate\" or\n\"acquired\" are not any more adequate tools for explanations, which call for a\nshift from reductionist to systemic accounts. To address this challenge,\nbuilding and experimenting with robots modeling the growing infant brain and\nbody is crucial. Systemic explanations of pattern formation in sensorimotor,\ncognitive and social development, viewed as a complex dynamical system, require\nthe use of formal models based on mathematics, algorithms and robots.\nFormulating hypothesis about development using such models, and exploring them\nthrough experiments, allows us to consider in detail the interaction between\nmany mechanisms and parameters. This complements traditional experimental\nmethods in psychology and neuroscience where only a few variables can be\nstudied at the same time. Furthermore, the use of robots is of particular\nimportance. The laws of physics generate everywhere around us spontaneous\npatterns in the inorganic world. They also strongly impact the living, and in\nparticular constrain and guide infant development through the properties of its\n(changing) body in interaction with the physical environment. Being able to\nconsider the body as an experimental variable, something that can be\nsystematically changed in order to study the impact on skill formation, has\nbeen a dream to many developmental scientists. This is today becoming possible\nwith developmental robotics.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Computing Horn Rewritings of Description Logics Ontologies",
        "authors": [
            "Mark Kaminski",
            "Bernardo Cuenca Grau"
        ],
        "summary": "We study the problem of rewriting an ontology O1 expressed in a DL L1 into an\nontology O2 in a Horn DL L2 such that O1 and O2 are equisatisfiable when\nextended with an arbitrary dataset. Ontologies that admit such rewritings are\namenable to reasoning techniques ensuring tractability in data complexity.\nAfter showing undecidability whenever L1 extends ALCF, we focus on devising\nefficiently checkable conditions that ensure existence of a Horn rewriting. By\nlifting existing techniques for rewriting Disjunctive Datalog programs into\nplain Datalog to the case of arbitrary first-order programs with function\nsymbols, we identify a class of ontologies that admit Horn rewritings of\npolynomial size. Our experiments indicate that many real-world ontologies\nsatisfy our sufficient conditions and thus admit polynomial Horn rewritings.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Adversarial patrolling with spatially uncertain alarm signals",
        "authors": [
            "Nicola Basilico",
            "Giuseppe De Nittis",
            "Nicola Gatti"
        ],
        "summary": "When securing complex infrastructures or large environments, constant\nsurveillance of every area is not affordable. To cope with this issue, a common\ncountermeasure is the usage of cheap but wide-ranged sensors, able to detect\nsuspicious events that occur in large areas, supporting patrollers to improve\nthe effectiveness of their strategies. However, such sensors are commonly\naffected by uncertainty. In the present paper, we focus on spatially uncertain\nalarm signals. That is, the alarm system is able to detect an attack but it is\nuncertain on the exact position where the attack is taking place. This is\ncommon when the area to be secured is wide such as in border patrolling and\nfair site surveillance. We propose, to the best of our knowledge, the first\nPatrolling Security Game model where a Defender is supported by a spatially\nuncertain alarm system which non-deterministically generates signals once a\ntarget is under attack. We show that finding the optimal strategy in arbitrary\ngraphs is APX-hard even in zero-sum games and we provide two (exponential time)\nexact algorithms and two (polynomial time) approximation algorithms.\nFurthermore, we analyse what happens in environments with special topologies,\nshowing that in linear and cycle graphs the optimal patrolling strategy can be\nfound in polynomial time, de facto allowing our algorithms to be used in\nreal-life scenarios, while in trees the problem is NP-hard. Finally, we show\nthat without false positives and missed detections, the best patrolling\nstrategy reduces to stay in a place, wait for a signal, and respond to it at\nbest. This strategy is optimal even with non-negligible missed detection rates,\nwhich, unfortunately, affect every commercial alarm system. We evaluate our\nmethods in simulation, assessing both quantitative and qualitative aspects.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Rare Speed-up in Automatic Theorem Proving Reveals Tradeoff Between\n  Computational Time and Information Value",
        "authors": [
            "Santiago Hern\u00e1ndez-Orozco",
            "Francisco Hern\u00e1ndez-Quiroz",
            "Hector Zenil",
            "Wilfried Sieg"
        ],
        "summary": "We show that strategies implemented in automatic theorem proving involve an\ninteresting tradeoff between execution speed, proving speedup/computational\ntime and usefulness of information. We advance formal definitions for these\nconcepts by way of a notion of normality related to an expected (optimal)\ntheoretical speedup when adding useful information (other theorems as axioms),\nas compared with actual strategies that can be effectively and efficiently\nimplemented. We propose the existence of an ineluctable tradeoff between this\nnormality and computational time complexity. The argument quantifies the\nusefulness of information in terms of (positive) speed-up. The results disclose\na kind of no-free-lunch scenario and a tradeoff of a fundamental nature. The\nmain theorem in this paper together with the numerical experiment---undertaken\nusing two different automatic theorem provers AProS and Prover9 on random\ntheorems of propositional logic---provide strong theoretical and empirical\narguments for the fact that finding new useful information for solving a\nspecific problem (theorem) is, in general, as hard as the problem (theorem)\nitself.",
        "year": 2015,
        "label": "cs.LO"
    },
    {
        "title": "Extending SROIQ with Constraint Networks and Grounded Circumscription",
        "authors": [
            "Arjun Bhardwaj"
        ],
        "summary": "Developments in semantic web technologies have promoted ontological encoding\nof knowledge from diverse domains. However, modelling many practical domains\nrequires more expressiveness than what the standard description logics (most\nprominently SROIQ) support. In this paper, we extend the expressive DL SROIQ\nwith constraint networks (resulting in the logic SROIQc) and grounded\ncircumscription (resulting in the logic GC-SROIQ). Applications of constraint\nmodelling include embedding ontologies with temporal or spatial information,\nwhile those of grounded circumscription include defeasible inference and closed\nworld reasoning.\n  We describe the syntax and semantics of the logic formed by including\nconstraint modelling constructs in SROIQ, and provide a sound, complete and\nterminating tableau algorithm for it. We further provide an intuitive algorithm\nfor Grounded Circumscription in SROIQc, which adheres to the general framework\nof grounded circumscription, and which can be applied to a whole range of\nexpressive logics for which no such specific algorithm presently exists.",
        "year": 2015,
        "label": "cs.LO"
    },
    {
        "title": "Beyond-Quantum Modeling of Question Order Effects and Response\n  Replicability in Psychological Measurements",
        "authors": [
            "Diederik Aerts",
            "Massimiliano Sassoli de Bianchi"
        ],
        "summary": "A general tension-reduction (GTR) model was recently considered to derive\nquantum probabilities as (universal) averages over all possible forms of\nnon-uniform fluctuations, and explain their considerable success in describing\nexperimental situations also outside of the domain of physics, for instance in\nthe ambit of quantum models of cognition and decision. Yet, this result also\nhighlighted the possibility of observing violations of the predictions of the\nBorn rule, in those situations where the averaging would not be large enough,\nor would be altered because of the combination of multiple measurements. In\nthis article we show that this is indeed the case in typical psychological\nmeasurements exhibiting question order effects, by showing that their\nstatistics of outcomes are inherently non-Hilbertian, and require the larger\nframework of the GTR-model to receive an exact mathematical description. We\nalso consider another unsolved problem of quantum cognition: response\nreplicability. It is has been observed that when question order effects and\nresponse replicability occur together, the situation cannot be handled anymore\nby quantum theory. However, we show that it can be easily and naturally\ndescribed in the GTR-model. Based on these findings, we motivate the adoption\nin cognitive science of a hidden-measurements interpretation of the quantum\nformalism, and of its GTR-model generalization, as the natural interpretational\nframework explaining the data of psychological measurements on conceptual\nentities.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Reflective Oracles: A Foundation for Classical Game Theory",
        "authors": [
            "Benja Fallenstein",
            "Jessica Taylor",
            "Paul F. Christiano"
        ],
        "summary": "Classical game theory treats players as special---a description of a game\ncontains a full, explicit enumeration of all players---even though in the real\nworld, \"players\" are no more fundamentally special than rocks or clouds. It\nisn't trivial to find a decision-theoretic foundation for game theory in which\nan agent's coplayers are a non-distinguished part of the agent's environment.\nAttempts to model both players and the environment as Turing machines, for\nexample, fail for standard diagonalization reasons.\n  In this paper, we introduce a \"reflective\" type of oracle, which is able to\nanswer questions about the outputs of oracle machines with access to the same\noracle. These oracles avoid diagonalization by answering some queries randomly.\nWe show that machines with access to a reflective oracle can be used to define\nrational agents using causal decision theory. These agents model their\nenvironment as a probabilistic oracle machine, which may contain other agents\nas a non-distinguished part.\n  We show that if such agents interact, they will play a Nash equilibrium, with\nthe randomization in mixed strategies coming from the randomization in the\noracle's answers. This can be seen as providing a foundation for classical game\ntheory in which players aren't special.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Optimal Release Time Decision from Fuzzy Mathematical Programming\n  Perspective",
        "authors": [
            "Arvind Kumar",
            "Adarsh Anand",
            "Pankaj Kumar Garg",
            "Mohini Agarwal"
        ],
        "summary": "Demand for high software reliability requires rigorous testing followed by\nrequirement of robust modeling techniques for software quality prediction. On\none side, firms have to steadily manage the reliability by testing it\nvigorously, the optimal release time determination is their biggest concern. In\npast many models have been developed and much research has been devoted towards\nassessment of release time of software. However, majority of the work deals in\ncrisp study. This paper addresses the problem of release time prediction using\nfuzzy Logic. Here we have formulated a Fuzzy release time problem considering\nthe cost of testing under the impact of warranty period. Results show that\nfuzzy model has good adaptability.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Causal Falling Rule Lists",
        "authors": [
            "Fulton Wang",
            "Cynthia Rudin"
        ],
        "summary": "A causal falling rule list (CFRL) is a sequence of if-then rules that\nspecifies heterogeneous treatment effects, where (i) the order of rules\ndetermines the treatment effect subgroup a subject belongs to, and (ii) the\ntreatment effect decreases monotonically down the list. A given CFRL\nparameterizes a hierarchical bayesian regression model in which the treatment\neffects are incorporated as parameters, and assumed constant within\nmodel-specific subgroups. We formulate the search for the CFRL best supported\nby the data as a Bayesian model selection problem, where we perform a search\nover the space of CFRL models, and approximate the evidence for a given CFRL\nmodel using standard variational techniques. We apply CFRL to a census wage\ndataset to identify subgroups of differing wage inequalities between men and\nwomen.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Turing's Red Flag",
        "authors": [
            "Toby Walsh"
        ],
        "summary": "Sometime in the future we will have to deal with the impact of AI's being\nmistaken for humans. For this reason, I propose that any autonomous system\nshould be designed so that it is unlikely to be mistaken for anything besides\nan autonomous sysem, and should identify itself at the start of any interaction\nwith another agent.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "On the Foundations of the Brussels Operational-Realistic Approach to\n  Cognition",
        "authors": [
            "Diederik Aerts",
            "Massimiliano Sassoli de Bianchi",
            "Sandro Sozzo"
        ],
        "summary": "The scientific community is becoming more and more interested in the research\nthat applies the mathematical formalism of quantum theory to model human\ndecision-making. In this paper, we provide the theoretical foundations of the\nquantum approach to cognition that we developed in Brussels. These foundations\nrest on the results of two decade studies on the axiomatic and\noperational-realistic approaches to the foundations of quantum physics. The\ndeep analogies between the foundations of physics and cognition lead us to\ninvestigate the validity of quantum theory as a general and unitary framework\nfor cognitive processes, and the empirical success of the Hilbert space models\nderived by such investigation provides a strong theoretical confirmation of\nthis validity. However, two situations in the cognitive realm, 'question order\neffects' and 'response replicability', indicate that even the Hilbert space\nframework could be insufficient to reproduce the collected data. This does not\nmean that the mentioned operational-realistic approach would be incorrect, but\nsimply that a larger class of measurements would be in force in human\ncognition, so that an extended quantum formalism may be needed to deal with all\nof them. As we will explain, the recently derived 'extended Bloch\nrepresentation' of quantum theory (and the associated 'general\ntension-reduction' model) precisely provides such extended formalism, while\nremaining within the same unitary interpretative framework.",
        "year": 2015,
        "label": "cs.AI"
    },
    {
        "title": "Unbounded Human Learning: Optimal Scheduling for Spaced Repetition",
        "authors": [
            "Siddharth Reddy",
            "Igor Labutov",
            "Siddhartha Banerjee",
            "Thorsten Joachims"
        ],
        "summary": "In the study of human learning, there is broad evidence that our ability to\nretain information improves with repeated exposure and decays with delay since\nlast exposure. This plays a crucial role in the design of educational software,\nleading to a trade-off between teaching new material and reviewing what has\nalready been taught. A common way to balance this trade-off is spaced\nrepetition, which uses periodic review of content to improve long-term\nretention. Though spaced repetition is widely used in practice, e.g., in\nelectronic flashcard software, there is little formal understanding of the\ndesign of these systems. Our paper addresses this gap in three ways. First, we\nmine log data from spaced repetition software to establish the functional\ndependence of retention on reinforcement and delay. Second, we use this memory\nmodel to develop a stochastic model for spaced repetition systems. We propose a\nqueueing network model of the Leitner system for reviewing flashcards, along\nwith a heuristic approximation that admits a tractable optimization problem for\nreview scheduling. Finally, we empirically evaluate our queueing model through\na Mechanical Turk experiment, verifying a key qualitative prediction of our\nmodel: the existence of a sharp phase transition in learning outcomes upon\nincreasing the rate of new item introductions.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Multi-resource defensive strategies for patrolling games with alarm\n  systems",
        "authors": [
            "Nicola Basilico",
            "Giuseppe De Nittis",
            "Nicola Gatti"
        ],
        "summary": "Security Games employ game theoretical tools to derive resource allocation\nstrategies in security domains. Recent works considered the presence of alarm\nsystems, even suffering various forms of uncertainty, and showed that\ndisregarding alarm signals may lead to arbitrarily bad strategies. The central\nproblem with an alarm system, unexplored in other Security Games, is finding\nthe best strategy to respond to alarm signals for each mobile defensive\nresource. The literature provides results for the basic single-resource case,\nshowing that even in that case the problem is computationally hard. In this\npaper, we focus on the challenging problem of designing algorithms scaling with\nmultiple resources. First, we focus on finding the minimum number of resources\nassuring non-null protection to every target. Then, we deal with the\ncomputation of multi-resource strategies with different degrees of coordination\namong resources. For each considered problem, we provide a computational\nanalysis and propose algorithmic methods.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Solving finite-domain linear constraints in presence of the\n  $\\texttt{alldifferent}$",
        "authors": [
            "Milan Bankovi\u0107"
        ],
        "summary": "In this paper, we investigate the possibility of improvement of the\nwidely-used filtering algorithm for the linear constraints in constraint\nsatisfaction problems in the presence of the alldifferent constraints. In many\ncases, the fact that the variables in a linear constraint are also constrained\nby some alldifferent constraints may help us to calculate stronger bounds of\nthe variables, leading to a stronger constraint propagation. We propose an\nimproved filtering algorithm that targets such cases. We provide a detailed\ndescription of the proposed algorithm and prove its correctness. We evaluate\nthe approach on five different problems that involve combinations of the linear\nand the alldifferent constraints. We also compare our algorithm to other\nrelevant approaches. The experimental results show a great potential of the\nproposed improvement.",
        "year": 2016,
        "label": "cs.LO"
    },
    {
        "title": "Juxtaposition of System Dynamics and Agent-based Simulation for a Case\n  Study in Immunosenescence",
        "authors": [
            "Grazziela P. Figueredo",
            "Peer-Olaf Siebers",
            "Uwe Aickelin",
            "Amanda Whitbrook",
            "Jonathan M. Garibaldi"
        ],
        "summary": "Advances in healthcare and in the quality of life significantly increase\nhuman life expectancy. With the ageing of populations, new un-faced challenges\nare brought to science. The human body is naturally selected to be\nwell-functioning until the age of reproduction to keep the species alive.\nHowever, as the lifespan extends, unseen problems due to the body deterioration\nemerge. There are several age-related diseases with no appropriate treatment;\ntherefore, the complex ageing phenomena needs further understanding.\nImmunosenescence, the ageing of the immune system, is highly correlated to the\nnegative effects of ageing, such as the increase of auto-inflammatory diseases\nand decrease in responsiveness to new diseases. Besides clinical and\nmathematical tools, we believe there is opportunity to further exploit\nsimulation tools to understand immunosenescence. Compared to real-world\nexperimentation, benefits include time and cost effectiveness due to the\nlaborious, resource-intensiveness of the biological environment and the\npossibility of conducting experiments without ethic restrictions. Contrasted\nwith mathematical models, simulation modelling is more suitable for\nrepresenting complex systems and emergence. In addition, there is the belief\nthat simulation models are easier to communicate in interdisciplinary contexts.\nOur work investigates the usefulness of simulations to understand\nimmunosenescence by employing two different simulation methods, agent-based and\nsystem dynamics simulation, to a case study of immune cells depletion with age.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Semi-supervised evidential label propagation algorithm for graph data",
        "authors": [
            "Kuang Zhou",
            "Arnaud Martin",
            "Quan Pan"
        ],
        "summary": "In the task of community detection, there often exists some useful prior\ninformation. In this paper, a Semi-supervised clustering approach using a new\nEvidential Label Propagation strategy (SELP) is proposed to incorporate the\ndomain knowledge into the community detection model. The main advantage of SELP\nis that it can take limited supervised knowledge to guide the detection\nprocess. The prior information of community labels is expressed in the form of\nmass functions initially. Then a new evidential label propagation rule is\nadopted to propagate the labels from labeled data to unlabeled ones. The\noutliers can be identified to be in a special class. The experimental results\ndemonstrate the effectiveness of SELP.",
        "year": 2016,
        "label": "cs.SI"
    },
    {
        "title": "Stable Models for Infinitary Formulas with Extensional Atoms",
        "authors": [
            "Amelia Harrison",
            "Vladimir Lifschitz"
        ],
        "summary": "The definition of stable models for propositional formulas with infinite\nconjunctions and disjunctions can be used to describe the semantics of answer\nset programming languages. In this note, we enhance that definition by\nintroducing a distinction between intensional and extensional atoms. The\nsymmetric splitting theorem for first-order formulas is then extended to\ninfinitary formulas and used to reason about infinitary definitions. This note\nis under consideration for publication in Theory and Practice of Logic\nProgramming.",
        "year": 2016,
        "label": "cs.LO"
    },
    {
        "title": "A Physician Advisory System for Chronic Heart Failure Management Based\n  on Knowledge Patterns",
        "authors": [
            "Zhuo Chen",
            "Kyle Marple",
            "Elmer Salazar",
            "Gopal Gupta",
            "Lakshman Tamil"
        ],
        "summary": "Management of chronic diseases such as heart failure, diabetes, and chronic\nobstructive pulmonary disease (COPD) is a major problem in health care. A\nstandard approach that the medical community has devised to manage widely\nprevalent chronic diseases such as chronic heart failure (CHF) is to have a\ncommittee of experts develop guidelines that all physicians should follow.\nThese guidelines typically consist of a series of complex rules that make\nrecommendations based on a patient's information. Due to their complexity,\noften the guidelines are either ignored or not complied with at all, which can\nresult in poor medical practices. It is not even clear whether it is humanly\npossible to follow these guidelines due to their length and complexity. In the\ncase of CHF management, the guidelines run nearly 80 pages. In this paper we\ndescribe a physician-advisory system for CHF management that codes the entire\nset of clinical practice guidelines for CHF using answer set programming. Our\napproach is based on developing reasoning templates (that we call knowledge\npatterns) and using these patterns to systemically code the clinical guidelines\nfor CHF as ASP rules. Use of the knowledge patterns greatly facilitates the\ndevelopment of our system. Given a patient's medical information, our system\ngenerates a recommendation for treatment just as a human physician would, using\nthe guidelines. Our system will work even in the presence of incomplete\ninformation. Our work makes two contributions: (i) it shows that highly complex\nguidelines can be successfully coded as ASP rules, and (ii) it develops a\nseries of knowledge patterns that facilitate the coding of knowledge expressed\nin a natural language and that can be used for other application domains. This\npaper is under consideration for acceptance in TPLP.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "NCBO Ontology Recommender 2.0: An Enhanced Approach for Biomedical\n  Ontology Recommendation",
        "authors": [
            "Marcos Martinez-Romero",
            "Clement Jonquet",
            "Martin J. O'Connor",
            "John Graybeal",
            "Alejandro Pazos",
            "Mark A. Musen"
        ],
        "summary": "Biomedical researchers use ontologies to annotate their data with ontology\nterms, enabling better data integration and interoperability. However, the\nnumber, variety and complexity of current biomedical ontologies make it\ncumbersome for researchers to determine which ones to reuse for their specific\nneeds. To overcome this problem, in 2010 the National Center for Biomedical\nOntology (NCBO) released the Ontology Recommender, which is a service that\nreceives a biomedical text corpus or a list of keywords and suggests ontologies\nappropriate for referencing the indicated terms. We developed a new version of\nthe NCBO Ontology Recommender. Called Ontology Recommender 2.0, it uses a new\nrecommendation approach that evaluates the relevance of an ontology to\nbiomedical text data according to four criteria: (1) the extent to which the\nontology covers the input data; (2) the acceptance of the ontology in the\nbiomedical community; (3) the level of detail of the ontology classes that\ncover the input data; and (4) the specialization of the ontology to the domain\nof the input data. Our evaluation shows that the enhanced recommender provides\nhigher quality suggestions than the original approach, providing better\ncoverage of the input data, more detailed information about their concepts,\nincreased specialization for the domain of the input data, and greater\nacceptance and use in the community. In addition, it provides users with more\nexplanatory information, along with suggestions of not only individual\nontologies but also groups of ontologies. It also can be customized to fit the\nneeds of different scenarios. Ontology Recommender 2.0 combines the strengths\nof its predecessor with a range of adjustments and new features that improve\nits reliability and usefulness. Ontology Recommender 2.0 recommends over 500\nbiomedical ontologies from the NCBO BioPortal platform, where it is openly\navailable.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Team-maxmin equilibrium: efficiency bounds and algorithms",
        "authors": [
            "Nicola Basilico",
            "Andrea Celli",
            "Giuseppe De Nittis",
            "Nicola Gatti"
        ],
        "summary": "The Team-maxmin equilibrium prescribes the optimal strategies for a team of\nrational players sharing the same goal and without the capability of\ncorrelating their strategies in strategic games against an adversary. This\nsolution concept can capture situations in which an agent controls multiple\nresources-corresponding to the team members-that cannot communicate. It is\nknown that such equilibrium always exists and it is unique (unless degeneracy)\nand these properties make it a credible solution concept to be used in\nreal-world applications, especially in security scenarios. Nevertheless, to the\nbest of our knowledge, the Team-maxmin equilibrium is almost completely\nunexplored in the literature. In this paper, we investigate bounds of\n(in)efficiency of the Team-maxmin equilibrium w.r.t. the Nash equilibria and\nw.r.t. the Maxmin equilibrium when the team members can play correlated\nstrategies. Furthermore, we study a number of algorithms to find and/or\napproximate an equilibrium, discussing their theoretical guarantees and\nevaluating their performance by using a standard testbed of game instances.",
        "year": 2016,
        "label": "cs.AI"
    },
    {
        "title": "Contractibility for Open Global Constraints",
        "authors": [
            "Michael J. Maher"
        ],
        "summary": "Open forms of global constraints allow the addition of new variables to an\nargument during the execution of a constraint program. Such forms are needed\nfor difficult constraint programming problems where problem construction and\nproblem solving are interleaved, and fit naturally within constraint logic\nprogramming. However, in general, filtering that is sound for a global\nconstraint can be unsound when the constraint is open. This paper provides a\nsimple characterization, called contractibility, of the constraints where\nfiltering remains sound when the constraint is open. With this characterization\nwe can easily determine whether a constraint has this property or not. In the\nlatter case, we can use it to derive a contractible approximation to the\nconstraint. We demonstrate this work on both hard and soft constraints. In the\nprocess, we formulate two general classes of soft constraints.",
        "year": 2017,
        "label": "cs.LO"
    },
    {
        "title": "Principles and Examples of Plausible Reasoning and Propositional\n  Plausible Logic",
        "authors": [
            "David Billington"
        ],
        "summary": "Plausible reasoning concerns situations whose inherent lack of precision is\nnot quantified; that is, there are no degrees or levels of precision, and hence\nno use of numbers like probabilities. A hopefully comprehensive set of\nprinciples that clarifies what it means for a formal logic to do plausible\nreasoning is presented. A new propositional logic, called Propositional\nPlausible Logic (PPL), is defined and applied to some important examples. PPL\nis the only non-numeric non-monotonic logic we know of that satisfies all the\nprinciples and correctly reasons with all the examples. Some important results\nabout PPL are proved.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Rational Choice and Artificial Intelligence",
        "authors": [
            "Tshilidzi Marwala"
        ],
        "summary": "The theory of rational choice assumes that when people make decisions they do\nso in order to maximize their utility. In order to achieve this goal they ought\nto use all the information available and consider all the choices available to\nchoose an optimal choice. This paper investigates what happens when decisions\nare made by artificially intelligent machines in the market rather than human\nbeings. Firstly, the expectations of the future are more consistent if they are\nmade by an artificially intelligent machine and the decisions are more rational\nand thus marketplace becomes more rational.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "A multi-method simulation of a high-frequency bus line using AnyLogic",
        "authors": [
            "Thierry van der Spek"
        ],
        "summary": "In this work a mixed agent-based and discrete event simulation model is\ndeveloped for a high frequency bus route in the Netherlands. With this model,\ndifferent passenger growth scenarios can be easily evaluated. This simulation\nmodel helps policy makers to predict changes that have to be made to bus routes\nand planned travel times before problems occur. The model is validated using\nseveral performance indicators, showing that under some model assumptions, it\ncan realistically simulate real-life situations. The simulation's workings are\nillustrated by two use cases.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Governing Governance: A Formal Framework for Analysing Institutional\n  Design and Enactment Governance",
        "authors": [
            "Thomas C. King"
        ],
        "summary": "This dissertation is motivated by the need, in today's globalist world, for a\nprecise way to enable governments, organisations and other regulatory bodies to\nevaluate the constraints they place on themselves and others. An organisation's\nmodus operandi is enacting and fulfilling contracts between itself and its\nparticipants. Yet, organisational contracts should respect external laws, such\nas those setting out data privacy rights and liberties. Contracts can only be\nenacted by following contract law processes, which often require bilateral\nagreement and consideration. Governments need to legislate whilst understanding\ntoday's context of national and international governance hierarchy where law\nmakers shun isolationism and seek to influence one another. Governments should\navoid punishment by respecting constraints from international treaties and\nhuman rights charters. Governments can only enact legislation by following\ntheir own, pre-existing, law making procedures. In other words, institutions,\nsuch as laws and contracts are designed and enacted under constraints.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Modeling Events as Machines",
        "authors": [
            "Sabah Al-Fedaghi"
        ],
        "summary": "The notion of events has occupied a central role in modeling and has an\ninfluence in computer science and philosophy. Recent developments in\ndiagrammatic modeling have made it possible to examine conceptual\nrepresentation of events. This paper explores some aspects of the notion of\nevents that are produced by applying a new diagrammatic methodology with a\nfocus on the interaction of events with such concepts as time and space,\nobjects. The proposed description applies to abstract machines where events\nform the dynamic phases of a system. The results of this nontechnical research\ncan be utilized in many fields where the notion of an event is typically used\nin interdisciplinary application.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "ResumeVis: A Visual Analytics System to Discover Semantic Information in\n  Semi-structured Resume Data",
        "authors": [
            "Chen Zhang",
            "Hao Wang",
            "Yingcai Wu"
        ],
        "summary": "Massive public resume data emerging on the WWW indicates individual-related\ncharacteristics in terms of profile and career experiences. Resume Analysis\n(RA) provides opportunities for many applications, such as talent seeking and\nevaluation. Existing RA studies based on statistical analyzing have primarily\nfocused on talent recruitment by identifying explicit attributes. However, they\nfailed to discover the implicit semantic information, i.e., individual career\nprogress patterns and social-relations, which are vital to comprehensive\nunderstanding of career development. Besides, how to visualize them for better\nhuman cognition is also challenging. To tackle these issues, we propose a\nvisual analytics system ResumeVis to mine and visualize resume data. Firstly, a\ntext-mining based approach is presented to extract semantic information. Then,\na set of visualizations are devised to represent the semantic information in\nmultiple perspectives. By interactive exploration on ResumeVis performed by\ndomain experts, the following tasks can be accomplished: to trace individual\ncareer evolving trajectory; to mine latent social-relations among individuals;\nand to hold the full picture of massive resumes' collective mobility. Case\nstudies with over 2500 online officer resumes demonstrate the effectiveness of\nour system. We provide a demonstration video.",
        "year": 2017,
        "label": "cs.HC"
    },
    {
        "title": "The Boolean Solution Problem from the Perspective of Predicate Logic -\n  Extended Version",
        "authors": [
            "Christoph Wernhard"
        ],
        "summary": "Finding solution values for unknowns in Boolean equations was a principal\nreasoning mode in the Algebra of Logic of the 19th century. Schr\\\"oder\ninvestigated it as \"Aufl\\\"osungsproblem\" (\"solution problem\"). It is closely\nrelated to the modern notion of Boolean unification. Today it is commonly\npresented in an algebraic setting, but seems potentially useful also in\nknowledge representation based on predicate logic. We show that it can be\nmodeled on the basis of first-order logic extended by second-order\nquantification. A wealth of classical results transfers, foundations for\nalgorithms unfold, and connections with second-order quantifier elimination and\nCraig interpolation show up. Although for first-order inputs the set of\nsolutions is recursively enumerable, the development of constructive methods\nremains a challenge. We identify some cases that allow constructions, most of\nthem based on Craig interpolation, and show a method to take vocabulary\nrestrictions on solution components into account.",
        "year": 2017,
        "label": "cs.LO"
    },
    {
        "title": "Path Integral Networks: End-to-End Differentiable Optimal Control",
        "authors": [
            "Masashi Okada",
            "Luca Rigazio",
            "Takenobu Aoshima"
        ],
        "summary": "In this paper, we introduce Path Integral Networks (PI-Net), a recurrent\nnetwork representation of the Path Integral optimal control algorithm. The\nnetwork includes both system dynamics and cost models, used for optimal control\nbased planning. PI-Net is fully differentiable, learning both dynamics and cost\nmodels end-to-end by back-propagation and stochastic gradient descent. Because\nof this, PI-Net can learn to plan. PI-Net has several advantages: it can\ngeneralize to unseen states thanks to planning, it can be applied to continuous\ncontrol tasks, and it allows for a wide variety learning schemes, including\nimitation and reinforcement learning. Preliminary experiment results show that\nPI-Net, trained by imitation learning, can mimic control demonstrations for two\nsimulated problems; a linear system and a pendulum swing-up problem. We also\nshow that PI-Net is able to learn dynamics and cost models latent in the\ndemonstrations.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Evaluating Social Networks Using Task-Focused Network Inference",
        "authors": [
            "Ivan Brugere",
            "Chris Kanich",
            "Tanya Y. Berger-Wolf"
        ],
        "summary": "Networks are representations of complex underlying social processes. However,\nthe same given network may be more suitable to model one behavior of\nindividuals than another. In many cases, aggregate population models may be\nmore effective than modeling on the network. We present a general framework for\nevaluating the suitability of given networks for a set of predictive tasks of\ninterest, compared against alternative, networks inferred from data. We present\nseveral interpretable network models and measures for our comparison. We apply\nthis general framework to the case study on collective classification of music\npreferences in a newly available dataset of the Last.fm social network.",
        "year": 2017,
        "label": "cs.SI"
    },
    {
        "title": "Armstrong's Axioms and Navigation Strategies",
        "authors": [
            "Kaya Deuser",
            "Pavel Naumov"
        ],
        "summary": "The paper investigates navigability with imperfect information. It shows that\nthe properties of navigability with perfect recall are exactly those captured\nby Armstrong's axioms from the database theory. If the assumption of perfect\nrecall is omitted, then Armstrong's transitivity axiom is not valid, but it can\nbe replaced by two new weaker principles. The main technical results are\nsoundness and completeness theorems for the logical systems describing\nproperties of navigability with and without perfect recall.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Computing LPMLN Using ASP and MLN Solvers",
        "authors": [
            "Joohyung Lee",
            "Samidh Talsania",
            "Yi Wang"
        ],
        "summary": "LPMLN is a recent addition to probabilistic logic programming languages. Its\nmain idea is to overcome the rigid nature of the stable model semantics by\nassigning a weight to each rule in a way similar to Markov Logic is defined. We\npresent two implementations of LPMLN, $\\text{LPMLN2ASP}$ and\n$\\text{LPMLN2MLN}$. System $\\text{LPMLN2ASP}$ translates LPMLN programs into\nthe input language of answer set solver $\\text{CLINGO}$, and using weak\nconstraints and stable model enumeration, it can compute most probable stable\nmodels as well as exact conditional and marginal probabilities. System\n$\\text{LPMLN2MLN}$ translates LPMLN programs into the input language of Markov\nLogic solvers, such as $\\text{ALCHEMY}$, $\\text{TUFFY}$, and $\\text{ROCKIT}$,\nand allows for performing approximate probabilistic inference on LPMLN\nprograms. We also demonstrate the usefulness of the LPMLN systems for computing\nother languages, such as ProbLog and Pearl's Causal Models, that are shown to\nbe translatable into LPMLN. (Under consideration for acceptance in TPLP)",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Navigability with Imperfect Information",
        "authors": [
            "Kaya Deuser",
            "Pavel Naumov"
        ],
        "summary": "The article studies navigability of an autonomous agent in a maze where some\nrooms may be indistinguishable. In a previous work the authors have shown that\nthe properties of navigability in such a setting depend on whether an agent has\nperfect recall. Navigability by an agent with perfect recall is a transitive\nrelation and without is not transitive.\n  This article introduces a notion of restricted navigability and shows that a\ncertain form of transitivity holds for restricted navigability, even for an\nagent without perfect recall. The main technical result is a sound and complete\nlogical system describing the properties of restricted navigability.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "The Advantage of Evidential Attributes in Social Networks",
        "authors": [
            "Salma Ben Dhaou",
            "Kuang Zhou",
            "Mouloud Kharoune",
            "Arnaud Martin",
            "Boutheina Ben Yaghlane"
        ],
        "summary": "Nowadays, there are many approaches designed for the task of detecting\ncommunities in social networks. Among them, some methods only consider the\ntopological graph structure, while others take use of both the graph structure\nand the node attributes. In real-world networks, there are many uncertain and\nnoisy attributes in the graph. In this paper, we will present how we detect\ncommunities in graphs with uncertain attributes in the first step. The\nnumerical, probabilistic as well as evidential attributes are generated\naccording to the graph structure. In the second step, some noise will be added\nto the attributes. We perform experiments on graphs with different types of\nattributes and compare the detection results in terms of the Normalized Mutual\nInformation (NMI) values. The experimental results show that the clustering\nwith evidential attributes gives better results comparing to those with\nprobabilistic and numerical attributes. This illustrates the advantages of\nevidential attributes.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "The Static and Stochastic VRPTW with both random Customers and Reveal\n  Times: algorithms and recourse strategies",
        "authors": [
            "Michael Saint-Guillain",
            "Christine Solnon",
            "Yves Deville"
        ],
        "summary": "Unlike its deterministic counterpart, static and stochastic vehicle routing\nproblems (SS-VRP) aim at modeling and solving real-life operational problems by\nconsidering uncertainty on data. We consider the SS-VRPTW-CR introduced in\nSaint-Guillain et al. (2017). Like the SS-VRP introduced by Bertsimas (1992),\nwe search for optimal first stage routes for a fleet of vehicles to handle a\nset of stochastic customer demands, i.e., demands are uncertain and we only\nknow their probabilities. In addition to capacity constraints, customer demands\nare also constrained by time windows. Unlike all SS-VRP variants, the\nSS-VRPTW-CR does not make any assumption on the time at which a stochastic\ndemand is revealed, i.e., the reveal time is stochastic as well. To handle this\nnew problem, we introduce waiting locations: Each vehicle is assigned a\nsequence of waiting locations from which it may serve some associated demands,\nand the objective is to minimize the expected number of demands that cannot be\nsatisfied in time. In this paper, we propose two new recourse strategies for\nthe SS-VRPTW-CR, together with their closed-form expressions for efficiently\ncomputing their expectations: The first one allows us to take vehicle\ncapacities into account; The second one allows us to optimize routes by\navoiding some useless trips. We propose two algorithms for searching for routes\nwith optimal expected costs: The first one is an extended branch-and-cut\nalgorithm, based on a stochastic integer formulation, and the second one is a\nlocal search based heuristic method. We also introduce a new public benchmark\nfor the SS-VRPTW-CR, based on real-world data coming from the city of Lyon. We\nevaluate our two algorithms on this benchmark and empirically demonstrate the\nexpected superiority of the SS-VRPTW-CR anticipative actions over a basic\n\"wait-and-serve\" policy.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Network Model Selection for Task-Focused Attributed Network Inference",
        "authors": [
            "Ivan Brugere",
            "Chris Kanich",
            "Tanya Y. Berger-Wolf"
        ],
        "summary": "Networks are models representing relationships between entities. Often these\nrelationships are explicitly given, or we must learn a representation which\ngeneralizes and predicts observed behavior in underlying individual data (e.g.\nattributes or labels). Whether given or inferred, choosing the best\nrepresentation affects subsequent tasks and questions on the network. This work\nfocuses on model selection to evaluate network representations from data,\nfocusing on fundamental predictive tasks on networks. We present a modular\nmethodology using general, interpretable network models, task neighborhood\nfunctions found across domains, and several criteria for robust model\nselection. We demonstrate our methodology on three online user activity\ndatasets and show that network model selection for the appropriate network task\nvs. an alternate task increases performance by an order of magnitude in our\nexperiments.",
        "year": 2017,
        "label": "cs.SI"
    },
    {
        "title": "Navigation Objects Extraction for Better Content Structure Understanding",
        "authors": [
            "Kui Zhao",
            "Bangpeng Li",
            "Zilun Peng",
            "Jiajun Bu",
            "Can Wang"
        ],
        "summary": "Existing works for extracting navigation objects from webpages focus on\nnavigation menus, so as to reveal the information architecture of the site.\nHowever, web 2.0 sites such as social networks, e-commerce portals etc. are\nmaking the understanding of the content structure in a web site increasingly\ndifficult. Dynamic and personalized elements such as top stories, recommended\nlist in a webpage are vital to the understanding of the dynamic nature of web\n2.0 sites. To better understand the content structure in web 2.0 sites, in this\npaper we propose a new extraction method for navigation objects in a webpage.\nOur method will extract not only the static navigation menus, but also the\ndynamic and personalized page-specific navigation lists. Since the navigation\nobjects in a webpage naturally come in blocks, we first cluster hyperlinks into\ndifferent blocks by exploiting spatial locations of hyperlinks, the\nhierarchical structure of the DOM-tree and the hyperlink density. Then we\nidentify navigation objects from those blocks using the SVM classifier with\nnovel features such as anchor text lengths etc. Experiments on real-world data\nsets with webpages from various domains and styles verified the effectiveness\nof our method.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Intrusions in Marked Renewal Processes",
        "authors": [
            "David Tolpin"
        ],
        "summary": "We present a probabilistic model of an intrusion in a marked renewal process.\nGiven a process and a sequence of events, an intrusion is a subsequence of\nevents that is not produced by the process. Applications of the model are, for\nexample, online payment fraud with the fraudster taking over a user's account\nand performing payments on the user's behalf, or unexpected equipment failures\ndue to unintended use.\n  We adopt Bayesian approach to infer the probability of an intrusion in a\nsequence of events, a MAP subsequence of events constituting the intrusion, and\nthe marginal probability of each event in a sequence to belong to the\nintrusion. We evaluate the model for intrusion detection on synthetic data, as\nwell as on anonymized data from an online payment system.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Faster Fuzzing: Reinitialization with Deep Neural Models",
        "authors": [
            "Nicole Nichols",
            "Mark Raugas",
            "Robert Jasper",
            "Nathan Hilliard"
        ],
        "summary": "We improve the performance of the American Fuzzy Lop (AFL) fuzz testing\nframework by using Generative Adversarial Network (GAN) models to reinitialize\nthe system with novel seed files. We assess performance based on the temporal\nrate at which we produce novel and unseen code paths. We compare this approach\nto seed file generation from a random draw of bytes observed in the training\nseed files. The code path lengths and variations were not sufficiently diverse\nto fully replace AFL input generation. However, augmenting native AFL with\nthese additional code paths demonstrated improvements over AFL alone.\nSpecifically, experiments showed the GAN was faster and more effective than the\nLSTM and out-performed a random augmentation strategy, as measured by the\nnumber of unique code paths discovered. GAN helps AFL discover 14.23% more code\npaths than the random strategy in the same amount of CPU time, finds 6.16% more\nunique code paths, and finds paths that are on average 13.84% longer. Using GAN\nshows promise as a reinitialization strategy for AFL to help the fuzzer\nexercise deep paths in software.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "A Robust Genetic Algorithm for Learning Temporal Specifications from\n  Data",
        "authors": [
            "Simone Silvetti",
            "Laura Nenzi",
            "Luca Bortolussi",
            "Ezio Bartocci"
        ],
        "summary": "We consider the problem of mining signal temporal logical requirements from a\ndataset of regular (good) and anomalous (bad) trajectories of a dynamical\nsystem. We assume the training set to be labeled by human experts and that we\nhave access only to a limited amount of data, typically noisy. We provide a\nsystematic approach to synthesize both the syntactical structure and the\nparameters of the temporal logic formula using a two-steps procedure: first, we\nleverage a novel evolutionary algorithm for learning the structure of the\nformula, second, we perform the parameter synthesis operating on the\nstatistical emulation of the average robustness for a candidate formula w.r.t.\nits parameters. We test our algorithm on a anomalous trajectory detection\nproblem of a naval surveillance system and we compare our results with our\nprevious work~\\cite{BufoBSBLB14} and with a recently proposed\ndecision-tree~\\cite{bombara_decision_2016} based method. Our experiments\nindicate that the proposed approach outperforms our previous work w.r.t.\naccuracy and show that it produces in general smaller and more compact temporal\nlogic specifications w.r.t. the decision-tree based approach with a comparable\nspeed and accuracy.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Computational Results for Extensive-Form Adversarial Team Games",
        "authors": [
            "Andrea Celli",
            "Nicola Gatti"
        ],
        "summary": "We provide, to the best of our knowledge, the first computational study of\nextensive-form adversarial team games. These games are sequential, zero-sum\ngames in which a team of players, sharing the same utility function, faces an\nadversary. We define three different scenarios according to the communication\ncapabilities of the team. In the first, the teammates can communicate and\ncorrelate their actions both before and during the play. In the second, they\ncan only communicate before the play. In the third, no communication is\npossible at all. We define the most suitable solution concepts, and we study\nthe inefficiency caused by partial or null communication, showing that the\ninefficiency can be arbitrarily large in the size of the game tree.\nFurthermore, we study the computational complexity of the equilibrium-finding\nproblem in the three scenarios mentioned above, and we provide, for each of the\nthree scenarios, an exact algorithm. Finally, we empirically evaluate the\nscalability of the algorithms in random games and the inefficiency caused by\npartial or null communication.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Heinrich Behmann's Contributions to Second-Order Quantifier Elimination\n  from the View of Computational Logic",
        "authors": [
            "Christoph Wernhard"
        ],
        "summary": "For relational monadic formulas (the L\\\"owenheim class) second-order\nquantifier elimination, which is closely related to computation of uniform\ninterpolants, projection and forgetting - operations that currently receive\nmuch attention in knowledge processing - always succeeds. The decidability\nproof for this class by Heinrich Behmann from 1922 explicitly proceeds by\nelimination with equivalence preserving formula rewriting. Here we reconstruct\nthe results from Behmann's publication in detail and discuss related issues\nthat are relevant in the context of modern approaches to second-order\nquantifier elimination in computational logic. In addition, an extensive\ndocumentation of the letters and manuscripts in Behmann's bequest that concern\nsecond-order quantifier elimination is given, including a commented register\nand English abstracts of the German sources with focus on technical material.\nIn the late 1920s Behmann attempted to develop an elimination-based decision\nmethod for formulas with predicates whose arity is larger than one. His\nmanuscripts and the correspondence with Wilhelm Ackermann show technical\naspects that are still of interest today and give insight into the genesis of\nAckermann's landmark paper \"Untersuchungen \\\"uber das Eliminationsproblem der\nmathematischen Logik\" from 1935, which laid the foundation of the two\nprevailing modern approaches to second-order quantifier elimination.",
        "year": 2017,
        "label": "cs.LO"
    },
    {
        "title": "Improvements to Inference Compilation for Probabilistic Programming in\n  Large-Scale Scientific Simulators",
        "authors": [
            "Mario Lezcano Casado",
            "Atilim Gunes Baydin",
            "David Martinez Rubio",
            "Tuan Anh Le",
            "Frank Wood",
            "Lukas Heinrich",
            "Gilles Louppe",
            "Kyle Cranmer",
            "Karen Ng",
            "Wahid Bhimji",
            "Prabhat"
        ],
        "summary": "We consider the problem of Bayesian inference in the family of probabilistic\nmodels implicitly defined by stochastic generative models of data. In\nscientific fields ranging from population biology to cosmology, low-level\nmechanistic components are composed to create complex generative models. These\nmodels lead to intractable likelihoods and are typically non-differentiable,\nwhich poses challenges for traditional approaches to inference. We extend\nprevious work in \"inference compilation\", which combines universal\nprobabilistic programming and deep learning methods, to large-scale scientific\nsimulators, and introduce a C++ based probabilistic programming library called\nCPProb. We successfully use CPProb to interface with SHERPA, a large code-base\nused in particle physics. Here we describe the technical innovations realized\nand planned for this library.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "SenseNet: 3D Objects Database and Tactile Simulator",
        "authors": [
            "Jason Toy"
        ],
        "summary": "The majority of artificial intelligence research, as it relates from which to\nbiological senses has been focused on vision. The recent explosion of machine\nlearning and in particular, dee p learning, can be partially attributed to the\nrelease of high quality data sets for algorithm s from which to model the world\non. Thus, most of these datasets are comprised of images. We believe that\nfocusing on sensorimotor systems and tactile feedback will create algorithms\nthat better mimic human intelligence. Here we present SenseNet: a collection of\ntactile simulators and a large scale dataset of 3D objects for manipulation.\nSenseNet was created for the purpose of researching and training Artificial\nIntelligences (AIs) to interact with the environment via sensorimotor neural\nsystems and tactile feedback. We aim to accelerate that same explosion in image\nprocessing, but for the domain of tactile feedback and sensorimotor research.\nWe hope that SenseNet can offer researchers in both the machine learning and\ncomputational neuroscience communities brand new opportunities and avenues to\nexplore.",
        "year": 2017,
        "label": "cs.AI"
    },
    {
        "title": "Accounting for hidden common causes when inferring cause and effect from\n  observational data",
        "authors": [
            "David Heckerman"
        ],
        "summary": "Identifying causal relationships from observation data is difficult, in large\npart, due to the presence of hidden common causes. In some cases, where just\nthe right patterns of conditional independence and dependence lie in the\ndata---for example, Y-structures---it is possible to identify cause and effect.\nIn other cases, the analyst deliberately makes an uncertain assumption that\nhidden common causes are absent, and infers putative causal relationships to be\ntested in a randomized trial. Here, we consider a third approach, where there\nare sufficient clues in the data such that hidden common causes can be\ninferred.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "Toward Scalable Verification for Safety-Critical Deep Networks",
        "authors": [
            "Lindsey Kuper",
            "Guy Katz",
            "Justin Gottschlich",
            "Kyle Julian",
            "Clark Barrett",
            "Mykel Kochenderfer"
        ],
        "summary": "The increasing use of deep neural networks for safety-critical applications,\nsuch as autonomous driving and flight control, raises concerns about their\nsafety and reliability. Formal verification can address these concerns by\nguaranteeing that a deep learning system operates as intended, but the state of\nthe art is limited to small systems. In this work-in-progress report we give an\noverview of our work on mitigating this difficulty, by pursuing two\ncomplementary directions: devising scalable verification techniques, and\nidentifying design choices that result in deep learning systems that are more\namenable to verification.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "FlashRL: A Reinforcement Learning Platform for Flash Games",
        "authors": [
            "Per-Arne Andersen",
            "Morten Goodwin",
            "Ole-Christoffer Granmo"
        ],
        "summary": "Reinforcement Learning (RL) is a research area that has blossomed\ntremendously in recent years and has shown remarkable potential in among others\nsuccessfully playing computer games. However, there only exists a few game\nplatforms that provide diversity in tasks and state-space needed to advance RL\nalgorithms. The existing platforms offer RL access to Atari- and a few\nweb-based games, but no platform fully expose access to Flash games. This is\nunfortunate because applying RL to Flash games have potential to push the\nresearch of RL algorithms.\n  This paper introduces the Flash Reinforcement Learning platform (FlashRL)\nwhich attempts to fill this gap by providing an environment for thousands of\nFlash games on a novel platform for Flash automation. It opens up easy\nexperimentation with RL algorithms for Flash games, which has previously been\nchallenging. The platform shows excellent performance with as little as 5% CPU\nutilization on consumer hardware. It shows promising results for novel\nreinforcement learning algorithms.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "Can a Chatbot Determine My Diet?: Addressing Challenges of Chatbot\n  Application for Meal Recommendation",
        "authors": [
            "Ahmed Fadhil"
        ],
        "summary": "Poor nutrition can lead to reduced immunity, increased susceptibility to\ndisease, impaired physical and mental development, and reduced productivity. A\nconversational agent can support people as a virtual coach, however building\nsuch systems still have its associated challenges and limitations. This paper\ndescribes the background and motivation for chatbot systems in the context of\nhealthy nutrition recommendation. We discuss current challenges associated with\nchatbot application, we tackled technical, theoretical, behavioural, and social\naspects of the challenges. We then propose a pipeline to be used as guidelines\nby developers to implement theoretically and technically robust chatbot\nsystems.",
        "year": 2018,
        "label": "cs.AI"
    },
    {
        "title": "DNA Reservoir Computing: A Novel Molecular Computing Approach",
        "authors": [
            "Alireza Goudarzi",
            "Matthew R. Lakin",
            "Darko Stefanovic"
        ],
        "summary": "We propose a novel molecular computing approach based on reservoir computing.\nIn reservoir computing, a dynamical core, called a reservoir, is perturbed with\nan external input signal while a readout layer maps the reservoir dynamics to a\ntarget output. Computation takes place as a transformation from the input space\nto a high-dimensional spatiotemporal feature space created by the transient\ndynamics of the reservoir. The readout layer then combines these features to\nproduce the target output. We show that coupled deoxyribozyme oscillators can\nact as the reservoir. We show that despite using only three coupled\noscillators, a molecular reservoir computer could achieve 90% accuracy on a\nbenchmark temporal problem.",
        "year": 2013,
        "label": "cs.NE"
    },
    {
        "title": "A hybrid neuro--wavelet predictor for QoS control and stability",
        "authors": [
            "Christian Napoli",
            "Giuseppe Pappalardo",
            "Emiliano Tramontana"
        ],
        "summary": "For distributed systems to properly react to peaks of requests, their\nadaptation activities would benefit from the estimation of the amount of\nrequests. This paper proposes a solution to produce a short-term forecast based\non data characterising user behaviour of online services. We use \\emph{wavelet\nanalysis}, providing compression and denoising on the observed time series of\nthe amount of past user requests; and a \\emph{recurrent neural network} trained\nwith observed data and designed so as to provide well-timed estimations of\nfuture requests. The said ensemble has the ability to predict the amount of\nfuture user requests with a root mean squared error below 0.06\\%. Thanks to\nprediction, advance resource provision can be performed for the duration of a\nrequest peak and for just the right amount of resources, hence avoiding\nover-provisioning and associated costs. Moreover, reliable provision lets users\nenjoy a level of availability of services unaffected by load variations.",
        "year": 2014,
        "label": "cs.NE"
    },
    {
        "title": "Online EM Algorithm for Hidden Markov Models",
        "authors": [
            "Olivier Capp\u00e9"
        ],
        "summary": "Online (also called \"recursive\" or \"adaptive\") estimation of fixed model\nparameters in hidden Markov models is a topic of much interest in times series\nmodelling. In this work, we propose an online parameter estimation algorithm\nthat combines two key ideas. The first one, which is deeply rooted in the\nExpectation-Maximization (EM) methodology consists in reparameterizing the\nproblem using complete-data sufficient statistics. The second ingredient\nconsists in exploiting a purely recursive form of smoothing in HMMs based on an\nauxiliary recursion. Although the proposed online EM algorithm resembles a\nclassical stochastic approximation (or Robbins-Monro) algorithm, it is\nsufficiently different to resist conventional analysis of convergence. We thus\nprovide limited results which identify the potential limiting points of the\nrecursion as well as the large-sample behavior of the quantities involved in\nthe algorithm. The performance of the proposed algorithm is numerically\nevaluated through simulations in the case of a noisily observed Markov chain.\nIn this case, the algorithm reaches estimation results that are comparable to\nthat of the maximum likelihood estimator for large sample sizes.",
        "year": 2009,
        "label": "stat.CO"
    },
    {
        "title": "Entropy-based closure for probabilistic learning on manifolds",
        "authors": [
            "C. Soizea",
            "R. Ghanem",
            "C. Safta",
            "X. Huan",
            "Z. P. Vane",
            "J. Oefelein",
            "G. Lacaz",
            "H. N. Najm",
            "Q. Tang",
            "X. Chen"
        ],
        "summary": "In a recent paper, the authors proposed a general methodology for\nprobabilistic learning on manifolds. The method was used to generate numerical\nsamples that are statistically consistent with an existing dataset construed as\na realization from a non-Gaussian random vector. The manifold structure is\nlearned using diffusion manifolds and the statistical sample generation is\naccomplished using a projected Ito stochastic differential equation. This\nprobabilistic learning approach has been extended to polynomial chaos\nrepresentation of databases on manifolds and to probabilistic nonconvex\nconstrained optimization with a fixed budget of function evaluations. The\nmethodology introduces an isotropic-diffusion kernel with hyperparameter\n{\\epsilon}. Currently, {\\epsilon} is more or less arbitrarily chosen. In this\npaper, we propose a selection criterion for identifying an optimal value of\n{\\epsilon}, based on a maximum entropy argument. The result is a comprehensive,\nclosed, probabilistic model for characterizing data sets with hidden\nconstraints. This entropy argument ensures that out of all possible models,\nthis is the one that is the most uncertain beyond any specified constraints,\nwhich is selected. Applications are presented for several databases.",
        "year": 2018,
        "label": "math.PR"
    },
    {
        "title": "Toward a statistical mechanics of four letter words",
        "authors": [
            "Greg J. Stephens",
            "William Bialek"
        ],
        "summary": "We consider words as a network of interacting letters, and approximate the\nprobability distribution of states taken on by this network. Despite the\nintuition that the rules of English spelling are highly combinatorial (and\narbitrary), we find that maximum entropy models consistent with pairwise\ncorrelations among letters provide a surprisingly good approximation to the\nfull statistics of four letter words, capturing ~92% of the multi-information\namong letters and even \"discovering\" real words that were not represented in\nthe data from which the pairwise correlations were estimated. The maximum\nentropy model defines an energy landscape on the space of possible words, and\nlocal minima in this landscape account for nearly two-thirds of words used in\nwritten English.",
        "year": 2007,
        "label": "q-bio.NC"
    },
    {
        "title": "A meta-analysis of state-of-the-art electoral prediction from Twitter\n  data",
        "authors": [
            "Daniel Gayo-Avello"
        ],
        "summary": "Electoral prediction from Twitter data is an appealing research topic. It\nseems relatively straightforward and the prevailing view is overly optimistic.\nThis is problematic because while simple approaches are assumed to be good\nenough, core problems are not addressed. Thus, this paper aims to (1) provide a\nbalanced and critical review of the state of the art; (2) cast light on the\npresume predictive power of Twitter data; and (3) depict a roadmap to push\nforward the field. Hence, a scheme to characterize Twitter prediction methods\nis proposed. It covers every aspect from data collection to performance\nevaluation, through data processing and vote inference. Using that scheme,\nprior research is analyzed and organized to explain the main approaches taken\nup to date but also their weaknesses. This is the first meta-analysis of the\nwhole body of research regarding electoral prediction from Twitter data. It\nreveals that its presumed predictive power regarding electoral prediction has\nbeen rather exaggerated: although social media may provide a glimpse on\nelectoral outcomes current research does not provide strong evidence to support\nit can replace traditional polls. Finally, future lines of research along with\na set of requirements they must fulfill are provided.",
        "year": 2012,
        "label": "cs.SI"
    },
    {
        "title": "A polynomial time algorithm for the Lambek calculus with brackets of\n  bounded order",
        "authors": [
            "Max Kanovich",
            "Stepan Kuznetsov",
            "Glyn Morrill",
            "Andre Scedrov"
        ],
        "summary": "Lambek calculus is a logical foundation of categorial grammar, a linguistic\nparadigm of grammar as logic and parsing as deduction. Pentus (2010) gave a\npolynomial-time algorithm for determ- ining provability of bounded depth\nformulas in the Lambek calculus with empty antecedents allowed. Pentus'\nalgorithm is based on tabularisation of proof nets. Lambek calculus with\nbrackets is a conservative extension of Lambek calculus with bracket\nmodalities, suitable for the modeling of syntactical domains. In this paper we\ngive an algorithm for provability the Lambek calculus with brackets allowing\nempty antecedents. Our algorithm runs in polynomial time when both the formula\ndepth and the bracket nesting depth are bounded. It combines a Pentus-style\ntabularisation of proof nets with an automata-theoretic treatment of\nbracketing.",
        "year": 2017,
        "label": "cs.LO"
    },
    {
        "title": "Community Interaction and Conflict on the Web",
        "authors": [
            "Srijan Kumar",
            "William L. Hamilton",
            "Jure Leskovec",
            "Dan Jurafsky"
        ],
        "summary": "Users organize themselves into communities on web platforms. These\ncommunities can interact with one another, often leading to conflicts and toxic\ninteractions. However, little is known about the mechanisms of interactions\nbetween communities and how they impact users.\n  Here we study intercommunity interactions across 36,000 communities on\nReddit, examining cases where users of one community are mobilized by negative\nsentiment to comment in another community. We show that such conflicts tend to\nbe initiated by a handful of communities---less than 1% of communities start\n74% of conflicts. While conflicts tend to be initiated by highly active\ncommunity members, they are carried out by significantly less active members.\nWe find that conflicts are marked by formation of echo chambers, where users\nprimarily talk to other users from their own community. In the long-term,\nconflicts have adverse effects and reduce the overall activity of users in the\ntargeted communities.\n  Our analysis of user interactions also suggests strategies for mitigating the\nnegative impact of conflicts---such as increasing direct engagement between\nattackers and defenders. Further, we accurately predict whether a conflict will\noccur by creating a novel LSTM model that combines graph embeddings, user,\ncommunity, and text features. This model can be used toreate early-warning\nsystems for community moderators to prevent conflicts. Altogether, this work\npresents a data-driven view of community interactions and conflict, and paves\nthe way towards healthier online communities.",
        "year": 2018,
        "label": "cs.SI"
    },
    {
        "title": "Photon counting compressive depth mapping",
        "authors": [
            "Gregory A. Howland",
            "Daniel J. Lum",
            "Matthew R. Ware",
            "John C. Howell"
        ],
        "summary": "We demonstrate a compressed sensing, photon counting lidar system based on\nthe single-pixel camera. Our technique recovers both depth and intensity maps\nfrom a single under-sampled set of incoherent, linear projections of a scene of\ninterest at ultra-low light levels around 0.5 picowatts. Only two-dimensional\nreconstructions are required to image a three-dimensional scene. We demonstrate\nintensity imaging and depth mapping at 256 x 256 pixel transverse resolution\nwith acquisition times as short as 3 seconds. We also show novelty filtering,\nreconstructing only the difference between two instances of a scene. Finally,\nwe acquire 32 x 32 pixel real-time video for three-dimensional object tracking\nat 14 frames-per-second.",
        "year": 2013,
        "label": "physics.optics"
    },
    {
        "title": "A Cooperative Q-learning Approach for Real-time Power Allocation in\n  Femtocell Networks",
        "authors": [
            "Hussein Saad",
            "Amr Mohamed",
            "Tamer ElBatt"
        ],
        "summary": "In this paper, we address the problem of distributed interference management\nof cognitive femtocells that share the same frequency range with macrocells\n(primary user) using distributed multi-agent Q-learning. We formulate and solve\nthree problems representing three different Q-learning algorithms: namely,\ncentralized, distributed and partially distributed power control using\nQ-learning (CPC-Q, DPC-Q and PDPC-Q). CPCQ, although not of practical interest,\ncharacterizes the global optimum. Each of DPC-Q and PDPC-Q works in two\ndifferent learning paradigms: Independent (IL) and Cooperative (CL). The former\nis considered the simplest form for applying Qlearning in multi-agent\nscenarios, where all the femtocells learn independently. The latter is the\nproposed scheme in which femtocells share partial information during the\nlearning process in order to strike a balance between practical relevance and\nperformance. In terms of performance, the simulation results showed that the CL\nparadigm outperforms the IL paradigm and achieves an aggregate femtocells\ncapacity that is very close to the optimal one. For the practical relevance\nissue, we evaluate the robustness and scalability of DPC-Q, in real time, by\ndeploying new femtocells in the system during the learning process, where we\nshowed that DPC-Q in the CL paradigm is scalable to large number of femtocells\nand more robust to the network dynamics compared to the IL paradigm",
        "year": 2013,
        "label": "cs.MA"
    },
    {
        "title": "On Analyzing Estimation Errors due to Constrained Connections in Online\n  Review Systems",
        "authors": [
            "Junzhou Zhao"
        ],
        "summary": "Constrained connection is the phenomenon that a reviewer can only review a\nsubset of products/services due to narrow range of interests or limited\nattention capacity. In this work, we study how constrained connections can\naffect estimation performance in online review systems (ORS). We find that\nreviewers' constrained connections will cause poor estimation performance, both\nfrom the measurements of estimation accuracy and Bayesian Cramer Rao lower\nbound.",
        "year": 2013,
        "label": "cs.SI"
    }
]